var relearn_search_index = [
  {
    "breadcrumb": "",
    "content": "官方文档 Relearn ",
    "description": "官方文档 Relearn ",
    "tags": [],
    "title": "Basics",
    "uri": "/basics/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Ansible",
    "uri": "/systems/linux/ansible/"
  },
  {
    "breadcrumb": "Systems",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Activation Key",
    "uri": "/systems/activation_key/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Backend",
    "uri": "/systems/linux/backend/"
  },
  {
    "breadcrumb": "Systems",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Black MacOs",
    "uri": "/systems/black-macos/"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Languges",
    "uri": "/language/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "CDN",
    "uri": "/systems/linux/cdn/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Codes",
    "uri": "/systems/linux/codes/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Crontab",
    "uri": "/systems/linux/crontab/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Daemon",
    "uri": "/systems/linux/daemon/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Databases",
    "uri": "/systems/linux/databases/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Email",
    "uri": "/systems/linux/email/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Firewalld",
    "uri": "/systems/linux/firewalld/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Gitlab",
    "uri": "/systems/linux/gitlab/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "HAProxy",
    "uri": "/systems/linux/haproxy/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Install_System",
    "uri": "/systems/linux/install_system/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "JDK",
    "uri": "/systems/linux/jdk/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Jenkins",
    "uri": "/systems/linux/jenkins/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "JumpServer",
    "uri": "/systems/linux/jumpserver/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Keepalived",
    "uri": "/systems/linux/keepalived/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Kubernetes",
    "uri": "/systems/linux/kubernetes/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "LDAP",
    "uri": "/systems/linux/ldap/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Logs",
    "uri": "/systems/linux/logs/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Message_Queue",
    "uri": "/systems/linux/message_queue/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Monitor",
    "uri": "/systems/linux/monitor/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Nosql",
    "uri": "/systems/linux/nosql/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Rsyncd",
    "uri": "/systems/linux/rsyncd/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Script",
    "uri": "/systems/linux/script/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Storage",
    "uri": "/systems/linux/storage/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Service_Management",
    "uri": "/systems/linux/service_management/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Web",
    "uri": "/systems/linux/web/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Work_Order",
    "uri": "/systems/linux/work_order/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "ClickHouse部署 ClickHouse ",
    "description": "ClickHouse部署 ClickHouse ",
    "tags": [],
    "title": "Install_ClickHouse",
    "uri": "/systems/linux/databases/install_clickhouse/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Service_Management",
    "content": "Apollo部署 Apollo ",
    "description": "Apollo部署 Apollo ",
    "tags": [],
    "title": "Install_Apollo",
    "uri": "/systems/linux/service_management/install_apollo/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Docker",
    "content": "使用Docker Docker命令 现有启动中容器打包成镜像 $ docker commit f61b39f3bb7e flanneld:$(date \"+%Y%m%d%H%M%S\") 构建镜像 $ docker build -t container_name/nginx:$(date +%Y%m%d%H%M) --rm . 打标签 # 查看 tag 使用帮助 $ docker tag -h $ docker tag nginx:v1 container_name/nginx:`date +%Y%m%d%H%M` 推送到远程仓库 $ docker push container_name/nginx:tagname # 推送到自建harbor $ docker tag SOURCE_IMAGE[:TAG] 192.168.35.128:9527/test/IMAGE[:TAG] # 推送镜像到当前项目 $ docker push 192.168.35.128:9527/test/IMAGE[:TAG] 启动停止命令 $ docker-compose -f /opt/docker-compose.yml down \u003e\u003e $log 2\u003e\u00261 $ docker-compose -f /opt/docker-compose.yml up -d \u003e\u003e $log 2\u003e\u00261 Dockerfile文件 d FROM nginx # 构建镜像基于哪个镜像 MAINTAINER：镜像维护者姓名或邮箱地址 RUN yum -y install wget \\ \u0026\u0026 wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\ \u0026\u0026 tar -xvf redis.tar.gz # 是在 docker build。构建镜像执行的命令，每一次RUN都会构建一层 CMD [\"/etc/nginx/nginx.conf\"] # 变参，运行容器时执行的shell环境，如果有多个则以最后一个为准，也可以为ENTRYPOINT提供参数 VOLUME：指定容器挂载点到宿主机自动生成的目录或其他容器，如果没有定义则使用默认 USER \u003c用户名\u003e[:\u003c用户组\u003e] # 为RUN、CMD、和 ENTRYPOINT 执行命令指定运行用户和如果没有定义则使用默认 WORKDIR \u003c工作目录路径\u003e # 为 RUN、CMD、ENTRYPOINT、COPY 和 ADD 设置工作目录，就是切换目录 HEALTHCHECH：健康检查 ARG：变量属性值，不在容器内部起作用，只有 docker build 的过程中有效 EXPOSE 80 443 # 声明容器的服务端口（仅仅是声明），使用端口需要做映射 ENV：设置容器环境变量 ADD：拷贝文件或目录到容器中，如果是URL或压缩包便会自动下载或自动解压 COPY hom?.txt /opt/data/ # 拷贝文件或目录到容器中，跟ADD类似，但不具备自动下载或解压的功能 ENTRYPOINT [\"nginx\", \"-c\"] # 定参，运行容器时执行的shell命令，如果存在多个 ENTRYPOINT 指令，仅最后一个生效 docker-compose文件 docker-compose-test.yml version: \"3\" # docker-compose版本 services: # 定义container mysql: # container名称-相当于--name web container_name: mysql # 启动后名称 network_mode: bridge image: mysql:8 # image来源 environment: - MYSQL_ROOT_PASSWORD: \"root\" # 设置root账号密码 - MYSQL_USER: \"user_name\" - MYSQL_PASSWORD: \"password\" - MYSQL_DATABASE: \"databases_name\" - MYSQL_ALLOW_EMPTY_PASSWORD: \"true\" - TZ: Asia/Shanghai # 指定东八时区 restart: always user: \"1001:1001\" # 启动后容器中用户id和组id，也可以指定用户名和组名 ulimits: memlock: soft: -1 hard: -1 volumes: # 设置持久化映射关系， - ../data/mysql:/var/lib/mysql - ../conf/mysql/conf.d:/etc/mysql/conf.d - ../conf/mysql/my.cnf:/etc/mysql/my.cnf - \"/etc/localtime:/etc/localtime:ro\" ports: # 指定端口映射 - \"3306:3306\" # 端口映射关系 和ports一起相当于-p 9001:9989 networks: # 指定network-相当于--network springboot - overlay springboot: ipv4_address: 172.20.0.6 # 指定容器ip地址-相当于--ip 172.20.0.6 command: - \"--lower_case_table_names=1\" # - \"--init-connect='SET NAMES UTF8MB4;'\" - \"--character-set-server=utf8mb4\" - \"--collation-server=utf8mb4_unicode_ci\" ##### 第二个容器es参数配置 ##### es: # container名称-相当于--name es image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: es environment: - discovery.type=single-node - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" restart: always ulimits: memlock: soft: -1 hard: -1 volumes: - \"../data/es:/usr/share/elasticsearch/data\" - \"/etc/localtime:/etc/localtime:ro\" - \"../conf/es/ik:/usr/share/elasticsearch/plugins/ik\" ports: - 9100:9100 - 9200:9200 # 前面为宿主机映射端口，后面为容器内端口 networks: - overlay rabbit: container_name: rabbit image: rabbitmq:3-management environment: RABBITMQ_DEFAULT_USER: \"user_name\" RABBITMQ_DEFAULT_PASS: \"password\" RABBITMQ_DEFAULT_VHOST: \"develop\" restart: always ports: - \"5672:5672\" - \"15672:15672\" volumes: - \"/etc/localtime:/etc/localtime:ro\" networks: - overlay ##### 第三个容器redis参数配置 ##### redis: container_name: redis image: redis:6 restart: always ports: - \"6379:6379\" command: \"redis-server --requirepass password\" volumes: - \"/etc/localtime:/etc/localtime:ro\" networks: - overlay ports: - \"7474:7474\" - \"7687:7687\" networks: - overlay ##### 第四个容器参数配置 ##### javaapp: container_name : javaapp image : javaapp build: context: ./ dockerfile: ./javaapp restart: always volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"/tmp/logs:/opt/logs\" - \"../service/javaapp-0.0.1-SNAPSHOT.jar:/javaapp-0.0.1-SNAPSHOT.jar\" environment: LOCAL_TEST: \"true\" MYSQL_URL: \"jdbc:mysql://mysql:3306/gcgdata?characterEncoding=utf-8\u0026useSSL=true\u0026serverTimezone=GMT\" MYSQL_USER: \"user_name\" MYSQL_PASSWD: \"password\" REDIS_HOST: \"redis\" REDIS_PORT: \"6379\" REDIS_PASSWD: \"password\" RABBITMQ_HOST: \"rabbit\" RABBITMQ_PORT: \"5672\" RABBITMQ_USER: \"user_name\" RABBITMQ_PASSWD: \"password\" RABBITMQ_VHOST: \"develop\" RABBITMQ_SSL_ENABLED: \"false\" ES_SCHEME: \"http\" ES_HOSTS: \"es:9200\" ES_USER: \"\" ES_PASSWD: \"\" XXXAPP_USER_DEFAULTAVATAR: \"https://oss.domain.com/xxx/default/icon_user_default.png\" XXXAPP_USER_NICKNAMEPREFIX: \"xxx_\" XXXAPP_URL_PREFIX: \"http://domain.com/appApi\" XXXAPP_SHARE_URL: '{scheme}://domain.com/{inviteCode}' XXXAPP_DOWNLOAD_URL_IOS_STORE: \"http://fir.domain.com/downapple?randStr=3psgechs0g\" CN_MSG_URL: 'http://IP:8000' DEFAUTL_SMS_URL: \"http://IP:80001\" DEFAULT_SMS_CONTENT: '' XXX_DOMAINS: \"http://domain.com,http://domain.vip\" XXX_API_DOMAINS: \"http://domain.com,http://domain.vip\" FORBID_MOBILE: \"165,171,172,1700,1701,1702,162,1703,1705,1706,1704,1707,1708,1709,167\" DATA_CENTER_ID: \"1\" XXX_SHARE_DOMAINS: \"domain.vip\" QINIU_AK: \"gXAT245FwtyTFqutHpouoc7oKg8tsfOUaawjTkqe\" QINIU_KK: \"YCMdEVi2cdZPqKm6N5dHv8H6UNdGAtDJ2OQBwI9G\" QINIU_BUCKET: \"ossprod\" depends_on: - mysql - es - rabbit - redis networks: - overlay ##### 第五个容器参数配置 ##### nginx: container_name: nginx image: nginx restart: always volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"../conf/nginx/nginx.conf:/etc/nginx/nginx.conf\" - \"../conf/nginx/mime.types:/etc/nginx/mime.types\" - \"../conf/nginx/conf.d:/etc/nginx/conf.d\" - \"../html:/usr/share/nginx/html\" ports: - \"80:80\" # depends_on: networks: - overlay networks: overlay: networks: # 定义network-相当于 docker network create --subnet=172.20.0.0/24 springboot 该命令创建的network默认也是桥接模式 springboot: # network名称 driver: bridge # 定义network类型为桥接模式 ipam: driver: default config: - subnet: 172.20.0.0/24 # 指定网段信息 ",
    "description": "使用Docker Docker命令 现有启动中容器打包成镜像 $ docker commit f61b39f3bb7e flanneld:$(date \"+%Y%m%d%H%M%S\") 构建镜像 $ docker build -t container_name/nginx:$(date +%Y%m%d%H%M) --rm .",
    "tags": [],
    "title": "Use_Docker",
    "uri": "/systems/linux/docker/use_docker/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Docker",
    "content": "Docker部署 Debian部署Docker 卸载所有冲突的包 $ for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done 设置Docker的apt存储库 # 添加Docker的官方GPG密钥 $ sudo apt-get update $ sudo apt-get install ca-certificates curl $ sudo install -m 0755 -d /etc/apt/keyrings $ sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc $ sudo chmod a+r /etc/apt/keyrings/docker.asc # 将存储库添加到 Apt 源 $ echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\ $(. /etc/os-release \u0026\u0026 echo \"$VERSION_CODENAME\") stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null $ sudo apt-get update 按照Docker # 安装最新版本 $ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # 列出可用的版本 $ apt-cache madison docker-ce | awk '{ print $3 }' 5:26.1.0-1~debian.12~bookworm 5:26.0.2-1~debian.12~bookworm $ VERSION_STRING=5:26.1.0-1~debian.12~bookworm $ sudo apt-get install docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-buildx-plugin docker-compose-plugin 启动 $ sudo systemctl enable docker \u0026\u0026 sudo systemctl start docker 配置普通用户加入Docker组 $ sudo usermod -aG docker user_name 配置docker-compose $ ln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/bin/docker-compose CentOS部署Docker 卸载旧版本 $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 使用rpm存储库安装 $ sudo yum install -y yum-utils $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装Docker Engine # 安装最新版本 $ sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # 安装特定版本 $ yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 3:26.1.3-1.el9 docker-ce-stable docker-ce.x86_64 3:26.1.2-1.el9 docker-ce-stable $ sudo yum install docker-ce-\u003cVERSION_STRING\u003e docker-ce-cli-\u003cVERSION_STRING\u003e containerd.io docker-buildx-plugin docker-compose-plugin 启动 $ $ sudo systemctl enable docker \u0026\u0026 sudo systemctl start docker ",
    "description": "Docker部署 Debian部署Docker 卸载所有冲突的包 $ for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done 设置Docker的apt存储库 # 添加Docker的官方GPG密钥 $ sudo apt-get update $ sudo apt-get install ca-certificates curl $ sudo install -m 0755 -d /etc/apt/keyrings $ sudo curl -fsSL https://download.",
    "tags": [],
    "title": "Install_Docker",
    "uri": "/systems/linux/docker/install_docker/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Docker",
    "uri": "/systems/linux/docker/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "资源控制器 graph LR A[思维导图] --\u003eB[1.前言] A[思维导图] --\u003eC[2.Namespace] A[思维导图] --\u003eD[3.Deployment] A[思维导图] --\u003eE[4.StatefulSet] A[思维导图] --\u003eF[5.DaemonSet] A[思维导图] --\u003eG[6.HorizontalPodAutoscaler] A[思维导图] --\u003eH[7.EndPoint] A[思维导图] --\u003eI[8.Service] A[思维导图] --\u003eJ[9.Label标签/Selector选择器] C[2.Namespace] --\u003e|a=1|C1[2.1概述] C[2.Namespace] --\u003e|a=2|C2[2.2应用示例] D[3.Deployment] --\u003e|a=1|D1[3.1概述] D[3.Deployment] --\u003e|a=2|D2[3.2语法以及应用示例] E[4.StatefulSet] --\u003e|a=1|E1[4.1概述] E[4.StatefulSet] --\u003e|a=2|E2[4.2语法以及应用示例] F[5.DaemonSet] --\u003e|a=1|F1[5.1概述] F[5.DaemonSet] --\u003e|a=2|F2[5.2语法以及应用示例] G[6.HorizontalPodAutoscaler] --\u003e|a=1|G1[6.1概述] G[6.HorizontalPodAutoscaler] --\u003e|a=2|G2[6.2语法以及应用] H[7.EndPoint] --\u003e|a=1|H1[7.1概述] H[7.EndPoint] --\u003e|a=2|H2[7.2语法以及应用] I[8.Service] --\u003e|a=1|I1[8.1概述] I[8.Service] --\u003e|a=2|I2[8.2语法以及应用] J[9.Label标签/Selector选择器] --\u003e|a=1|J1[9.1概述] J[9.Label标签/Selector选择器] --\u003e|a=2|J2[9.2语法以及应用] Z[横向流程图] graph TD A[Deployment] --\u003e D[ReplicaSet] B[CronJob] --\u003e E[Job] C[DaemonSet] --\u003e G{{容器}} D[ReplicaSet] --\u003e G{{容器}} E[Job] --\u003e G{{容器}} F[StatefulSet] --\u003e G{{容器}} G{{容器}} --\u003e J[/Volume\\] G{{容器}} --\u003e H(Service服务) J[/Volume\\] --\u003e K[/configMap\\] J[/Volume\\] --\u003e L[/PVC\\] J[/Volume\\] --\u003e M[/Secret\\] Z[Kubernetes控制流程] 标签选择器 graph LR A[Deployment\u003cbr\u003eseletor:env=dev] -.- C[Label\u003cbr\u003e] B{Service\u003cbr\u003eseletor:env=dev} --- C[Label\u003cbr\u003e] C[Label\u003cbr\u003e] --- C1((Pod\u003cbr\u003elabe:env=dev)) C[Label\u003cbr\u003e] --- C2((Pod\u003cbr\u003elabe:env=dev)) C[Label\u003cbr\u003e] --- C3((Pod\u003cbr\u003elabe:env=dev)) Z[Service] graph TD A[user containerN\u003cbr\u003euser ImageN\u003cbr\u003euser container1\u003cbr\u003euser Image1\u003cbr\u003ePause\u003cbr\u003egcr.io/google_containers/pause-amd64\u003cbr\u003e] Z[Pod] 资源名称 kubectl api-resources -o wide：获取参数定义命令 Name(名称) ShortNames(简写) apiVersion(API版本) NameSpaced(命名空间) kind(类型) Verbs(可执行操作命令) configmaps cm v1 true ConfigMap create、delete、deletecollection、get、list、patch、update、watch events ev v1 true Event create、delete、deletecollection、get、list、patch、update、watch limitranges limits v1 true LimitRange create、delete、deletecollection、get、list、patch、update、watch pods po v1 true Pod create、delete、deletecollection、get、list、patch、update、watch serviceaccounts sa v1 true ServiceAccount create、delete、deletecollection、get、list、patch、update、watch services svc v1 true Service create、delete、deletecollection、get、list、patch、update、watch daemonsets ds apps/v1 true DaemonSet create、delete、deletecollection、get、list、patch、update、watch deployments deploy apps/v1 true Deployment create、delete、deletecollection、get、list、patch、update、watch replicasets rs apps/v1 true ReplicaSet create、delete、deletecollection、get、list、patch、update、watch statefulsets sts apps/v1 true StatefulSet create、delete、deletecollection、get、list、patch、update、watch horizontalpodautoscalers hpa autoscaling/v2 true HorizontalPodAutoscaler create,delete,deletecollection,get,list,patch,update,watch all cronjobs cj batch/v1 true CronJob create、delete、deletecollection、get、list、patch、update、watch jobs batch/v1 true Job create、delete、deletecollection、get、list、patch、update、watch events ev events.k8s.io/v1 true Event create、delete、deletecollection、get、list、patch、update、watch ingresses ing networking.k8s.io/v1 true Ingress create、delete、deletecollection、get、list、patch、update、watch networkpolicies netpol networking.k8s.io/v1 true NetworkPolicy create、delete、deletecollection、get、list、patch、update、watch poddisruptionbudgets pdb policy/v1 true PodDisruptionBudget create、delete、deletecollection、get、list、patch、update、watch 资源控制器作用 资源分类 资源名称 缩写 资源作用 Pod资源控制器 replicasets rs 保证指定数量的Pod运行，并支持Pod数量变更，镜像版本变更 — deployments deploy 通过控制ReplicaSet来控制Pod，并支持滚动升级、版本回退 — daemonsets ds 在集群中的指定Node上都运行一个副本，一般用于日志采集、监控、守护进程类的任务。 — jobs — 它创建出来的Pod只要完成任务就立即退出，用于执行一次性任务 — cronjobs cj 它创建的Pod会周期性的执行，用于执行周期性的任务 — horizontalpodautoscalers hpa 可以根据集群负载自动调整Pod的数量，实现削峰填谷 Pod资源控制器 statefulsets sts 管理有状态的应用。 资源控制器字段类型作用 使用explain选项获取字段使用方式 $ kubectl explain deployment.metadata # 获取 deployment的metadata使用方式， 还可以获取：spec、kind $ kubectl explain deployment.spec.selector # 获取yaml基础格式命令 资源控制器必选字段 参数名 字段类型 说明 version String Kubernetes API 的版本，可以用kubectl api-versions命令查询 kind String 标明YAML定义的资源类型和角色，如Pod、Deployment等 metadata String 元数据对象 metadata.name String 元数据对象的名字，可自定义，比如命名Pod的名字 spec Object 详细定义对象 spec.containers[] List 容器列表定义 spec.containers[].name String 定义容器的名字 spec.containers[].image String 定义容器使用的镜像 metadata字段选择 参数名称 字段类型 说明 metadata.name Pod名称 metadata.uid Pod的UID metadata.namespace Pod名字空间 metadata.labels['\u003cKEY\u003e'] Pod标签 \u003cKEY\u003e 的值 (例如metadata.labels['mylabel']） metadata.annotations['\u003cKEY\u003e'] Pod的注解 \u003cKEY\u003e 的值（例如, metadata.annotations['myannotation']） spec.containers字段定义 参数名称 字段类型 说明 spec.containers[].name String 定义容器的名字。 spec.containers[].image String 定义容器使用的镜像。 spec.containers[].imagePullSecrets 要从私有仓库拉取镜像，Kubernetes需要凭证。 配置文件中的 imagePullSecrets字段表明Kubernetes应该通过名为 regcred 的 Secret 获取凭证 spec.containers[].imagePullPolicy S 定镜像拉取有3个值可选: Always：总是从远程仓库拉取镜像、IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像。如上面 3个值都没设置，默认是AlwaysNever：仅使用本地镜像，本地没有就报错 spec.containers[].command[] List 指定容器启动命令，因为是数组形式，所以可以指定多个启动命令，不指定则使用镜像打包时的启动命令。 spec.containers[].args[] List 指定容器启动命令参数，因为是数组形式，所以可以指定多个参数。 spec: # 必选，Pod中容器的详细定义 imagePullSecrets: # 配置登录 docker registry 的 secret 仓库 - name: docker-harbor # 指定使用的secret库房名称 containers: # 必选，Pod中容器列表，一个Pod中可以定义多个容器 - name: tomcat-demo # 指定容器名称，不可更新 image: 192.168.80.210:8080/test/tomcat-demo:v1 # 镜像仓库地址 imagePullPolicy: Always # 容器下载策略：Always|Never|IfNotPresent，不管本地存不存在，都从仓库拉取镜像 command: [string] # 容器的启动命令列表，替代docker的ENTRYPOINT指令、如不指定，使用打包时使用的启动命令 args: # 容器的启动命令参数列表、替代docker的CMD指令 - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -fr /tmp/healthy; sleep 600 spec.containers.volumeMounts容器工作目录定义 参数名称 字段类型 说明 spec.containers[].workingDir String 指定容器的工作目录 spec.containers[].volumeMounts[] List 指定容器内部的存储卷配置 spec.containers[].volumeMounts[].name String 指定可以被容器挂载的存储卷的名称 spec.containers[].volumeMounts[].mountPath String 指定可以被容器挂载的存储卷的路径。 spec.containers[].volumeMountsf].readOnly String 设置存储卷路径的读写模式，true 或者 false，默认为读写模式。 spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 workingDir: string # 容器的工作目录、不指定则使用镜像默认值 volumeMounts: # 挂载到容器内部的存储卷配置 - name: data # 引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: /opt/data # 存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean # 是否为只读模式 spec.containers.ports容器端口定义 $ kubectl explain deployment.spec.containers.ports # 获取端口使用方式 参数名称 字段类型 说明 spec.containers[].ports[] List 指定容器需要用到的端口列表。 spec.containers[].ports[].name String 指定端口名称。 spec.containers[].ports[].containerPort String 指定容器需要监听的端口号。 spec.containers[].ports[].hostPort String 指定容器所在主机需要监听的端口号，默认和 spec.containers[].ports[].containerPort 相同。注意，设置了则同一台主机无法启动该容器的相同副本（主机的端口号不能相同，若相同，会引发冲突）。 spec.containers[].ports[].protocol String 指定端口协议，支持 TCP 和 UDP，默认值为 TCP 。 spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 ports: # 容器暴露的端口 - name: http # 服务名称、该名称可以在service种被引用 containerPort: 80 # 容器需要监听的端口号 hostPort: int # 容器所在主机需要监听的端口号，默认与Container相同 - protocol: TCP # 端口协议，支持TCP和UDP，默认TCP - port: 80 # 集群端口 targetPort: 80 # Pod端口 nodePort: 30080 # 节点对外端口 spec.containers.env容器变量定义 参数名称 字段类型 说明 spec.containers[].env[] List 指定容器运行前需要设置的环境变量列表。 spec.containers[].env[].name String 指定环境变量名称。 spec.containers[].env[].value String 指定环境变量值。 spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 env: # 容器运行前需设置的环境变量列表 - name: JAVA_OPTS # 环境变量名称 value: \"-Xmx1g\" # 定义使用内存、环境变量的值 spec.containers.resources容器资源限制 参数名称 字段类型 说明 spec.containers[].resources Object 指定资源限制和资源请求的值（这里开始就是设置容器的资源上限）。 spec.containers[].resources.limits Object 指定设置容器运行时资源的运行上限。 spec.containers[].resources.limits.cpu String 指定CPU的限制，单位为core，是用于运行 docker run --cpu-shares命令的参数。 spec.containers[].resources.limits.memory String 指定内存的限制，单位为 MiB 或 GiB。 spec.containers[].resources.requests Object 指定容器启动和调度时的限制。 spec.containers[].resources.requests.cpu String CPU 请求，单位为 core，容器启动时初始化可用数量。 spec.containers[].resources.requests.memory String 内存请求，单位为 MiB 或 GiB，容器启动的初始化可用数量。 # 设定默认request和limit apiVersion: v1 kind: Namespace metadata: name: apps --- apiVersion: v1 kind: LimitRange metadata: name: limit-resource # 在一个名称空间不能重复 namespace: default # 指定名称空间，默认defalut labels: \u003cmap[string]string\u003e # 标签 annotations: \u003cmap[string]string\u003e # 注释 spec: limits: # 设定默认request和limit - default: # 默认的资源上限, limit memory: 1024Mi cpu: 500m defaultRequest: # 默认的资源申请值, required memory: 128Mi cpu: 100m max: # 声明的limit上限 memory: 2048Mi cpu: 1000m min: # 声明的required下线 memory: 64Mi cpu: 50m type: Container # 被限制的对象，Container ############################################### spec: # Pod中容器的详细定义 containers: # Pod中容器列表 resources: # 资源限制和请求的设置 limits: # 限定Pod最大使用硬件资源、通常设置cpu和memory cpu: \"1\" # Cpu的限制，单位为core数 memory: \"1Gi\" # 内存限制，单位可以为Mib/Gib requests: # 最低资源要求，在scheduler中被用到，通常设置cpu和memory cpu: \"0.5\" # 限定使用几个核心CPU、容器启动的初始可用数量 memory: \"256Mi\" # 设定使用内存、容器启动的初始可用数量 容器健康检查设置 startupProbe： 启动探测：容器启动完毕的配置，该配置与readinessProbe一致，在lifecycle和Probe之前运行，失败则重启\nk8s1.16版本后新加startupProbe探测方式，用于判断容器内应用程序是否已经启动，如果配置了startuprobe，就会先禁用其他的探测，直到它成功为止\nliveness probe(存活探针)Kubelet 使用liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去（谁的程序还没几个bug呢）\nreadiness probe(就绪探针)Kubelet使用readiness probe(就绪探针)来确定容器是否已经就绪可以接受流量。只有当Pod中的容器都处于就绪状态时kubelet才会认定该Pod处于就绪状态。该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除\n参数名称 字段类型 说明 spec.containers[].livenessProbe(存活探针) Object 指定Pod内容器健康检查的设置，当探测几次无响应后，系统将自动重启该容器。参数可以设置为exec、httpGet、tcpSocket。 spec.containers[].livenessProbe.exec Object 指定Pod内容器健康检查的设置，确定是exec方式。 spec.containers[].livenessProbe.exec.command[] String 指定exec方式后用这个参数设置需要指定的命令或者脚本。 spec.containers[].livenessProbe.httpGet Object 指定 Pod 内容器健康检查的设置，确定是httpGet方式。 spec.containers[].livenessProbe.tcpSocket Object 指定 Pod 内容器健康检查的设置，确定是 tcpSocket方式。 spec.containers[].livenessProbe.initialDelaySeconds Number 指定容器启动完成后延迟多久开始首次探测的时间间隔，单位为秒。 spec.containers[].livenessProbe.timeoutSeconds Number 容器健康检查的探测等待时间，单位为秒，默认为 1 秒。若超过该时间，则认为该次探测失败。 spec.containers[].livenessProbe.periodSeconds Number 对容器健康检查的定期探测时间设置，单位为秒，默认每 10 秒探测一次。Kubernetes如果连续执行3次Liveness探测均失败，则会杀掉并重启容器 spec.containers[].livenessProbe.failureThreshold Number 连续探测失败多少次才被认定为失败。默认是3。最小值是1 spec.containers[].livenessProbe.successThreshold Number 连续探测成功多少次才被认定为成功。默认是1 infrastructure Container:基础容器，维护整个Pod网络空间 initContainers:初始化容器，先于业务容器开始运行 Containers:业务容器，并行启动 Pod内所有容器公用一个ip apiVersion: v1 kind: Pod metadata: name: initc-template namespace: default labels: name: initc-template spec: initContainers: - name: initc-template image: busybox imagePullPolicy: IfNotPresent command: ['sh', '-c', 'sleep 10; echo \"Hello\" \u003e\u003e/tmp/hello.txt'] containers: - name: my-container image: busybox command: ['sh', '-c', 'echo The app is running! \u0026\u0026 sleep 3600'] exec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常 Pod五种状态 Pending(挂起)：API Server已经创建了Pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中 Running(运行中)：Pod已经被调度到某节点，并且所有容器都已经被kubelet创建完成 Succeeded(成功终止)：Pod中的所有容器都已经成功终止并且不会被重启 Failed(失败)：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态 Unknown(未知)：API Server无法正常获取到Pod对象的状态信息，通常由于网络通信失败所导致 spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 lifecycle: # 生命周期钩子 postStart: # 容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启 exec: # 通过执行特定命令来探测容器健康状态 command: [\"/bin/sh\",\"-c\",\"echo Hello from the postStart handler\u003e /usr/share/message\"] preStop: # 容器终止前执行此钩子,无论结果如何,容器都会终止 exec: command: [\"/bin/sh\",\"-c\",\"nginx -s quit; while killall -0 nginx; do sleep 1; done\"] ################# 启动探针\t##################### startupProbe: # 容器启动完毕的配置，该配置与readinessProbe一致，在lifecycle和Probe之前运行，失败则重启 tcpSocket: # 使用TcpSocket、httpGet健康检查 port: 8010 # 探测8010端口 failureThreshold: 5 # 检测失败5次表示未就绪 initialDelaySeconds: 60 # 指定容器启动60s之后开始执行Liveness探测， periodSeconds: 10 # 两次探测的间隔多少秒，默认值为10 successThreshold: 1 # 连续多少次检测成功认为容器正常，默认值为1。不支持修改 failureThreshold: 3 # 连续多少次检测失败认为容器异常，默认值为3 timeoutSeconds: 5 # 探测请求超时时间 ################## 存活探针编写方式 ################ livenessprobe: # 存活探针检查,不通过不转发流量 tcpSocket: port: 8010 failureThreshold: 5 initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 ##################### 就绪探针编写方式 ################ readinessProbe: # 就绪探针检查、不通过重建pod tcpSocket: port: 8010 failureThreshold: 5 initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 #################### httpGet编写 ########################### httpGet: path: / # URI地址 port: 80 # 端口号,或者协议：http/https host: 192.168.109.100 # 主机地址 scheme: HTTP # 支持的协议，http或者https failureThreshold: 5 initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 spec.volumes挂载目录字段 参数名 字段类型 说明 spec.volumes[].name String 定义Pod共享存储卷的名称，容器定义部分 spec.containers[].volumeMounts[].name的值和这里是一样的。 spec.volumes[].emptyDir Object 指定Pod的临时目录，值为一个空对象：emptyDir:{} spec.volumes[].hostPath Object 指定挂载Pod所在宿主机的目录。 spec.volumes[].hostPath.path String 指定Pod所在主机的目录，将被用于容器中mount的目录。 spec.volumes.nfs spec.volumes[] Object 指定类型为Secret的存储卷，Secret意为私密、秘密，这很容易理解，它存储一些密码、密钥等敏感安全文件。挂载集群预定义的Secret对象到容器内部。 spec.volumes[].configMap Object 指定类型为ConfigMap的存储卷，表示挂载集群预定义的ConfigMap对象到容器内部。 $ kubectl explain deployment.spec.volumes # 获取 deployment存储使用 $ kubectl explain deployment.spec.volumes.hostPath.type # 类型声明 简单存储模式→volume-emptydir apiVersion: v1 kind: Pod metadata: name: volume-emptydir # 定义名称 namespace: default spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent volumeMounts: # 将logs-volume挂载到nginx容器中对应的目录，该目录为/var/log/nginx - name: logs-volume mountPath: /var/log/nginx ports: - containerPort: 80 - name: busybox image: busybox:1.30 # 可以选择 1.28.4版本 imagePullPolicy: IfNotPresent command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的对应目录，该目录为/logs - name: logs-volume mountPath: /logs volumes: # 声明volume，name为logs-volume，类型为emptyDir - name: logs-volume # 共享存储卷名称 （volumes类型有很多种） emptyDir: {} # 类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 简单存储模式→volume-HostPath DirectoryOrCreate：目录存在就使用，不存在就先创建后使用 Directory：目录必须存在 FileOrCreate：文件存在就使用，不存在就先创建后使用 File：文件必须存在 Socket：unix套接字必须存在 CharDevice：字符设备必须存在 BlockDevice：块设备必须存在 apiVersion: v1 kind: Pod metadata: name: volume-hostpath namespace: default spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: # 将logs-volume挂载到nginx容器中对应的目录，该目录为/var/log/nginx - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 imagePullPolicy: IfNotPresent command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的对应目录，该目录为/logs - name: logs-volume mountPath: /logs volumes: # 声明volume，name为logs-volume，类型为hostPath - name: logs-volume hostPath: # 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: /root/logs # Pod所在宿主机的目录，将被用于同期中mount的目录 type: DirectoryOrCreate # 目录存在就使用，不存在就先创建再使用 简单存储模式→volume-nfs apiVersion: v1 kind: Pod metadata: name: volume-nfs namespace: default spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: # 将logs-volume挂载到nginx容器中对应的目录，该目录为/var/log/nginx - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 imagePullPolicy: IfNotPresent command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的对应目录，该目录为/logs - name: logs-volume mountPath: /logs volumes: # 声明volume - name: logs-volume nfs: # 存储类型，和底层正则的存储对应 server: 192.168.18.100 # NFS服务器地址 path: /root/data/nfs # 共享文件路径 高级存储模式→volume-pv PV：kubernetes管理员维护 apiVersion: v1 kind: PersistentVolume metadata: name: pv2 spec: nfs: # 存储类型，和底层正则的存储对应 path: /root/data/pv1 server: 192.168.18.100 capacity: # 存储能力，目前只支持存储空间的设置 storage: 2Gi accessModes: # 访问模式 - ReadWriteMany storageClassName: # 存储类别 persistentVolumeReclaimPolicy: Retain # 回收策略 高级存储→volume-pvc apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc1 namespace: dev spec: accessModes: # 访客模式 - ReadWriteMany selector: # 采用标签对PV选择 storageClassName: # 存储类别 resources: # 请求空间 requests: storage: 1Gi #################################################### 创建 Pod 访问 PVC 类型存储 apiVersion: v1 kind: Pod metadata: name: pod1 namespace: dev spec: containers: - name: busybox image: busybox:1.30 command: [\"/bin/sh\",\"-c\",\"while true;do echo pod1 \u003e\u003e /root/out.txt; sleep 10; done;\"] volumeMounts: - name: volume mountPath: /root/ volumes: - name: volume persistentVolumeClaim: claimName: pvc1 readOnly: false 配置存储→volumes-secret apiVersion: v1 kind: Secret metadata: name: secret namespace: dev type: Opaque data: # 提前编码实名：data、使用Kubernetes进行编码使用：stringData username: YWRtaW4= # 使用kubernetes进行编码写原数据：admin password: MTIzNDU2 # 使用kubernetes进行编码写原数据：123456 ############################################## 配置 pod-secret apiVersion: v1 kind: Pod metadata: name: pod-secret namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: - mountPath: /secret/config name: config volumes: - name: config secret: # 类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 secretName: secret items: - key: string path: string 额外的参数对象 参数名 参数类型 说明 spec.restartPolicy String 定义Pod的重启策略，可选值为Always、OnFailure，默认值为Always。(1) Always：Pod一旦终止运行，无论容器是如何终止的，kubelet服务都将重启它(2) OnFailure：只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器正常结束（退出码为 0），则kubelet将不会重启它 (3)Never：Pod终止后，kubelet将退出码报告给master，不会重启该 Pod spec.nodeName 定向调度 spec.nodeSelector Object 定向调度，定义节点的过滤标签（以key:value格式指定）。 pod.spec.affinity 亲和调度 pod.spec.affinity.nodeAffinity （node亲和性）：以Node为目标，解决Pod可以调度到那些Node的问题。 pod.spec.affinity.podAffinity （pod亲和性）：以Pod为目标，解决Pod可以和那些已存在的Pod部署在同一个拓扑域中的问题。 pod.spec.affinity.podAntiAffinity （pod反亲和性）：以Pod为目标，解决Pod不能和那些已经存在的Pod部署在同一拓扑域中的问题。 pod.spec.tolerations 容忍调度 污点就是拒绝，容忍就是忽略，Node通过污点拒绝Pod调度上去，Pod通过容忍忽略拒绝 spec.imagePullSecrets List 定义拉取镜像时使用Secret名称（以name:secretkey格式指定）。 spec.hostNetwork Boolean 定义是否使用主机网络模式，默认值为 false。 设置 true 表示使用宿主机网络，不使用 Docker 网桥，同时设置了 true 将无法在同一台宿主机上启动第二个副本。 service.spec.type type确定服务的公开方式。 默认为ClusterIP。有效的选项是ExternalName、ClusterIP、NodePort和LoadBalancer service.spec.type.ClusterIP ClusterIP为负载均衡分配集群内部IP地址端点。 端点由选择器确定，或者如果不是通过手动构造Endpoints对象或EndpointSlice指定对象。 如果clusterIP为None，则不分配虚拟IP，并且端点作为一组端点而不是虚拟IP发布。 service.spec.type.NodePort NodePort建立在ClusterIP之上，并在每个节点上分配一个端口路由到与clusterIP相同的端点。 service.spec.type.LoadBalancer LoadBalancer建立在NodePort并创建一个外部负载均衡器（如果当前支持cloud) 路由到与clusterIP相同的端点。 service.spec.type.ExternalName ExternalName将此服务别名为指定的externalName。 其他几个领域不适用于ExternalName服务 tolerations(容忍)配置 $ kubectl explain deployment.spec.template.spec.tolerations affinity(亲和性)配置 $ kubectl explain deployment.spec.template.spec.affinity # 查看 Deployment 亲和性使用 nodeAffinity节点亲和性 requiredDuringSchedulingIgnoredDuringExecution:硬性要求，必须满足条件 preferredDuringSchedulingIgnoredDuringExecution:软性要求，不强制满足 In：满足条件之一 NotIn：所有条件都不满足，反亲和性 Exists：存在就满足 DoesNotExist不存在就满足 Gt大于节点上的数值就满足 Lt小于节点上的数值就满足 $ kubectl explain deployment.spec.template.spec.affinity.nodeAffinity # 查看Deployment nodes亲和性使用apiVersion: v1 kind: Pod metadata: name: with-affinity-anti-affinity spec: affinity: nodeAffinity: # 节点亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 必须满足条件 nodeSelectorTerms: # 选择器，nodeSelectorTerms：节点选择器，labelSelector：标签选择器 - matchExpressions: # 表达式匹配 - key: kubernetes.io/os # 必须存在的Key operator: In # 在Key中满足一个条件，匹配类型：In、NotIn、Exists、DoesNotExist、Gt、Lt values: # 下方 value 在 Key 中必须存在其中之一(value) - linux # 必须是Linux才部署 preferredDuringSchedulingIgnoredDuringExecution: # 软性要求，不强制满足，优先选择亲和性目标 - weight: 1 # 权重，数值越大，优先部署 preference: matchExpressions: - key: label-1 operator: In values: - key-1 - weight: 50 preference: matchExpressions: - key: label-2 operator: In values: - key-2 containers: - name: with-node-affinity image: registry.k8s.io/pause:2.0 podAffinity亲和性 $ kubectl explain pod.spec.affinity.podAffinityapiVersion: v1 kind: Pod metadata: name: with-pod-affinity spec: affinity: podAffinity: # Pod 亲和性 requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: # 选择器： matchExpressions: - key: security operator: In values: - S1 topologyKey: topology.kubernetes.io/zone # 匹配节点标签亲和性 podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: topology.kubernetes.io/zone containers: - name: with-pod-affinity image: registry.k8s.io/pause:2.0 podAntiAffinity反亲和性 $ kubectl explain pod.spec.affinity.podAntiAffinity spec: # 必选，Pod中容器的详细定义 replicas: 2 # 创建Pod个数 selector: # 标签选择器 matchLabels: # 标签选择方式:直接给定标签键值,这里是取交集的,也就是Pod必须满足下面两个标签才能被调度 project: ms app: product # 此行以上定义控制器本身 template: # 定义Deployment更新回滚 metadata: labels: - name: string annotations: # 注释，不能作为被筛选 - name: nginx spec: hostAliases: # /etc/hosts/手动添加解析 - ip: \"192.168.4.110\" hostnames: - \"k8s.com\" containers: # 必选，Pod中容器列表 restartPolicy: [Always、Never、OnFailure] #默认K8S-Pod的重启策略,此容器退出后立即创建一个相同容器 nodeName: k8s-node1 # NodeName表示将该Pod调度到指定到名称的node节点上 nodeSelector: obeject # nodeSelector用于将Pod调度到添加了指定标签的Node节点上 imagePullSecrets: # 配置登录 docker registry 的 secret 仓库 - name: docker-harbor # 指定使用的secret库房名称 hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 ReplicaSet(RS)类型控制器 ReplicaSet：主要作用是保证一定数量的Pod能够正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对Pod数量的扩缩容和版本镜像的升级 Kubernetes replicaset Template模板 apiVersion: apps/v1 # 版本号 kind: ReplicaSet # 类型 metadata: # 元数据 name: replicaset-template # 名称、在一个名称空间内不能重复 namespace: default # 指定名称空间、默认defalut labels: # 标签 name: replicaset-template spec: # 详情描述 replicas: 3 # 指定副本数量，是rs创建出来的Pod的数量，默认为1. selector: # 选择器，它的作用是建立Pod控制器和Pod之间的关联关系，采用了Label Selector机制（在Pod模块上定义Label，在控制器上定义选择器，就可以表明当前控制器能管理哪些Pod了） matchLabels: # Labels匹配规则，matchExpressions：Expressions匹配规则 name: replicaset-template template: # 模块 当副本数据不足的时候，会根据下面的模板创建Pod副本 metadata: labels: name: replicaset-template spec: containers: - name: nginx # 容器名称 image: nginx:1.17.1 # 容器需要的镜像地址 ports: - containerPort: 80 # 容器所监听的端口 protocol: TCP resources: limits: cpu: 100m memory: 128Mi requests: cpu: 50m memory: 128Mi HorizontalPodAutoscaler类型 Kubernetes HorizontalPodAutoscaler Template模板 deployment：类型控制器 deployment-name：Pod的名称 --cpu-percent：使用CPU百分比 --min：Pod最少数量 --max：Pod最多数量 $ kubectl autoscale deployment deployment-name --cpu-percent=50 --min=2 --max=10 apiVersion: autoscaling/v2 # 版本号 kind: HorizontalPodAutoscaler # 类型 metadata: # 元数据 namespace: default # 指定名称空间、默认default name: hpa-template spec: minReplicas: 2 # 最小Pod数量 maxReplicas: 10 # 最大Pod数量 metrics: - resource: name: cpu # 扩缩容名称 target: averageUtilization: 30 # 设置CPU使用百分比，超过就扩容 type: Utilization # 利用率：Utilization，平均值：AverageValue：1k、1M、1G type: Resource scaleTargetRef: # 指定要控制Pod、Deployment信息 apiVersion: apps/v1 kind: Deployment name: deployment-template --- apiVersion: v1 kind: Service metadata: name: service-template namespace: default spec: selector: name: deployment-nginx-template # clusterIP: None # 将clusterIP设置为None，即可创建headliness Service type: NodePort # Pod使用的IP类型：ClusterIP、NodePort ports: - port: 80 # Service的端口 targetPort: 80 # StatefulSet 的Pod端口 --- apiVersion: apps/v1 # 版本号 kind: Deployment # 类型 metadata: # 元数据 name: deployment-template # deployment的名称 namespace: default # 指定名称空间、默认default labels: # 标签 name: deployment-nginx-template spec: # 详情描述 replicas: 3 # 副本数量 revisionHistoryLimit: 3 # 保留历史版本，默认为10 paused: false # 暂停部署，默认是false progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 strategy: # pod更新策略，即如何替换已有的pod type: RollingUpdate # 更新策略、支持 Recreate, RollingUpdate。默认RollingUpdate rollingUpdate: # 当type为RollingUpdate的时候生效，用于为rollingUpdate设置参数 maxUnavailable: 30% # 用来指定在升级过程中不可用的Pod的最大数量，默认为25%。 maxSurge: 30% # 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25% selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则，matchExpressions：Expressions匹配规则 name: deployment-nginx-template template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: # Pod 的标签 name: deployment-nginx-template spec: # Pod 的期望信息 containers: # Pod 容器描述 - name: nginx # 镜像名称 image: nginx:1.17.1 imagePullPolicy: IfNotPresent # IfNotPresent：如果镜像不存在就拉取 ports: - containerPort: 80 resources: limits: cpu: 100m memory: 128Mi requests: cpu: 50m memory: 128Mi restartPolicy: Always # 重启策略，Always：代表一直重启 terminationGracePeriodSeconds: 30 # 删除操作宽限时间 Deployment(deploy)无状态类型 graph TD A[\u003cp\u003eDeployment\u003cbr\u003eseletor:env=dev] --\u003e A1((\u003cp\u003ePod\u003cbr\u003elabel:env=dev)) A[\u003cp\u003eDeployment\u003cbr\u003eseletor:env=dev] --\u003e A2((\u003cp\u003ePod\u003cbr\u003elabel:env=dev)) A[\u003cp\u003eDeployment\u003cbr\u003eseletor:env=dev] --\u003e A3((\u003cp\u003ePod\u003cbr\u003elabel:env=dev)) Z[Deployment控制Pod] Deployment：为了更好的解决服务编排的问题，kubernetes在v1.2版本开始，引入了Deployment控制器。值得一提的是，Deployment控制器并不直接管理Pod，而是通过管理ReplicaSet来间接管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment的功能比ReplicaSet强大 支持ReplicaSet的所有功能 支持发布的停止、继续 支持版本滚动更新和版本回退 Recreate重建更新：在创建出新的Pod之前会先杀掉所有已经存在的Pod\nRollingUpdate滚动更新：杀死一部分，就启动一部分，在更新过程中存在两个版本的Pod，当type为RollingUpdate的时候生效，用于为rollingUpdate设置参数， 支持两个属性：\nmaxSurge：用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%\nmaxUnavailable：用来指定在升级过程中不可用的Pod的最大数量，默认为25%\nKubernetes Deployment Template模板 apiVersion: apps/v1 # 版本号 kind: Deployment # 类型 metadata: # 元数据 name: deployment-template # deployment的名称 namespace: default # 指定名称空间、默认defalut labels: # 标签 name: deployment-nginx-template spec: # 详情描述 replicas: 3 # 副本数量 revisionHistoryLimit: 3 # 保留历史版本，默认为10 paused: false # 暂停部署，默认是false progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 strategy: # pod更新策略，即如何替换已有的pod rollingUpdate: # 当type为RollingUpdate的时候生效，用于为rollingUpdate设置参数 maxUnavailable: 30% # 用来指定在升级过程中不可用的Pod的最大数量，默认为25%。 maxSurge: 30% # 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25% type: RollingUpdate # 更新策略、支持 Recreate, RollingUpdate。默认RollingUpdate selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则，matchExpressions：Expressions匹配规则 name: deployment-nginx-template template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: # Pod 的标签 name: deployment-nginx-template spec: # Pod 的期望信息 containers: # Pod 容器描述 - name: nginx # 镜像名称 image: nginx:1.17.1 # fxgxxxxx/nginx:v1 在所有节点登录自己的 hub.docker.com 账户 imagePullPolicy: IfNotPresent # IfNotPresent：如果镜像不存在就拉取 ports: - containerPort: 80 volumeMounts: # 挂载到容器内部的存储卷配置 - name: nginx_vhosts # 引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: /usr/local/nginx/conf/vhosts # 存储卷在容器内mount的绝对路径，应少于512字符 name: nginx_logs mountPath: /usr/local/nginx/logs name: nginx_html resources: # 资源限制和请求的设置 limits: # 限定Pod最大使用硬件资源、通常设置cpu和memory cpu: \"6\" # Cpu的限制，单位为core数，将用于docker run --cpu-shares参数，1000m等于一个核心 memory: \"128Mi\" # 内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: # 最低资源要求，在scheduler中被用到，通常设置cpu和memory cpu: \"3\" # 限定使用几个核心CPU、容器启动的初始可用数量 memory: \"64Mi\" # 设定使用内存、容器启动的初始可用数量 restartPolicy: Always # 重启策略，Always：代表一直重启 terminationGracePeriodSeconds: 30 # 删除操作宽限时间 volumes: # 在该pod上定义共享存储卷列表 - name: nginx_vhosts # 共享存储卷名称 （volumes类型有很多种） hostPath: # 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: /opt/data/nginx/vhosts type: DirectoryOrCreate # 目录存在就使用，不存在就先创建再使用 name: nginx_logs hostPath: path: /opt/data/nginx/logs type: DirectoryOrCreate name: nginx_html hostPath: path: /opt/data/nginx/html type: DirectoryOrCreate status: {} StatefulSet有状态类型 无状态应用定义 认为Pod都是一样的 没有顺序要求 不用考虑在哪个Node节点上运行 随意进行伸缩和扩展 有状态应用定义 有顺序要求 认为每个Pod都是不一样的 需要考虑在哪个Node节点上运行 需要按照顺序进行伸缩和扩展 让每个Pod都是独立的，保持Pod启动顺序和唯一性 StatefulSet 是Kubernetes提供的管理有状态应用的负载管理控制器 StatefulSet常用来部署RabbitMQ集群、Zookeeper集群、MySQL集群、Eureka集群等 StatefulSet部署需要HeadLinessService（无头服务） 在用Deployment时，每一个Pod名称是没有顺序的，是随机字符串，因此是Pod名称是无序的，但是在StatefulSet中要求必须是有序 ，每一个Pod不能被随意取代，Pod重建后pod名称还是一样的 而Pod IP是变化的，所以是以Pod名称来识别。Pod名称是Pod唯一性的标识符，必须持久稳定有效。这时候要用到无头服务，它可以给每个Pod一个唯一的名称 Deployment和StatefulSet区别：Deployment没有唯一标识而StatefulSet有唯一标识 StatefulSet唯一标识生成规则： 根据主机名+一定规则生成的：主机名.无头Service名称.命名空间.svc.cluster.local StatefulSet控制器支持两种更新策略 OnDelete： OnDelete表示删除之后才更新 (默认)RollingUpdate：RollingUpdate表示滚动更新 Kubernetes StatefulSet Template模板 apiVersion: v1 kind: Service metadata: name: service-template namespace: default spec: selector: name: statefulset-template clusterIP: None # 将clusterIP设置为None，即可创建headliness Service type: ClusterIP # 类型：NodePort ports: - port: 80 # Service的端口 protocol: TCP targetPort: 80 # StatefulSet 的Pod端口 --- apiVersion: apps/v1 kind: StatefulSet metadata: name: statefulset-template namespace: default spec: replicas: 3 serviceName: service-template # 使用那个Service管理DNS updateStrategy: type: RollingUpdate # 滚动更新，OnDelete：删除更新 rollingUpdate: # 如果更新的策略是OnDelete，那么rollingUpdate就失效 partition: 2 # 表示从第2个分区开始更新，默认是0 selector: matchLabels: name: statefulset-template template: metadata: labels: name: statefulset-template spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 DaemonSet(ds)守护进程类型 DaemonSet：控制器可以保证集群中的每一台（或指定）节点上都运行一个副本，一般适用于日志(elk)收集、节点监控(zabbix)等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建\nDaemonSet控制器的特点\n每向集群中添加一个节点的时候，指定的Pod副本也将添加到该节点上\n当节点从集群中移除的时候，Pod也会被垃圾回收\nKubernetes DaemonSet Template模板\napiVersion: apps/v1 # 版本号 kind: DaemonSet # 类型 metadata: # 元数据 name: fluentd-daemonset # Pod 名称 namespace: default # 指定名称空间、默认default labels: # 标签 name: 'fluentd-es' spec: # Pod 详情描述 revisionHistoryLimit: 3 # 保留历史版本、默认为最大值(2^32) updateStrategy: # 更新策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 maxUnavailable: 1 # 最大不可用状态的Pod的最大值，可用为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理那些Pod matchLabels: # Labels匹配规则，matchExpressions: 匹配规则 name: 'fluentd-es' template: # 模板，当副本数量不足时，会根据下面的模板创建Pod模板 metadata: labels: name: 'fluentd-es' spec: containers: - name: fluentd-es image: agilestacks/fluentd-elasticsearch:v1.3.0 env: # 环境变量配置 - name: FLUENTD_ARGS # 环境变量的 key value: -qq # 环境变量的 value volumeMounts: # 加载数据卷 避免数据丢失 - name: containers # 数据卷名称 mountPath: /var/lib/docker/containers # 将数据卷挂载到容器内那个目录 - name: varlog mountPath: /var/log volumes: # 定义数据卷 - name: containers # 定义数据卷的名称 hostPath: # 数据卷类型，主机路径模式 path: /var/lib/docker/containers # node 中共享目录 - name: varlog hostPath: path: /var/log Service类型控制器 在kubernetes中，Pod是应用程序的载体，我们可以通过Pod的IP来访问应用程序，但是Pod的IP地址不是固定的，这就意味着不方便直接采用Pod的IP对服务进行访问 为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个Pod进行聚合，并且提供一个统一的入口地址，通过访问Service的入口地址就能访问到后面的Pod服务 Service在很多情况下只是一个概念：真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行了一个kube-proxy的服务进程。当创建Service的时候会通过API Server向etcd写入创建的Service的信息，而kube-proxy会基于监听的机制发现这种Service的变化，然后它会将最新的Service信息转换为对应的访问规则 假如：10.97.97.97:80是service提供的访问入口：当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用，kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去，这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上访问都可以 ClusterIP默认值：它是kubernetes系统自动分配的虚拟IP(VIP)，只能在集群内部（所有Node节点）访问 NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问（使用浏览器域名或IP端口访问）服务 创建的Service的IP地址只能在集群内部才可以访问，如果希望Service暴露给集群外部使用，那么就需要使用到另外一种类型的Service，称为NodePort类型的Service。NodePort的工作原理就是将Service的端口映射到Node的一个端口上，然后就可以通过NodeIP:NodePort来访问Service了 LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境的支持 LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境的支持，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中 ExternalName：把集群外部的服务引入集群内部，直接使用 ExternalName类型的Service用于引入集群外部的服务，它通过externalName属性指定一个服务的地址，然后在集群内部访问此Service就可以访问到外部的服务了 $ kubectl explain service.spec.type # Kubernetes Service Template模板 apiVersion: v1 # 版本 kind: Service # 类型 metadata: # 元数据 name: service-template # Service 名字 namespace: default # 命名空间 labels: name: nginx # Service 自己本身的标签 spec: selector: # 标签选择器，用于确定当前Service代理那些Pod name: nginx-deploymen # 所有匹配到这些标签的Pod 都可以进行访问 type: NodePort # 指定Service的类型访问方式、ClusterIP、NodePort、ExternalName，NodePort支持集群外部访问，启用ingress设置：ClusterIP externalName: www.baidu.com # 改成IP地址也可以,只有type类型为：ExternalName，域名配置才生效 clusterIP: 10.64.0.47 # 定service IP，不指定就随机生成，启用ingress设置为：None sessionAffinity: None # 分发策略、session亲和性，支持ClientIP、None两个选项，默认值为None ports: # 端口映射信息 - port: 80 # Service 端口，在使用内网IP访问时使用 protocol: TCP # 协议 targetPort : 80 # 目标Pod端口，例如：deployment、statefulset等，Nginx：80，Tomcat：8080 nodePort: 30002 # 绑定到node主机上的端口(端口使用范围：30000~32767)，如果不指定，会默认分配，启用ingress删除此行 kube-proxy目前支持的三种工作模式 userspace模式 userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法（负载均衡算法）选择一个提供服务的Pod并和其建立连接，以便将请求转发到Pod上 userspace模式下，kube-proxy充当了一个四层负载均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理的时候会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率非常低下 iptables模式 iptables模式下，kube-proxy为Service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod的IP上 iptables模式下kube-proxy不承担四层负载均衡器的角色，只负责创建iptables规则。该模式的优点在于较userspace模式效率更高，但是不能提供灵活的LB策略，当后端Pod不可用的时候无法进行重试 ipvs模式 ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高，除此之外，ipvs支持更多的LB算法\nipvs的映射规则，rr表示轮询\n$ ipvsadm -Ln # 查看kube-proxy工作模式 对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略 默认使用kube-proxy的策略，比如随机、轮询等 sessionAffinity：基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上，这对于传统基于Session的认证项目来说很友好，此模式可以在spec中添加sessionAffinity: ClusterIP选项 HeadLiness类型负载均的Service 在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLinesss Service，这类Service不会分配Cluster IP，如果想要访问Service，只能通过Service的域名进行查询 clusterIP: None：将clusterIP设置为None，即可创建headliness Service Endpoint类型控制器 实际中使用的不多 Endpoint：是kubernete中的一个资源对象，存储在etcd中，用来记录一个service对应的所有Pod的访问地址，它是根据service配置文件中的selector描述产生的 一个service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换言之servic和Pod之间的联系是通过Endpoints实现的 $ kubectl describe svc nginx-service -n app $ kubectl get endpoints -n dev -o wide Kubernetes Endpoint Template模板 apiVersion: v1 kind: Endpoints metadata: name: endpoints-template namespace: default labels: name: nginx # 标签和Service 里的labels一致 subsets: - addresses: - ip: 23.41.187.94 # 目标IP地址 ports: # 与 Service一致 - port: 80 protocol: TCP --- apiVersion: v1 # 版本 kind: Service # 类型 metadata: # 元数据 name: service-template # Service 名字 namespace: default # 命名空间 labels: name: nginx # Service 自己本身的标签 spec: type: ClusterIP # 指定Service的类型访问方式、ClusterIP、NodePort、ExternalName sessionAffinity: None # 分发策略、session亲和性，支持ClientIP、None两个选项，默认值为None ports: # 端口映射信息 - port: 80 # Service 端口，在使用内网IP访问时使用 protocol: TCP # 协议 targetPort : 80 # 目标Pod端口，例如：deployment、statefulset等 Job类型控制器 Job主要用于负责批量处理短暂的一次性任务 Job特点 当Job创建的Pod执行成功结束时，Job将记录成功结束的Pod数量 当成功结束的Pod达到指定的数量时，Job将完成执行 Job模板使用重启策略定义 设置为：OnFailure， Job会在Pod出现故障的时候重启容器，而不是创建Pod，failed次数不变 设置为：Never，Job会在Pod出现故障的时候创建新的Pod，并且故障Pod不会消失也不会重启，failed次数+1 设置为：Always，意味Job一直重启，意味Pod任务会重复执行，这和Job的定义冲突，所以不能设置为Always Job资源清单 apiVersion: batch/v1 # 版本号 kind: Job # 类型 metadata: # 元数据 name: job-template # 名称 namespace: default # 命名空间 labels: # 标签 controller: job spec: # 详情描述 completions: 1 # 指定Job需要成功运行Pod的总次数，默认为1 parallelism: 1 # 指定Job在任一时刻应该并发运行Pod的数量，默认为1 activeDeadlineSeconds: 30 # 指定Job可以运行的时间期限，超过时间还没结束，系统将会尝试进行终止 backoffLimit: 6 # 指定Job失败后进行重试的次数，默认为6 manualSelector: true # 是否可以使用selector选择器选择Pod，默认为false selector: # 选择器，通过它指定该控制器管理那些Pod matchLabels: # Labels匹配规则 app: counter-pod matchExpressions: # Expressions匹配规则 - key: app operator: In values: - counter-pod template: # 模板，当副本数量不足时，会根据下面的模板创建Pod模板 metadata: labels: app: counter-pod spec: restartPolicy: Never # 重启策略只能设置为Never或OnFailure containers: - name: counter image: busybox:1.30 command: [\"/bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1;do echo $i;sleep 20;done\"] CronJob类型控制器 CronJob控制器：以Job控制器为其管控对象，并借助它管理Pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似Linux操作系统的周期性任务作业计划的方式控制器运行时间点及重复运行的方式，换言之，CronJob可以在特定的时间点反复去执行Job任务 schedule：cron表达式，用于指定任务的执行时间 /1 *：表示分钟 小时 日 月份 星期 分钟值从0到59 小时值从0到23 日(天)的值从1到31 月的值从1到12 星期的值从0到6，0表示星期日 多个时间可以用逗号隔开，范围可以用连字符给出：* 可以作为通配符，/表示每… concurrencyPolicy并发执行策略 Allow：运行Job并发调度（默认） Forbid：禁止并发运行，如果之前的任务没完成，则跳过，直接执行新的 Replace：替换，取消当前正在运行的作业并使用新作业替换它 Kubernetes CronJob Template模板 apiVersion: batch/v1 # 版本号 kind: CronJob # 类型 metadata: # 元数据 name: cronjob-template # 名称 namespace: default # 命名空间 labels: controller: cronjob spec: # 详情描述 concurrencyPolicy: Allow # 并发执行策略，Allow：并发调度， failedJobsHistoryLimit: 1 # 保留多少个失败的任务，默认为1 successfulJobsHistoryLimit: 3 # 保留多少个成功的任务，默认为3 # startingDeadlineSeconds: 30 # 间隔多长时间检测失败的任务并重新执行，时间不能小于：10 suspend: false # 是否挂起任务，若为：true 则该任务不执行 schedule: \"*/1 * * * * \" # cron格式的作业调度运行时间点，用于控制任务任务时间执行 jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象，下面其实就是job的定义 metadata: {} spec: completions: 1 # 指定Job需要成功运行Pod的总次数，默认为1 parallelism: 1 # 指定Job在任一时刻应该并发运行Pod的数量，默认为1 activeDeadlineSeconds: 30 # 指定Job可以运行的时间期限，超过时间还没结束，系统将会尝试进行终止 backoffLimit: 6 # 指定Job失败后进行重试的次数，默认为6 template: # 模板，当副本数量不足时，会根据下面的模板创建Pod模板 spec: restartPolicy: Never # 重启策略只能设置为Never或OnFailure containers: - name: container-name image: busybox:1.30 command: [ \"/bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1;do echo $i;sleep 20;done\" ] 模板详细描述 名称地址 描述 Bitnami模板库 Kubernetes的Bitnami库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 Kubernetes的Charts-docs库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 Kubernetes Template模板 apiVersion: v1 # 版本号，例如v1 kind: Deployment # 资源类型，例如 Pod、Deployment、Service、ReplicaSet、StatefulSet metadata: # POd相关的元数据，用于描述Pod数据 name: java-demo # Pod名称、在同一个名称空间内不能重复 namespace: string # Pod所属的命名空间,默认为\"default\" labels: # 定义Pod的标签，只能使用字符串类型：string - name: java-demo # 自定义label标签，key(键)为：name，value(值)为：java-demo version: v1.1.0 # 自定义版本 annotations: # 注释，不能作为被筛选 - name: java-demo spec: # Pod中容器的详细定义 replicas: 3 # 创建的副本数量 revisionHistoryLimit: 10 # 滚动更新后保留的历史版本数 selector: # 选择器，用于找到匹配的 ReplicaSet(副本) matchLabels: # 按照Labels标签匹配副本 - name: java-demo # 匹配的key，value version: v1.1.0 strategy: # 更新策略，StatefulSet更新使用：updateStrategy rollingUpdate: # 滚动更新配置 partition: 3 # 实现灰度/金丝雀发布，按序号更新，更新大于等于3的序号，不和百分比共用 maxSurge: 25% # 多少个/百分之多少Pods处于更新，数值越大更新越快，不稳定 maxUnavailable: 25% # 多少个/百分之多少Pods处于关闭，数值越小更新慢，稳定 type: RollingUpdate # 更新类型选择器，采用滚动更新，OnDelete：方式更新，删除pods时更新 template: # Pod 模板 metadata: # Pod 的元信息 labels: # Pod 的标签 - name: java-demo version: v1.1.0 spec: # Pod的期望信息 nodeName: k8s-node1 # 设置NodeName表示将该Pod调度到指定到名称的node节点上 nodeSelector: obeject # 设置NodeSelector表示将该Pod调度到包含这个label的node上 hostNetwork: false # 是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 tolerations: # 容忍配置 - effect: \"污点的类型\" # Noschedule key: \"污点的Key\" # 污点的Key operate: \"Equal\" # Exists：匹配Key，Equal添加：value配置， value: \"污点的value\" # 污点的value imagePullSecrets: # 配置登录 docker registry 的 secret 仓库 - name: docker-harbor # 指定使用的secret库房名称 containers: # 对于 Pod中容器描述 - name: tomcat-demo # 指定容器名称，不可更新 image: 192.168.80.210:8080/test/tomcat-demo:v1 # 镜像仓库地址 imagePullPolicy: [ Always | Never | IfNotPresent ] # 镜像拉取方式 command: [string] # 以数组方式指定容器启动命令列表，如不指定，使用打包时使用的启动命令 args: # 以数组方式指定容器启动命令参数列表，替代docker的CMD指令 - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -fr /tmp/healthy; sleep 600 # 不能超过探针执行时间 workingDir: string # 容器启动后进入的工作目录，不指定则使用镜像默认值 volumeMounts: # 挂载到容器内部的存储卷配置 - name: data # 引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: /opt/data # 存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean # 是否为只读模式 ports: # 需要暴露的端口库号列表 - name: http # 为端口取名，该名称可以在service种被引用 containerPort: int # 容器需要监听的端口号 hostPort: int # 容器所在主机需要监听的端口号，默认与Container相同 protocol: TCP # 端口协议，支持TCP和UDP，默认TCP targetPort: 80 # Pod 本身服务端口，比如Nginx：80，Tomcat：8080 nodePort: 30001 # 节点对外端口 env: # 容器运行前需设置的环境变量列表 - name: JAVA_OPTS # 环境变量名称 value: \"-Xmx1g\" # 环境变量的值 resources: # 资源限制和请求的设置 limits: # 限定Pod最大使用硬件资源、通常设置cpu和memory cpu: \"1\" # Cpu的限制，单位为core数，将用于docker run --cpu-shares参数，1000m等于一个核心 memory: \"1Gi\" # 内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: # 最低资源要求，在scheduler中被用到，通常设置cpu和memory cpu: \"0.5\" # 限定使用几个核心CPU、容器启动的初始可用数量 memory: \"256Mi\" # 设定使用内存、容器启动的初始可用数量 lifecycle: # 生命周期钩子 postStart: # 容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启 exec: command: [\"/bin/sh\",\"-c\",\"echo Hello from the postStart handler \u003e/usr/share/message\"] preStop: # 容器终止前执行此钩子,无论结果如何,容器都会终止 exec: command: [\"/bin/sh\",\"-c\",\"nginx -s quit; while killall -0 nginx; do sleep 1; done\"] startupProbe: tcpSocket: # 使用TcpSocket、httpGet健康检查 port: 8010 # 探测8010端口 failureThreshold: 5 # 检测失败5次表示未就绪 initialDelaySeconds: 60 # 指定容器启动60s之后开始执行Liveness探测， periodSeconds: 10 # 指定每10秒执行一次Liveness探测。 successThreshold: 1 # 检查成功为2次表示就绪 timeoutSeconds: 5 # 检测失败1次表示未就绪 livenessProbe: # 对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器 exec: # 对Pod容器内检查方式设置为exec方式 command: # exec方式需要制定的命令或脚本 - sh - c - \"sleep 5; echo 'success';\" httpGet: # 对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: / # URI地址：http://:80/index.html port: 8010 host: 192.168.109.100 # 主机地址 scheme: HTTP # 支持的协议，http或者https HttpHeaders: - name: string value: string(字符串) tcpSocket: # 对Pod内个容器健康检查方式设置为tcpSocket方式 port: 8010 initialDelaySeconds: 60 # 容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 5 # 对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 10 # 对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 1 # 配置为：1，表示检查一次成功就成功，配置为：3，表示检查3次 failureThreshold: 5 # 失败次数，检查5次失败表示失败 securityContext: privileged: false restartPolicy: [Always | Never | OnFailure] # Pod的重启策略 terminationGracePeriodSeconds: 30 # 删除pods、deployment后等待时间 volumes: # 在该pod上定义共享存储卷列表 - name: logs-volume # 共享存储卷名称 （volumes类型有很多种） emptyDir: {} # 类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: # 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: /root/logs # Pod所在宿主机的目录，将被用于同期中mount的目录 type: DirectoryOrCreate # 目录存在就使用，不存在就先创建再使用 secret: # 类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 scretname: secret items: - key: string path: string configMap: # 类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: configmap items: - key: string path: string 编写适用Java的yaml 下载java demo代码 $ git clone https://github.com/frankinbj/tomcat-java-demo.git 修改连接数据库配置文件 $ cat \u003etomcat-java-demo/src/main/resources/application.yml\u003c\u003c-EOF datasource: url: jdbc:mysql://192.168.80.215:3306/test?characterEncoding=utf-8 username: admin password: admin EOF 打包java war包 $ cd /opt/tomcat-java-demo/ $ mvn clean package -Dmaven.test.skip=true # 生成war包 $ ll /opt/tomcat-java-demo/target/ly-simple-tomcat-0.0.1-SNAPSHOT.war 把数据导入数据库，创建授权连接用户 $ mysql -uroot -p \u003c tomcat-java-demo/doc/db/tables_ly_tomcat.sql $ grant all privileges on *.* to admin@'%' identified by 'admin'; JDK、Maven配置环境变量 $ echo \"##### JDK 環境變數 ##### export JAVA_HOME=/usr/local/jdk export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=${JAVA_HOME}/lib:${JAVA_HOME}/lib/tools.jar export PATH=${PATH}:${JAVA_HOME}/bin:${JAVA_HOME}/jre/bin export PATH=${PATH}:/usr/local/maven/bin \"\u003e\u003e/etc/profile 修改Dockerfile配置文件，docker build成镜像 6.1 使用Tomcat服务打包启动容器 $ cat \u003e/opt/tomcat-java-demo/Dockerfile\u003c\u003c-EOF FROM lizhenliang/tomcat RUN rm -rf /usr/local/tomcat/webapps/* ADD target/*.war /usr/local/tomcat/webapps/ROOT.war # 声明时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026\u0026 echo 'Asia/Shanghai' \u003e/etc/timezone EOF 6.2 使用java -jar打包镜像，可以使用xxl-job的jar包 FROM openjdk VOLUME /tmp COPY ./target/live-server-1.0.0-SNAPSHOT.jar live-server-1.0.0-SNAPSHOT.jar RUN bash -c \"touch /live-server-1.0.0-SNAPSHOT.jar\" # 声明时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026\u0026 echo 'Asia/Shanghai' \u003e/etc/timezone # 声明运行时容器提供服务端口，运行时不会开启这个端口的服务，需要把端口映射 EXPOSE 8080 ENTRYPOINT [\"java\",\"-jar\",\"/live-server-1.0.0-SNAPSHOT.jar\"] 6.3 生成docker images：镜像并推送到私人仓库 -t,--tag list：镜像名称\n-f，--file string：如果文件名不是Dockerfile，-f可以指定其他文件\n192.168.80.210:8080：私人仓库地址\ntest：私人仓库名\ntomcat-demo:v1：定义镜像名称以及版本\n如果打包报错：epository does not exist,更换Dockerfile的FROM源地址\n$ cd /opt/tomcat-java-demo/ $ docker build -t 192.168.80.210:8080/test/tomcat-demo:v1 . # 打包镜像 $ docker push 192.168.80.210:8080/test/tomcat-demo:v1 # 推送到私人仓库 部署ELK日志服务 Kubernetes Elasticsearch Template模板 Kubernetes Logstash Template模板 Kubernetes Filebeat Template模板 Kubernetes Kibana Template模板 ",
    "description": "资源控制器 graph LR A[思维导图] --\u003eB[1.前言] A[思维导图] --\u003eC[2.Namespace] A[思维导图] --\u003eD[3.Deployment] A[思维导图] --\u003eE[4.",
    "tags": [],
    "title": "Kubernetes_Template",
    "uri": "/systems/linux/kubernetes/kubernetes_template/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "Kubernetes命令使用 名称地址 描述 Kubernetes官方命令文档 Kubernetes官方文档详解 Kube-shell kubectl获取资源名称、使用命令 kubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装和部署 kubectl api-resources是查看kubernetes资源命令 Kubernetes中所有的内容都抽象为资源，所有命令都是围绕资源操作、执行 资源分类 资源名称 缩写 描述 集群级别资源 nodes no 集群组成部分 集群级别资源 namespaces ns 隔离Pod Pods Pods po 装载容器 Pod资源控制器 replicationcontrollers rc 比较原始的Pod控制器，已经被废弃，由ReplicaSet替代 — replicasets rs 保证指定数量的Pod运行，并支持Pod数量变更，镜像版本变更 — deployments deploy 通过控制ReplicaSet来控制Pod，并支持滚动升级、版本回退 — daemonsets ds 在集群中的指定Node上都运行一个副本，一般用于守护进程类的任务 — jobs — 它创建出来的Pod只要完成任务就立即退出，用于执行一次性任务 — cronjobs cj 它创建的Pod会周期性的执行，用于执行周期性的任务 — horizontalpodautoscalers hpa 可以根据集群负载自动调整Pod的数量，实现削峰填谷 Pod资源控制器 statefulsets sts 管理有状态的应用 服务发现资源 services svc 统一Pod对外接口 服务发现资源 ingress ing 统一Pod对外接口 存储资源 volumeattachments — 存储 — persistentvolumes pv 存储 存储资源 persistentvolumeclaims pvc 存储 配置资源 configmaps cm 配置 配置资源 secrets — 配置 常用命令 命令 翻译 命令作用 — run 运行 在集群中运行一个指定的镜像 — get 获取 获取显示一个或多个资源 — set 设置 设置一个对象的特定特征 — create 创建 从文件或标准输入创建资源 — edit 编辑 编辑服务器上的资源 — patch 更新 更新一个资源，更新资源的字段 — apply 应用 通过文件名或标准输入将配置应用于资源 — replace 替换 用文件名或标准输入替换资源 — delete 删除 delete按文件名、标准输入、资源和名称，或按资源和标签选择器删除资源 — api-resources — 打印服务器上支持的API资源 — api-versions — 打印服务器上支持的API版本，格式为group/version 常用命令 version 版本 打印客户端和服务器版本信息 中级命令 命令 翻译 命令作用 — cp 复制 在Pod内外复制文件 — exec 执行 在容器中执行命令 — label 标签 更新资源上的标签 — logs 日志 打印pod中容器的日志 — attach 缠绕 进入运行中的容器、附加到正在运行的容器 — describe 描述 describe显示特定资源或资源组的详细信息 — expose 暴露 将复制控制器、服务、部署或pod暴露为新的Kubernetes服务Service — explain 解释 展示资源类型、属性文档，获取资源控制器字段使用 — annotate 注释 更新资源上的注释 — rollout 首次展示 管理资源的发布，查看、更新Pods版本发布 — scale 手动扩容、缩容 扩(缩)容Pod的数量,为Deployment、ReplicaSet或Replication Controller设置新的大小 — autoscale 监控CPU、内存自动扩容、缩容 自动调整Pod的数量，自动缩放Deployment、ReplicaSet、StatefulSet或ReplicationController — plugin — 提供与插件交互的实用程序 — taint 污点 taint节点上设置污点 中级命令 config — 修改kubeconfig文件 高级命令 命令 翻译 命令作用 — top 顶部显示资源（CPU/内存）使用情况 — auth 检查授权 — diff 对比 对比实时版本与将要应用的版本之间的差异 — wait 等待 等待实验：等待一个或多个资源的特定条件 proxy 代理 运行到Kubernetes API服务器的代理 cordon 警戒线 警戒线 将节点标记为不可调度 uncordon uncordon将节点标记为可调度 drain 排水 排水节点准备维护 completion 完成输出指定shell的shell完成代码（bash或zsh） certificate 证书 修改证书资源 cluster-info 集群信息 显示集群信息 port-forward 转发 将一个或多个本地端口转发到一个pod debug 调试 创建调试会话以对工作负载和节点进行故障排除 高级命令 kustomize 从目录或URL构建一个kustomization目标 品控级别(Track) 日期、时间 — 每天 daily — 每周 weekly — 常用命令：创建、删除 kubectl --help：可以通过--help查看详细的操作命令 kubectl命令的语法如下$ kubectl [command] [type] [name] [flags] command:\t指定要对资源执行的操作，比如：create、get、delete type：指定资源的类型，比如：deployment、pod、service name： 指定资源的名称，名称大小写敏感 flags： 指定额外的可选参数 kubectl run --help：命令使用镜像创建容器 $ kubectl run nginx --image=nginx:1.17.1 -n web kubectl get --help：获取资源，选择输出的格式 3.1 -o wide 3.2 -o json 3.3 -o yaml 3.4 Service可以看做是一组同类的Pod对外的访问接口，借助Service，应用可以方便的实现服务发现和负载均衡 $ kubectl get csr # 查看申请加入kubernetes集群的token信息 $ kubectl get endpoints # 获取service对应的所有pod的访问地址 $ kubectl get all --namespace=kube-system # 查看所有namespace下所有资源 $ kubectl get pods -n web -o wide -w # 查看namespace web下的pod，-o wide:查看更多信息，-w：动态查看 # 使用kubectl get命令导出yaml文件 $ kubectl get pod coredns-558bd4d5db-9h55s -n kube-system -o yaml \u003e /tmp/coredns-558bd4d5db-9h55s.yaml kubectl set --help更新镜像、设置一个对象的特定特征 $ kubectl set image deployment/web nginx=nginx1.15 kubectl create --help：创建命令用于创建资源 yaml文件详解、使用kubectl create命令生成yaml文件 deployment：无状态应用部署 java-demo：自定义名称 --image：使用镜像 --dry-run：测试 -o：输出 \u003e/tmp/deploy.yaml：定向输出到文件，不加\u003e/tmp/deploy.yaml 输出到屏幕查看 # 创建一个namespace命名空间 $ kubectl create namespace dev $ kubectl create deployment java-demo --image=192.168.80.210:8080/test/tomcat-demo:v1 --dry-run=client -o yaml \u003e/tmp/deploy.yaml $ kubectl create service clusterip ngx-dep --tcp=80:80 # 命令行创建service $ kubectl create -f ns-dev.yaml # 根据yaml文件创建资源 kubectl edit --help：cm：编辑configMap中的配置 # 修改service中的服务 $ kubectl edit service/ingress-nginx-controller-admission -n ingress-nginx $ kubectl edit cm kube-proxy -n kube-system # 修改ipvs(必须安装ipvs内核模块，否则会降级为iptables) 修改：mode: \"ipvs\" kubectl patch --help：补丁修改、更新资源的字段 $ kubectl patch pod rc-nginx-2-kpiqt -p '{\"metadata\":{\"labels\":{\"app\":\"nginx-3\"}}}' kubectl apply --help 如果资源不存在，就创建，相当于kubectl create 如果资源存在，就更新，相当于kubectl patch # 运行构建命令 $ kubectl apply -f ./ # 应用当前目录下所有yaml文件 $ kubectl apply -f deploy.yaml # K8S默认拉去GitHub上镜像 $ kubectl apply -f nginx-pod.yaml -n web --record kubectl replace --help：根据yaml文件更新修改后配置资源，会停掉原来的资源，重新创建 $ kubectl replace -f rc-nginx.yaml kubectl delete --help：删除 删除Terminating(正在终止)状态命名空间 $ kubectl delete svc/web $ kubectl delete -f deployment-nginx.yaml #删除该yaml中创建的资源 $ kubectl delete pod nginx-deployment-798444d598-87hlk -n web #删除pod资源 kubectl api-resources --help $ kubectl api-resources # 查看k8s所有的资源以及对应的apiversion $ kubectl api-versions # 查看k8s所有 版本号 中级命令：运行、调试 kubectl exec --help进入容器 $ kubectl exec -it nginx-deployment-798444d598-87hlk -n web -- /bin/sh $ kubectl exec my-pod -it -- ls /opt/ # 在已存在的容器中执行命令（只有一个容器的情况下） $ kubectl exec my-pod -c my-container -- ls / # 在已存在的容器中执行命令（pod中有多个容器的情况下） kubectl label --help：更新资源上的标签 标签Key Values 说明 release(发布) 版本：stable(稳定版)、canary(金丝雀版)、alpha(内测)、bate(公测) — environment(环境) 环境：dev(开发)、qa/test(测试)、gray(灰度)、production(生产)、op(运维)、ui,as,pc,sc(应用类(app)) — tier(层级) 层级：frontend(前端)、backend(后端)、cache(缓存) — partition(分区/模块) 分区/模块：customerA(业务A/客户A)、customerB(业务B/客户B) — version(版本号) 版本号：v1.1、v1.2 — 给节点Nodes打标签、删除标签 # 显示 Nodes 标签 $ kubectl get node --show-labels # 给 Nodes 节点打上，名字为：data 的标签 $ kubectl label nodes nodes_name data=labels_name # 删除 Nodes 上，名字为：data 的标签 $ kubectl label nodes nodes_name data- 给节点Pods打标签、删除标签 # 显示命名空间为：web 下 Pods 的标签 $ kubectl get pods --show-labels -n web -o wide # 为 Pods 打上，名字为：version 的标签 $ kucectl label pods pods_name version=1.0 -n web # 覆盖原来的标签：--overwrite $ kucectl label pods pods_name version=2.0 --overwrite -n web # 删除 Pods 上，名字为：version 的标签 $ kucectl label pods pods_name version- -n web kubectl describe --help显示资源内部信息 $ kubectl describe namespace kube-system Name: kube-system Labels: kubernetes.io/metadata.name=kube-system Annotations: \u003cnone\u003e Status: Active # 表示正在使用中，Terminating:表示正在删除命名空间 No resource quota. # 表示：针对命名空间做的资源限制 No LimitRange resource. # 表示：针对命名空间中的每个组件做的资源限制 $ kubectl describe pods -n web nginx-pod # 查看pod 的详细信息 $ kubectl describe service -n web nginx-svc # 查看service的 详细信息 $ kubectl describe node 192.168.3.125 # 查看node的详细信息 kubectl logs --help日志查看 $ kubectl logs -n web nginx-deployment-798444d598-87hlk # 查看pod日志 $ kubectl logs -f nginx-deployment-798444d598-87hlk -n web # 实时查看日志 $ kubectl log nginx-deployment-798444d598-87hlk -c \u003ccontainer_name\u003e -n web # 查看pod中单个容器的日志 $ kubectl logs -l app=frontend -n web # 返回全部标记为 app=frontend 的 pod 的合并日志 kubectl expose --help端口暴露 expose端口设置固定选项 java-demo： 自定义名称 --port：Pod的Service服务端口，集群内部互通端口 --target-port：Pod容器内服务端口端口 --type：随机生成外部访问端口 \u003ejava-demo-svc.yaml：定向输出到文件，不加\u003ejava-demo-svc.yaml输出到屏幕查看 $ kubectl expose --help $ kubectl expose deployment java-demo --port=80 --target-port=8080 --type=NodePort --dry-run=client -o yaml \u003ejava-demo-svc.yaml $ kubectl apply -f java-demo-svc.yaml # 对外发布允许外网访问 $ kubectl expose deployment web --port=80 --type=NodePort --target-port=80 --name=web $ kubectl get service $ kubectl get deploy # PORT(S):80(集群内部互通端口)、30040/TCP(外部访问端口) $ kubectl get pods,svc NAME READY STATUS RESTARTS AGE pod/java-demo-56d54df448-2m8kr 1/1 Running 0 68m pod/java-demo-56d54df448-9k5dn 1/1 Running 0 68m pod/java-demo-56d54df448-wvqkf 1/1 Running 0 68m pod/nginx-6799fc88d8-5sxfn 1/1 Running 0 3h4m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/java-demo NodePort 10.103.37.12 \u003cnone\u003e 80:30040/TCP 105s service/kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 4h35m service/nginx NodePort 10.106.61.55 \u003cnone\u003e 80:31750/TCP 3h4m kubectl explain --help：展示资源使用文档 $ kubectl explain pod.kind.replicasets # 查看某种资源可以配置的一级配置如：pod、deployment $ kubectl explain pod.metadata # 查看资源的子属性，资源类型：pod、属性：metadata $ kubectl explain pod.spec # nodes $ kubectl explain pod.spec.nodeName.containers $ kubectl explain pod.spec.nodeSelector.containers kubectl rollout --help：管理资源 status：显示当前升级状态 history：显示升级历史记录 pause：暂停版本升级过程 resume：继续已经暂停的版本升级过程 restart：重启版本升级过程 undo：回滚到上一级版本(可以使用--to-revision，指定版本) --record：记录CHANGE-CAUSE(改变原因)操作记录,便于回滚 # 更新发布 $ kubectl apply -f nginx-deployment.yml --record # --record，记录操作记录,便于回滚 # pause 暂定更新发布 $ kubectl rollout pause deployment nginx-deployment -n app # resume 继续更新发布 $ kubectl rollout resume deployment nginx-deployment -n app # 查看升级状态 $ kubectl rollout status deployment/nginx-deployment # 查看升级历史版本 $ kubectl rollout history deployment/web $ kubectl rollout history deployment -n app $ kubectl rollout history deployment/web --revision=2 # 查看某个更新具体内容 # 回滚 $ kubectl rollout undo deployment/web --revision=2 $ kubectl rollout undo deployment/nginx-deployment --to-revision=1 -n app # 版本回滚到v1 kubectl scale --help：手动扩缩容Pod数量 --replicas：参数定义Pod数量 $ kubectl scale rc redis --replicas=3 -n web # 操作pod 的扩容和缩容 $ kubectl scale --replicas=2 -f redis-slave-deployment.yaml kubectl autoscale --help：监控CPU使用百分比自动扩缩Pod数量 deployment：类型控制器 deployment-name：Pod的名称 --cpu-percent：使用CPU百分比 --min：Pod最少数量 --max：Pod最多数量 $ kubectl autoscale deployment deployment-name --cpu-percent=60 --min=2 --max=10 kubectl taint --help：污点配置 查看节点上的污点 $ kubectl describe nodes k8s-node1 | grep Taints 设置污点 tag=webapps、tag：污点名称，可以自定义，依Key=value NoSchedule：影响，不会调度到此节点 NoExecute：驱除，把此节点上的Pods驱除到其他节点 $ kubectl taint node k8s-node1 tag=webapps:NoSchedule 去除污点 -：污点名称后面跟减号就是去除污点意思 $ kubectl taint node k8s-master-01 node-role.kubernetes.io/control-plane:NoSchedule- node/k8s-master-01 untainted # 返回结果 污点已去除 # 去除以 tag 为名设置的所有污点 $ kubectl taint node k8s-node1 tag- 高级命令：管理、排查 名称地址 描述 Kubernetes指标服务器 安装Prometheus监控服务器资源 kubectl top --help：监控集群内存CPU指标 metrics-server可以用来收集集群中的资源使用情况、需要单独安装 新增参数：hostNetwork: true，用于使用宿主机网络 国内修改为阿里云地址：image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6 新增参数：- --kubelet-insecure-tls，不验证客户端证书，仅用于测试目的，kubelet的10250端口使用的是https协议，连接需要验证tls证书 $ wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml -O metrics-server.yaml # 替换为阿里云镜像地址 $ sed -i 's/k8s.io\\/metrics-server/cn-hangzhou.aliyuncs.com\\/google_containers/g' metrics-server.yaml 修改metrics-server.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: hostNetwork: true # 新增参数，使用宿主机网络 containers: - args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname - --kubelet-use-node-status-port - --metric-resolution=15s - --kubelet-insecure-tls # 新增参数，不校验https协议 image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.6.4 imagePullPolicy: IfNotPresent$ kubectl apply -f metrics-server.yaml $ kubectl top node --use-protocol-buffers $ kubectl top pod/node -n dev kubectl port-forward --help转发Pod中端口 $ kubectl port-forward my-pod 5000:6000 # 转发pod中的6000端口到本地的 5000 端口 故障排查、解决 nodes节点显示NotReady是节点之间网络不通导致 查看集群健康状况 $ kubectl get cs $ kubectl cluster-info # 使用镜像测试容器命令 $ kubectl run -it --image busybox:1.28.4 container-name --restart=Never --rm /bin/sh $ ping pod-name.server-name 先处理网络、后处理配置文件 $ vim /etc/kubernetes/manifests/kube-controller-manager.yaml （注释掉 - --port=0） $ vim /etc/kubernetes/manifests/kube-scheduler.yaml （注释掉 - --port=0） $ systemctl start kubelet 2.1 再次查看，节点正常显示： Ready 重置Kubernetes集群 # 在master、node节点都执行以下命令 $ kubeadm reset $ rm -rf /etc/cni/net.d # 在master上执行 $ kubeadm init --kubernetes-version=1.19.0 --apiserver-advertise-address=192.168.3.124 --service-cidr=10.64.0.0/24 --pod-network-cidr=10.244.0.0/16 $ mkdir -p $HOME/.kube $ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ chown $(id -u):$(id -g) $HOME/.kube/config $ vim /etc/kubernetes/manifests/kube-controller-manager.yaml （注释掉 - --port=0） $ vim /etc/kubernetes/manifests/kube-scheduler.yaml （注释掉 - --port=0） $ systemctl start kubelet # 在node节点执行 $ kubeadm reset $ kubeadm join 192.168.3.124:6443 --token f62e1g.exfdrr8bg2fxpdmu \\ --discovery-token-ca-cert-hash sha256:7e4762cccce2e8306b6635cbc2091eae34bbf33577276413521a343c49fc026a ",
    "description": "Kubernetes命令使用 名称地址 描述 Kubernetes官方命令文档 Kubernetes官方文档详解 Kube-shell kubectl获取资源名称、使用命令 kubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装和部署 kubectl api-resources是查看kubernetes资源命令 Kubernetes中所有的内容都抽象为资源，所有命令都是围绕资源操作、执行 资源分类 资源名称 缩写 描述 集群级别资源 nodes no 集群组成部分 集群级别资源 namespaces ns 隔离Pod Pods Pods po 装载容器 Pod资源控制器 replicationcontrollers rc 比较原始的Pod控制器，已经被废弃，由ReplicaSet替代 — replicasets rs 保证指定数量的Pod运行，并支持Pod数量变更，镜像版本变更 — deployments deploy 通过控制ReplicaSet来控制Pod，并支持滚动升级、版本回退 — daemonsets ds 在集群中的指定Node上都运行一个副本，一般用于守护进程类的任务 — jobs — 它创建出来的Pod只要完成任务就立即退出，用于执行一次性任务 — cronjobs cj 它创建的Pod会周期性的执行，用于执行周期性的任务 — horizontalpodautoscalers hpa 可以根据集群负载自动调整Pod的数量，实现削峰填谷 Pod资源控制器 statefulsets sts 管理有状态的应用 服务发现资源 services svc 统一Pod对外接口 服务发现资源 ingress ing 统一Pod对外接口 存储资源 volumeattachments — 存储 — persistentvolumes pv 存储 存储资源 persistentvolumeclaims pvc 存储 配置资源 configmaps cm 配置 配置资源 secrets — 配置 常用命令 命令 翻译 命令作用 — run 运行 在集群中运行一个指定的镜像 — get 获取 获取显示一个或多个资源 — set 设置 设置一个对象的特定特征 — create 创建 从文件或标准输入创建资源 — edit 编辑 编辑服务器上的资源 — patch 更新 更新一个资源，更新资源的字段 — apply 应用 通过文件名或标准输入将配置应用于资源 — replace 替换 用文件名或标准输入替换资源 — delete 删除 delete按文件名、标准输入、资源和名称，或按资源和标签选择器删除资源 — api-resources — 打印服务器上支持的API资源 — api-versions — 打印服务器上支持的API版本，格式为group/version 常用命令 version 版本 打印客户端和服务器版本信息 中级命令 命令 翻译 命令作用 — cp 复制 在Pod内外复制文件 — exec 执行 在容器中执行命令 — label 标签 更新资源上的标签 — logs 日志 打印pod中容器的日志 — attach 缠绕 进入运行中的容器、附加到正在运行的容器 — describe 描述 describe显示特定资源或资源组的详细信息 — expose 暴露 将复制控制器、服务、部署或pod暴露为新的Kubernetes服务Service — explain 解释 展示资源类型、属性文档，获取资源控制器字段使用 — annotate 注释 更新资源上的注释 — rollout 首次展示 管理资源的发布，查看、更新Pods版本发布 — scale 手动扩容、缩容 扩(缩)容Pod的数量,为Deployment、ReplicaSet或Replication Controller设置新的大小 — autoscale 监控CPU、内存自动扩容、缩容 自动调整Pod的数量，自动缩放Deployment、ReplicaSet、StatefulSet或ReplicationController — plugin — 提供与插件交互的实用程序 — taint 污点 taint节点上设置污点 中级命令 config — 修改kubeconfig文件 高级命令 命令 翻译 命令作用 — top 顶部显示资源（CPU/内存）使用情况 — auth 检查授权 — diff 对比 对比实时版本与将要应用的版本之间的差异 — wait 等待 等待实验：等待一个或多个资源的特定条件 proxy 代理 运行到Kubernetes API服务器的代理 cordon 警戒线 警戒线 将节点标记为不可调度 uncordon uncordon将节点标记为可调度 drain 排水 排水节点准备维护 completion 完成输出指定shell的shell完成代码（bash或zsh） certificate 证书 修改证书资源 cluster-info 集群信息 显示集群信息 port-forward 转发 将一个或多个本地端口转发到一个pod debug 调试 创建调试会话以对工作负载和节点进行故障排除 高级命令 kustomize 从目录或URL构建一个kustomization目标 品控级别(Track) 日期、时间 — 每天 daily — 每周 weekly — 常用命令：创建、删除 kubectl --help：可以通过--help查看详细的操作命令 kubectl命令的语法如下$ kubectl [command] [type] [name] [flags] command:\t指定要对资源执行的操作，比如：create、get、delete type：指定资源的类型，比如：deployment、pod、service name： 指定资源的名称，名称大小写敏感 flags： 指定额外的可选参数 kubectl run --help：命令使用镜像创建容器 $ kubectl run nginx --image=nginx:1.",
    "tags": [],
    "title": "Kubernetes_Command",
    "uri": "/systems/linux/kubernetes/kubernetes_command/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "部署Kubernetes Etcd：负责存储集群中各种资源对象的信息\nKubelet：负责维护容器的生命周期，即通过控制Docker，来创建、更新、销毁容器\nKubeProxy：负责提供集群内部的服务发现和负载均衡\nDocker：负责节点上容器的各种操作\nScheduler：负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nAPI Server：集群操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nControllerManager：负责维护集群的状态，比如程序部署安排、故障检测、自动扩展和滚动更新等\nCore DNS：可以为集群中的SVC创建一个域名IP的对应关系解析\nDashboard：给K8S集群提供一个B/S结构的体系访问\nIngress Controller：官方只能实现四层代理，Ingress可以实现七层代理\nFedetation：提供一个可以跨集群中心的多K8S统一管理功能\nPrometheus：提供一个K8S集群监控能力\nELK：提供K8S集群日志统一分析介入平台\nK8S部署方式分为二进制以及快速部署方式，官方给予三种快速部署方式：使用kubeadm引导集群、使用Kops安装Kubernetes、使用Kubespray安装Kubernetes\n名称地址 描述 KubeWharf轻量级多租户 Kubernetes性能测试 kubernetes排错思维 Ansible-playbook使用kubespray安装K8S 服务器、端口准备 部署一主三从kubernetes架构 graph TD F[一主多从] A{{K8S-Master}} ==\u003e B{{K8S-Nodes}} A{{K8S-Master}} ==\u003e C{{K8S-Nodes}} A{{K8S-Master}} ==\u003e D{{K8S-Nodes}} Z[多主多从] G{{K8S-Master}} ==\u003e J{{K8S-Nodes}} G{{K8S-Master}} ==\u003e K{{K8S-Nodes}} G{{K8S-Master}} ==\u003e L{{K8S-Nodes}} H{{K8S-Master}} ==\u003e J{{K8S-Nodes}} H{{K8S-Master}} ==\u003e K{{K8S-Nodes}} H{{K8S-Master}} ==\u003e L{{K8S-Nodes}} 角色 IP地址 配置 操作系统 Master 192.168.35.128 2core、4G、80Gdisk CentOS Linux release 7.9.2 node-1 192.168.35.129 2core、1G、60Gdisk CentOS Linux release 7.9.2 node-2 192.168.35.130 2core、1G、60Gdisk CentOS Linux release 7.9.2 集群架构 角色 IP地址 配置 操作系统 Master-1 192.168.80.210 2core、4G、80Gdisk CentOS Linux release 7.9.2 Master-2 192.168.80.211 2core、4G、80Gdisk CentOS Linux release 7.9.2 node-1 192.168.80.212 2core、2G、60Gdisk CentOS Linux release 7.9.2 node-2 192.168.80.213 2core、2G、60Gdisk CentOS Linux release 7.9.2 node-3 192.168.80.215 2core、2G、60Gdisk CentOS Linux release 7.9.2 控制节点master：集群的控制平面，负责集群的决策，以及需要开放的端口 协议 方向 端口范围 作用 使用者 TCP 入站 6443 Kubernetes API 服务器 所有组件,管理员操作Kubernetes的接口。因此，API服务器通常暴露在控制平面之外。API服务器被设计成可扩展的，可能存在于多个控制平面节点上 TCP 入站 2379-2380 etcd服务器客户端 API kube-apiserver, etcd，持久化的备份存储，关于集群状态的所有信息都保存在这里。Etcd不应该被直接操作，而应该通过 API 服务器来管理。 TCP 入站 10250 Kubelet API kubelet自身、在每个工作节点上运行，以协调和验证Pod的执行 TCP 入站 10259 kube-scheduler kube-scheduler自身，跟踪工作节点的状态并决定在哪里运行 Pod。Kube-scheduler 只可以由控制平面内的节点访问。 TCP 入站 10257 kube-controller-manager kube-controller-manager自身，监视Kubernetes集群，以检测和维护Kubernetes环境的几个方面，包括将Pod加入到服务中，保持一组Pod的正确数量，并对节点的丢失做出反应 TCP 入站 10258 Cloud controller manager 一个用于基于云的部署的可选组件。云控制器与云服务提供商接口，以管理集群的负载均衡器和虚拟网络 工作节点node：集群的数据平面，负责为容器提供运行环境 ，需要开放的端口 协议 方向 端口范围 作用 使用者 TCP 入站 10250 Kubelet API kubelet自身、控制平面组件 TCP 入站 30000-32767 NodePort服务† 所有组件 初始化环境 设置三台主机名 $ hostnamectl set-hostname k8s-master-128 $ hostnamectl set-hostname k8s-node-01-129 $ hostnamectl set-hostname k8s-node-02-130 设置集群的主机名 $ hostnamectl set-hostname k8s-master-1-80-210 $ hostnamectl set-hostname k8s-master-2-80-211 $ hostnamectl set-hostname k8s-node-1-80-212 $ hostnamectl set-hostname k8s-node-2-80-213 $ hostnamectl set-hostname k8s-node-3-80-215 分别在三台服务器做本地hosts解析 $ cat \u003e\u003e/etc/hosts\u003c\u003c-EOF 192.168.35.128 k8s-master-01 192.168.35.129 k8s-node-01 192.168.35.130 k8s-node-02 EOF 五台服务器的集群hosts配置 $ cat \u003e\u003e/etc/hosts\u003c\u003c-EOF 192.168.80.210 k8s-master-01 192.168.80.211 k8s-master-02 192.168.80.212 k8s-node-01 192.168.80.213 k8s-node-02 192.168.80.215 k8s-node-03 192.168.80.220 k8s-master-lb # VIP(虚拟IP)用于LoadBalance，如果不是高可用集群，该IP可以是k8s-master01的IP EOF 设置时间同步，修改时区两种方式 安装tzdata时区软件包 $ yum -y install tzdata $ timedatectl set-timezone Asia/Shanghai 第一种 $ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 第二种 $ systemctl enable chronyd.service \u0026\u0026 systemctl start chronyd.service 关闭防火墙并禁止开机自启 $ systemctl disable firewalld \u0026\u0026 systemctl stop firewalld 关闭SElinux $ setenforce 0 # 临时关闭Selinux $ sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config # 永久关闭Selinux 关闭swap交换分区 $ sed -ri 's/.*swap.*/#\u0026/' /etc/fstab \u0026\u0026 swapoff -a Ubunt关闭交换分区 $ cat \u003eetc/fstab\u003c\u003c-EOF /dev/disk/by-uuid/95e38332-76fc-4d2f-81a4-04bc581f2ed3 none swap sw,noauto 0 0 # 添加：noauto # /swap.img none swap sw 0 0 # 添加注释 EOF # 查询验证，输出为空则生效 $ sudo swapon --show 允许iptables检查桥接流量 确保br_netfilter模块被加载。这一操作可以通过运行lsmod | grep br_netfilter来完成。若要显式加载该模块，可执行modprobe br_netfilter 为了让你的Linux节点上的iptables能够正确地查看桥接流量，你需要确保在你的sysctl配置中将net.bridge.bridge-nf-call-iptables设置为 1 $ cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF $ cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF $ sysctl --system ########################################################## 使用脚本函数 __k8s_kernel_iptables() { # 加载br_netfilter模块 modprobe br_netfilter # 查看是否加载 lsmod | grep br_netfilter # 写内核配置文件 cat \u003e/etc/sysctl.d/k8s.conf \u003c\u003cEOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 vm.swappiness = 0 EOF # 内核参数生效 sysctl --system } __k8s_kernel_iptables 开启ipvs 在kubernetes中service有两种代理模型，一种是基于iptables，另一种是基于ipvs的。ipvs的性能要高于iptables的，但是如果要使用它，需要手动载入ipvs模块。 Centos系统在每个节点安装配置ipset和ipvsadm $ yum -y install ipset ipvsadm # 在所有节点执行如下脚本 $ cat \u003e/etc/sysconfig/modules/ipvs.modules\u003c\u003c-EOF ##!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 # 高版本替换为nf_conntrack EOF # 授权、运行、检查是否加载 $ chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026\u0026 bash /etc/sysconfig/modules/ipvs.modules # 检查是否加载 $ lsmod | grep -e ipvs -e nf_conntrack_ipv4 Debian系统在每个节点安装配置ipset和ipvsadm $ mkdir -vp /etc/modules.d/ $ tee /etc/modules.d/k8s.modules \u003c\u003c'EOF' #!/bin/bash # netfilter 模块 允许 iptables 检查桥接流量 modprobe -- br_netfilter # containerd modprobe -- overlay # nf_conntrack modprobe -- nf_conntrack # ipvs modprobe -- ip_vs modprobe -- ip_vs_lc modprobe -- ip_vs_lblc modprobe -- ip_vs_lblcr modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- ip_vs_dh modprobe -- ip_vs_fo modprobe -- ip_vs_nq modprobe -- ip_vs_sed modprobe -- ip_vs_ftp modprobe -- ip_tables modprobe -- ip_set modprobe -- ipt_set modprobe -- ipt_rpfilter modprobe -- ipt_REJECT modprobe -- ipip modprobe -- xt_set EOF $ chmod 755 /etc/modules.d/k8s.modules \u0026\u0026 bash /etc/modules.d/k8s.modules \u0026\u0026 lsmod | grep -e ip_vs -e nf_conntrack # ip_vs_sh 16384 0 # ip_vs_wrr 16384 0 # ip_vs_rr 16384 0 # ip_vs 155648 6 ip_vs_rr,ip_vs_sh,ip_vs_wrr # nf_conntrack 139264 1 ip_vs # nf_defrag_ipv6 24576 2 nf_conntrack,ip_vs # nf_defrag_ipv4 16384 1 nf_conntrack # libcrc32c 16384 5 nf_conntrack,btrfs,xfs,raid456,ip_vs $ sysctl --system 所有节点配置Limit $ ulimit -SHn 65536 # 临时生效 $ echo \" * soft nproc 65535 # soft 软限制 * hard nproc 65535 # hard 硬限制 * soft nofile 25535 * hard nofile 25535 * soft memlock unlimited * soft memlock unlimited \" \u003e\u003e/etc/security/limits.conf # 永久生效 k8s-master01节点设置免密登录其他节点 ssh-keygen：用于创建密钥的程序 -m PEM：将密钥的格式设为PEM -t rsa：创建密钥类型为：RSA格式，系统默认提供名为 id_rsa 的密钥对，有些工具可能要求私钥文件名为id_rsa -b 4096：密钥的位数，本例中为4096 -C \"xxx@myserver\"：追加到公钥文件末尾以便于识别的注释。 通常以电子邮件地址用作注释，但也可以使用任何最适合你基础结构的事物 -f ~/.ssh/：私钥文件的文件名（如果选择不使用默认名称）。 追加了.pub的相应公钥文件在相同目录中生成。 该目录必须存在 -N mypassphrase：用于访问私钥文件的其他密码 $ ssh-keygen \\ -m PEM \\ -t rsa \\ -b 4096 \\ -C \"xxx@163.com\" \\ -f ~/.ssh/name_rsa \\ -N mypassphrase $ for i in master-01 master-02 noder-01 noder-02 noder-03;do ssh-copy-id -i .ssh/id_rsa.pub $i;done 所有节点更新系统并且重启 $ yum -y --exclude=kernel* update \u0026\u0026 reboot 升级系统Kernel内核到4.18+以上 $ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org $ rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm # 令列出可用的内核相关包 $ yum --disablerepo=\"*\" --enablerepo=\"elrepo-kernel\" list available # 安装最新主线稳定内核 $ yum -y --enablerepo=elrepo-kernel install kernel-ml # 设置 GRUB 默认的内核版本： $ vim /etc/default/grub GRUB_DEFAULT=0 # 修改部分， GRUB 初始化页面的第一个内核将作为默认内核 # 重新创建内核配置 $ grub2-mkconfig -o /boot/grub2/grub.cfg $ reboot 所有节点都安装docker yum源的使用 使用官方源 $ yum install -y yum-utils $ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 使用阿里云官方repo源 # 备份服务器上原有的CentOS-Base和epel $ mv /etc/yum.repos.d/CentOS-Base.repo{,.bak} $ mv /etc/yum.repos.d/epel.repo{,.bak} # 安装CentOS0-Base和epel源 $ curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # 第一种方式安装docker 源 $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo # 第二种方式docker源 $ yum install -y yum-utils device-mapper-persistent-data lvm2 $ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 做替换 $ sed -i 's+download.docker.com+mirrors.aliyun.com/docker-ce+' /etc/yum.repos.d/docker-ce.repo 卸载服务器自带docker $ yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine 安装对应docker版本服务 $ yum makecache fast $ yum list docker-ce --showduplicates|sort -r $ yum install -y docker-ce-20.10.4 docker-ce-cli-20.10.4 containerd.io docker-compose-plugin $ systemctl enable docker \u0026\u0026 systemctl start docker 安装docker-compose $ sudo curl -L \"https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose $ ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose $ docker compose COMMAND --help # 查看镜像编写方式 Kubernetes文件驱动默认由systemd改成cgroupfs, 而我们安装的docker使用的文件驱动是systemd, 造成不一致, 导致镜像无法启动 \"exec-opts\": [\"native.cgroupdriver=systemd\"] $ sudo cat \u003e/etc/docker/daemon.json\u003c\u003c-EOF { \"registry-mirrors\": [\"https://bn4ll166.mirror.aliyuncs.com\"], \"data-root\": \"/data/docker-root\", \"dns\": [\"223.5.5.5\",\"119.29.29.29\"], \"bip\": \"172.31.255.254/16\", \"storage-driver\": \"overlay2\", \"storage-opts\": [\"overlay2.override_kernel_check=true\"], \"userland-proxy\": false, \"log-driver\": \"json-file\", \"log-opts\": {\"max-size\": \"500m\",\"max-file\": \"1\"}, \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"live-restore\": true } EOF Docker+Kubernetes 所有节点配置kubernetes yum源 国内修改为阿里云yum源 $ cat \u003e/etc/yum.repos.d/kubernetes.repo\u003c\u003c-EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 直接使用kubernetes官方yum源 $ cat \u003c\u003c-EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF 重启所有节点服务器 $ reboot 所有节点都安装kubeadm、kubelet、kubectl $ yum list kubelet kubeadm kubectl --showduplicates | sort -r $ yum -y install kubelet-1.24.5 kubeadm-1.24.5 kubectl-1.24.5 --cgroup-driver=systemd：为了实现Docker使用的cgroup drvier和kubelet使用的cgroup默认值为一致，/etc/sysconfig/kubelet文件中添加 --fail-swap-on=false忽略swap报错 --feature-gates EphemeralContainers=true开启临时容器参数 $ kubelet -h | grep EphemeralContainers$ cat \u003e/etc/sysconfig/kubelet\u003c\u003c-EOF KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd --fail-swap-on=false\" KUBE_PROXY_MODE=\"ipvs\" EOF 置为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动 $ systemctl enable kubelet \u0026\u0026 systemctl start kubelet 使用Kubeadm部署Kubernetes 查看下载所需镜像 查看k8s所需镜像kubeadm config images list $ kubeadm config images list # list替换：pull、拉取镜像 k8s.gcr.io/kube-apiserver:v1.24.6 k8s.gcr.io/kube-controller-manager:v1.24.6 k8s.gcr.io/kube-scheduler:v1.24.6 k8s.gcr.io/kube-proxy:v1.24.6 k8s.gcr.io/pause:3.7 k8s.gcr.io/etcd:3.5.3-0 k8s.gcr.io/coredns/coredns:v1.8.6 $ docker images --digests # 验证镜像完整性 下载K8S所需镜像 (如果过程中有提示失败迹象, 那么可能是网络原因, 多执行几次) $ kubeadm config images list | xargs -n1 docker pull # 指定拉取阿里云源的镜像 $ kubeadm config images pull --kubernetes-version=v1.20.2 --image-repository=registry.aliyuncs.com/google_containers 部署master节点 两种方式部署Master节点：命令行和**yaml** **注意：**主机名中不能带有_（下划线），不然初始化会报错kubeadm init 使用命令行方式初始化Kubernetes --kubernetes-version：指定版本 --apiserver-advertise-address：master本机IP --service-cidr：用于指定为Service分配使用网络地址，它由kubernetes管理，默认网段：10.96.0.0/12 --pod-network-cidr：启动容器给容器所分配IP，ip a可以查看服务器本机生成IP段，当有从集群外节点通过静态路由方式访问集群内Service的需求时，需要在创建集群时指定pod-network-cidr， 以对来自非Pod网络的流量(外部流量)执行MASQ，外部访问pod服务做nat转发,它通常应该与部署使用的网络插件(例如：flannel、calico)默认设定保持一致，10.244.0.0/16是flannel默认使用网络 --ignore-preflight-errors=Swap：通过此参数忽略swap报错 --image-repository registry.aliyuncs.com/google_containers：指定从阿里云下载 --cri-socket：配置CRI端点 $ kubeadm init --kubernetes-version=v1.24.6 \\ --apiserver-advertise-address=192.168.35.128 --node-name=k8s-master \\ --service-cidr=10.64.0.0/12 --pod-network-cidr=10.244.0.0/16 \\ --cri-socket unix:///var/run/containerd/containerd.sock # 配置 CRI 端点 通过配置文件初始化Kubernetes的master节点 # 输出初始化配置到文件 $ kubeadm config print init-defaults \u003e/opt/k8s/yaml/kubeadm-config.yaml # 修改配置文件 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 # 修改为master本机IP bindPort: 6443 # 使用端口 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock # 配置 CRI 端点 imagePullPolicy: IfNotPresent name: node # 配置主机名， 主机名不允许使用下划线 taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io # 定义使用镜像源 ## imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像源 kind: ClusterConfiguration kubernetesVersion: 1.24.6 # 定义kubernetes版本 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 # 10.244.0.0/16 是`flannel`默认使用网络 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration featureGates: SupportIPVSProxyMode: true mode: ipvs # 启用ipvs $ kubeadm init --config=/opt/k8s/yaml/kubeadm-config.yaml # 初始化配置文件 如果初始化报错执行下面命令、然后重新初始化 ############################################################# 配置containerd服务 $ rm -rf /etc/containerd/config.toml $ containerd config default \u003e/etc/containerd/config.toml # 生成新配置来覆盖默认配置 $ sudo cat \u003e\u003e/etc/containerd/config.toml\u003c\u003c-EOF [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = false # 修改为：true EOF $ systemctl restart containerd ############################################################# kubelet 配置文件修改 $ sudo cat \u003e\u003e/var/lib/kubelet/kubeadm-flags.env\u003c\u003c-EOF KUBELET_KUBEADM_ARGS=\"--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.9\" EOF # 启动配置增加--container-runtime=remote --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock $ sudo cat \u003e\u003e/usr/lib/systemd/system/kubelet.service\u003c\u003c-EOF ExecStart=/usr/bin/kubelet --container-runtime=remote --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock EOF ############################################################## 删除配置重载 $ swapoff -a \u0026\u0026 kubeadm reset \\ \u0026\u0026 systemctl daemon-reload \\ \u0026\u0026 systemctl restart kubelet \\ \u0026\u0026 iptables -F \u0026\u0026 iptables -t nat -F \\ \u0026\u0026 iptables -t mangle -F \u0026\u0026 iptables -X 查看node信息 $ kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready control-plane,master 23h v1.21.12 k8s-node1 Ready \u003cnone\u003e 23h v1.21.12 k8s-node2 Ready \u003cnone\u003e 23h v1.21.12 根据提示消息，在Master节点上使用kubectl工具，可以把下列.kube目录同步到node节点，以便node节点使用kubectl工具 注意：如果不执行以下命令，执行kubectl get nodes命令报错：couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused $ mkdir -p $HOME/.kube $ cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config $ chown $(id -u):$(id -g) ${HOME}/.kube/config $ scp -r /root/.kube root@k8s-node-01:/root/ node节点加入集群 当主节点启动完k8s之后会生成加入节点的命令，视自己服务器而定 $ kubeadm join 192.168.35.128:6443 --token l37r7y.75gjs1ltufdp8kp2 \\ --discovery-token-ca-cert-hash sha256:9ebc670ec3f97b5f42d77908f378786ed806ef22e9ae2cf21fe5fb239483833c 默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下： $ kubeadm token list # 查看Token $ kubeadm token create --print-join-command $ kubeadm token create --ttl 0 --print-join-command # 生成一个永不过期的token # 重新获取sha56key $ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outfrom der 2\u003edev/null | openssl dgst -sha256 -hex | sed 's/^.* //' master执行命令查看节点是否已加入 $ kubectl get componentstatuses # 查看集群健康状况，缩写为：cs NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\"health\":\"true\"} 查看部署好的命名空间 default：所有未指定的Namespace的对象都会被分配在default命名空间 kube-node-lease：集群节点之间的心跳维护，v1.13开始引入 kube-public：此命名空间的资源可以被所有人访问（包括未认证用户） kube-system：所有由kubernetes系统创建的资源都处于这个命名空间 $ kubectl get namespace # 缩写为： ns NAME STATUS AGE default Active 19h kube-node-lease Active 19h kube-public Active 19h kube-system Active 19h 处理集群状态：STATUS：NotReady是网络不通部署：CNI网络插件 名称地址 描述 网络：Flannel、Calico、Canal和Weave 简单聊聊Calico与Flannel kubernetes支持多种网络插件，比如flannel、calico、canal等，任选一种即可，本次选择flannel，当然你也可以安装calico，推荐安装calico 在Master节点上获取flannel配置文件(可能会失败，如果失败，请下载到本地，然后安装)： flannel、calico：基于隧道 隧道方案最具普适性，在任何网络环境下都可以正常工作，这与它的原理密不可分。 最常见的隧道方案是flannel \"Type\": \"vxlan\"模式，以及calico的ipip模式， flannel、calico：基于路由 路由方案性能最好，原因是该方案不需要封包和解包，所以没有隧道方案的劣势，网络性能很好。 常见的路由方案包括了flannel的\"Type\": \"host-gw\"模式，以及calico的bgp模式。 master节点执行一下语句安装calico网络插件 $ curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml -O # 看情况修改 calico配置文件 $ cat \u003ecalico.yaml\u003c\u003c-EOF - name: CALICO_IPV4POOL_CIDR # 修改 CALICO_IPV4POOL_CIDR对应的参数 value: \"192.168.1.0/24\" # 修改为 --pod-network-cidr 对应的网段 EOF # 修改calico 镜像地址 $ grep image calico.yaml $ sed -i 's#docker.io/##g' calico.yaml $ kubectl apply -f calico.yaml master节点执行一下语句安装flannel网络插件 $ wget -P /opt/k8s/yaml/ https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml $ kubectl get pods -n kube-system kubernetes中kubectl命令自动补全 $ yum install -y bash-completion $ source /etc/profile.d/bash_completion.sh 集群不健康 需要注释掉etc/kubernetes/manifests目录下的kube-controller-manager.yaml和kube-scheduler.yaml的--port=0：\n修改kube-controller-manager.yaml文件\n$ sudo cat \u003e\u003e/etc/kubernetes/manifests/kube-controller-manager.yaml\u003c\u003c-EOF spec: containers: - command: - kube-controller-manager - --allocate-node-cidrs=true - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf - --bind-address=127.0.0.1 - --client-ca-file=/etc/kubernetes/pki/ca.crt - --cluster-cidr=10.244.0.0/16 - --cluster-name=kubernetes - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key - --controllers=*,bootstrapsigner,tokencleaner - --kubeconfig=/etc/kubernetes/controller-manager.conf - --leader-elect=true # 修改部分 # - --port=0 - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt - --root-ca-file=/etc/kubernetes/pki/ca.crt - --service-account-private-key-file=/etc/kubernetes/pki/sa.key - --service-cluster-ip-range=10.96.0.0/12 - --use-service-account-credentials=true EOF 修改kube-scheduler.yaml文件 $ sudo cat \u003e\u003e/etc/kubernetes/manifests/kube-scheduler.yaml\u003c\u003c-EOF spec: containers: - command: - kube-scheduler - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf - --bind-address=127.0.0.1 - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true # 修改部分 # - --port=0 EOF # 在所有Master节点再次查看集群健康状况： $ kubectl get cs 部署Kubernetes集群 安装高可用组件 注意：如果不是高可用集群，haproxy和keepalived无需安装 所有Master节点安装HAPROXY和Keepalived $ yum -y install keepalived haproxy 所有Master节点配置HAProxy $ cat \u003e/etc/haproxy/haproxy.cfg\u003c\u003c-EOF global maxconn 2000 ulimit-n 16384 log 127.0.0.1 local0 err stats timeout 30s defaults log global mode http option httplog timeout connect 5000 timeout client 50000 timeout server 50000 timeout http-request 15s timeout http-keep-alive 15s frontend monitor-in bind *:33305 mode http option httplog monitor-uri /monitor listen stats bind *:8006 mode http stats enable stats hide-version stats uri /stats stats refresh 30s stats realm Haproxy\\ Statistics stats auth admin:admin frontend k8s-master bind 0.0.0.0:16443 bind 127.0.0.1:16443 mode tcp option tcplog tcp-request inspect-delay 5s default_backend k8s-master backend k8s-master mode tcp option tcplog option tcp-check balance roundrobin default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100 # 下面的配置根据实际情况修改 server k8s-master-01 192.168.80.210:6443 check server k8s-master-02 192.168.80.211:6443 check EOF Msster-01的Keepalived配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { # 标识本节点的字条串，通常为 hostname router_id k8s-master-01 script_user root enable_script_security } # 检测脚本 # keepalived会定时执行脚本并对脚本执行的结果进行分析，动态调整vrrp_instance的优先级。如果脚本执行结果为0，并且weight配置的值大于0，则优先级相应的增加。如果脚本执行结果非0，并且weight配置的值小于0，则优先级相应的减少。其他情况，维持原本配置的优先级，即配置文件中priority对应的值。 vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" # 每2秒检查一次 interval 2 # 一旦脚本执行成功，权重减少5 weight -5 fall 3 rise 2 } # 定义虚拟路由，VI_1 为虚拟路由的标示符，自己定义名称 vrrp_instance VI_1 { # 主节点为 MASTER，对应的备份节点为 BACKUP state MASTER # 绑定虚拟 IP 的网络接口，与本机 IP 地址所在的网卡名称相同 interface ens32 # 主机的IP地址 mcast_src_ip 192.168.80.210 # 虚拟路由id virtual_router_id 100 # 节点优先级，值范围 0-254，MASTER 要比 BACKUP 高 priority 100 # 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题 nopreempt # 组播信息发送间隔，所有节点设置必须一样，默认 1s advert_int 2 # 设置验证信息，所有节点必须一致 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } # 虚拟 IP 池, 所有节点设置必须一样 virtual_ipaddress { # 虚拟 ip，可以定义多个\t192.168.80.220/24 } track_script { chk_apiserver } } EOF Master-02的Keepalived配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { router_id k8s-master-02 script_user root enable_script_security } vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" interval 2 weight -5 fall 3 rise 2 } vrrp_instance VI_1 { state BACKUP interface ens32 mcast_src_ip 192.168.80.211 virtual_router_id 101 priority 99 advert_int 2 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } virtual_ipaddress { 192.168.80.220/24 } track_script { chk_apiserver } } EOF 所有Master节点设置监控脚本，并且给予执行权限 $ cat \u003e/etc/keepalived/check_apiserver.sh\u003c\u003c-EOF ##!/bin/bash err=0 for k in $(seq 1 5) do check_code=$(pgrep kube-apiserver) if [[ $check_code == \"\" ]]; then err=$(expr $err + 1) sleep 5 continue else err=0 break fi done if [[ $err != \"0\" ]]; then echo \"systemctl stop keepalived\" /usr/bin/systemctl stop keepalived exit 1 else exit 0 fi EOF $ chmod +x /etc/keepalived/check_apiserver.sh 所有Master节点启动HAProxy和Keepalived并且测试VIP(虚拟IP) $ systemctl daemon-reload $ systemctl enable --now haproxy $ systemctl enable --now keepalived $ ping 192.168.80.220 -c 4 初始化Kubernetes 命令行方式初始化所有Master节点 在k8s-master01节点执行下面的命令： $ kubeadm init \\ --apiserver-advertise-address=192.168.80.210 \\ --image-repository registry.aliyuncs.com/google_containers \\ --control-plane-endpoint=192.168.80.225:16443 \\ --kubernetes-version v1.20.2 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 \\ --cri-socket unix:///var/run/containerd/containerd.sock # 配置 CRI 端点 --upload-certs 将k8s-master02节点加入到集群中，其他master节点加入同样命令 $ kubeadm join 192.168.80.225:16443 --token povqsg.arg07e5ia1pywr71 \\ --discovery-token-ca-cert-hash sha256:9efd30b7f35747289b9de0c8d0768b9c2d5eb7d675cb86fa05b9a6d9526c3441 \\ --control-plane --certificate-key 363cc6296537b41607851c10f1f41ef23cf5cdc6965cb9c26e4b252315086855 防止在Master-02节点中不能使用kubectl命令 $ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 如果Token过期，需要在Master-01生成新的Token $ kubeadm token create --print-join-command 如果Master要加入到集群中，需要在Master-01生成--certificate-key $ kubeadm init phase upload-certs --upload-certs yaml方式初始化所有Master节点 在k8s-master01创建目录生成配置文件kubeadm-config.yaml $ mkdir -p /opt/k8s/yaml $ kubeadm config print init-defaults \u003e/opt/k8s/yaml/kubeadm-config.yaml # 修改配置文件 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 # 修改为master本机IP bindPort: 6443 # 使用端口 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock # 配置 CRI 端点 imagePullPolicy: IfNotPresent name: node # 配置主机名， 主机名不允许使用下划线 taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io # 定义使用镜像源 # imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像源 kind: ClusterConfiguration kubernetesVersion: 1.24.0 # 定义kubernetes版本 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration featureGates: SupportIPVSProxyMode: true mode: ipvs # 启用ipvs 可以使用如下的命令更新kubeadm-config.yaml文件，需要将k8s设置到对应的版本 $ kubeadm config migrate --old-config /opt/k8s/yaml/kubeadm-config.yaml --new-config \"new.yaml\" 将new.yaml文件复制到所有的master节点 $ scp new.yaml k8s-master-02:/opt/k8s/yaml/ # 查看以及下载所有master节点提前下载镜像 $ kubeadm config images pull --config /opt/k8s/yaml/new.yaml # pull替换list可查看所需镜像 k8s-master01节点初始化后，会在/etc/kubernetes目录下生成对应的证书和配置文件，之后其他的Master节点加入到k8s-master01节点即可 $ kubeadm init --config /opt/k8s/yaml/new.yaml --upload-certs 如果初始化失败，重置后再次初始化，命令如下： $ kubeadm reset -f;ipvsadm --clear;rm -rf ~/.kube 初始化成功后，会产生token值，用于其他节点加入时使用， Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of the control-plane node running the following command on each as root: # 其他 Master 节点执行 kubeadm join 192.168.80.210:16443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:505e373bae6123fc3e27e778c5fedbccbf0f91a51efdcc11b32c4573605b8e71 \\ --control-plane --certificate-key 70aef5f76111a5824085c644b3f34cf830efad00c1b16b878701166bf069664e Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward. Then you can join any number of worker nodes by running the following on each as root: # 所有 Node 节点执行 kubeadm join 192.168.80.210:16443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:505e373bae6123fc3e27e778c5fedbccbf0f91a51efdcc11b32c4573605b8e71 k8s-master01节点配置环境变量，用于访问kubernetes集群 # root用户 $ cat \u003e/root/.bashrc\u003c\u003c-EOF export KUBECONFIG=/etc/kubernetes/admin.conf EOF $ source ~/.bash_profile # 普通用户 $ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config # k8s-master-01中查看节点的状态： $ kubectl get nodes Node节点加入集群 所有Node节点执行 $ kubeadm join 192.168.80.225:16443 --token povqsg.arg07e5ia1pywr71 \\ --discovery-token-ca-cert-hash sha256:9efd30b7f35747289b9de0c8d0768b9c2d5eb7d675cb86fa05b9a6d9526c3441 二进制安装kubernetes 部署Etcd存储集群、三台主机作为节点 键值对数据库，存储K8S集群所有重要信息(持久化) Kubernetes存储大脑之etcd、突破etcd限制！字节开源自研K8s存储KubeBrain Etcd 是一个分布式键值存储系统，Kubernetes使用Etcd进行数据存储，所以先准备一个Etcd数据库，为解决Etcd单点故障，应采用集群方式部署，这里使用3台组建集群，可容忍1台机器故障，当然，你也可以使用5台组建集群，可容忍2台机器故障 1.1 注意这里profiles字段下名称，其中CjServer下注明server auth用于服务器端认证，后续在生成服务器证书时候，需要使用这个名称作为cfssl命令的配置文件名称作为参数传入。 1.2 注意这里profiles字段下名称，其中CjServer下注明server auth用于服务器端认证，后续在生成服务器证书时候，需要使用这个名称作为cfssl命令的配置文件名称作为参数传入。 {\"code\":5100,\"message\":\"Invalid policy: no key usage available\"} Failed to parse input: unexpected end of JSON input 1.3 往往是提供的-profile参数中的配置文件名在ca-config.json中无法匹配 $ echo ' ##!/bin/bash # 1.准备cfssl证书生成工具、cfssl是一个开源的证书管理工具，使用json文件生成证书，找任意一台服务器操作， $ cd /usr/local/src/ $ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 # 是v1.2.0 最好升级到v1.3.4 $ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 $ chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64 # 添加环境变量第一种方式 $ vim /etc/profile export PATH=$PATH:/opt/kubernetes/bin $ source /etc/profile # 把可执行文件挪移并改名 $ mv cfssl_linux-amd64 /usr/local/bin/cfssl $ mv cfssljson_linux-amd64 /usr/local/bin/cfssljson $ mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo # 2.生成Etcd证书、自签证书颁发机构（CA）创建工作目录： $ cat \u003e/opt/kubernetes/ssl/ca-config.json\u003c\u003c-EOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } } } EOF ################################################################### $ cat \u003e/opt/kubernetes/ssl/ca-csr.json\u003c\u003c-EOF { \"CN\": \"etcd CA\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ] } EOF ################################################################## # 3.生成证书 $ cd /opt/kubernetes/ssl/ $ cfssl gencert -initca ca-csr.json | cfssljson -bare ca - # 4. 使用自签CA签发Etcd HTTPS证书:创建证书申请文件 ##### $ cat \u003e/opt/kubernetes/ssl/etcd-csr.json\u003c\u003c-EOF { \"CN\": \"etcd\", \"hosts\": [ \"192.168.4.110\", # 修改IP、为了扩容方便可以多写几个IP、去掉注释 \"192.168.4.111\", \"192.168.4.112\", \"xxx.xxx.xxx.xxx\", \"xxx.xxx.xxx.xxx\", \"xxx.xxx.xxx.xxx\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\" } ] } EOF ################################################################## # 5. 生成证书 $ cd /opt/kubernetes/ssl/ $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes etcd-csr.json | cfssljson -bare etcd # 6.在GitHub上下载二进制文件 $ cd /usr/local/src/ $ wget https://github.com/etcd-io/etcd/releases/download/v3.4.14/etcd-v3.4.14-linux-amd64.tar.gz $ tar zxvf etcd-v3.4.14-linux-amd64.tar.gz $ mv etcd-v3.4.14-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/ # 6.创建etcd配置文件：针对IP修改为本机IP，拷贝过去后把所有结尾的“注释取消掉” $ cat \u003e/opt/etcd/cfg/etcd.conf\u003c\u003c-EOF # [Member] ETCD_NAME=\"etcd-node1\" # 修改此处，节点2改为etcd-2，节点3改为etcd-3 ETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\" ETCD_LISTEN_PEER_URLS=\"https://192.168.4.110:2380\" # 修改此处为当前服务器IP ETCD_LISTEN_CLIENT_URLS=\"https://192.168.4.110:2379,https://127.0.0.1:2379\" # 修改此处为当前服务器IP # [Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://192.168.4.110:2380\" # 修改此处为当前服务器IP ETCD_ADVERTISE_CLIENT_URLS=\"https://192.168.4.110:2379\" # 修改此处为当前服务器IP # 修改为所有节点IP ETCD_INITIAL_CLUSTER=\"etcd-node1=https://192.168.4.110:2380,etcd-node2=https://192.168.4.111:2380,etcd-node3=https://192.168.4.112:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_INITIAL_CLUSTER_STATE=\"new\" # [security] # CLIENT_CERT_AUTH=\"true\" # ETCD_CA_FILE=\"/opt/etcd/ssl/ca.pem\" # ETCD_CERT_FILE=\"/opt/etcd/ssl/server.pem\" # ETCD_KEY_FILE=\"/opt/etcd/ssl/server-key.pem\" # PEER_CLIENT_CERT_AUTH=\"true\" # ETCD_PEER_CA_FILE=\"/opt/etcd/ssl/ca.pem\" # ETCD_PEER_CERT_FILE=\"/opt/etcd/ssl/server.pem\" # ETCD_PEER_KEY_FILE=\"/opt/etcd/ssl/server-key.pem\" EOF ##################################################################### # ETCD_NAME：节点名称，集群中唯一 # ETCD_DATA_DIR：数据目录 # ETCD_LISTEN_PEER_URLS：集群通信监听地址 # ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址 # ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址 # ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址 # ETCD_INITIAL_CLUSTER：集群节点地址 # ETCD_INITIAL_CLUSTER_TOKEN：集群Token # ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new是新集群，existing表示加入已有集群 # 7.systemctl管理etcd $ cat \u003e/usr/lib/systemd/system/etcd.service\u003c\u003c-EOF [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify EnvironmentFile=/opt/etcd/cfg/etcd.conf ExecStart=/opt/etcd/bin/etcd \\\\ --cert-file=/opt/etcd/ssl/etcd.pem \\\\ --key-file=/opt/etcd/ssl/etcd-key.pem \\\\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\\\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem \\\\ --trusted-ca-file=/opt/etcd/ssl/ca.pem \\\\ --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\\\ --logger=zap Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF ################################################################### # 8.拷贝刚刚生成证书到etcd目录下 $ cd /opt/kubernetes/ssl/ $ cp ca*.pem etcd*.pem /opt/etcd/ssl/ # 9.节点1生成的所有文件拷贝到其他所有节点、然后在其他节点分别修改etcd.conf配置文件中的节点名称和当前服务器IP： $ ansible node -i /etc/ansible/hosts -m copy -a \"src=/opt/etcd dest=/opt\" -f 5 $ ansible node -i /etc/ansible/hosts -m copy -a \"src=/usr/lib/systemd/system/etcd.service dest=/usr/lib/systemd/system\" -f 5 $ mkdir -p /var/lib/etcd # 三个节点都执行 $ chmod +x /opt/etcd/bin/* # 其他两个节点执行语句给予执行权限 # 10.所有节点设置开机自启 $ systemctl daemon-reload $ systemctl enable etcd \u0026\u0026 systemctl start etcd # 测试etcd数据库可用性 $ etcdctl set testdir/testkey0 0 # 设置一个键值对 0 $ etcdctl get testdir/testkey0 # 查看是否获取到数据 $ etcdctl -C http://localhost:2379 cluster-health # 11.查看集群状态 $ ETCDCTL_API=3 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/etcd.pem --key=/opt/etcd/ssl/etcd-key.pem --endpoints=\"https://192.168.4.110:2379,https://192.168.4.111:2379,https://192.168.4.112:2379\" endpoint health ' \u003e\u003einstall_etcd.sh 署Master Node，生成kube-apiserver证书：自签证书颁发机构CA api-server：所有服务访问统一入口 $ echo ' ##!/bin/bash # 1.创建证书申请文件： # hosts字段中IP为所有Master/LB/VIP IP,一个都不能少！为了方便后期扩容可以多写几个预留的IP $ cat \u003e /opt/kubernetes/ssl/kube-apiserver-csr.json \u003c\u003c EOF { \"CN\": \"kubernetes\", \"hosts\": [ \"10.0.0.1\", \"127.0.0.1\", \"192.168.4.110\", \"192.168.4.111\", \"192.168.4.112\", \"xxx.xxx.xxx.xxx\", \"xxx.xxx.xxx.xxx\", \"kubernetes\", \"kubernetes.default\", \"kubernetes.default.svc\", \"kubernetes.default.svc.cluster\", \"kubernetes.default.svc.cluster.local\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ] } EOF ###################################################################### # 2.生成证书: $ cd /opt/kubernetes/ssl $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare api-server # 打开链接下载二进制包 # https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#v1202 $ cd /usr/local/src $ wget https://dl.k8s.io/v1.18.6/kubernetes-server-linux-amd64.tar.gz $ tar zxvf kubernetes-server-linux-amd64.tar.gz $ cd kubernetes/server/bin/ $ cp kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bin/ $ cp kubectl /usr/bin/ # 3.部署kube-apiserver # 两个\"\\\\\"第一个是转义符，第二个是换行符，使用转义符是为了使用EOF保留换行符 $ cat \u003e/opt/kubernetes/cfg/kube-apiserver.conf\u003c\u003c-EOF KUBE_APISERVER_OPTS=\"--logtostderr=false \\\\ --v=2 \\\\ --log-dir=/opt/kubernetes/logs \\\\ --etcd-servers=https://192.168.4.110:2379,https://192.168.4.111:2379,https://192.168.4.112:2379 \\\\ --bind-address=192.168.4.110 \\\\ --secure-port=6443 \\\\ --advertise-address=192.168.4.110 \\\\ --allow-privileged=true \\\\ --service-cluster-ip-range=10.0.0.0/24 \\\\ --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\\\ --authorization-mode=RBAC,Node \\\\ --enable-bootstrap-token-auth=true \\\\ --token-auth-file=/opt/kubernetes/cfg/token.csv \\\\ --service-node-port-range=30000-32767 \\\\ --kubelet-client-certificate=/opt/kubernetes/ssl/api-server.pem \\\\ --kubelet-client-key=/opt/kubernetes/ssl/api-server-key.pem \\\\ --tls-cert-file=/opt/kubernetes/ssl/api-server.pem \\\\ --tls-private-key-file=/opt/kubernetes/ssl/api-server-key.pem \\\\ --client-ca-file=/opt/kubernetes/ssl/ca.pem \\\\ --service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\ --etcd-cafile=/opt/etcd/ssl/ca.pem \\\\ --etcd-certfile=/opt/etcd/ssl/server.pem \\\\ --etcd-keyfile=/opt/etcd/ssl/server-key.pem \\\\ # 证书需要修改 \\ --audit-log-maxbackup=3 \\\\ --audit-log-maxsize=100 \\\\ --audit-log-path=/opt/kubernetes/logs/k8s-audit.log\" EOF ####################################################################### –logtostderr：启用日志 —v：日志等级 –log-dir：日志目录 –etcd-servers：etcd集群地址 –bind-address：监听地址 –secure-port：https安全端口 –advertise-address：集群通告地址 –allow-privileged：启用授权 –service-cluster-ip-range：Service虚拟IP地址段 –enable-admission-plugins：准入控制模块 –authorization-mode：认证授权，启用RBAC授权和节点自管理 –enable-bootstrap-token-auth：启用TLS bootstrap机制 –token-auth-file：bootstrap token文件 –service-node-port-range：Service nodeport类型默认分配端口范围 –kubelet-client-xxx：apiserver访问kubelet客户端证书 –tls-xxx-file：apiserver https证书 –etcd-xxxfile：连接Etcd集群证书 –audit-log-xxx：审计日志 '\u003e\u003e kube-apiserver.sh 启用TLS Bootstrapping机制 TLS Bootstraping：Master apiserver启用TLS认证后，Node节点kubelet和kube-proxy要与kube-apiserver进行通信，必须使用CA签发的有效证书才可以，当Node节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes引入了TLS bootstraping机制来自动颁发客户端证书，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。所以强烈建议在Node上使用这种方式，目前主要用于kubelet，kube-proxy还是由我们统一颁发一个证书 $ echo ' ##!/bin/bash cat \u003e/opt/kubernetes/cfg/token.csv\u003c\u003c-EOF $(head -c 16 /dev/urandom | od -An -t x | tr -d ' '),kubelet-bootstrap,10001,\"system:node-bootstrapper\" EOF ########################################### # 自行生成token # token=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ') # C语言执行生成方式 # token=`head -c 16 /dev/urandom | od -An -t x | tr -d ' '` # shell执行生成方式 # sed -i \"s/c47ffb939f5ca36231d9e3121a252940/${token}/g\" /opt/kubernetes/cfg/token.csv # systemct管理apiserver、并设置开机自启 cat \u003e/usr/lib/systemd/system/kube-apiserver.service\u003c\u003c-EOF [Unit] Description=Kubernetes API Server Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf ExecStart=/opt/kubernetes/bin/kube-apiserver \\$KUBE_APISERVER_OPTS Restart=on-failure [Install] WantedBy=multi-user.target EOF ####################################################################### $ systemctl daemon-reload $ systemctl enable kube-apiserver \u0026\u0026 systemctl start kube-apiserver # kube-apiserver报错排查 $ cat /var/log/messages|grep kube-apiserver|grep -i error # -i不区分大小写 journalctl -xe -u kube-apiserver | more # 命令排错 # 3.设置授权kubelet-bootstrap用户允许请求证书 $ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap ' \u003e\u003etoken-apiserver.sh 部署kube-controller-manager(控制器) Pod 1.1 最小部署单元 1.2 一组容器的集合 1.3 一个Pod中的容器共享网络命名空间 1.4 Pod是短暂的 Controllers 2.1 Deployment：无状态应用部署 2.2 StatefulSet：有状态应用部署 2.3 DaemonSet：确保所有的Node运行一个Pod 2.4 Job：一次性任务 2.5 Cronjob：定时任务 更高级层级对象，部署和管理Pod Service 4.1 防止Pod失联 4.2 定义一组Pod的访问策略 Label：标签，附加到某个资源上，用于关联对象，查询和筛选 Namespaces：命名空间，将对象逻辑上隔离 Controller：维持副本期望数目,ReplicaSet替代ReplicationControlled deployent：管理RS，实现滚动更新 8.1 --kubeconfig：连接apiserver配置文件 8.2 --master：通过本地非安全本地端口8080连接apiserver 8.3 --leader-elect：当该组件启动多个时，自动选举HA 8.4 --cluster-signing-cert-file/--cluster-signing-key-file：自动为kubelet颁发证书的CA，与apiserver保持一致 # 创建配置文件 $ cat \u003e/opt/kubernetes/cfg/kube-controller-manager.conf\u003c\u003c-EOF KUBE_CONTROLLER_MANAGER_OPTS=\"--logtostderr=false \\\\ --v=2 \\\\ --log-dir=/opt/kubernetes/logs \\\\ --leader-elect=true \\\\ --kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\\\ --master=127.0.0.1:8080 \\\\ --bind-address=127.0.0.1 \\\\ --allocate-node-cidrs=true \\\\ --cluster-cidr=10.244.0.0/16 \\\\ --service-cluster-ip-range=10.0.0.0/24 \\\\ --cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\\\ --cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\ --root-ca-file=/opt/kubernetes/ssl/ca.pem \\\\ --service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\ --experimental-cluster-signing-duration=87600h0m0s\" EOF # 创建kube-controller-manager-csr.json 证书请求文件，可以越过 # cat \u003e/opt/kubernetes/ssl/kube-controller-manager-csr.json\u003c\u003c-EOF # { # \"CN\": \"system:kube-controller-manager\", # \"hosts\": [], # \"key\": { # \"algo\": \"rsa\", # \"size\": 2048 # }, # \"names\": [ # { # \"C\": \"CN\", # \"L\": \"BeiJing\", # \"ST\": \"BeiJing\", # \"O\": \"system:masters\", # \"OU\": \"System\" # } # ] # } # EOF # # 生成证书 $ cd /opt/kubernetes/ssl $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager 生成kubeconfig文件（以下是shell命令，直接在终端执行）：可以越过 # KUBE_CONFIG=\"/opt/kubernetes/cfg/kube-controller-manager.kubeconfig\" # KUBE_APISERVER=\"https://192.168.4.110:6443\" # $ kubectl config set-cluster kubernetes \\ # --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ # --embed-certs=true \\ # --server=${KUBE_APISERVER} \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config set-credentials kube-controller-manager \\ # --client-certificate=./kube-controller-manager.pem \\ # --client-key=./kube-controller-manager-key.pem \\ # --embed-certs=true \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config set-context default \\ # --cluster=kubernetes \\ # --user=kube-controller-manager \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config use-context default --kubeconfig=${KUBE_CONFIG} systemd管理controller-manager Controller manager（默认端口：10252）监视Kubernetes集群，以检测和维护Kubernetes环境的几个方面，包括将Pod加入到服务中，保持一组Pod的正确数量，并对节点的丢失做出反应 Cloud controller manager（默认端口：10258）一个用于基于云的部署的可选组件。云控制器与云服务提供商接口，以管理集群的负载均衡器和虚拟网络 $ cat \u003e/usr/lib/systemd/system/kube-controller-manager.service\u003c\u003c-EOF [Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf ExecStart=/opt/kubernetes/bin/kube-controller-manager \\$KUBE_CONTROLLER_MANAGER_OPTS ExecReload=/bin/kill -HUP $MAINPID Restart=on-failure [Install] WantedBy=multi-user.target EOF 启动并设置开机启动 $ systemctl daemon-reload $ systemctl enable kube-controller-manager \u0026\u0026 systemctl start kube-controller-manager 部署kube-scheduler:创建配置文件(调度器负责集群资源调度,组件抽离) Scheduler：负责介绍任务，选择合适的节点进行分配任务 1.1 --kubeconfig：连接apiserver配置文件 1.2 --master：通过本地非安全本地端口8080连接apiserver 1.3 --leader-elect：当该组件启动多个时，自动选举(HA) $ cat \u003e/opt/kubernetes/cfg/kube-scheduler.conf\u003c\u003c-EOF KUBE_SCHEDULER_OPTS=\"--logtostderr=false \\\\ --v=2 \\\\ --log-dir=/opt/kubernetes/logs \\\\ --leader-elect \\\\ #--kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\\\ --master=127.0.0.1:8080 \\\\ --bind-address=127.0.0.1\" EOF 创建kube-scheduler-csr.json证书请求文件：可以越过此步骤 # cat \u003e/opt/kubernetes/ssl/kube-scheduler-csr.json\u003c\u003c-EOF # { # \"CN\": \"system:kube-scheduler\", # \"hosts\": [], # \"key\": { # \"algo\": \"rsa\", # \"size\": 2048 # }, # \"names\": [ # { # \"C\": \"CN\", # \"L\": \"BeiJing\", # \"ST\": \"BeiJing\", # \"O\": \"system:masters\", # \"OU\": \"System\" # } # ] # } # EOF # 生成证书 $ cd /opt/kubernetes/ssl $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler 生成kubeconfig文件(以下是shell命令，直接在终端执行)：此步骤可以越过 # KUBE_CONFIG=\"/opt/kubernetes/cfg/kube-scheduler.kubeconfig\" # KUBE_APISERVER=\"https://192.168.100.11:6443\" $ kubectl config set-cluster kubernetes \\ # --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ # --embed-certs=true \\ # --server=${KUBE_APISERVER} \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config set-credentials kube-scheduler \\ # --client-certificate=./kube-scheduler.pem \\ # --client-key=./kube-scheduler-key.pem \\ # --embed-certs=true \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config set-context default \\ # --cluster=kubernetes \\ # --user=kube-scheduler \\ # --kubeconfig=${KUBE_CONFIG} $ kubectl config use-context default --kubeconfig=${KUBE_CONFIG} systemd管理scheduler $ cat \u003e/usr/lib/systemd/system/kube-scheduler.service\u003c\u003c-EOF [Unit] Description=Kubernetes Scheduler Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf ExecStart=/opt/kubernetes/bin/kube-scheduler \\$KUBE_SCHEDULER_OPTS Restart=on-failure [Install] WantedBy=multi-user.target EOF 设置开机自己并且启动服务器 $ systemctl daemon-reload $ systemctl enable kube-scheduler \u0026\u0026 systemctl start kube-scheduler 生成kubectl连接集群的证书： $ cat \u003e/opt/kubernetes/ssl/admin-csr.json\u003c\u003c-EOF { \"CN\": \"admin\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\", \"O\": \"system:masters\", \"OU\": \"System\" } ] } EOF 生成证书 $ cd /opt/kubernetes/ssl/ $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin 生成kubeconfig文件 $ mkdir /root/.kube $ KUBE_CONFIG=\"/root/.kube/config\" $ KUBE_APISERVER=\"https://192.168.4.110:6443\" $ kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=${KUBE_CONFIG} $ kubectl config set-credentials cluster-admin \\ --client-certificate=./admin.pem \\ --client-key=./admin-key.pem \\ --embed-certs=true \\ --kubeconfig=${KUBE_CONFIG} $ kubectl config set-context default \\ --cluster=kubernetes \\ --user=cluster-admin \\ --kubeconfig=${KUBE_CONFIG} $ kubectl config use-context default --kubeconfig=${KUBE_CONFIG} 通过kubectl工具查看当前集群组件状态 $ kubectl get cs NAME STATUS MESSAGE ERROR controller-manager Healthy ok scheduler Healthy ok etcd-0 Healthy {\"health\":\"true\"} etcd-1 Healthy {\"health\":\"true\"} etcd-2 Healthy {\"health\":\"true\"} 在Master操作部署Worker Node Kubelet：直接跟容器引擎交互实现容器的生命周期管理 Kube proxy：负责写入规则至iptables、ipvs实现服务映射访问 2.1 --hostname-override：显示名称，集群中唯一 2.2 --network-plugin：启用CNI 2.3 --kubeconfig：空路径，会自动生成，后面用于连接apiserver 2.4 --bootstrap-kubeconfig：首次启动向apiserver申请证书 2.5 --config：配置参数文件 2.6 --cert-dir：kubelet证书生成目录 2.7 --pod-infra-container-image：管理Pod网络容器的镜像 $ cd /usr/local/src/kubernetes/server/bin/ $ cp kubelet kube-proxy /opt/kubernetes/bin # 本地拷贝 # 部署bubelet $ cat \u003e/opt/kubernetes/cfg/kubelet.conf\u003c\u003c-EOF KUBELET_OPTS=\"--logtostderr=false \\\\ --v=2 \\\\ --log-dir=/opt/kubernetes/logs \\\\ --hostname-override=k8s-master \\\\ --network-plugin=cni \\\\ --kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\\\ --bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\\\ --config=/opt/kubernetes/cfg/kubelet-config.yml \\\\ --cert-dir=/opt/kubernetes/ssl \\\\ --pod-infra-container-image=lizhenliang/pause-amd64:3.0\" EOF 配置参数文件 $ cat \u003e/opt/kubernetes/cfg/kubelet-config.yml\u003c\u003c-EOF kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 address: 0.0.0.0 port: 10250 readOnlyPort: 10255 cgroupDriver: cgroupfs clusterDNS: - 10.0.0.2 clusterDomain: cluster.local failSwapOn: false authentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /opt/kubernetes/ssl/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30s evictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5% maxOpenFiles: 1000000 maxPods: 110 EOF 在master节点执行以下命令，生成kubelet初次加入集群引导bootstrap.kubeconfig文件 $ KUBE_CONFIG=\"/opt/kubernetes/cfg/bootstrap.kubeconfig\" $ KUBE_APISERVER=\"https://192.168.4.110:6443\" # apiserver IP:PORT $ TOKEN=\"bed185231bd89516f68ed5031946b9f9\" # 与token.csv里保持一致 # 生成 kubelet bootstrap kubeconfig 配置文件 $ kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=${KUBE_CONFIG} Cluster \"kubernetes\" set. $ kubectl config set-credentials \"kubelet-bootstrap\" \\ --token=${TOKEN} \\ --kubeconfig=${KUBE_CONFIG} User \"kubelet-bootstrap\" set. $ kubectl config set-context default \\ --cluster=kubernetes \\ --user=\"kubelet-bootstrap\" \\ --kubeconfig=${KUBE_CONFIG} Context \"default\" created. $ kubectl config use-context default --kubeconfig=${KUBE_CONFIG} Switched to context \"default\". system管理kubelet $ cat \u003e /usr/lib/systemd/system/kubelet.service \u003c\u003c EOF [Unit] Description=Kubernetes Kubelet After=docker.service [Service] EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf ExecStart=/opt/kubernetes/bin/kubelet \\$KUBELET_OPTS Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF #################################################################### $ systemctl daemon-reload $ systemctl enable kubelet systemctl start kubelet 批准kubelet证书申请并加入集群 # 查看kubelet证书请求 [root@k8s-master ~]# kubectl get csr NAME AGE SIGNERNAME REQUESTOR CONDITION node-csr-Pbamt5FDLAwv0HlJpcgUP9B5c4ynIRe0Xa17zXq9I6E 4m16s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending # 批准申请 [root@k8s-master ~]# kubectl certificate approve node-csr-Pbamt5FDLAwv0HlJpcgUP9B5c4ynIRe0Xa17zXq9I6E certificatesigningrequest.certificates.k8s.io/node-csr-Pbamt5FDLAwv0HlJpcgUP9B5c4ynIRe0Xa17zXq9I6E approved # 查看节点,由于网络插件没有部署，节点状态 NotReady [root@k8s-master ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-master NotReady \u003cnone\u003e 71s v1.18.3 部署kube-proxy # 1. 创建配置kube-proxy文件 $ cat \u003e/opt/kubernetes/cfg/kube-proxy.conf\u003c\u003c-EOF KUBE_PROXY_OPTS=\"--logtostderr=false \\\\ --v=2 \\\\ --log-dir=/opt/kubernetes/logs \\\\ --config=/opt/kubernetes/cfg/kube-proxy-config.yml\" EOF # 2. 配置参数文件 $ cat \u003e/opt/kubernetes/cfg/kube-proxy-config.yml\u003c\u003c-EOF kind: KubeProxyConfiguration apiVersion: kubeproxy.config.k8s.io/v1alpha1 bindAddress: 0.0.0.0 metricsBindAddress: 0.0.0.0:10249 clientConnection: kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig hostnameOverride: k8s-master clusterCIDR: 10.0.0.0/24 EOF # 3. 生成kube-proxy.kubeconfig文件：生成kube-proxy证书： $ cat \u003e/opt/kubernetes/ssl/kube-proxy-csr.json\u003c\u003c-EOF { \"CN\": \"system:kube-proxy\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ] } EOF # 4.生成证书 $ cd /opt/kubernetes/ssl/ $ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy # 5. 生成kubeconfig文件 $ KUBE_CONFIG=\"/opt/kubernetes/cfg/kube-proxy.kubeconfig\" $ KUBE_APISERVER=\"https://192.168.4.110:6443\" [root@k8s-master ssl]# kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=${KUBE_CONFIG} Cluster \"kubernetes\" set. [root@k8s-master ssl]# kubectl config set-credentials kube-proxy \\ --client-certificate=./kube-proxy.pem \\ --client-key=./kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=${KUBE_CONFIG} User \"kube-proxy\" set. [root@k8s-master ssl]# kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=${KUBE_CONFIG} Context \"default\" created. [root@k8s-master ssl]# kubectl config use-context default --kubeconfig=${KUBE_CONFIG} Switched to context \"default\". # 6.system管理kube-proxy $ cat \u003e/usr/lib/systemd/system/kube-proxy.service\u003c\u003c-EOF [Unit] Description=Kubernetes Proxy After=network.target [Service] EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf ExecStart=/opt/kubernetes/bin/kube-proxy \\$KUBE_PROXY_OPTS Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF ######################################################################## $ systemctl daemon-reload $ systemctl enable kube-proxy \u0026\u0026 systemctl start kube-proxy 部署网络组件 Calico是一个纯三层的数据中心网络方案，是目前Kubernetes主流的网络方案。部署Calico $ cd /usr/local/src/ $ wget https://docs.projectcalico.org/v3.14/manifests/calico.yaml [root@k8s-master src]# kubectl apply -f calico.yaml # 等Calico Pod都Running，节点也会准备就绪 [root@k8s-master src]# kubectl get node [root@k8s-master src]# kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-65f8bc95db-27zj8 1/1 Running 0 37m calico-node-skvcj 1/1 Running 0 37m 部署CNI网络 先准备好CNI二进制文件 $ mkdir -p /opt/cni/bin $ cd /usr/local/src/ $ wget https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz # 下载二进制安装包 $ tar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin # 部署CNI网络 $ cd /opt/kubernetes/cfg/ $ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml $ sed -i -r \"s#quay.io/coreos/flannel:.*-amd64#lizhenliang/flannel:v0.12.0-amd64#g\" kube-flannel.yml [root@k8s-master cfg]# kubectl apply -f kube-flannel.yml podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created [root@k8s-master cfg]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE kube-flannel-ds-xv7db 1/1 Running 0 58s [root@k8s-master cfg]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-master Ready \u003cnone\u003e 23m v1.18.3 授权apiserver访问kubelet $ cat \u003e/opt/kubernetes/cfg/apiserver-to-kubelet-rbac.yaml\u003c\u003c-EOF apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubelet rules: - apiGroups: - \"\" resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics - pods/log verbs: - \"*\" --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: system:kube-apiserver namespace: \"\" roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubelet subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetes EOF ############################################################## [root@k8s-master cfg]# kubectl apply -f apiserver-to-kubelet-rbac.yaml clusterrole.rbac.authorization.k8s.io/system:kube-apiserver-to-kubelet created clusterrolebinding.rbac.authorization.k8s.io/system:kube-apiserver created 新增加Worker Node:拷贝已部署好的Node相关文件到新节点 在master节点将Worker Node涉及文件拷贝到其他几个新节点 [root@k8s-master ~]# ansible node -i /etc/ansible/hosts -m copy -a \"src=/opt/kubernetes dest=/opt/\" -f 5 [root@k8s-master ~]# ansible node -i /etc/ansible/hosts -m copy -a \"src=/opt/cni dest=/opt/\" -f 5 [root@k8s-master ~]# scp -r /usr/lib/systemd/system/{kubelet,kube-proxy}.service k8s-node-1:/usr/lib/systemd/system [root@k8s-master ~]# scp -r /usr/lib/systemd/system/{kubelet,kube-proxy}.service k8s-node-2:/usr/lib/systemd/system # 这几个文件是证书申请审批后自动生成的，每个Node不同，必须删除其他几个节点删除kubelet证书和kubeconfig文件，重新生成 [root@k8s-node-1 ~]# rm -rf /opt/kubernetes/cfg/kubelet.kubeconfig [root@k8s-node-2 ~]# rm -rf /opt/kubernetes/cfg/kubelet.kubeconfig [root@k8s-node-1 ~]# rm -f /opt/kubernetes/ssl/kubelet* # 修改主机名 [root@k8s-node-1 ~]# sed -i \"s/k8s-master/k8s-node-1/g\" /opt/kubernetes/cfg/kubelet.conf [root@k8s-node-1 ~]# sed -i \"s/k8s-master/k8s-node-1/g\" /opt/kubernetes/cfg/kube-proxy-config.yml [root@k8s-node-2 ~]# sed -i \"s/k8s-master/k8s-node-2/g\" /opt/kubernetes/cfg/kubelet.conf [root@k8s-node-2 ~]# sed -i \"s/k8s-master/k8s-node-2/g\" /opt/kubernetes/cfg/kube-proxy-config.yml # 在其他几个几点给予可执行文件执行权限， $ chmod +x /opt/cni/bin/* $ chmod +x /opt/etcd/bin/* $ chmod +x /opt/kubernetes/bin/* $ systemctl daemon-reload $ systemctl enable kubelet \u0026\u0026 systemctl start kubelet $ systemctl enable kube-proxy \u0026\u0026 systemctl start kube-proxy # 在Master操作批准Node kubelet证书申请 $ kubectl get csr NAME AGE SIGNERNAME REQUESTOR CONDITION node-csr-4vSZMnrv8OUR-zfD7dQYcDdi1L84Tv_nkNHlS8Iltfk 2m46s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending node-csr-KRMLTPJj4yvk5Cb6s0n5T4HtFPYJ152PpDjYHLM3Ass 10s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending node-csr-Pbamt5FDLAwv0HlJpcgUP9B5c4ynIRe0Xa17zXq9I6E 71m kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issued $ kubectl certificate approve node-csr-KRMLTPJj4yvk5Cb6s0n5T4HtFPYJ152PpDjYHLM3Ass $ kubectl certificate approve node-csr-4vSZMnrv8OUR-zfD7dQYcDdi1L84Tv_nkNHlS8Iltfk # STATUS 都是Ready $ kubectl get node NAME STATUS ROLES AGE VERSION k8s-master Ready \u003cnone\u003e 70m v1.18.3 k8s-node-1 Ready \u003cnone\u003e 3m21s v1.18.3 k8s-node-2 Ready \u003cnone\u003e 3m2s v1.18.3 # STATUS 都是Runing $ kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-65f8bc95db-27zj8 1/1 Running 0 65m calico-node-skvcj 1/1 Running 0 65m calico-node-wc72m 1/1 Running 0 2m22s calico-node-z5kmp 1/1 Running 0 2m2s 创建local的Storage Class $ mkdir -p /opt/data $ cat \u003e/opt/kubernetes/cfg/storage-class.yml\u003c\u003c-EOF kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer EOF # 执行命令创建 $ kubectl create -f storage-class.yml # 查看一下创建的storage class $ kubectl get sc 创建PV $ cat \u003e/opt/kubernetes/cfg/pv-sdc.yml\u003c\u003c-EOF apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-sdc spec: capacity: storage: 30Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: local-storage local: path: /opt/data nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - cka EOF # 执行创建命令 $ kubectl create -f pv-sdc.yml [root@k8s-master cfg]# kubectl get pv 创建PVC $ cat \u003e/opt/kubernetes/cfg/pvc1.yml\u003c\u003c-EOF kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc1 spec: accessModes: - ReadWriteOnce storageClassName: local-storage resources: requests: storage: 10Gi EOF $ kubectl create -f pvc1.yml PVC将会一直处于Pending状态直到我们创建一个Pod使用它 [root@k8s-master cfg]# kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE pvc1 Pending local-storage 5s ",
    "description": "部署Kubernetes Etcd：负责存储集群中各种资源对象的信息\nKubelet：负责维护容器的生命周期，即通过控制Docker，来创建、更新、销毁容器\nKubeProxy：负责提供集群内部的服务发现和负载均衡\nDocker：负责节点上容器的各种操作\nScheduler：负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nAPI Server：集群操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nControllerManager：负责维护集群的状态，比如程序部署安排、故障检测、自动扩展和滚动更新等\nCore DNS：可以为集群中的SVC创建一个域名IP的对应关系解析",
    "tags": [],
    "title": "Install_Kubernetes",
    "uri": "/systems/linux/kubernetes/install_kubernetes/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "安装Rancher图形化管理 Rancher是供采用容器的团队使用的完整软件堆栈。它解决了管理多个 Kubernetes集群的运营和安全挑战，并为DevOps团队提供用于运行容器化工作负载的集成工具 必须存在Docker环境 服务器 IP 内存 CPU master 192.168.35.128 8G 8core node-1 192.168.35.129 4G 4core node-2 192.168.35.130 4G 4core 安装基础环境 Nano：超轻量级开源云平台 Naco：基于KVM技术，使用Go语言开发，简单易学的虚拟机管理软件，从Web管理门户、主机监控、镜像克隆到故障切换，功能完备，开箱即用，数分钟之内即可将您的服务器集群升级为云主机平台 $ yum install -y nano 在所有节点都安装Docker # ENV configuration $ sed -i '/swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab $ swapoff -a $ modprobe br_netfilter $ echo \"br_netfilter\" \u003e /etc/modules-load.d/br_netfilter.conf $ echo \"net.bridge.bridge-nf-call-iptables = 1\" \u003e\u003e /etc/sysctl.conf $ echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf $ sysctl -p $ sed -i 's/#AllowTcpForwarding/AllowTcpForwarding/g' /etc/ssh/sshd_config $ systemctl reload sshd $ systemctl stop firewalld \u0026\u0026 systemctl disable firewalld $ sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config $ setenforce 0 # timedate configration $ timedatectl set-timezone Asia/Shanghai $ yum install -y chrony $ systemctl start chronyd \u0026\u0026 sudo systemctl enable chronyd $ yum install -y yum-utils $ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo $ yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 --nogpgcheck $ systemctl enable docker \u0026\u0026 systemctl start docker 安装Rancher v2.6.5 使用Docker在单节点上安装Rancher Rancher v2.6.5支持的Kubernetes Versions版本 v1.23.6 Default v1.22.9 v1.21.12 v1.20.15 v1.19.16 v1.18.20 $ docker pull rancher/rancher:v2.6.5 $ docker run -d --restart=unless-stopped -p 888:80 -p 4443:443 --privileged rancher/rancher:v2.6.5 在Kubernetes集群上安装/升级Rancher 在Kubernetes集群上安装/升级Rancher 安装Helm 基于K8S 1.21.2集群安装Rancher 2.5.9 HA # 使用二进制安装Helm $ wget https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz $ tar -zxvf helm-v3.9.0-linux-amd64.tar.gz $ mv linux-amd64/helm /usr/local/bin/helm # 脚本安装 $ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 $ chmod 700 get_helm.sh $ ./get_helm.sh # 源代码安装 $ git clone https://github.com/helm/helm.git $ cd helm $ make 安装cert-manager $ kubectl create namespace cert-manager # 添加Jetstack Helm存储库 $ helm repo add jetstack https://charts.jetstack.io # 更新本地 Helm 图表存储库缓存 $ helm repo update # 安装cert-manager自定义所需的自定义资源 # kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.crds.yaml $ helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.7.1 --set installCRDs=true # 验证cert-manager证书管理器是否安装成功 $ kubectl get pods --namespace cert-manager 使用Helm安装稳定版Rancher # 为Rancher创建命名空间 $ kubectl create namespace cattle-system # 添加 Helm 添加 Rancher 库 $ helm repo add rancher-stable https://releases.rancher.com/server-charts/stable 使用helm安装Rancher注意选好版本，版本不对会报错 $ helm install rancher rancher-stable/rancher --namespace cattle-system --set hostname=my.rancher.org --set bootstrapPassword=admin --set replicas=3 --version 2.6.3 # --set ingress.tls.source=letsEncrypt \\ # --set letsEncrypt.email=\u003ccaviardé\u003e NAME: rancher LAST DEPLOYED: Wed May 25 18:01:51 2022 NAMESPACE: cattle-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Rancher Server has been installed. NOTE: Rancher may take several minutes to fully initialize. Please standby while Certificates are being issued, Containers are started and the Ingress rule comes up. Check out our docs at https://rancher.com/docs/ If you provided your own bootstrap password during installation, browse to https://my.rancher.org to get started. If this is the first time you installed Rancher, get started by running this command and clicking the URL it generates:$ echo https://my.rancher.org/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}') # To get just the bootstrap password on its own, run: $ kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ \"\\n\" }}' Happy Containering! 等待Rancher安装成功 $ kubectl -n cattle-system rollout status deploy/rancher $ kubectl get pods -o wide -n cattle-system $ kubectl get pods --show-labels -n cattle-system 浏览器登录Rancher页面设置 默认用户名：admin 密码新设置或者随机生成 设置Rancher Server地址IP或者域名 设置Rancher中文页面 登录后可以看到目前Rancher所管理只有Rancher本身存在K3S 5.1 Rancher Labs推出Kubernetes开源K3S是一个轻量级，只有40MB大小，易于安装Kubernetes发布版本，转为资源有限和低互动系统设计，适用于边缘应用、物联网、持续整合以及ARM等 使用Rancher创建RKE Kubernetes集群 等待被创建的集群都是基于数个实体服务器或虚拟机组成，其中这些机器硬件最低要求1Cores、1GB并且需要提前安装好Docker服务，操作系统必须符合RKE安装要求 生产环境下不允许把worker角色添加具有etcd或control plane角色节点中 Web页面配置Kubernetes Cluster集群 在Rancher浏览器页面中添加Kubernetes Cluster 选择Existing nodes(自定义集群) 定义集群名称、然后下一步 先选择etcd、Control Plane角色，把生成的命令复制到节点上执行，然后下一步 选择Worker工作节点,把生成的命令复制到节点执行 命令执行完成后，等待节点加入集群，成功后下方显示添加成功 如果错过复制添加命令选择命名空间点击Edit ",
    "description": "安装Rancher图形化管理 Rancher是供采用容器的团队使用的完整软件堆栈。它解决了管理多个 Kubernetes集群的运营和安全挑战，并为DevOps团队提供用于运行容器化工作负载的集成工具 必须存在Docker环境 服务器 IP 内存 CPU master 192.168.35.128 8G 8core node-1 192.",
    "tags": [],
    "title": "Install_K8s_Rancher",
    "uri": "/systems/linux/kubernetes/install_k8s_rancher/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "在现有Kubernetes上安装KubeSphere Web管理系统 Kuboard一款免费的Kubernetes管理界面 KubeOperator可视化的Web UI 如需在Kubernetes上安装KubeSphere 3.3.0，您的Kubernetes版本必须为：v1.19.x，v1.20.x，v1.21.x，v1.22.x 或 v1.23.x（实验性支持） 确保您的机器满足最低硬件要求：CPU \u003e 1核、内存 \u003e 2GB 在安装之前，需要配置Kubernetes集群中的默认存储类型，以便实现动态供应 配置NFS的动态供应的默认存储类 $ cat \u003e/opt/k8s/yaml/data-storage.yaml\u003c\u003c-EOF # 创建一个存储类 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs-storage annotations: storageclass.kubernetes.io/is-default-class: \"true\" provisioner: k8s-sigs.io/nfs-subdir-external-provisioner parameters: archiveOnDelete: \"true\" # 删除pv的时候，pv的内容是否要备份 --- apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/nfs-subdir-external-provisioner:v4.0.2 # resources: # limits: # cpu: 10m # requests: # cpu: 10m volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: k8s-sigs.io/nfs-subdir-external-provisioner - name: NFS_SERVER value: 192.168.94.110 # 指定自己nfs服务器地址 - name: NFS_PATH value: /opt/data/kubesphere # nfs服务器共享的目录 volumes: - name: nfs-client-root nfs: server: 192.168.94.110 path: /opt/data/kubesphere --- apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\"\"] resources: [\"nodes\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"create\", \"update\", \"patch\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default rules: - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io EOF 配置集群指标监控组件Kubernetes指标服务器 5.1 - --kubelet-insecure-tls：kubelet的10250端口使用的是https协议，连接需要验证tls证书，--kubelet-insecure-tls不验证客户端证书，仅用于测试目的 5.2 kube-state-metrics $ cat \u003e/opt/k8s/yaml/metrics_server.yaml\u003c\u003c-EOF apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server rbac.authorization.k8s.io/aggregate-to-admin: \"true\" rbac.authorization.k8s.io/aggregate-to-edit: \"true\" rbac.authorization.k8s.io/aggregate-to-view: \"true\" name: system:aggregated-metrics-reader rules: - apiGroups: - metrics.k8s.io resources: - pods - nodes verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server name: system:metrics-server rules: - apiGroups: - \"\" resources: - pods - nodes - nodes/stats - namespaces - configmaps verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server-auth-reader namespace: kube-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-reader subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server:system:auth-delegator roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegator subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: system:metrics-server roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-server subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: v1 kind: Service metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: ports: - name: https port: 443 protocol: TCP targetPort: https selector: k8s-app: metrics-server --- apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --kubelet-insecure-tls - --secure-port=4443 - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP - --kubelet-use-node-status-port image: k8s.gcr.io/metrics-server/metrics-server:v0.6.0 # image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/metrics-server:v0.4.3 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: path: /livez port: https scheme: HTTPS periodSeconds: 10 name: metrics-server ports: - containerPort: 4443 name: https protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /readyz port: https scheme: HTTPS periodSeconds: 10 securityContext: readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 volumeMounts: - mountPath: /tmp name: tmp-dir nodeSelector: kubernetes.io/os: linux priorityClassName: system-cluster-critical serviceAccountName: metrics-server volumes: - emptyDir: {} name: tmp-dir --- apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: k8s-app: metrics-server name: v1beta1.metrics.k8s.io spec: group: metrics.k8s.io groupPriorityMinimum: 100 insecureSkipTLSVerify: true service: name: metrics-server namespace: kube-system version: v1beta1 versionPriority: 100 EOF 5.1 执行命令查看Node节点结果 $ kubectl top nodes NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master-01 148m 7% 3690Mi 46% k8s-node-01 35m 1% 492Mi 8% k8s-node-02 32m 1% 358Mi 6% 5.2 执行命令查看Pod状态 $ kubectl top pods -A NAMESPACE NAME CPU(cores) MEMORY(bytes) default nfs-client-provisioner-6f9769d4c4-h6jw9 3m 12Mi ingress-nginx ingress-nginx-controller-5fd8bfcbdc-bzppj 2m 96Mi kube-flannel kube-flannel-ds-6tl2b 5m 33Mi kube-flannel kube-flannel-ds-n4k68 3m 33Mi kube-flannel kube-flannel-ds-zkqhz 3m 33Mi kube-system coredns-64897985d-6r9ds 2m 17Mi kube-system coredns-64897985d-fwmz5 2m 14Mi kube-system etcd-k8s-master-01 20m 112Mi kube-system kube-apiserver-k8s-master-01 63m 237Mi kube-system kube-controller-manager-k8s-master-01 20m 50Mi kube-system kube-proxy-blnt7 1m 18Mi kube-system kube-proxy-k5gkm 1m 17Mi kube-system kube-proxy-xpvqr 1m 17Mi kube-system kube-scheduler-k8s-master-01 5m 21Mi kube-system metrics-server-658c4cf555-bpfcf 5m 19Mi 下载、安装KubeSphere的yaml文件 $ wget -P /opt/k8s/yaml/kubesphere/ https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/kubesphere-installer.yaml $ wget -P /opt/k8s/yaml/kubesphere/ https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/cluster-configuration.yaml 6.1 修改cluster-configuration文件启用可插拔组件 6.1.1 官网启用可插拔组件 kind: ClusterConfiguration metadata: name: ks-installer namespace: kubesphere-system labels: version: v3.3.0 spec: persistence: storageClass: \"\" # If there is no default StorageClass in your cluster, you need to specify an existing StorageClass here. authentication: jwtSecret: \"\" # Keep the jwtSecret consistent with the Host Cluster. Retrieve the jwtSecret by executing \"kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v \"apiVersion\" | grep jwtSecret\" on the Host Cluster. local_registry: \"\" # Add your private registry address if it is needed. # dev_tag: \"\" # Add your kubesphere image tag you want to install, by default it's same as ks-installer release version. etcd: monitoring: true # 启用或禁用 etcd 监控仪表板安装。 在启用之前，您必须为 etcd 创建一个 Secret， 启用修改为：true endpointIps: 192.168.94.110 # etcd 集群 EndpointIps。 这里可以是一堆IP。 port: 2379 # etcd port. tlsEnable: true common: core: console: enableMultiLogin: true # Enable or disable simultaneous logins. It allows different users to log in with the same account at the same time. port: 30880 type: NodePort # apiserver: # Enlarge the apiserver and controller manager's resource requests and limits for the large cluster # resources: {} # controllerManager: # resources: {} redis: enabled: true # 启用 Redis 功能，修改为：true enableHA: false volumeSize: 2Gi # Redis PVC size. openldap: enabled: true # 启用轻量级目录协议，修改为：true volumeSize: 2Gi # openldap PVC size. minio: volumeSize: 20Gi # Minio PVC size. monitoring: # type: external # Whether to specify the external prometheus stack, and need to modify the endpoint at the next line. endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090 # Prometheus endpoint to get metrics data. GPUMonitoring: # Enable or disable the GPU-related metrics. If you enable this switch but have no GPU resources, Kubesphere will set it to zero. enabled: false gpu: # Install GPUKinds. The default GPU kind is nvidia.com/gpu. Other GPU kinds can be added here according to your needs. kinds: - resourceName: \"nvidia.com/gpu\" resourceType: \"GPU\" default: true es: # Storage backend for logging, events and auditing. # master: # volumeSize: 4Gi # The volume size of Elasticsearch master nodes. # replicas: 1 # The total number of master nodes. Even numbers are not allowed. # resources: {} # data: # volumeSize: 20Gi # The volume size of Elasticsearch data nodes. # replicas: 1 # The total number of data nodes. # resources: {} logMaxAge: 7 # Log retention time in built-in Elasticsearch. It is 7 days by default. elkPrefix: logstash # The string making up index names. The index name will be formatted as ks-\u003celk_prefix\u003e-log. basicAuth: enabled: false username: \"\" password: \"\" externalElasticsearchHost: \"\" externalElasticsearchPort: \"\" alerting: # (CPU: 0.1 Core, Memory: 100 MiB) It enables users to customize alerting policies to send messages to receivers in time with different time intervals and alerting levels to choose from. enabled: true # 启用或禁用 KubeSphere 警报系统，修改为：true # thanosruler: # replicas: 1 # resources: {} auditing: # Provide a security-relevant chronological set of records，recording the sequence of activities happening on the platform, initiated by different tenants. enabled: true # 启用或禁用 KubeSphere 审计日志系统，修改为：true # operator: # resources: {} # webhook: # resources: {} devops: # (CPU: 0.47 Core, Memory: 8.6 G) Provide an out-of-the-box CI/CD system based on Jenkins, and automated workflow tools including Source-to-Image \u0026 Binary-to-Image. enabled: true # 启用或禁用 KubeSphere DevOps 系统，修改为：true # resources: {} jenkinsMemoryLim: 2Gi # Jenkins memory limit. jenkinsMemoryReq: 1500Mi # Jenkins memory request. jenkinsVolumeSize: 8Gi # Jenkins volume size. jenkinsJavaOpts_Xms: 1200m # The following three fields are JVM parameters. jenkinsJavaOpts_Xmx: 1600m jenkinsJavaOpts_MaxRAM: 2g events: # Provide a graphical web console for Kubernetes Events exporting, filtering and alerting in multi-tenant Kubernetes clusters. enabled: true # 启用或禁用 KubeSphere 事件系统，修改为：true # operator: # resources: {} # exporter: # resources: {} # ruler: # enabled: true # replicas: 2 # resources: {} logging: # (CPU: 57 m, Memory: 2.76 G) Flexible logging functions are provided for log query, collection and management in a unified console. Additional log collectors can be added, such as Elasticsearch, Kafka and Fluentd. enabled: true # 启用或禁用 KubeSphere 日志系统，修改为：true logsidecar: enabled: true replicas: 2 # resources: {} metrics_server: # (CPU: 56 m, Memory: 44.35 MiB) It enables HPA (Horizontal Pod Autoscaler). enabled: false # 启用或禁用监控指标服务器，从hub.docker官方拉取镜像，网络不好会报网络错误，如果已提前安装请忽略，修改为：true monitoring: storageClass: \"\" # If there is an independent StorageClass you need for Prometheus, you can specify it here. The default StorageClass is used by default. node_exporter: port: 9100 # resources: {} # kube_rbac_proxy: # resources: {} # kube_state_metrics: # resources: {} # prometheus: # replicas: 1 # Prometheus replicas are responsible for monitoring different segments of data source and providing high availability. # volumeSize: 20Gi # Prometheus PVC size. # resources: {} # operator: # resources: {} # alertmanager: # replicas: 1 # AlertManager Replicas. # resources: {} # notification_manager: # resources: {} # operator: # resources: {} # proxy: # resources: {} gpu: # GPU monitoring-related plug-in installation. nvidia_dcgm_exporter: # Ensure that gpu resources on your hosts can be used normally, otherwise this plug-in will not work properly. enabled: false # Check whether the labels on the GPU hosts contain \"nvidia.com/gpu.present=true\" to ensure that the DCGM pod is scheduled to these nodes. # resources: {} multicluster: clusterRole: none # host | member | none # You can install a solo cluster, or specify it as the Host or Member Cluster. network: networkpolicy: # Network policies allow network isolation within the same cluster, which means firewalls can be set up between certain instances (Pods). # Make sure that the CNI network plugin used by the cluster supports NetworkPolicy. There are a number of CNI network plugins that support NetworkPolicy, including Calico, Cilium, Kube-router, Romana and Weave Net. enabled: true # 启用或禁用网络策略，修改为：true ippool: # Use Pod IP Pools to manage the Pod network address space. Pods to be created can be assigned IP addresses from a Pod IP Pool. type: none # 如果 Calico 用作您的 CNI 插件，请为此字段指定“calico”。 “none”表示 Pod IP 池已禁用 topology: # Use Service Topology to view Service-to-Service communication based on Weave Scope. type: none # Specify \"weave-scope\" for this field to enable Service Topology. \"none\" means that Service Topology is disabled. openpitrix: # An App Store that is accessible to all platform tenants. You can use it to manage apps across their entire lifecycle. store: enabled: true # 启用或禁用 KubeSphere 应用商店，修改为：true servicemesh: # (0.3 Core, 300 MiB) Provide fine-grained traffic management, observability and tracing, and visualized traffic topology. enabled: true # 基础组件（试点）。 启用或禁用 KubeSphere 服务网格（基于 Istio）微服务治理功能，修改为：true istio: # Customizing the istio installation configuration, refer to https://istio.io/latest/docs/setup/additional-setup/customize-installation/ components: ingressGateways: - name: istio-ingressgateway enabled: false cni: enabled: false edgeruntime: enabled: true # 将边缘节点添加到集群并在边缘节点上部署工作负载，启动边缘计算服务，修改为：true kubeedge: # kubeedge configurations enabled: false cloudCore: cloudHub: advertiseAddress: # At least a public IP address or an IP address which can be accessed by edge nodes must be provided. - \"\" # Note that once KubeEdge is enabled, CloudCore will malfunction if the address is not provided. service: cloudhubNodePort: \"30000\" cloudhubQuicNodePort: \"30001\" cloudhubHttpsNodePort: \"30002\" cloudstreamNodePort: \"30003\" tunnelNodePort: \"30004\" # resources: {} # hostNetWork: false iptables-manager: enabled: true mode: \"external\" # resources: {} # edgeService: # resources: {} gatekeeper: # Provide admission policy and rule management, A validating (mutating TBA) webhook that enforces CRD-based policies executed by Open Policy Agent. enabled: false # Enable or disable Gatekeeper. # controller_manager: # resources: {} # audit: # resources: {} terminal: # image: 'alpine:3.15' # There must be an nsenter program in the image timeout: 600 # Container timeout, if set to 0, no timeout will be used. The unit is seconds 6.2 修改好配置后安装KubeSphere $ kubectl apply -f kubesphere-installer.yaml $ kubectl apply -f cluster-configuration.yaml 6.3 跟踪安装进度 $ kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f 6.4 查看所有Pod是否在KubeSphere的相关命名空间中正常运行 $ kubectl get svc/ks-console -n kubesphere-system 6.5 解决prometheus-k8s的pods因为证书不能启动 $ kubectl -n kubesphere-monitoring-system create secret generic kube-etcd-client-certs --from-file=etcd-client-ca.crt=/etc/kubernetes/pki/etcd/ca.crt --from-file=etcd-client.crt=/etc/kubernetes/pki/apiserver-etcd-client.crt --from-file=etcd-client.key=/etc/kubernetes/pki/apiserver-etcd-client.key 6.6 使用浏览器访问KubeSphere放行：30880端口 默认用户名：admin 默认密码：P@88w0rd $ http://IP:30880 ",
    "description": "在现有Kubernetes上安装KubeSphere Web管理系统 Kuboard一款免费的Kubernetes管理界面 KubeOperator可视化的Web UI 如需在Kubernetes上安装KubeSphere 3.3.0，您的Kubernetes版本必须为：v1.19.x，v1.20.x，v1.21.x，v1.22.x 或 v1.23.x（实验性支持） 确保您的机器满足最低硬件要求：CPU \u003e 1核、内存 \u003e 2GB 在安装之前，需要配置Kubernetes集群中的默认存储类型，以便实现动态供应 配置NFS的动态供应的默认存储类 $ cat \u003e/opt/k8s/yaml/data-storage.",
    "tags": [],
    "title": "Install_K8s_KubeSphere",
    "uri": "/systems/linux/kubernetes/install_k8s_kubesphere/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "安装Harbor私有镜像库 默认用户名：admin 默认密码：Harbor12345 必须先安装docker Harbor依赖docker-compose 安装docker-compose $ curl -L https://get.daocloud.io/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose # 给予执行权限 $ chmod +x /usr/local/bin/docker-compose # 安装Compose命令补全工具 $ curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose $ systemctl daemon-reload \u0026\u0026 systemctl restart docker 安装Harbor $ wget https://github.com/goharbor/harbor/releases/download/v2.10.0/harbor-offline-installer-v2.10.0.tgz $ tar -zxvf harbor-offline-installer-v2.10.0.tgz $ vim harbor/harbor.yml hostname: reg.mydomain.com # 修改主机名： my.harbor.com port: 80 # 修改http默认端口：8080 # port: 443 # 注释https协议端口 $ ./install.sh 配置对Harbor的HTTPS访问 # 生成 CA 证书私钥 $ openssl genrsa -out ca.key 4096 # 生成 CA 证书 $ openssl req -x509 -new -nodes -sha512 -days 3650 \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=yourdomain.com\" \\ -key ca.key \\ -out ca.crt # 生成私钥 $ openssl genrsa -out yourdomain.com.key 4096 # 生成证书签名请求 (CSR) $ openssl req -sha512 -new \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=yourdomain.com\" \\ -key yourdomain.com.key \\ -out yourdomain.com.csr # 生成 x509 v3 扩展文件 $ cat \u003e v3.ext \u003c\u003c-EOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1=yourdomain.com DNS.2=yourdomain DNS.3=hostname EOF # 使用该v3.ext文件为您的 Harbor 主机生成证书 $ openssl x509 -req -sha512 -days 3650 \\ -extfile v3.ext \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -in yourdomain.com.csr \\ -out yourdomain.com.crt docker登录Harbor $ docker login http://192.168.80.225:8080 如果报错：Error response from daemon: Get http: server gave HTTP response to HTTPS client 修改配置文件(指定私有仓库，可忽略跳过) $ tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"storage-driver\": \"overlay2\", \"registry-mirrors\":[\"https://r2hd8p9u.mirror.aliyuncs.com\"], \"insecure-registries\":[\"*.*.*.*:5000\",\"192.168.4.126\"] } EOF$ vim /etc/docker/daemon.json { \"insecure-registries\": [\"harbor服务器IP:端口\"] } $ systemctl daemon-reload \u0026\u0026 systemctl restart docker 报错：request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) (Client.Timeout exceeded while awaiting headers) $ vim /etc/hosts # 修改hosts解析 本机服务IP my.harbodomain.com 推送镜像到Harbor仓库 SOURCE_IMAGE[:TAG]：原镜像名字和tag test：Harbor项目名称 IMAGE[:TAG]：自定义命名，以及版本标签 示例：\n# 在项目中标记镜像 $ docker tag SOURCE_IMAGE[:TAG] 192.168.35.128:9527/test/IMAGE[:TAG] # 推送镜像到当前项目 $ docker push 192.168.35.128:9527/test/IMAGE[:TAG] 其他服务器拉取Harbor仓库镜像 /etc/hosts做好解析 daemon.json文件中添加私人仓库参数 $ cat /etc/docker/daemon.json \"insecure-registries\":[\"192.168.80.210:8080\"], 拉取私人仓库镜像，前提仓库是公开类型，然后获取拉取命令 配置K8S使用Harbor镜像仓库 docker-harbor：secret名称自定义 --docker-server：Harbor仓库地址 --docker-username：Harbor登录用户名 --docker-password：Harbor仓库登录密码 --docker-email：邮箱地址 --namespace：指定命名空间，不指定默认为：default $ kubectl create secret docker-registry docker-harbor --docker-server=192.168.80.210:8080 --docker-username=admin --docker-password=Harbor12345 --docker-email=xxx@xxx.com --namespace=harbor 将机密数据转换为可读格式 $ kubectl get secret docker-harbor --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode # 输入以下内容 {\"auths\":{\"192.168.80.210:8080\":{\"username\":\"admin\",\"password\":\"Harbor12345\",\"email\":\"xxx@xxx.com\",\"auth\":\"YWRtaW46SGFyYm9yMTIzNDU=\"}}} 将base64编码的数据转换为可读格式 $ echo \"YWRtaW46SGFyYm9yMTIzNDU=\" | base64 --decode admin:Harbor12345 # 输出结果 生成yaml文件，并在spec.containers字段中修改私人镜像参数 生成Deployment的yaml文件并应用 $ kubectl create deployment java-demo --image=192.168.80.210:8080/test/tomcat-demo:v1 --dry-run=client -o yaml \u003e/tmp/deploy.yaml 192.168.80.210:8080：指定使用私人仓库地址，域名或者IP地址加端口号 test：私人仓库库房名称 tomcat-demo：使用私人仓库的镜像 v1：必须指定要使用私人仓库镜像的版本号 name: tomcat-demo：指定使用的镜像名字 imagePullSecrets:：指定使用其他镜像地址 - name: docker-harbor：指定定义的私人仓库名字 apiVersion: apps/v1 kind: Deployment metadata: labels: app: java-demo name: java-demo spec: replicas: 3 selector: matchLabels: app: java-demo template: metadata: labels: app: java-demo spec: containers: - image: 192.168.80.210:8080/test/tomcat-demo:v1 # 需修改处 name: tomcat-demo # 默认生成 imagePullSecrets: # 手动添加字段 - name: docker-harbor # 指定使用的secret库房名称 创建Service的yaml文件，应用并访问 $ kubectl expose deployment java-demo --port=80 --target-port=8080 --type=NodePort --dry-run=client -o yaml \u003e/opt/yaml/java-demo-svc.yaml $ cat \u003e\u003e/opt/yaml/java-demo-svc.yaml\u003c\u003c-EOF apiVersion: v1 kind: Service metadata: labels: app: java-demo name: java-demo spec: ports: - port: 8080 # Service 集群端口 protocol: TCP targetPort: 8080 # Pod 本身服务端口，比如Nginx：80，Tomcat：8080 nodePort: 30001 # 外网访问端口 selector: app: java-demo type: NodePort EOF $ kubectl create -f java-demo-svc.yaml $ kubectl get service $ http://192.168.80.210:30001/ # 浏览器访问地址 ",
    "description": "安装Harbor私有镜像库 默认用户名：admin 默认密码：Harbor12345 必须先安装docker Harbor依赖docker-compose 安装docker-compose $ curl -L https://get.daocloud.io/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose # 给予执行权限 $ chmod +x /usr/local/bin/docker-compose # 安装Compose命令补全工具 $ curl -L https://raw.",
    "tags": [],
    "title": "Install_K8s_Harbor",
    "uri": "/systems/linux/kubernetes/install_k8s_harbor/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "部署Dashboard(端口映射，可以用于web访问) 名称地址 描述 Kubernetes Dashboard 官方可视化界面 KubeSphere 青云 Rancher Kuboard kubernetes官方开发了一个基于web的用户界面DashBoard。用户可以使用DashBoard部署容器化的应用，而且还可以监控应用的状态，执行故障排查以及管理kubernetes中的各种资源。 下载用于部署DashBoard的yaml文件修改并运行 下载部署文件 $ cd /opt/kubernetes/cfg/ $ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml 修改recommended.yaml文件的Service类型 --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 # 此处新增 type: NodePort # 此处新增 selector: k8s-app: kubernetes-dashboard --- 部署DashBoard $ kubectl create -f recommended.yaml 查看namespace下名为kubernetes-dashboard下的资源 $ kubectl get pods,svc -n kubernetes-dashboard NAME READY STATUS RESTARTS AGE pod/dashboard-metrics-scraper-694557449d-mvnc8 1/1 Running 0 21s pod/kubernetes-dashboard-9774cc786-fm748 1/1 Running 0 21s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/dashboard-metrics-scraper ClusterIP 10.0.0.248 \u003cnone\u003e 8000/TCP 21s service/kubernetes-dashboard NodePort 10.0.0.15 \u003cnone\u003e 443:30001/TCP 22s dashboard-admin.yaml apiVersion: v1 kind: ServiceAccount metadata: name: dashboard-admin namespace: kubernetes-dashboard labels: name: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: dashboard-admin roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: dashboard-admin namespace: kubernetes-dashboard 创建service account并绑定默认cluster-admin管理员集群角色： $ kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard 授权： $ kubectl create clusterrolebinding dashboard-admin \\ --clusterrole=cluster-admin \\ --serviceaccount=kubernetes-dashboard:dashboard-admin 获取账号token # 第一种方式 $ kubectl describe secrets -n kubernetes-dashboard $(kubectl -n kubernetes-dashboard get secret | awk '/dashboard-admin/{print $1}') # 第二种方式 $ kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin $ kubectl describe secrets dashboard-admin-token-b992l -n kubernetes-dashboard 通过浏览器访问DashBoard的UI 打开浏览器访问：https://NodeIP:30001 打开谷歌浏览器提示：NET::ERR_CERT_INVALID 在chrome该页面上，直接键盘敲入这12个字符：thisisunsafe 注意：鼠标点击当前页面任意位置，让页面处于最上层即可输入 复制创建cluster-admin生成的token到浏览器登录 ",
    "description": "部署Dashboard(端口映射，可以用于web访问) 名称地址 描述 Kubernetes Dashboard 官方可视化界面 KubeSphere 青云 Rancher Kuboard kubernetes官方开发了一个基于web的用户界面DashBoard。用户可以使用DashBoard部署容器化的应用，而且还可以监控应用的状态，执行故障排查以及管理kubernetes中的各种资源。 下载用于部署DashBoard的yaml文件修改并运行 下载部署文件 $ cd /opt/kubernetes/cfg/ $ wget https://raw.",
    "tags": [],
    "title": "Install_K8s_Dashboard",
    "uri": "/systems/linux/kubernetes/install_k8s_dashboard/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "安装CoreDNS 去官网下载CoreDNSdeploy.sh和coredns.yam.sed两个文件 CoreDNS配置 $ wget https://github.com/coredns/deployment/blob/08c2b11241ef67b5d22d2020c00001ce0baec566/kubernetes/deploy.sh $ wget https://github.com/coredns/deployment/blob/08c2b11241ef67b5d22d2020c00001ce0baec566/kubernetes/coredns.yaml.sed # 查看帮助 $ ./deploy.sh -h REVERSE_CIDRS=\"10.254.0.0/16\"：配置kubernetes svc网段 CLUSTER_DNS_IP=\"10.254.0.2\"：配置kubernetes DNS IP CLUSTER_DOMAIN=\"cluster.local\"：配置kubernetes的域名 -r：kubernetes svc网段、-i：kubernetes DNS IP、-d：kubernetes的域名 $ ./deploy.sh -s -r 10.254.0.0/16 -i 10.254.0.10 -d cluster.local \u003e coredns.yaml # 修改前后对比 $ diff coredns.yaml coredns.yaml.sed # 启动Coredns $ kubectl apply -f coredns.yaml ",
    "description": "安装CoreDNS 去官网下载CoreDNSdeploy.sh和coredns.yam.sed两个文件 CoreDNS配置 $ wget https://github.com/coredns/deployment/blob/08c2b11241ef67b5d22d2020c00001ce0baec566/kubernetes/deploy.sh $ wget https://github.com/coredns/deployment/blob/08c2b11241ef67b5d22d2020c00001ce0baec566/kubernetes/coredns.yaml.sed # 查看帮助 $ .",
    "tags": [],
    "title": "Install_K8s_CoreDNS",
    "uri": "/systems/linux/kubernetes/install_k8s_coredns/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "Argo CD介绍 Argo CD是一个为Kubernetes而生的，遵循声明式GitOps理念的持续部署CD工具。Argo CD可在Git存储库更改时自动同步和部署应用程序 应用定义、配置和环境信息是声明式的，并可以进行版本控制 应用部署和生命周期管理是全自动化的、是可审计的，清晰易懂 安装Argo CD 创建ArgoCD命名空间 $ kubectl create namespace argocd 下载并启动ArgoCD $ kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 使用NodePort方式暴露argocd ui $ kubectl patch service -n argocd argocd-server -p '{\"spec\": {\"type\": \"NodePort\"}}' 获取ArgoCD的admin登陆密码 $ kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d 安装cli：CLI是用于管理Argo CD的命令行工具 $ curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/download/v2.3.3/argocd-linux-amd64 \u0026\u0026 chmod +x /usr/local/bin/argocd 查看argocd-server暴露端口 $ kubectl get svc -n argocd ",
    "description": "Argo CD介绍 Argo CD是一个为Kubernetes而生的，遵循声明式GitOps理念的持续部署CD工具。Argo CD可在Git存储库更改时自动同步和部署应用程序 应用定义、配置和环境信息是声明式的，并可以进行版本控制 应用部署和生命周期管理是全自动化的、是可审计的，清晰易懂 安装Argo CD 创建ArgoCD命名空间 $ kubectl create namespace argocd 下载并启动ArgoCD $ kubectl apply -n argocd -f https://raw.",
    "tags": [],
    "title": "Install_K8s_Argo_CD",
    "uri": "/systems/linux/kubernetes/install_k8s_argo_cd/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "Kubernetes数据存储 都知道容器的生命周期可能很短，会被频繁的创建和销毁。那么容器在销毁的时候，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器中的数据，kubernetes引入了Volume的概念 Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里面的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命周期不和Pod中的单个容器的生命周期有关，当容器终止或者重启的时候，Volume中的数据也不会丢失 kubernetes的Volume支持多种类型，比较常见的有下面的几个： 简单存储：EmptyDir、HostPath、NFS 高级存储：PV、PVC 配置存储：ConfigMap、Secret 简单存储 EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录 EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时，EmptyDir中的数据也会被永久删除。 EmptyDir的用途如下 临时空间例如用于某些应用程序运行时所需的临时目录，且无须永久保留 多容器共享目录一个容器需要从另一个容器中获取数据的目录 接下来，通过一个容器之间的共享案例来使用描述一个EmptyDir 在一个Pod中准备两个容器nginx和busybox然后声明一个volume分别挂载到两个容器的目录中，然后nginx容器负责向volume中写日志，busybox中通过命令将日志内容读到控制台 Kubernetes Emptydir Template模板 apiVersion: v1 kind: Pod metadata: name: emptydir-volume-template # 定义名称 namespace: default spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent command: [\"bash\",\"-c\",\"for i in {1..100};do echo $i \u003e\u003e/tmp/hello.txt;sleep 1;done\"] ports: - containerPort: 80 volumeMounts: # 将logs-volume挂载到nginx容器中的目录路径 - name: logs-volume mountPath: /tmp readOnly: false # 是否只读，默认false - name: busybox image: busybox:1.30 imagePullPolicy: IfNotPresent command: [\"bash\",\"-c\",\"tail -f /tmp/hello.txt\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的目录路径 - name: logs-volume mountPath: /tmp volumes: # 声明volume，name为logs-volume，类型为emptyDir - name: logs-volume # 共享存储卷名称 （volumes类型有很多种） emptyDir: {} # 类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值，使用 emptyDir: {} 表使用默认值 # medium: string # 存储介质，支持Memory和空字符串(默认) # sizeLimit: string # 大小限制，默认不限制。一般在使用Memory时会限制 HostPath 已经知道EmptyDir中的数据不会被持久化，它会随着Pod的结束而销毁，如果想要简单的将数据持久化到主机中，可以选择HostPath HostPath就是将Node主机中的一个实际目录挂载到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依旧可以保存在Node主机上 $ kubectl explain Pod.spec.volumes.hostPath.type # 类型声明 Directory：目录，必须存在 DirectoryOrCreate：目录存在就使用，不存在就先创建后使用 File：文件，必须存在 FileOrCreate：文件存在就使用，不存在就先创建后使用 Socket：unix套接字，必须存在 CharDevice：字符设备，必须存在 BlockDevice：块设备，必须存在 Kubernetes HostPath Template模板 apiVersion: v1 kind: Pod metadata: name: hostpath-volume-template namespace: default spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: # 将logs-volume挂载到nginx容器中的目录目录路径 - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 imagePullPolicy: IfNotPresent command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的目录目录路径 - name: logs-volume mountPath: /logs volumes: # 声明volume，name为logs-volume，类型为hostPath - name: logs-volume hostPath: # 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: /opt/logs # Pod所在宿主机的目录，将被用于同期中mount的目录 type: DirectoryOrCreate # 目录存在就使用，不存在就先创建再使用 NFS HostPath虽然可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到别的Node节点上，又会出现问题，此时需要准备单独的网络存储系统，比较常用的是NFS和CIFS NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样，无论Pod在节点上怎么转移，只要Node和NFS的对接没有问题，数据就可以成功访问 编辑nfs-volume.yaml文件挂载NFS Kubernetes NFS Template模板 apiVersion: v1 kind: Pod metadata: name: nfs-volume-template namespace: default spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: # 将logs-volume挂载到nginx容器中的目录路径 - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 imagePullPolicy: IfNotPresent command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件 volumeMounts: # 将logs-volume挂载到busybox容器中的目录路径 - name: logs-volume mountPath: /logs volumes: # 声明volume - name: logs-volume nfs: # 存储类型，和底层正则的存储对应 server: 192.168.18.100 # NFS服务器地址 path: /opt/data/nfs # 共享文件路径 readOnly: false # 是否只读，默认false 高级存储 PV持久卷 PV(Persistent Volume)是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它和底层具体的共享存储技术有关，并通过插件完成和共享存储的对接 pv的关键配置参数说明 存储类型：底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置有所不同 capacity(存储能力)：目前只支持存储空间的设置storage=1Gi，不过未来可能会加入IOPS、吞吐量等指标的配置 accessModes(访问模式)：用来描述用户应用对存储资源的访问权限，访问权限包括下面几种方式 需要注意的是：底层不同的存储类型可能支持的访问模式不同\nReadWriteOnce(RWO)：读写权限，但是只能被单个节点挂载\nReadOnlyMany(ROX)：只读权限，可以被多个节点挂载\nReadWriteMany(RWX)：读写权限，可以被多个节点挂载\npersistentVolumeReclaimPolicy(回收策略)：当PV不再被使用之后，对其的处理方式，目前支持三种策略 需要注意的是：底层不同的存储类型可能支持的回收策略不同\nRetain(保留)：保留数据，需要管理员手动清理数据\nRecycle(回收)：清除PV中的数据，效果相当于rm -rf /volume/*\nDelete(删除)：和PV相连的后端存储完成volume的删除操作，常见于云服务器厂商的存储服务\nstorageClassName(存储类别)：PV可以通过storageClassName参数指定一个存储类别 具有特定类型的PV只能和请求了该类别的PVC进行绑定 未设定类别的PV只能和不请求任何类别的PVC进行绑定 status(状态)：一个PV的生命周期，可能会处于4种不同的阶段 Available(可用)：表示可用状态，还未被任何PVC绑定 Bound(已绑定)：表示PV已经被PVC绑定 Released(已释放)：表示PVC被删除，但是资源还没有被集群重新释放 Failed(失败)：表示该PV的自动回收失败 PV：kubernetes管理员维护 构建静态PV存储卷 Kubernetes PV Template模板 ########## 定义Redis的静态 PV持久卷 ########## apiVersion: v1 kind: PersistentVolume metadata: name: redis-pv-template namespace: default labels: name: redis-pv-template spec: capacity: # 存储能力，目前只支持存储空间的设置 storage: 10Gi # 限制容量为 10G volumeMode: Filesystem # 存储类型为文件系统 accessModes: # 访问模式 - ReadWriteMany # Read：读、Write：写、Once：单节点、Many：代表多节点，Only：只读只写 persistentVolumeReclaimPolicy: Retain # 回收策略：Retain：保留、Recycle：回收、Delete：删除 storageClassName: nfs # 创建 PV 的存储类的自定义名字，PVC需要于此相同，存储类型，分别为： NFS、CephFS、iSCSI mountOptions: # 加载配置 - hard - nfsvers=4.1 # NFS 版本 nfs: # 存储类型，和storageClassName的存储类别对应 path: /opt/data/redis # nfs 授权目录 server: 192.168.186.110 # nfs 所在服务器PV持久卷 --- # 分隔符可以定义多个 ########## 定义Nginx的静态 PV持久卷 ########## apiVersion: v1 kind: PersistentVolume metadata: name: nginx-pv-template namespace: default labels: name: nginx-pv-template spec: capacity: storage: 10Gi volumeMode: Filesystem accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: nfs mountOptions: # 加载配置 - hard - nfsvers=4.1 # NFS 版本 nfs: path: /opt/data/nginx server: 192.168.186.110 构建动态PV存储卷 StorageClass动态资源存储 Kubernetes StorageClass Template模板 apiVersion: storage.k8s.io/v1 kind: StorageClass # 创建动态存储类 metadata: name: nfs-storage-template namespace: default annotations: storageclass.kubernetes.io/is-default-class: \"true\" provisioner: fuseim.pri/ifs # 外部制备器提供者，编写为提供者的名称，k8s-sigs.io/nfs-subdir-external-provisioner allowVolumeExpansion: true # 动态调整持久卷大小 parameters: # archiveOnDelete: \"true\" # 是否存档，false：表示不存档，会删除oldPath下面的数据，true：表示存档，会重命名路径 reclaimPolicy: Retain # 回收策略，默认为：Delete， volumeBindingMode: Immediate # 默认为：Immediate，表示创建 PVC立即进行绑定，只有：azuredisk和：AWSelasticblockstore 支持其他值 创建权限，Kubernetes Permissions Template模板 apiVersion: v1 kind: ServiceAccount # 权限管理 metadata: name: nfs-client-provisioner namespace: default --- kind: ClusterRole # 创建集群角色 apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\"\"] resources: [\"nodes\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"create\", \"update\", \"patch\"] --- kind: ClusterRoleBinding # 绑定集群角色 apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role # 创建普通角色 apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner namespace: default rules: - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"] --- kind: RoleBinding # 绑定普通角色 apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner namespace: default subjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 创建适用与provisioner的DeploymentKubernetes Deployment Provisioner NFS Template模板 apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner namespace: default labels: app: nfs-client-provisioner spec: replicas: 2 strategy: type: Recreate # Recreate:不滚动更新， selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: hostNetwork: true serviceAccountName: nfs-client-provisioner # 关联：nfs-client-provisioner 账号授与账户权限 containers: - name: nfs-client-provisioner image: registry.cn-beijing.aliyuncs.com/pylixm/nfs-subdir-external-provisioner:v4.0.0 resources: limits: cpu: 200m memory: 128Mi requests: cpu: 50m memory: 64Mi volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs # 必须和StorageClass的外部制备器提供者名字相同 - name: NFS_SERVER value: 192.168.186.110 # 指定自己nfs服务器地址 - name: NFS_PATH value: /opt/data/redis # nfs服务器共享的目录 volumes: - name: nfs-client-root nfs: server: 192.168.186.110 path: /opt/data/redis 创建Service、StatefulSet、PVC申请动态存储卷Kubernetes Service StatefulSet NFS Template模板 apiVersion: v1 kind: Service metadata: name: service-template namespace: default spec: selector: name: statefulset-template type: NodePort ports: - port: 80 # Service的端口 protocol: TCP targetPort: 80 # StatefulSet 的Pod端口 --- apiVersion: apps/v1 kind: StatefulSet metadata: name: statefulset-template namespace: default spec: replicas: 3 serviceName: service-template # 使用那个Service管理DNS updateStrategy: type: RollingUpdate # 滚动更新，OnDelete：删除更新 rollingUpdate: # 如果更新的策略是OnDelete，那么rollingUpdate就失效 partition: 2 # 表示从第2个分区开始更新，默认是0 selector: matchLabels: name: statefulset-template template: metadata: labels: name: statefulset-template spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - name: nginx-pvc-test # 关联 PVC 名字，以便使用 mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: nginx-pvc-test # 定义：PVC 名字 spec: storageClassName: nfs-storage-template # 存储类名字，必须和StorageClass的pods名字相同 accessModes: # 访问模式 - ReadWriteMany # 多节点读写 resources: # 期望资源 requests: storage: 2Gi # 期望的空间容量 StatefulSet的Pods处于Pending状态，describe命令查看有以下报错 0/3 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.. quay.io/external_storage/nfs-client-provisioner:latest官方镜像需要用到K8S里的SelfLink参数 解决方法 # 方法一：更换镜像，建议使用此方法 # 镜像一 gcr.io/k8s/staging-sig-storage/nfs-subdir-external-provisioner:v4.0.0 # 镜像二 registry.cn-beijing.aliyuncs.com/pylixm/nfs-subdir-external-provisioner:v4.0.0 # 更换镜像后重新应用 $ kubectl replace -f kubernetes-deployment-provisioner-nfs-template.yaml # 方法二：解决官方不支持方式 $ sudo cat \u003e\u003e/etc/kubernetes/manifests/kube-apiserver.yaml\u003c\u003c-EOF spec: containers: - command: - kube-apiserver - --feafure-gates=RemoveSelfLink=false # 新增参数，默认是：true EOF # 重新应用 $ kubectl apply -f /etc/kubernetes/manifests/kube-apiserver.yaml 使用PVC 方式申请动态StorageClass apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-template namespace: default spec: accessModes: - ReadWriteMany resources: requests: storage: 200Mi storageClassName: nfs-storage-template # 存储类名字，必须和StorageClass的pods名字相\tPVC持久卷申请书 PVC(Persistent Volume Claim)是持久化卷声明的意思，是用户对于存储需求的一种声明。换言之，PVC其实就是用户向kubernetes系统发出的一种资源需求申请 PVC：kubernetes用户维护 PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息 PVC的关键配置参数说明 accessModes(访客模式)：用于描述用户应用对存储资源的访问权限 selector(选择条件)：通过Label Selector的设置，可使PVC对于系统中已存在的PV进行筛选 storageClassName(存储类别)：PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出 resources(资源请求)：描述对存储资源的请求 Kubernetes PVC Template模板 ########## 定义Redis的PVC申请书，用于申请 Redis的PV ########## apiVersion: v1 kind: PersistentVolumeClaim metadata: name: redis-pvc-template namespace: default labels: name: redis-pvc-template spec: volumeMode: Filesystem # 文件系统也需要与 PV相同才能使用 accessModes: # 访问模式 - ReadWriteMany # 权限需要与对应的PV 相同，才可以使用，Read：读、Write：写、Once：单节点、Many：代表多节点，Only：只读只写 storageClassName: nfs # 需要与PV名字相同，Block:代表块存储、Filesystem:代表文件系统、nfs resources: # 请求空间 requests: storage: 5Gi # 对PV申请 5G 的存储空间 --- ########## 定义Nginx的PVC申请书，用于申请 Redis的PV ########## apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc-template namespace: default labels: name: nginx-pvc-template spec: volumeMode: Filesystem accessModes: # 访问模式 - ReadWriteMany # Read:代表可读、Write:代表写、Many:代表多节点 storageClassName: nfs # 存储类型 ，Block:代表块存储、Filesystem:代表文件系统、nfs resources: # 请求空间 requests: storage: 5Gi # 对PV申请 5G 的存储空间 --- ########## 创建 Deployment 访问 PVC 类型存储 ########## apiVersion: apps/v1 kind: Deployment metadata: name: redis-pod-pvc-template namespace: default labels: name: redis-pod-pvc-template spec: replicas: 2 revisionHistoryLimit: 3 progressDeadlineSeconds: 600 strategy: rollingUpdate: # 当type为RollingUpdate的时候生效，用于为rollingUpdate设置参数 maxUnavailable: 30% # 用来指定在升级过程中不可用的Pod的最大数量，默认为25%。 maxSurge: 30% # 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25% type: RollingUpdate # 更新策略、支持 Recreate, RollingUpdate。默认RollingUpdate selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则，matchExpressions：Expressions匹配规则 name: redis-pvc-template template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: # Pod 的标签 name: redis-pvc-template spec: # nodeSelector: # kubernetes.io/hostname: kube-01 # 指定节点 containers: - name: reids image: redis:6.2.7 command: [\"/bin/sh\",\"-c\",\"while true;do echo pod1 \u003e\u003e /root/out.txt; sleep 10; done;\"] volumeMounts: - name: redis-data # 必须与volume定义的名称相同 mountPath: /opt/redis/conf # 容器内路径 volumes: - name: redis-data # 自定义名称 persistentVolumeClaim: # 关联 PVC claimName: redis-pvc-template # 关联 PVC，必须和定义PVC名称相同且，必须和当前pod在同一个命名空间 readOnly: false # 是否只读，默认false PV和PVC 创建PVC后一直绑定不了PV的原因 ① PVC的空间申请大小比PV的空间要大\n② PVC的storageClassName和PV的storageClassName不一致\n③ PVC的accessModes和PV的accessModes不一致\nPVC和PV是一一对应，PV和PVC之间的相互作用遵循如下生命周期 资源供应：管理员手动创建底层存储和PV 资源绑定 用户创建PVC，kubernetes负责根据PVC声明去寻找PV，并绑定在用户定义好PVC之后，系统将根据PVC对存储资源的请求在以存在的PV中选择一个满足条件的 一旦找到就将该PV和用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了 如果找不到PVC就会无限期的处于Pending状态，直到系统管理员创建一个符合其要求的PV PV一旦绑定到某个PVC上就会被这个PVC独占，不能再和其他的PVC进行绑定了 资源使用：用户可以在Pod中像volume一样使用PVC，Pod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用 资源释放 用户删除PVC来释放PV 当存储资源使用完毕后，用户可以删除PVC，和该PVC绑定的PV将会标记为已释放但是还不能立刻和其他的PVC进行绑定。通过之前PVC写入的数据可能还留在存储设备上，只有在清除之后该PV才能再次使用 资源回收 kubernetes根据PV设置的回收策略进行资源的回收 对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用 配置文件存储管理 ConfigMap\u0026Secret覆盖热更新 注意事项 使用SubPath解决ConfigMap\u0026\u0026Secret目录覆盖问题，SubPath不支持热更新 如果ConfigMap和Secret是以subPath的形式挂载的，那么Pod是不会感知到ConfigMap和Secret的更新的 如果Pod的变量来自ConfigMap和Secret中定义的内容，那么ConfigMap和Secret更新后，也不会更新Pod中的变量 immutable: true：禁止修改ConfigMap、Secret ConfigMap配置类型 ConfigMap简介以及注意事项 ConfigMap：是一个比较特殊的存储卷，它的主要作用是用来存储配置信息的 ConfigMap中的key映射为一个文件，value映射为文件中的内容。如果更新了ConfigMap中的内容，容器中的值也会动态更新 ConfigMap是一种API对象，用来将非加密数据保存到键值对中。可以用作环境变量、命令行参数或者存储卷中的配置文件 ConfigMap可以将环境变量配置信息和容器镜像解耦，便于应用配置的修改。如果需要存储加密信息时可以使用Secret对象 使用ConfigMap有以下几个限制条件： ConfigMap必须在pod之前创建 ConfigMap受namespace的限制，只能相同namespace的pod才可以引用 注意事项 ConfigMap在设计上不是用来保存大量数据的在ConfigMap中保存的数据不可超过1 MiB 如果需要保存超出此尺寸限制的数据，需要考虑挂载存储卷或者使用独立的数据库或者文件服务 ConfigMap使用以及配置 获取使用帮助 $ kubectl create configmap -h # 查看使用帮助 $ kubectl create configmap \u003cmap-name\u003e \u003cdata-source\u003e # 命令使用方式 从目录中创建ConfigMap $ mkdir -pv /opt/yaml/configmap/config $ cat \u003e\u003e/opt/yaml/configmap/config/db.properties\u003c\u003c-EOF port=3306 username=root host=127.0.0.1 password=password EOF $ cat \u003e\u003e/opt/yaml/configmap/config/redis.properties\u003c\u003c-EOF port=6379 host=127.0.0.1 password=password EOF # --from-file：目录下的所有文件都会被用在ConfigMap里面创建一个键值对，键的名字就是文件名，值就是文件的内容， $ kubectl create configmap configmap-template --from-file=/opt/yaml/configmap/config/ 从文件中创建ConfigMap，并自定义ConfigMap中key的名称 # --from-file，可以使用多次，同样键为文件名，值为文件中的内容 $ kubectl create configmap configmap-template-2 \\ --from-file=rename1=/opt/yaml/configmap/config/db.properties \\ --from-file=rename2=/opt/yaml/configmap/config/redis.properties --from-literal=key=value键值对方式 # 使用：literal(key:value)，方式，--from-literal=key1=123 --from-literal=key2=234 $ kubectl create configmap configmap-template-3 \\ --from-literal=key-1=value-1 \\ --from-literal=key-2=value-2 从环境变量文件创建ConfigMap 注意：当--from-env-file从多个数据源创建ConfigMap的时候，仅仅最后一个env文件有效\n语法规则：\nenv文件中的每一行必须为VAR = VAL格式\n以＃开头的行(即注释)将被忽略\n空行将被忽略\n引号没有特殊处理(即它们将成为ConfigMap值的一部分)\n$ kubectl create configmap configmap-template-3 \\ --from-literal=password=passwd123 \\ --from-literal=APP_NAME=springboot-test \\ --from-literal=JAVA_OPTS_TEST='Xms512m -Xmx512' Kubernetes ConfigMap ENV Template模板 apiVersion: apps/v1 kind: Deployment metadata: name: configmap-env-test namespace: default spec: replicas: 2 revisionHistoryLimit: 10 progressDeadlineSeconds: 600 selector: matchLabels: name: configmap-env-test strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: labels: name: configmap-env-test spec: containers: - name: env-test image: busybox command: [ \"/bin/sh\", \"-c\", \"env;sleep 3600\" ] imagePullPolicy: IfNotPresent env: # 定义环境变量 - name: APP_ENV_TEST_CM # 定义环境变量名 valueFrom: configMapKeyRef: name: configmap-template-3 # ConfigMap 的名字 key: APP_NAME # 表示从 name的ConfigMap中获取名字为Key 的value，将其赋值给容器内本地的环境变量 APP_ENV_TEST_CM - name: JAVA_ENV_TEST_CM valueFrom: configMapKeyRef: name: configmap-template-3 # ConfigMap 的名字 key: JAVA_OPTS_TEST # ConfigMap 的 key volumeMounts: # 加载数据卷 - name: passwd-config # 表示加载 volumes 属性中那个数据卷 mountPath: \"/opt/\" # 想要将数据卷中的文件加载到那个目录下 readOnly: true # 是否只读 volumes: # 依数据卷方式挂载 ConfigMap Secret - name: passwd-config # 自定义名字 configMap: # 数据卷类型为：ConfigMap name: configmap-template-3 # ComfigMap 的名字，必须和加载的ConfigMap相同 items: # 对 ConfigMap中的Key进行映射，如果不指定，默认会将ConfigMap中所有Key全部转换为一个个同名文件 - key: \"password\" # ConfigMap中的Key path: \"password\" # 将该Key的值转换为文件 restartPolicy: Always$ cat \u003e\u003e/opt/yaml/configmap/config/env-file.properties\u003c\u003c-EOF enemies=aliens lives=3 allowed=\"true\" EOF $ kubectl create cm configmap-template-3 \\ --from-env-file=/opt/yaml/configmap/config/env-file.properties $ cat \u003e\u003eenv.txt\u003c\u003c-EOF # 其中，env.txt的文件格式为: key1=*** key2=*** EOF $ kubectl create configmap configmap名 --from-env-file=env.txt ConfigMap使用nginx.conf配置文件进行替换 $ cat \u003e\u003enginx.conf\u003c\u003c-EOF #user nobody; worker_processes 1; events { worker_connections 1024; } ######### 我是测试配置文件 ########## http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } EOF 使用nginx.conf创建ConfigMap $ kubectl create configmap nginxconf-cm-template --from-file=nginx.conf Kubernetes configmap Template模板 ########## 配置 Deployment 引用 ConfigMap 创建的文件 ########## apiVersion: apps/v1 kind: Deployment metadata: name: nginx-configmap-template namespace: default spec: replicas: 2 revisionHistoryLimit: 10 progressDeadlineSeconds: 600 selector: matchLabels: name: nginx-cm-template strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: labels: name: nginx-cm-template spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: IfNotPresent resources: limits: cpu: 200m memory: 128Mi requests: cpu: 50m memory: 128Mi volumeMounts: - name: nginx-config # 引用定义的 vulumes 名称 mountPath: '/etc/nginx/nginx.conf' # 文件全路径 subPath: etc/nginx/nginx.conf # subPath：要覆盖文件的相对路径，只覆盖必要文件，如果缺少此配置，将清空原有的所有文件和目录，不需要最前面的：/ restartPolicy: Always terminationGracePeriodSeconds: 30 volumes: - name: nginx-config # 定义 volumes 的名称 configMap: # 类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: nginxconf-cm-template # ConfigMap名称，使用名称进行关联 ConfigMap items: # 将configMap中的Key进行映射，如果不指定，默认会将configMap中所有Key全部转为一个个同名文档 - key: nginx.conf # configMap中的Key path: etc/nginx/nginx.conf # 将该Key的值转为文件，最前面不需要：/ 进入Pod中查看 $ kubectl exec -it nginx-configmap-pod -- /bin/sh $ more /etc/nginx/nginx.conf Kubernetes ConfigMap Simple Template模板 apiVersion: v1 kind: ConfigMap metadata: name: configmap-template # ConfigMap namespace: default data: # \u003cmap[string]string\u003e info: username:admin password:123456 ########## 挂载数据方式 ########## data: stream.conf: | stream.conf { server { listen 1550; proxy_pass 192.168.3.125:16303; } } ########## 挂载数据方式 ########## data: listen-port: \"8080\" server-name: www.erge.com default-vhost: | # 此内容传给 Pod 中 items: 下 path: 路径中 server { listen 8080 default; location / { return 200 \"default-vhost!\\r\\n\"; } } blog-vhosts: | server { listen 8080; server_name blog.erge.com; location / { return 200 \"blog-vhosts!\\r\\n\"; } } --- ########## 配置env引用方式 pod-configmap ########## apiVersion: v1 kind: Pod metadata: name: configmap-pod namespace: default labels: tier: configmap role: slb spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: - mountPath: '/etc/nginx' name: config env: - name: LISTEN_PORT valueFrom: configMapKeyRef: name: slb-vhosts-config key: listen-port - name: SERVER_NAME valueFrom: configMapKeyRef: name: slb-vhosts-config key: server-name volumes: - name: config # 定义 volumes 的名称 configMap: # 类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: configmap-template # ConfigMap生成的Pod 名称，使用名称关联 # items: # 将configMap中的Key进行映射，如果不指定，默认会将configMap中所有Key全部转为一个个同名文档 # - key: nginx.conf # configMap中的Key # path: etc/nginx/nginx.conf # 将该Key的值转为文件 --- ########## 配置volume引用方式 pod-configmap ########## apiVersion: v1 kind: Pod metadata: name: pod-configmap namespace: default spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: - mountPath: /configmap/config # 没有则会自动创建,目录下有文件则会覆盖掉 name: nginx-config volumes: - name: nginx-config # 此名称和 volumeMounts定义name名称一样 configMap: # 类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: configmap # 配置为 configMap 容器的名称 defaultMode: integer # 挂载到Pod中后，文件权限，如0444 items: - key: default-vhost # configMap中data下的key path: default.conf # 挂载路径，获取Configmap中data关键字下 定义配置文件名传给 volumeMounts 下的mountPath中 mode: integer # 文件权限 - key: blog-vhosts path: blog.conf optional: true # 当key不存在时是否报错，默认true Secret密码令牌类型 Secret简介以及注意事项 Secret：在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象，它主要用来存储敏感信息，例如密码、密钥、证书等等 imagePullSecret：Pod拉取私有镜像仓库的时使用的账户密码，会传递给kubelet，然后kubelet就可以拉取有密码的仓库里面的镜像 如果同时使用data和stringData，那么data会被忽略 Secret使用以及配置 获取使用帮助 $ kubectl create secret -h # 查看使用帮助 $ kubectl create secret [flags] [options] # 命令使用方式 使用base64对准备的数据进行编码：对用户名、密码进行编码 $ echo -n 'user_name' | base64 # 特殊字符使用：''(单引号) $ echo -n 'password' | base64 # 解码使用：--decode $ echo -n 'dXNlcl9uYW1l' | base64 --decode 从命令行创建Secret $ kubectl create secret generic secret-name \\ --from-literal=username=admin \\ --from-literal=password='passwd@!3-' # 特殊字符使用：''(单引号) 创建Secret连接Harbor私人仓库 docker-harbor-registrykey：Secret的Pods名称，自定义 --docker-server：镜像仓库地址 --docker-username：镜像仓库用户名 --docker-password：镜像仓库密码 --docker-email：邮箱地址 # 获取 docker-registry 使用帮助 $ kubectl create secret docker-registry -h # 创建一个ImagePullSecret $ kubectl create secret docker-registry docker-harbor-registrykey \\ --docker-server=192.168.18.119:85:8080 \\ --docker-username=admin \\ --docker-password=Harbor12345 \\ --docker-email=xxxxx@qq.com # 查看是否创建成功 $ kubectl get secret docker-harbor-registrykey 创建redis.yaml文件，获取Harbor仓库镜像 apiVersion: v1 kind: Pod metadata: name: redis namespace: default spec: imagePullSecrets: # 配置登录 docker registry 的 secret 仓库 - name: docker-harbor-registrykey # 引用Secret的Pods，容器名称 containers: - name: redis image: 192.168.18.119:85/yuncloud/redis # 这是Harbor的镜像私有仓库地址 准备volumes-secret资源清单 apiVersion: v1 kind: Secret metadata: name: secret namespace: default type: Opaque data: # 提前编码使用：data、使用Kubernetes进行编码使用：stringData username: YWRtaW4= # 使用kubernetes进行编码写，原数据：admin password: MTIzNDU2 # 使用kubernetes进行编码写，原数据：123456 --- ########## 配置 secret-pod ########## apiVersion: v1 kind: Pod metadata: name: secret-pod namespace: default spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: - name: config mountPath: /secret/config volumes: - name: config secret: # 类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 secretName: secret items: - key: string path: string 查看编码后的目录以及信息 # 将nginx.conf导出到本地 $ kubectl exec -it nginx -- cat /etc/nginx/nginx.conf \u003e nginx.conf $ kubectl exec -it secret-pod-name -n default -- /bin/sh $ ls /secret/config $ more /secret/config/username $ more /secret/config/password ",
    "description": "Kubernetes数据存储 都知道容器的生命周期可能很短，会被频繁的创建和销毁。那么容器在销毁的时候，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器中的数据，kubernetes引入了Volume的概念 Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里面的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命周期不和Pod中的单个容器的生命周期有关，当容器终止或者重启的时候，Volume中的数据也不会丢失 kubernetes的Volume支持多种类型，比较常见的有下面的几个： 简单存储：EmptyDir、HostPath、NFS 高级存储：PV、PVC 配置存储：ConfigMap、Secret 简单存储 EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录 EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时，EmptyDir中的数据也会被永久删除。 EmptyDir的用途如下 临时空间例如用于某些应用程序运行时所需的临时目录，且无须永久保留 多容器共享目录一个容器需要从另一个容器中获取数据的目录 接下来，通过一个容器之间的共享案例来使用描述一个EmptyDir 在一个Pod中准备两个容器nginx和busybox然后声明一个volume分别挂载到两个容器的目录中，然后nginx容器负责向volume中写日志，busybox中通过命令将日志内容读到控制台 Kubernetes Emptydir Template模板 apiVersion: v1 kind: Pod metadata: name: emptydir-volume-template # 定义名称 namespace: default spec: # 必选，Pod中容器的详细定义 containers: # 必选，Pod中容器列表 - name: nginx image: nginx:1.",
    "tags": [],
    "title": "Configure_K8s_Storage",
    "uri": "/systems/linux/kubernetes/configure_k8s_storage/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "Rancher服务宕机情况下使用Kubernetes Cluster Rancher清理节点 #!/bin/bash KUBE_SVC=' kubelet kube-scheduler kube-proxy kube-controller-manager kube-apiserver ' for kube_svc in ${KUBE_SVC}; do # 停止服务 if [[ `systemctl is-active ${kube_svc}` == 'active' ]]; then systemctl stop ${kube_svc} fi # 禁止服务开机启动 if [[ `systemctl is-enabled ${kube_svc}` == 'enabled' ]]; then systemctl disable ${kube_svc} fi done # 停止所有容器 docker stop $(docker ps -aq) # 删除所有容器 docker rm -f $(docker ps -qa) # 删除所有容器卷 docker volume rm $(docker volume ls -q) # 卸载mount目录 for mount in $(mount | grep tmpfs | grep '/var/lib/kubelet' | awk '{ print $3 }') /var/lib/kubelet /var/lib/rancher; do umount $mount; done # 备份目录 mv /etc/kubernetes /etc/kubernetes-bak-$(date +\"%Y%m%d%H%M\") mv /var/lib/etcd /var/lib/etcd-bak-$(date +\"%Y%m%d%H%M\") mv /var/lib/rancher /var/lib/rancher-bak-$(date +\"%Y%m%d%H%M\") mv /opt/rke /opt/rke-bak-$(date +\"%Y%m%d%H%M\") # 删除残留路径 rm -rf /etc/ceph \\ /etc/cni \\ /opt/cni \\ /run/secrets/kubernetes.io \\ /run/calico \\ /run/flannel \\ /var/lib/calico \\ /var/lib/cni \\ /var/lib/kubelet \\ /var/log/containers \\ /var/log/kube-audit \\ /var/log/pods \\ /var/run/calico \\ /usr/libexec/kubernetes # 清理网络接口 no_del_net_inter=' lo docker0 eth ens bond ' network_interface=`ls /sys/class/net` for net_inter in $network_interface; do if ! echo \"${no_del_net_inter}\" | grep -qE ${net_inter:0:3}; then ip link delete $net_inter fi done # 清理残留进程 port_list=' 80 443 6443 2376 2379 2380 8472 9099 10250 10254 ' for port in $port_list; do pid=`netstat -atlnup | grep $port | awk '{print $7}' | awk -F '/' '{print $1}' | grep -v - | sort -rnk2 | uniq` if [[ -n $pid ]];then kill -9 $pid fi done kube_pid=`ps -ef | grep -v grep | grep kube | awk '{print $2}'` if [[ -n $kube_pid ]];then kill -9 $kube_pid fi # 清理Iptables表 ## 注意：如果节点Iptables有特殊配置，以下命令请谨慎操作 sudo iptables --flush sudo iptables --flush --table nat sudo iptables --flush --table filter sudo iptables --table nat --delete-chain sudo iptables --table filter --delete-chain systemctl restart docker Rancher Server是上游中心管理角色，控制或创建旗下N个Kubernetes Cluster集群，不管是测试中的单个节点或者是Kubernetes Cluster集群失效都无法读取，运维仍需要对下游所有Kubernetes Cluster集群管控 服务器 IP CPU 内存 master 192.168.35.128 8core 8G node-1 192.168.35.129 4core 4G node-2 192.168.35.130 4core 4G 前提条件 3.1 所有机器都是CentOS 7 3.2 Rancher Server是以Docker方式单独建立 3.3 test-cluster Kubernetes Cluster集群是以Rancher Server自定义方式创建 模拟Racnher Server服务失效对Kubernetes Cluster集群进行管控 4.1 点击创建集群名称 4.2 提前下载Kubernetesfig文件 模拟Rancher服务宕机 停止Rancher Server服务docker stop rancher 1.1 查看Kubernetes集群版本号 安装Kubectl 在能连接test-kubernetes-cluster集群中任意一个节点部署Kubectl Kubectl版本需和test-cluster-cluster版本相同或者高于 $ cat \u003e/etc/yum.repos.d/kubernetes.repo\u003c\u003c-EOF [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF $ yum -y install kubectl-1.23.6-0 创建.kube目录修改文件 并且将下载的Kubernetesfig文件改名为config，然后放到${HOME}/.kube/目录中 $ mkdir ${HOME}/.kube $ mv ${HOME}/.kube/test-kubernetes-cluster.yaml ${HOME}/.kube/config ${HOME}/.kube/config文件没修改前 $ cat ${HOME}/.kube/config apiVersion: v1 kind: Config clusters: - name: \"test-kubernetes-cluster\" cluster: server: \"https://192.168.80.210:4443/k8s/clusters/c-gwknl\" certificate-authority-data: \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJwekNDQ\\ VUyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQTdNUnd3R2dZRFZRUUtFeE5rZVc1aGJXbGoKY\\ kdsemRHVnVaWEl0YjNKbk1Sc3dHUVlEVlFRREV4SmtlVzVoYldsamJHbHpkR1Z1WlhJdFkyRXdIa\\ GNOTWpJdwpOVEkxTVRFeE9UUXhXaGNOTXpJd05USXlNVEV4T1RReFdqQTdNUnd3R2dZRFZRUUtFe\\ E5rZVc1aGJXbGpiR2x6CmRHVnVaWEl0YjNKbk1Sc3dHUVlEVlFRREV4SmtlVzVoYldsamJHbHpkR\\ 1Z1WlhJdFkyRXdXVEFUQmdjcWhrak8KUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVJTb3NwRzE4OHJBQ\\ mZabTAwQnRqcjAyL29udnZGVnppU09wZUdVd09SUApoSHpUbk1acTRmazVpRFhPV2lIUy9iQ0hvT\\ WQra1VtYkx6QVRPNkd2azdtSm8wSXdRREFPQmdOVkhROEJBZjhFCkJBTUNBcVF3RHdZRFZSMFRBU\\ UgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVZ1YzR1g0Z2tXN3hPZVZWQURWem0KVEpxSW95b3dDZ\\ 1lJS29aSXpqMEVBd0lEU0FBd1JRSWdlTHh3WTVGcGkweDBGNXhBQUNZMnNPbVQ4aHBqNjVCWApUc\\ 1lsQk1sOGx0RUNJUURkNmlONTJmbG9hVzZybXpvWXRLQy9nOEJRRW00b2UrcGN0YldCaGY0UENRP\\ T0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQ==\" - name: \"test-kubernetes-cluster-node-1-80-211\" cluster: server: \"https://192.168.80.211:6443\" certificate-authority-data: \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM0VENDQ\\ WNtZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFTTVJBd0RnWURWUVFERXdkcmRXSmwKT\\ FdOaE1CNFhEVEl5TURVeU5URXhNek0xTUZvWERUTXlNRFV5TWpFeE16TTFNRm93RWpFUU1BNEdBM\\ VVFQXhNSAphM1ZpWlMxallUQ0NBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ\\ 0VCQUtJSzVRVy84eHB3CkRHUzMrN0M2Q0lobS8zcWFUUENvVmdFeU91YkVtR1EzbnAvYk9qTUJKY\\ 3Ayck05cW5CV2M4ZmtUUWhCNHZsL24Kay8zSkUrMkdta1RBbVAwaGpLa3d6d1JiT2lrYzdYVEtnd\\ ElTQ3I2cjRkOWhZTElERElzTTJtUzZYYnhNdGd1SApoamk3MTJYQmNoZ3lEamxjREl3S1k5WXRYc\\ 3lDY3hPejdFNXN4YmpLTk1nb2sxK3VZSTlHaHhYYUlGcGp0VWFUClJXUW00dE9JOFplWWlUWG9aT\\ nJldTU1SVkyZ3pQVjZ1dURTWGQybFRHMEtmVng0Y1FYSDJIekdSODJ4NWZkK3kKS01HY0M1N21DN\\ HpiM3pET1Z2NVNEdmxOZEhyQ0g3QmpVYzh0MlFpU2JyQUwrQ216NnhMVFF4dlp1YkVLejU2TApKe\\ ElKUGFhNkdSY0NBd0VBQWFOQ01FQXdEZ1lEVlIwUEFRSC9CQVFEQWdLa01BOEdBMVVkRXdFQi93U\\ UZNQU1CCkFmOHdIUVlEVlIwT0JCWUVGSkN3bmVCVXZUMUtoeWtCUjF6bmxWQ2I1T2RnTUEwR0NTc\\ UdTSWIzRFFFQkN3VUEKQTRJQkFRQnRwa0doRDJ1RFdYTmZaSUhaa0NNclNpSkZXaGxIUGNPa2VPZ\\ TJwcmp1UEZ0bzFWMVpyNlloWWVpcQp1cGxRdWlpenBwbEthZncxR1lpSnY4SCsrcHpjUFZoS3JTM\\ 2F5Ykp1T2hxdnFyYUVZbzJDbjVVbkFpVWxBb2g1CnRqY1lNcVFKdkVzODd5UlFtUVhMSVNEMkdYb\\ 3UwN24ySy9wTVZXQWpHYjRsUTk0VmpHcjI3dHppSlhIYkh2L04KbHNNZklJV2czbTFKSW9SMlBNa\\ 3gvY1FpcGl6a3JRVHRpalhMbW0xbUFGOEtMR2JZcnNaTk1sMFdITWZWWjdXcgplemRBVjhVNDdsb\\ GowKzUzQ0FkZk0rYWpiSk5uMUtYMWF1Sm8rb1JXVTJjVno0SkYydUllMnBjcFcxUUplY1NPCmZ2U\\ ysyOU9FK09GZW5tenRINTdZTStTWk1jRE8KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\" users: - name: \"test-kubernetes-cluster\" user: token: \"kubeconfig-user-j85xz8pbjt:ls679hfqpvf9c25nswd5gdfm2hf4qtxj2kvqmj6kzzrjkj48lwwlpd\" contexts: - name: \"test-kubernetes-cluster\" context: user: \"test-kubernetes-cluster\" cluster: \"test-kubernetes-cluster\" - name: \"test-kubernetes-cluster-node-1-80-211\" context: user: \"test-kubernetes-cluster\" cluster: \"test-kubernetes-cluster-node-1-80-211\" current-context: \"test-kubernetes-cluster\" ${HOME}/.kube/config文件修改后 $ cat ${HOME}/.kube/config apiVersion: v1 kind: Config clusters: - name: \"test-kubernetes-cluster-rke-master\" cluster: server: \"https://192.168.80.211:6443\" certificate-authority-data: \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM0VENDQ\\ WNtZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFTTVJBd0RnWURWUVFERXdkcmRXSmwKT\\ FdOaE1CNFhEVEl5TURVeU5URXhNek0xTUZvWERUTXlNRFV5TWpFeE16TTFNRm93RWpFUU1BNEdBM\\ VVFQXhNSAphM1ZpWlMxallUQ0NBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ\\ 0VCQUtJSzVRVy84eHB3CkRHUzMrN0M2Q0lobS8zcWFUUENvVmdFeU91YkVtR1EzbnAvYk9qTUJKY\\ 3Ayck05cW5CV2M4ZmtUUWhCNHZsL24Kay8zSkUrMkdta1RBbVAwaGpLa3d6d1JiT2lrYzdYVEtnd\\ ElTQ3I2cjRkOWhZTElERElzTTJtUzZYYnhNdGd1SApoamk3MTJYQmNoZ3lEamxjREl3S1k5WXRYc\\ 3lDY3hPejdFNXN4YmpLTk1nb2sxK3VZSTlHaHhYYUlGcGp0VWFUClJXUW00dE9JOFplWWlUWG9aT\\ nJldTU1SVkyZ3pQVjZ1dURTWGQybFRHMEtmVng0Y1FYSDJIekdSODJ4NWZkK3kKS01HY0M1N21DN\\ HpiM3pET1Z2NVNEdmxOZEhyQ0g3QmpVYzh0MlFpU2JyQUwrQ216NnhMVFF4dlp1YkVLejU2TApKe\\ ElKUGFhNkdSY0NBd0VBQWFOQ01FQXdEZ1lEVlIwUEFRSC9CQVFEQWdLa01BOEdBMVVkRXdFQi93U\\ UZNQU1CCkFmOHdIUVlEVlIwT0JCWUVGSkN3bmVCVXZUMUtoeWtCUjF6bmxWQ2I1T2RnTUEwR0NTc\\ UdTSWIzRFFFQkN3VUEKQTRJQkFRQnRwa0doRDJ1RFdYTmZaSUhaa0NNclNpSkZXaGxIUGNPa2VPZ\\ TJwcmp1UEZ0bzFWMVpyNlloWWVpcQp1cGxRdWlpenBwbEthZncxR1lpSnY4SCsrcHpjUFZoS3JTM\\ 2F5Ykp1T2hxdnFyYUVZbzJDbjVVbkFpVWxBb2g1CnRqY1lNcVFKdkVzODd5UlFtUVhMSVNEMkdYb\\ 3UwN24ySy9wTVZXQWpHYjRsUTk0VmpHcjI3dHppSlhIYkh2L04KbHNNZklJV2czbTFKSW9SMlBNa\\ 3gvY1FpcGl6a3JRVHRpalhMbW0xbUFGOEtMR2JZcnNaTk1sMFdITWZWWjdXcgplemRBVjhVNDdsb\\ GowKzUzQ0FkZk0rYWpiSk5uMUtYMWF1Sm8rb1JXVTJjVno0SkYydUllMnBjcFcxUUplY1NPCmZ2U\\ ysyOU9FK09GZW5tenRINTdZTStTWk1jRE8KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\" users: - name: \"test-kubernetes-cluster-rke-master\" user: token: \"kubeconfig-user-j85xz8pbjt:ls679hfqpvf9c25nswd5gdfm2hf4qtxj2kvqmj6kzzrjkj48lwwlpd\" contexts: - name: \"test-kubernetes-cluster-rke-master\" context: user: \"test-kubernetes-cluster-rke-master\" cluster: \"test-kubernetes-cluster-rke-master\" current-context: \"test-kubernetes-cluster-rke-master\" 使用Kubectl控制Kubernetes Cluster集群 $ kubectl --kubeconfig ${HOME}/.kube/config get pods -n kube-system $ kubectl create ns dev ",
    "description": "Rancher服务宕机情况下使用Kubernetes Cluster Rancher清理节点 #!/bin/bash KUBE_SVC=' kubelet kube-scheduler kube-proxy kube-controller-manager kube-apiserver ' for kube_svc in ${KUBE_SVC}; do # 停止服务 if [[ `systemctl is-active ${kube_svc}` == 'active' ]]; then systemctl stop ${kube_svc} fi # 禁止服务开机启动 if [[ `systemctl is-enabled ${kube_svc}` == 'enabled' ]]; then systemctl disable ${kube_svc} fi done # 停止所有容器 docker stop $(docker ps -aq) # 删除所有容器 docker rm -f $(docker ps -qa) # 删除所有容器卷 docker volume rm $(docker volume ls -q) # 卸载mount目录 for mount in $(mount | grep tmpfs | grep '/var/lib/kubelet' | awk '{ print $3 }') /var/lib/kubelet /var/lib/rancher; do umount $mount; done # 备份目录 mv /etc/kubernetes /etc/kubernetes-bak-$(date +\"%Y%m%d%H%M\") mv /var/lib/etcd /var/lib/etcd-bak-$(date +\"%Y%m%d%H%M\") mv /var/lib/rancher /var/lib/rancher-bak-$(date +\"%Y%m%d%H%M\") mv /opt/rke /opt/rke-bak-$(date +\"%Y%m%d%H%M\") # 删除残留路径 rm -rf /etc/ceph \\ /etc/cni \\ /opt/cni \\ /run/secrets/kubernetes.",
    "tags": [],
    "title": "Configure_K8s_Rancher",
    "uri": "/systems/linux/kubernetes/configure_k8s_rancher/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "安装配置JFrog Artifactory 下载最新JFrog Artifactory社区版镜像 $ docker pull docker.bintray.io/jfrog/artifactory-jcr:latest 为私有镜像仓库做持久化存储 $ mkdir -p /opt/docker/volume/artifactory $ chmod 777 -R /opt/docker # 切换到上述目录后执行数据卷创建命令 $ cd /opt/docker/volume/artifactory $ docker volume create data 启动镜像 3.1 默认用户名：admin 3.2 默认密码：password $ docker run --name jfrog-artifactory -d -v /opt/docker/volume/artifactory:/var/opt/jfrog/artifactory -p 8081:8081 -p 8082:8082 docker.bintray.io/jfrog/artifactory-jcr:latest 打开浏览器访问 http://ip:8082 # 或者配置Nginx域名 ",
    "description": "安装配置JFrog Artifactory 下载最新JFrog Artifactory社区版镜像 $ docker pull docker.bintray.io/jfrog/artifactory-jcr:latest 为私有镜像仓库做持久化存储 $ mkdir -p /opt/docker/volume/artifactory $ chmod 777 -R /opt/docker # 切换到上述目录后执行数据卷创建命令 $ cd /opt/docker/volume/artifactory $ docker volume create data 启动镜像 3.",
    "tags": [],
    "title": "Configure_K8s_Jcr",
    "uri": "/systems/linux/kubernetes/configure_k8s_jcr/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "使用Helm配置管理K8s 名称地址 描述 Bitnami模板库 Kubernetes的Bitnami库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 Kubernetes的Charts-docs库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 查找、安装和发布Kubernetes包 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 kubernetes上的应用对象，都是由特定的资源描述组成，包括Deployment、Service等，都保存在各自文件中或者集中写在一个配置文件，然后通过kubectl apply -f 部署。如果应用只由一个或几个这样的服务组成，上面的部署方式就足够了。但是对于一个复杂的应用，会有很多类似上面的资源描述文件，例如微服务架构应用，组成应用的服务可能多达几十、上百个，如果有更新或回滚应用的需求，可能要修改和维护所涉及到大量的资源文件，而这种组织和管理应用的方式就显得力不从心了。并且由于缺少对发布过的应用进行版本管理和控制，使得kubernetes上的应用维护和更新面临诸多的挑战，主要面临以下的问题： 如何将这些服务作为一个整体管理？ 这些资源文件如何高效复用？ 应用级别的版本如何管理？ Helm是一个kubernetes的包管理工具，就像Linux下的包管理器，如yum、apt等，可以很方便的将之前打包好的yaml文件部署到kubernetes上 Helm有3个重要概念 helm：一个命令行客户端工具，主要用于kubernetes应用chart的创建、打包、发布和管理 chart：应用描述，一系列用于描述kubernetes资源相关文件的集合，类似Ansible的Playbook剧本 release：基于chart的部署实体，一个chart被Helm运行后将会生成对应的一个release，将在kubernetes中创建出真实运行的资源对象 Helm v3变化 最明显变化删除Tiller组件 release名称可以在不同的命名空间重用。 支持将chart推动到Docker镜像仓库中 使用JSONSchema验证chart values Helm常用命令 命令 描述 get 下载一个release。可用的子命令：all、hooks、manifest、note、values repo 添加、列出、移除、更新和索引chart仓库。可用的子命令：add、index、list、remove、update list 列出release pull 从远程仓库中下载chart并解压到本地。比如：helm install stable/mysql --untar show 查看chart的详细信息。可用的子命令：all、chart、readme、values search 根据关键字搜索chart。可用的子命令：all、chart、readme、values create 创建一个chart并指定名字 install 安装一个chart status 显示已命名版本的状态 upgrade 更新升级一个release history 获取release历史 package 将chart目录打包到chart存档文件中 template 本地呈现模板 rollback 从之前的版本回退 uninstall 卸载一个release dependency 管理chart依赖 version 查看Helm客户端版本 安装Helm 使用二进制安装Helm $ wget https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz $ tar -zxvf helm-v3.9.0-linux-amd64.tar.gz $ mv linux-amd64/helm /usr/local/bin/helm 脚本安装 $ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 $ chmod 700 get_helm.sh $ ./get_helm.sh 源代码安装 $ git clone https://github.com/helm/helm.git $ cd helm $ make 配置chart仓库 Helm添加仓库方式 $ helm repo add 仓库名 仓库地址 使用官方仓库 $ helm repo add helm https://hub.kubeapps.com/charts/incubator 添加其它仓库 # Bitnami $ helm repo add bitnami https://charts.bitnami.com/bitnami # 使用微软仓库 $ helm repo add microsoft http://mirror.azure.cn/kubernetes/charts # 国内添加阿里云、微软仓库 $ helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 更新仓库命令 $ helm repo update 删除存储库 $ helm repo remove 仓库名 获取配置的存储库 $ helm repo list Helm基本使用 根据关键字搜索chart $ helm search repo | hub chart名称 $ helm search repo redis # 示例 DEPRECATED # 表示已过期 查看chart信息 $ helm show chart 仓库名/chart名称 $ helm show chart bitnami/redis readme查看安装文档说明 $ helm show readme bitnami/redis 安装chart，形成release 自定义选项是因为并不是所有的chart都能按照默认配置运行成功，可能会需要一些环境依赖，例如PV。 所以需要自定义chart配置选项，安装过程中有两种方法可以传递配置数据： --values：的使用(麻烦、不推荐) --set：在命令行上指定替代。如果两种都用，那么--set的优先级高 --values 或 -f：指定带有覆盖的YAML文件。这里可以多次指定，最右边的文件优先 安装可能报错，需要自己手动安装PV 先将修改的变量写到一个文件中，并修改此文件 $ helm show values stable/mysql \u003e config.yaml 修改config.yaml文件 -- 修改部分 persistence: enabled: true accessMode: ReadWriteOnce size: 8Gi mysqlUser: \"k8s\" mysqlPassword: \"123456\" mysqlDatabase: \"k8s\" 使用-f来替换默认的配置 $ helm install -f config.yaml self-mysql stable/mysql 推荐使用命令行替代变量 $ helm install db --set persistence.storageClass=\"managed-nfs-storage\" stable/mysql 安装chart $ helm install 安装之后的名称 仓库名/chart的名称(即搜索之后的应用名称) $ helm install k8s_ui stable/weave-scope # 安装 stable/weave-scope，并将其命名为 k8s_ui # 查看当前的 release 列表 $ helm list # 查看已命名 release 的状态 $ helm status k8s_ui 安装之后的名称 使用Helm构建一个Chart 使用helm create创建chart $ helm create mychart # chart名称 进入自定义chart目录的templates目录中，修改其中的deployment.yaml和service.yaml等文件 charts：该目录保存其他依赖的chart(子chart) Chart.yaml：定义当前Chart属性信息 templates：chart配置模板，目录存放所有yaml文件 Deployment.yaml： _helpers.tpl： hpa.yaml： ingress.yaml： NOTES.txt：用于介绍Chart的帮助信息，Helm install部署后展示给用户 serviceaccount.yaml： service.yaml： tests： tests-connection.yaml： values.yaml：定义所有yaml全局变量 $ cd chart名称/templates 通过刚才创建的chart目录，将其部署 $ helm install web mychart # web:自定义名称，chart名称 打包chart，让别人共享 $ helm package mychart # chart名称 查看Service，并将其改为NodePort $ kubectl edit svc xxx $ kubectl edit svc ui-weave-scope 应用示例 root目录下操作的 创建chart $ helm create nginx 进入chart目录，修改values.yaml文件，内容如下 $ sudo cat \u003e\u003enginx/values.yaml\u003c\u003c-EOF replicas: 3 image: nginx tag: 1.17 serviceport: 80 targetport: 80 label: nginx EOF 删除templates目录中的文件和文件夹 $ rm -rf emplates/* 修改deployment.yaml文件，内容如下 $ sudo cat \u003e\u003edeployment.yaml\u003c\u003c-EOF apiVersion: apps/v1 kind: Deployment metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: replicas: {{ .Values.replicas }} selector: matchLabels: app: {{ .Values.label }} strategy: {} template: metadata: labels: app: {{ .Values.label }} spec: containers: - image: {{ .Values.image }}:{{ .Values.tag }} name: {{ .Values.image }} EOF 修改service.yaml文件，内容如下： $ sudo cat \u003e\u003eservice.yaml\u003c\u003c-EOF apiVersion: v1 kind: Service metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: ports: - port: {{ .Values.serviceport }} protocol: TCP targetPort: {{ .Values.targetport }} selector: app: {{ .Values.label }} type: NodePort EOF 切换到chart目录的上一层目录、并且安装 $ cd ~ $ helm install nginx nginx/ 调试 Helm也提供了--dry-run和--debug调试参数，帮助你验证模板的正确性。在执行helm install的时候带上这两个参数就可以把对应的values值和渲染的资源清单打印出来，而不是真正的做部署一个release $ helm install nginx nginx/ --dry-run --debug 一些常用的内置对象： 内置对象 描述 Release.Name release的名称 Release.Namespace release的命名空间 Release.Service release的服务的名称 Release.Revision release的修订版本号，从1开始累加 Values Values对象是为Chart模板提供值，这个对象的值有4个来源： chart包中的values.yaml文件 父chart包的values.yaml文件 通过helm install或者helm upgrade的-f或者--values参数传入的自定义的yaml文件 通过--set参数传入的值 Chart的values.yaml提供的值可以被用户提供的values文件覆盖，而该文件同样可以被--set参数所覆盖，换言之，--set参数的优先级高 升级、回滚和卸载发行版本 升级发布新版本的chart时，或者当我们需要更改发布的配置，可以使用helm upgrade命令 $ helm upgrade --set imageTag=1.18 nginx nginx $ helm upgrade web mychart # web:自定义名称，chart名称 $ helm upgrade -f values.yaml nginx nginx 回滚如果在发布后没有达到预期的效果，则可以使用helm rollback回滚到之前的版本 $ helm history redis -n default # 查看历史版本 $ helm rollback nginx 1 卸载可以使用helm uninstall命令 $ helm uninstall nginx 查看历史版本配置信息 $ helm get all --revision 1 nginx 管道、函数 管道 quote .Values.label.app将后面的值作为参数传递过quote函数 模板函数调用语法为：functionName arg1 arg2... 在上面的案例中，其实是将值传递给模板引擎进行渲染，模板引擎还支持对拿到的数据进行二次处理，示例：从.Values中读取的值变成字符串，可以使用quote函数实现 $ cat templates/deployment.yaml # 略... app: {{ quote .Values.label.app }} # 略... $ helm install --dry-run nginx ../nginx/ app:\"nginx\" 函数 default函数运行在模板中指定默认值，以防止该值会忽略掉。如果忘记定义，执行helm install的时候会因为缺少字段而无法创建资源，这时就可以定义一个默认值了，示例： $ sudo cat \u003e\u003etemplates/deployment.yaml\u003c\u003c-EOF apiVersion: apps/v1 kind: Deployment metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: replicas: {{ .Values.replicas }} selector: matchLabels: app: {{ .Values.label }} strategy: {} template: metadata: labels: app: {{ .Values.label }} spec: containers: - image: {{ .Values.image| default \"nginx\" }}:{{ .Values.tag }} name: {{ .Values.image }} EOF 缩进函数： {{ .Values.resources | indent 12 }} 大写函数 {{ upper .Values.resources }} 首字母大写函数 {{ title .Values.resources }} 流程控制 流程控制是为模板提供了一种能力，满足更复杂的数据逻辑处理 Helm模板语言提供以下流程控制语句： if/else条件块 with指定范围 range循环块 if/else：块是用于在模板有条件的包含文本块的方法 条件判断：就是判断条件是否为真，如果值为以下几种情况则为false，否则为true： 一个布尔类型的false 一个数字0 一个空的字符串 一个空的集合(map、slice、tuple、dict、array) 还可以使用ne、lt、gt、and、or等运算符 {{ if 条件表达式 }} # xxx {{ else if 条件表达式 }} # xxx {{ else }} # xxx {{ end }} # 示例 apiVersion: apps/v1 kind: Deployment metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: replicas: {{ .Values.replicas }} selector: matchLabels: app: {{ .Values.label }} strategy: {} template: metadata: labels: app: {{ .Values.label }} spec: containers: - image: {{ .Values.image| default \"nginx\" }}:{{ .Values.tag }} name: {{ .Values.image }} env: {{ if eq .Values.devops \"k8s\" }} - name : hello value: \"123\" {{ else }} - name : hello value: \"456\" {{ end }} # 模板引擎渲染一下，会得到如下的结果： $ helm install --dry-run nginx nginx 可以看到渲染出来会有多余的空行，这是因为当模板引擎运行的时候，会将控制指令删除，所以之前占的位置也就空白了，需要使用{{- if ...}}的方式消除此空行 apiVersion: apps/v1 kind: Deployment metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: replicas: {{ .Values.replicas }} selector: matchLabels: app: {{ .Values.label }} strategy: {} template: metadata: labels: app: {{ .Values.label }} spec: containers: - image: {{ .Values.image| default \"nginx\" }}:{{ .Values.tag }} name: {{ .Values.image }} env: {{- if eq .Values.devops \"k8s\" }} - name : hello value: \"123\" {{- else }} - name : hello value: \"456\" {{- end }} # 通过模板引擎渲染，会得到如下的结果 $ helm install --dry-run nginx nginx 如果使用{{- if ... -}}那么就需要谨慎，比如： apiVersion: apps/v1 kind: Deployment metadata: labels: app: {{ .Values.label }} name: {{ .Release.Name }} spec: replicas: {{ .Values.replicas }} selector: matchLabels: app: {{ .Values.label }} strategy: {} template: metadata: labels: app: {{ .Values.label }} spec: containers: - image: {{ .Values.image| default \"nginx\" }}:{{ .Values.tag }} name: {{ .Values.image }} env: {{- if eq .Values.devops \"k8s\" -}} - name : hello value: \"123\" {{- else }} - name : hello value: \"456\" {{- end }} # 通过模板引擎渲染，会得到如下的结果： $ helm install --dry-run nginx nginx 相当于下面这种格式 当然不对，因为{{- if ... -}}删除了双方的换行符 NAME: nginx LAST DEPLOYED: Mon Jan 11 20:46:10 2021 NAMESPACE: default STATUS: pending-install REVISION: 1 TEST SUITE: None HOOKS: MANIFEST: --- # Source: nginx/templates/service.yaml apiVersion: v1 kind: Service metadata: labels: app: nginx name: nginx spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: nginx type: NodePort --- # Source: nginx/templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx name: nginx spec: replicas: 3 selector: matchLabels: app: nginx strategy: {} template: metadata: labels: app: nginx spec: containers: - image: nginx:1.17 name: nginx env: - name: hello value: 123 range循环块 在Helm模板语言中，使用range关键字来进行循环操作 在values.yaml中添加一个变量列表： test: - 1 - 2 - 3 4.3 循环打印该列表： apiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }} data: test: {{- range . Values.test }} {{ . }} {{- end }} with指定范围 with可以用来控制变量作用域 前面我们使用{{ .Release.xxx }}或者{{ .Values.xxx }}，其中.就是表示对当前范围的引用，.values就是告诉模板在当前范围中查找Values对象的值 with语句就可以用来控制变量的作用域范围，其语法和一个简单的if语句类似： {{ with 条件表达式 }} # xxx {{ end }} with语句可以允许将当前范围的.设置为特定的对象，比如我们前面一直使用的.Values.label，我们可以使用with来将.范围指向.Values.label示例：values.yaml nodeSelector: team: a gpu: yes deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: {{ .Release.Name }}-deployment spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: {{- with .Values.nodeSelector }} nodeSelector: team: {{ .team }} gpu: {{ .gpu }} {{- end }} 命名模板 需要复用代码的地方可以使用命名模板 命名模板：使用define定义，template引入，在templates目录中默认下划线开头的文件为公共模板,比如：_helpers.tpl。 示例： _helpers.tpl {{- define \"demo.fullname\" -}} {{- .Chart.Name -}}-{{ .Release.Name }} {{- end -}} deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: {{ template\"demo.fullname\" . }} # 其他略 template指令是将一个模板包含在另一个模板中的方法。但是，template函数不能用于Go模板管道，为了解决该问题，增加了include功能 _helpers.tpl： {{- define \"demo.labels\" -}} app: {{ template\"demo.fullname\" . }} chart: \"{{ .Chart.Name }}-{{ .Chart.Version }}\" release: \"{{ .Release.Name }}\" {{- end -}} 4.3 deployment.yaml 下面包含一个名为demo.labels的模板，然后将值 . 传递给模板，最后将该模板的 输出传递给nindent函数。\napiVersion: apps/v1 kind: Deployment metadata: name: {{ include\"demo.fullname\" . }} labels: {{- include \"demo.labels\" . | nindent 4 }} ... graph LR A(创建模板) --\u003eB(修改Chart.yaml Values.yaml文件\u003cbr\u003e添加常用变量\u003cbr\u003e) B --\u003e C(在Templates目录下创建部署镜像所需的yaml文件\u003cbr\u003e并且使用变量\u003cbr\u003e引用yaml文件里面的常变动字段\u003cbr\u003e) C --\u003e|a=1| D{暂未启用} C --\u003e|a=2| E[暂未启用] F[开发自己的chart] 使用Helm安装Jenkins 获取更新仓库信息 $ helm repo add jenkins https://charts.jenkins.io $ helm repo update 查看已经添加的helm仓库 $ helm repo list 搜索仓库中的Jenkins $ helm search repo jenkins NAME CHART VERSION\tAPP VERSION\tDESCRIPTION jenkins/jenkins\t4.2.5 2.361.1 Jenkins - Build great things at any scale! The ... 查看、下载Jenkins $ helm show values jenkins/jenkins $ helm pull jenkins/jenkins # 下载 Jenkins 安装包 $ tar -zxvf jenkins-3.5.9.tgz $ sed -i -e '/#/d;/^$/d' values.yaml # 去掉注释和空行后修改 安装以及查看登录名和密码 $ helm install jenkins ./jenkins # 查看登录的用户名 $ kubectl exec jenkins-0 -- cat /run/secrets/chart-admin-username # 查看登录的密码 $ kubectl exec jenkins-0 -- cat /run/secrets/chart-admin-password 使用Helm安装Redis 添加Bitnami仓库 $ helm repo add bitnami https://charts.bitnami.com/bitnami $ helm repo list $ helm search repo redis 下载、配置安装包 $ helm pull bitnami/redis $ tar xvf redis-18.8.0.tgz 修改values.yaml StorageClass的名字，如果storageClass不正常，redis启动不了 global: imageRegistry: \"\" imagePullSecrets: [] storageClass: \"nfs-storage-template\" # StorageClass 的名字，如果storageClass不正常，redis启动不了 redis: password: \"Password\" # redis 连接密码 kubeVersion: \"\" nameOverride: \"\" fullnameOverride: \"\" namespaceOverride: \"\" commonLabels: {} commonAnnotations: {} secretAnnotations: {} clusterDomain: cluster.local extraDeploy: [] useHostnames: true nameResolutionThreshold: 5 nameResolutionTimeout: 5 diagnosticMode: enabled: false command: - sleep args: - infinity image: registry: docker.io repository: bitnami/redis tag: 7.2.4-debian-11-r2 digest: \"\" pullPolicy: IfNotPresent pullSecrets: [] debug: false architecture: replication # standalone:单节点部署，replication：一主三从配置 auth: enabled: true sentinel: true password: \"\" existingSecret: \"\" existingSecretPasswordKey: \"\" usePasswordFiles: false commonConfiguration: |- appendonly yes save \"\" existingConfigmap: \"\" master: count: 1 configuration: \"\" disableCommands: - FLUSHDB - FLUSHALL command: [] args: [] enableServiceLinks: true preExecCmds: [] extraFlags: [] extraEnvVars: [] extraEnvVarsCM: \"\" extraEnvVarsSecret: \"\" containerPorts: redis: 6379 startupProbe: enabled: false initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 livenessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 5 customStartupProbe: {} customLivenessProbe: {} customReadinessProbe: {} resources: limits: {} requests: {} podSecurityContext: enabled: true fsGroupChangePolicy: Always sysctls: [] supplementalGroups: [] fsGroup: 1001 containerSecurityContext: enabled: true seLinuxOptions: {} runAsUser: 1001 runAsGroup: 0 runAsNonRoot: true allowPrivilegeEscalation: false seccompProfile: type: RuntimeDefault capabilities: drop: - ALL kind: StatefulSet schedulerName: \"\" updateStrategy: type: RollingUpdate minReadySeconds: 0 priorityClassName: \"\" automountServiceAccountToken: false hostAliases: [] podLabels: {} podAnnotations: {} shareProcessNamespace: false podAffinityPreset: \"\" podAntiAffinityPreset: soft nodeAffinityPreset: type: \"\" key: \"\" values: [] affinity: {} nodeSelector: {} tolerations: [] topologySpreadConstraints: [] dnsPolicy: \"\" dnsConfig: {} lifecycleHooks: {} extraVolumes: [] extraVolumeMounts: [] sidecars: [] initContainers: [] persistence: # 持久化配置 enabled: true # 默认启用 medium: \"\" sizeLimit: \"\" path: /data # 存储目录 subPath: \"\" subPathExpr: \"\" storageClass: \"\" accessModes: - ReadWriteOnce size: 2Gi # Master 主节点默认使用空间 annotations: {} labels: {} selector: {} dataSource: {} existingClaim: \"\" persistentVolumeClaimRetentionPolicy: enabled: false whenScaled: Retain whenDeleted: Retain service: # 服务端口配置 type: ClusterIP ports: redis: 6379 nodePorts: redis: \"\" externalTrafficPolicy: Cluster extraPorts: [] internalTrafficPolicy: Cluster clusterIP: \"\" loadBalancerIP: \"\" loadBalancerClass: \"\" loadBalancerSourceRanges: [] externalIPs: [] annotations: {} sessionAffinity: None sessionAffinityConfig: {} terminationGracePeriodSeconds: 30 serviceAccount: create: true name: \"\" automountServiceAccountToken: false annotations: {} replica: kind: StatefulSet replicaCount: 2 # 从节点副本数量 configuration: \"\" disableCommands: - FLUSHDB - FLUSHALL command: [] args: [] enableServiceLinks: true preExecCmds: [] extraFlags: [] extraEnvVars: [] extraEnvVarsCM: \"\" extraEnvVarsSecret: \"\" externalMaster: enabled: false host: \"\" port: 6379 containerPorts: redis: 6379 startupProbe: enabled: true initialDelaySeconds: 10 periodSeconds: 10 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 22 livenessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 5 customStartupProbe: {} customLivenessProbe: {} customReadinessProbe: {} resources: limits: {} # cpu: 250m # memory: 256Mi requests: {} # cpu: 250m # memory: 256Mi podSecurityContext: enabled: true fsGroupChangePolicy: Always sysctls: [] supplementalGroups: [] fsGroup: 1001 containerSecurityContext: enabled: true seLinuxOptions: {} runAsUser: 1001 runAsGroup: 0 runAsNonRoot: true allowPrivilegeEscalation: false seccompProfile: type: RuntimeDefault capabilities: drop: - ALL schedulerName: \"\" updateStrategy: type: RollingUpdate minReadySeconds: 0 priorityClassName: \"\" podManagementPolicy: \"\" automountServiceAccountToken: false hostAliases: [] podLabels: {} podAnnotations: {} shareProcessNamespace: false podAffinityPreset: \"\" podAntiAffinityPreset: soft nodeAffinityPreset: type: \"\" key: \"\" values: [] affinity: {} nodeSelector: {} tolerations: [] topologySpreadConstraints: [] dnsPolicy: \"\" dnsConfig: {} lifecycleHooks: {} extraVolumes: [] extraVolumeMounts: [] sidecars: [] initContainers: [] persistence: enabled: true medium: \"\" sizeLimit: \"\" path: /data subPath: \"\" subPathExpr: \"\" storageClass: \"\" accessModes: - ReadWriteOnce size: 2Gi # 从节点使用磁盘空间 annotations: {} labels: {} selector: {} dataSource: {} existingClaim: \"\" persistentVolumeClaimRetentionPolicy: enabled: false whenScaled: Retain whenDeleted: Retain service: type: ClusterIP ports: redis: 6379 nodePorts: redis: \"\" externalTrafficPolicy: Cluster internalTrafficPolicy: Cluster extraPorts: [] clusterIP: \"\" loadBalancerIP: \"\" loadBalancerClass: \"\" loadBalancerSourceRanges: [] annotations: {} sessionAffinity: None sessionAffinityConfig: {} terminationGracePeriodSeconds: 30 autoscaling: enabled: false minReplicas: 1 maxReplicas: 11 targetCPU: \"\" targetMemory: \"\" serviceAccount: create: true name: \"\" automountServiceAccountToken: false annotations: {} sentinel: enabled: false image: registry: docker.io repository: bitnami/redis-sentinel tag: 7.2.4-debian-11-r3 digest: \"\" pullPolicy: IfNotPresent pullSecrets: [] debug: false annotations: {} masterSet: mymaster quorum: 2 getMasterTimeout: 90 automateClusterRecovery: false redisShutdownWaitFailover: true downAfterMilliseconds: 60000 failoverTimeout: 180000 parallelSyncs: 1 configuration: \"\" command: [] args: [] enableServiceLinks: true preExecCmds: [] extraEnvVars: [] extraEnvVarsCM: \"\" extraEnvVarsSecret: \"\" externalMaster: enabled: false host: \"\" port: 6379 containerPorts: sentinel: 26379 startupProbe: enabled: true initialDelaySeconds: 10 periodSeconds: 10 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 22 livenessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 10 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 6 readinessProbe: enabled: true initialDelaySeconds: 20 periodSeconds: 5 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 6 customStartupProbe: {} customLivenessProbe: {} customReadinessProbe: {} persistence: enabled: false storageClass: \"\" accessModes: - ReadWriteOnce size: 100Mi annotations: {} labels: {} selector: {} dataSource: {} medium: \"\" sizeLimit: \"\" persistentVolumeClaimRetentionPolicy: enabled: false whenScaled: Retain whenDeleted: Retain resources: limits: {} requests: {} containerSecurityContext: enabled: true seLinuxOptions: {} runAsUser: 1001 runAsGroup: 0 runAsNonRoot: true allowPrivilegeEscalation: false seccompProfile: type: RuntimeDefault capabilities: drop: - ALL lifecycleHooks: {} extraVolumes: [] extraVolumeMounts: [] service: type: ClusterIP ports: redis: 6379 sentinel: 26379 nodePorts: redis: \"\" sentinel: \"\" externalTrafficPolicy: Cluster extraPorts: [] clusterIP: \"\" loadBalancerIP: \"\" loadBalancerClass: \"\" loadBalancerSourceRanges: [] annotations: {} sessionAffinity: None sessionAffinityConfig: {} headless: annotations: {} terminationGracePeriodSeconds: 30 serviceBindings: enabled: false networkPolicy: enabled: false allowExternal: true extraIngress: [] extraEgress: [] ingressNSMatchLabels: {} ingressNSPodMatchLabels: {} metrics: allowExternal: true ingressNSMatchLabels: {} ingressNSPodMatchLabels: {} podSecurityPolicy: create: false enabled: false rbac: create: false rules: [] serviceAccount: create: true name: \"\" automountServiceAccountToken: false annotations: {} pdb: create: false minAvailable: 1 maxUnavailable: \"\" tls: enabled: false authClients: true autoGenerated: false existingSecret: \"\" certificatesSecret: \"\" certFilename: \"\" certKeyFilename: \"\" certCAFilename: \"\" dhParamsFilename: \"\" metrics: enabled: false image: registry: docker.io repository: bitnami/redis-exporter tag: 1.56.0-debian-11-r1 digest: \"\" pullPolicy: IfNotPresent pullSecrets: [] startupProbe: enabled: false initialDelaySeconds: 10 periodSeconds: 10 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 livenessProbe: enabled: true initialDelaySeconds: 10 periodSeconds: 10 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: enabled: true initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 1 successThreshold: 1 failureThreshold: 3 customStartupProbe: {} customLivenessProbe: {} customReadinessProbe: {} command: [] redisTargetHost: \"localhost\" extraArgs: {} extraEnvVars: [] containerSecurityContext: enabled: true seLinuxOptions: {} runAsUser: 1001 runAsGroup: 0 runAsNonRoot: true allowPrivilegeEscalation: false seccompProfile: type: RuntimeDefault capabilities: drop: - ALL extraVolumes: [] extraVolumeMounts: [] resources: limits: {} requests: {} podLabels: {} podAnnotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"9121\" service: type: ClusterIP port: 9121 externalTrafficPolicy: Cluster extraPorts: [] loadBalancerIP: \"\" loadBalancerClass: \"\" loadBalancerSourceRanges: [] annotations: {} clusterIP: \"\" serviceMonitor: enabled: false namespace: \"\" interval: 30s scrapeTimeout: \"\" relabellings: [] metricRelabelings: [] honorLabels: false additionalLabels: {} podTargetLabels: [] sampleLimit: false targetLimit: false podMonitor: enabled: false namespace: \"\" interval: 30s scrapeTimeout: \"\" relabellings: [] metricRelabelings: [] honorLabels: false additionalLabels: {} podTargetLabels: [] sampleLimit: false targetLimit: false prometheusRule: enabled: false namespace: \"\" additionalLabels: {} rules: [] volumePermissions: enabled: false image: registry: docker.io repository: bitnami/os-shell tag: 11-debian-11-r94 digest: \"\" pullPolicy: IfNotPresent pullSecrets: [] resources: limits: {} requests: {} containerSecurityContext: seLinuxOptions: {} runAsUser: 0 sysctl: enabled: false image: registry: docker.io repository: bitnami/os-shell tag: 11-debian-11-r94 digest: \"\" pullPolicy: IfNotPresent pullSecrets: [] command: [] mountHostSys: false resources: limits: {} requests: {} useExternalDNS: enabled: false suffix: \"\" annotationKey: external-dns.alpha.kubernetes.io/ additionalAnnotations: {} 安装Redis形成Release $ helm install release-name project-dir -n namespace $ helm install redis ./redis/ -n default 登录Redis $ kubectl exec --tty -i redis-master-0 --namespace default -- bash $ kubectl exec --tty -i redis-replicas-1 --namespace default -- bash 升级Redis $ helm upgrade redis ./redis/ -n default 使用Helm安装Prometheus 名称地址 描述 kube-prometheus 使用Helm安装ELK 名称地址 描述 ",
    "description": "使用Helm配置管理K8s 名称地址 描述 Bitnami模板库 Kubernetes的Bitnami库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 Kubernetes的Charts-docs库 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 查找、安装和发布Kubernetes包 Helm安装Kubernetes服务Zabbix、Redis、Mysql模板 kubernetes上的应用对象，都是由特定的资源描述组成，包括Deployment、Service等，都保存在各自文件中或者集中写在一个配置文件，然后通过kubectl apply -f 部署。如果应用只由一个或几个这样的服务组成，上面的部署方式就足够了。但是对于一个复杂的应用，会有很多类似上面的资源描述文件，例如微服务架构应用，组成应用的服务可能多达几十、上百个，如果有更新或回滚应用的需求，可能要修改和维护所涉及到大量的资源文件，而这种组织和管理应用的方式就显得力不从心了。并且由于缺少对发布过的应用进行版本管理和控制，使得kubernetes上的应用维护和更新面临诸多的挑战，主要面临以下的问题： 如何将这些服务作为一个整体管理？ 这些资源文件如何高效复用？ 应用级别的版本如何管理？ Helm是一个kubernetes的包管理工具，就像Linux下的包管理器，如yum、apt等，可以很方便的将之前打包好的yaml文件部署到kubernetes上 Helm有3个重要概念 helm：一个命令行客户端工具，主要用于kubernetes应用chart的创建、打包、发布和管理 chart：应用描述，一系列用于描述kubernetes资源相关文件的集合，类似Ansible的Playbook剧本 release：基于chart的部署实体，一个chart被Helm运行后将会生成对应的一个release，将在kubernetes中创建出真实运行的资源对象 Helm v3变化 最明显变化删除Tiller组件 release名称可以在不同的命名空间重用。 支持将chart推动到Docker镜像仓库中 使用JSONSchema验证chart values Helm常用命令 命令 描述 get 下载一个release。可用的子命令：all、hooks、manifest、note、values repo 添加、列出、移除、更新和索引chart仓库。可用的子命令：add、index、list、remove、update list 列出release pull 从远程仓库中下载chart并解压到本地。比如：helm install stable/mysql --untar show 查看chart的详细信息。可用的子命令：all、chart、readme、values search 根据关键字搜索chart。可用的子命令：all、chart、readme、values create 创建一个chart并指定名字 install 安装一个chart status 显示已命名版本的状态 upgrade 更新升级一个release history 获取release历史 package 将chart目录打包到chart存档文件中 template 本地呈现模板 rollback 从之前的版本回退 uninstall 卸载一个release dependency 管理chart依赖 version 查看Helm客户端版本 安装Helm 使用二进制安装Helm $ wget https://get.",
    "tags": [],
    "title": "Configure_K8s_Helm",
    "uri": "/systems/linux/kubernetes/configure_k8s_helm/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Kubernetes",
    "content": "安全控制 访问控制 kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对kubernetes的各种客户端进行认证和授权操作 在kubernetes集群中，客户端通常由两类： User Account：一般是独立于kubernetes之外的其他服务管理的用户账号 Service Account：kubernetes管理的账号，用于为Pod的服务进程在访问kubernetes时提供身份标识 graph LR C1((用户)) --\u003e B1(User\u003cbr\u003eAccount) --\u003e A((Kubernetes)) C2((Pod)) --\u003e B2(Service\u003cbr\u003eAccount) --\u003e A((Kubernetes)) 认证、授权和准入控制 API Server是访问和管理资源对象的唯一入口。任何一个请求访问API Server，都要经过下面的三个流程： Authentication(认证)：身份鉴别，只有正确的账号才能通过认证 Authorization(授权)：权限鉴别，判断用户是否有权限对访问的资源执行特定的动作 Admission Control(准入控制)：精细访问控制，用于补充授权机制以实现更加精细的访问控制功能 需要注意：在Kubernetes中不能通过API调用将普通用户添加到集群中 普通账户是针对（人）用户的，服务账户针对Pods进程 普通账户是全局性，在集群所有namespaces中，名称具有唯一性 通常，集群的普通账户可以与企业数据库同步，新的普通账户创建需要特殊权限，服务账户创建目的是更轻量化，允许集群用户为特定任务创建服务账户 普通账户和服务账户的审核注意事项不同 对于复杂系统的配置包，可以包括对该系统的各种组件的服务账户的定义 graph LR A((请求)) --\u003e B[Authentication\u003cbr\u003e认证\u003cbr\u003e身份鉴别\u003cbr\u003e] --\u003e C[Authorization\u003cbr\u003e授权\u003cbr\u003e权限鉴别\u003cbr\u003e] --\u003e D[Admission Control\u003cbr\u003e注入控制\u003cbr\u003e精细访问控制\u003cbr\u003e] --\u003e E((Kubernetes\u003cbr\u003e资源)) 认证管理 User Accounts(普通账户) Service Accounts(服务账户) apiVersion: v1 kind: ServiceAccount # 权限管理 metadata: name: nfs-client-provisioner namespace: default kubernetes的客户端http和https身份认证方式 kubernetes允许同时配置多种认证方式，只要其中任意一种方式认证通过即可 kubernetes集群安全的关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式 2.1 HTTP Base认证： 通过用户名+密码的方式进行认证，这种方式是把用户名:密码用BASE64算法进行编码后的字符串放在HTTP请求中的Header的Authorization域里面发送给服务端。服务端收到后进行解码，获取用户名和密码，然后进行用户身份认证的过程 2.2 HTTP Token认证： 通过一个Token来识别合法用户，这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户端身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求的时候，需要在HTTP的Header中放入Token，API Server接受到Token后会和服务器中保存的Token进行比对，然后进行用户身份认证的过程。 2.3 HTTPS证书认证： 基于CA根证书签名的双向数字证书认证方式，这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式 证书申请和下发：HTTPS通信双方的服务器向CA机构申请证书，CA机构发根证书、服务端证书及私钥给申请者 客户端和服务器的双向认证 客户端向服务端发起请求，服务端下发自己的证书给客户端。客户端收到证书后，通过私钥解密证书，在证书中获取服务端的私钥。客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器。 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书。在证书中获取客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法。 服务器端和客户端进行通信 服务器端和客户端协商好加密方案后，客户端会产生一个随机的私钥并加密，然后发送到服务器端 服务器端接收到这个私钥后，双方接下来通信的所有内容都通过该随机私钥加密 graph TB A((CA机构)) -- 申请证书 --\u003eB((服务端)) A((CA机构)) -- 申请证书 --\u003e C((客户端)) B((服务端)) -- 下发证书 --\u003e A((CA机构)) C((客户端)) -- 下发证书 --\u003e A((CA机构)) B((服务端)) \u003c-- 双向身份认证 --\u003e C((客户端)) B((服务端)) \u003c-- 双向通信 --\u003e C((客户端)) 授权管理 授权发生在认证成功之后，通过认证就可以知道请求用户是谁，然后kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权 每个发送到API Server的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。 API Server目前支持的几种授权策略 AlwaysDeny：表示拒绝所有请求，一般用于测试 AlwaysAllow：允许接收所有的请求，相当于集群不需要授权流程（kubernetes默认的策略） ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webhook：通过调用外部REST服务对用户进行授权 Node：是一种专用模式，用于对kubelet发出的请求进行访问控制 RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项） RBAC基于角色的访问控制 RBAC基于角色的访问控制(Role Based Access Control)主要是在描述一件事情：给哪些对象授权了哪些权限 RBAC涉及到了下面几个概念： 对象：User、Groups、ServiceAccount。 角色：代表着一组定义在资源上的可操作的动作（权限）的集合 绑定：将定义好的角色和用户绑定在一起 RBAC引入的4个顶级资源对象： Role(角色)，用于指定一组权限 ClusterRole(集群角色)，用于指定一组权限 RoleBinding(角色绑定)，用于将角色（权限的集合）赋予给对象 ClusterRoleBinding(集群角色绑定)，用于将角色（权限的集合）赋予给对象 graph TB A1(Group) --- A[RoleBinding] A2(User) --- A[RoleBinding] A3(Service\u003cbr\u003eAccount) --- A[RoleBinding] A[RoleBinding] --- B[Role] B[Role] --- Pod --- |a=1|B1[List] B[Role] --- Pod --- |a=2|B2[Get] B[Role] --- Pod --- |a=3|B3[Watch] B[Role] --- Deployment --- |b=1|B4[List] B[Role] --- Deployment --- |b=2|B5[Get] B[Role] --- Deployment --- |b=3|B6[Watch] Role(普通角色) 一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单） Role只能对命名空间的资源进行授权，需要指定namespace rules:中的参数说明： $ kubectl explain role.rules.resources # 显示 resources 使用方式 1.1 apiGroups: 支持的API组列表，\"\",\"apps\",\"autoscaling\"\",\"batch\"。 1.2 resources: 支持的资源对象列表，\"namespaces\",\"services\",\"endpoints\",\"pods\",\"secrets\",\"configmaps\",\"crontabs\",\"deployments\",\"jobs\",\"nodes\",\"rolebindings\",\"clusterroles\",\"daemonsets\",\"replicasets\",\"statefulsets\",\"horizontalpodautoscalers\",\"replicationcontrollers\",\"cronjobs\" 1.3 verbs: 对资源对象的操作方法列表，\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\",\"exec\" apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: authorization-role namespace: default rules: - apiGroups: [\"\"] # 支持的API组列表，\"\"空字符串，表示核心API群 resources: [\"pods\"] # 支持的资源对象列表 verbs: [\"get\",\"watch\",\"list\"] RoleBinding(普通角色绑定) 角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount RoleBinding可以将同一namespace中的subject对象绑定到某个Role下，则此Subject具有该Role定义的权限 subjects: roleRef: apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: authorization-role-binding namespace: default subjects: - kind: User # User，Group，ServiceAccoun name: user-name apiGroup: rbac.authorization.k8s.io roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: authorization-role ClusterRole(集群角色) ClusterRole可以对集群范围内的资源、跨namespace的范围资源、非资源类型进行授权 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: authorization-clusterrole rules: - apiGroups: [\"\"] # 支持的API组列表，\"\"空字符串，表示核心API群 resources: [\"pods\"] # 支持的资源对象列表 verbs: [\"get\",\"watch\",\"list\"] ClusterRoleBinding(集群角色绑定) ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: authorization-clusterrole-binding subjects: # 应用什么类型的主体 - kind: User # User，Group，ServiceAccoun name: user-name # 对应的名字 apiGroup: rbac.authorization.k8s.io roleRef: # 角色绑定 apiGroup: rbac.authorization.k8s.io # 对应的Api分组 kind: ClusterRole # 角色类型 name: authorization-clusterrole 准入控制 通过了前面的认证和授权之后，还需要经过准入控制通过之后，API Server才会处理这个请求。 准入控制是一个可配置的控制器列表，可以通过在API Server上通过命令行设置选择执行哪些注入控制器。 只有当所有的注入控制器都检查通过之后，API Server才会执行该请求，否则返回拒绝。 --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds Admission Control(准入控制) AlwaysAdmit：允许所有请求 AlwaysDeny：禁止所有请求，一般用于测试 AlwaysPullImages：在启动容器之前总去下载镜像 DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求 ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能 Service Account：实现ServiceAccount实现了自动化 SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效 ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标 LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制 InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置 NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒 绝。当删除一个namespace时，系统将会删除该namespace中所有对象 DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节 DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制 RBAC实战 创建一个只能管理dev命名空间下Pods资源的账号。 创建密钥 $ cd /etc/kubernetes/pki/ $ (umask 077;openssl genrsa -out user-name.key 2048) 用API Server的密钥去签署证书 证书申请：申请的用户是user-name，组是group-name $ openssl req -new -key user-name.key -out user-name.csr -subj \"/CN=user-name/O=group-name\" 签署证书 $ openssl x509 -req -in user-name.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out user-name.crt -days 3650 设置集群、用户、上下文信息： $ kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https://192.168.18.100:6443 $ kubectl config set-credentials user-name --embed-certs=true --client-certificate=/etc/kubernetes/pki/user-name.crt --client-key=/etc/kubernetes/pki/user-name.key $ kubectl config set-context user-name@kubernetes --cluster=kubernetes --user=user-name 测试账户、切换 切换账号到user-name $ kubectl config use-context user-name@kubernetes 查看default下的Pod，发现没有权限： $ kubectl get pods -n default 切换到admin账户： $ kubectl config use-context kubernetes-admin@kubernetes RoleBinding引用ClusterRole进行授权 RoleBinding(角色绑定)可以引用ClusterRole(集群角色)，对属于同一命名空间内ClusterRole定义的资源主体进行授权。 一种很常用的做法是，集群管理员为集群范围预定义好一组角色ClusterRole，然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅度提高授权管理工作效率，也使得各个命名空间下的基础性授权规则和使用体验保持一致。 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding，所以xudaxian只能读取default命名空间中的资源 apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: authorization-clusterrole-binding subjects: - name: xudaxian kind: User apiGroup: rbac.authorization.k8s.io roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: authorization-clusterrole 创建Role和RoleBinding，为user-name授权 创建dev-role.yaml文件，内容如下： apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: dev-role namespace: default rules: - apiGroups: [\"\"] # 支持的API组列表，\"\"空字符串，表示核心API群 resources: [\"pods\"] # 支持的资源对象列表 verbs: [\"get\",\"watch\",\"list\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: authorization-role-binding namespace: default subjects: - kind: User name: user-name apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: dev-role apiGroup: rbac.authorization.k8s.io 创建Role和RoleBinding： $ kubectl create -f dev-role.yaml 切换账户到user-name用户，再次验证： $ kubectl config use-context user-name@kubernetes # 再次查看： $ kubectl get pod -n default # 切回admin账户： $ kubectl config use-context kubernetes-admin@kubernetes ",
    "description": "安全控制 访问控制 kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对kubernetes的各种客户端进行认证和授权操作 在kubernetes集群中，客户端通常由两类： User Account：一般是独立于kubernetes之外的其他服务管理的用户账号 Service Account：kubernetes管理的账号，用于为Pod的服务进程在访问kubernetes时提供身份标识 graph LR C1((用户)) --\u003e B1(User\u003cbr\u003eAccount) --\u003e A((Kubernetes)) C2((Pod)) --\u003e B2(Service\u003cbr\u003eAccount) --\u003e A((Kubernetes)) 认证、授权和准入控制 API Server是访问和管理资源对象的唯一入口。任何一个请求访问API Server，都要经过下面的三个流程： Authentication(认证)：身份鉴别，只有正确的账号才能通过认证 Authorization(授权)：权限鉴别，判断用户是否有权限对访问的资源执行特定的动作 Admission Control(准入控制)：精细访问控制，用于补充授权机制以实现更加精细的访问控制功能 需要注意：在Kubernetes中不能通过API调用将普通用户添加到集群中 普通账户是针对（人）用户的，服务账户针对Pods进程 普通账户是全局性，在集群所有namespaces中，名称具有唯一性 通常，集群的普通账户可以与企业数据库同步，新的普通账户创建需要特殊权限，服务账户创建目的是更轻量化，允许集群用户为特定任务创建服务账户 普通账户和服务账户的审核注意事项不同 对于复杂系统的配置包，可以包括对该系统的各种组件的服务账户的定义 graph LR A((请求)) --\u003e B[Authentication\u003cbr\u003e认证\u003cbr\u003e身份鉴别\u003cbr\u003e] --\u003e C[Authorization\u003cbr\u003e授权\u003cbr\u003e权限鉴别\u003cbr\u003e] --\u003e D[Admission Control\u003cbr\u003e注入控制\u003cbr\u003e精细访问控制\u003cbr\u003e] --\u003e E((Kubernetes\u003cbr\u003e资源)) 认证管理 User Accounts(普通账户) Service Accounts(服务账户) apiVersion: v1 kind: ServiceAccount # 权限管理 metadata: name: nfs-client-provisioner namespace: default kubernetes的客户端http和https身份认证方式 kubernetes允许同时配置多种认证方式，只要其中任意一种方式认证通过即可 kubernetes集群安全的关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式 2.",
    "tags": [],
    "title": "Configure_K8s_Auth",
    "uri": "/systems/linux/kubernetes/configure_k8s_auth/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": "Linux系统优化 系统初始化 $ yum -y install vim lrzsz epel-release $ yum -y update $ setenforce 0 \u0026\u0026 sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 优化系统内核 系统控制 $ echo \"# 所有配置都是：0：为关闭，1：为开启 # 关闭ipv6 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 # 调整 IPv6 net.ipv6.conf.default.router_solicitations = 0 net.ipv6.conf.default.accept_ra_rtr_pref = 0 net.ipv6.conf.default.accept_ra_pinfo = 0 net.ipv6.conf.default.accept_ra_defrtr = 0 net.ipv6.conf.default.autoconf = 0 net.ipv6.conf.default.dad_transmits = 0 net.ipv6.conf.default.max_addresses = 1 # 忽略 ICMP 回显请求、设置服务器禁ping net.ipv4.icmp_echo_ignore_all = 1 net.ipv6.icmp.echo_ignore_all = 1 # 避免放大攻击 net.ipv4.icmp_echo_ignore_broadcasts = 1 # 开启恶意icmp错误消息保护 net.ipv4.icmp_ignore_bogus_error_responses = 1 # 开启/关闭路由转发 1：为开启，0：为关闭 net.ipv4.ip_forward = 1 net.ipv4.conf.all.forwarding = 1 net.ipv6.conf.all.forwarding = 1 # 开启反向路径过滤、通过启用反向路径过滤，内核将对从机器上所有接口接收到的数据包进行源验证。这可以防止攻击者使用 IP 欺骗方法造成伤害 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.rp_filter = 1 # 打开并记录欺骗、源路由和重定向数据包 net.ipv4.conf.default.log_martians = 1 net.ipv4.conf.all.log_martians = 1 # 处理无源路由的包 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 # 关闭sysrq功能 kernel.sysrq = 0 # core文件名中添加pid作为扩展名 kernel.core_uses_pid = 1 # TCP/IP 堆栈加固、开启SYNCookies,当出现SYN等待队列溢出时,启用cookies 来处理 net.ipv4.tcp_syncookies = 1 # 修改消息队列长度 kernel.msgmnb = 65536 kernel.msgmax = 65536 # 优化 LB 端口使用 增加系统文件描述符限制 fs.file-max = 65535 # 允许更多的 PID（以减少翻转问题）； 可能会破坏某些程序 32768 kernel.pid_max = 65535 # 设置最大内存共享段大小bytes kernel.shmmax = 68719476736 kernel.shmall = 4294967296 # 启用timewait快速回收 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_sack = 1 net.ipv4.tcp_window_scaling = 1 # 增加专用于网络接口的内存 net.core.rmem_default = 1048576 net.core.rmem_max = 16777216 net.core.wmem_default = 1048576 net.core.wmem_max = 16777216 net.core.optmem_max = 65536 net.ipv4.tcp_rmem = 4096 1048576 2097152 net.ipv4.tcp_wmem = 4096 65536 16777216 net.ipv4.udp_rmem_min = 8192 net.ipv4.udp_wmem_min = 8192 # 启用 TCP 快速打开、通过在发送方的初始 TCP SYN 期间启用数据交换来帮助减少网络延迟。使用该值3而不是默认值1允许 net.ipv4.tcp_fastopen = 3 # 增加最大连接数、警告：增加此值可能只会提高高负载服务器的性能，并可能导致处理速度变慢（例如单线程阻塞服务器）或工作线程/进程数量不足 # net.core.somaxconn = 8192 # 下述内存单位是页，而不是字节。可参考的优化值是:786432 1048576 1572864 # net.ipv4.tcp_tw_len = 1 # 增加接收队列的大小、每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.core.netdev_max_backlog = 262144 # 限制仅仅是为了防止简单的DoS 攻击 net.ipv4.tcp_max_orphans = 3276800 # 调整挂起的连接处理、未收到客户端确认信息的连接请求的最大值 net.ipv4.tcp_max_syn_backlog = 8192 # 等待时间，默认是:180000 net.ipv4.tcp_max_tw_buckets = 6000 # 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_slow_start_after_idle = 0 # TCP 时间戳 net.ipv4.tcp_timestamps = 0 # 内核放弃建立连接之前发送SYNACK 包的数量 net.ipv4.tcp_synack_retries = 1 # 内核放弃建立连接之前发送SYN 包的数量 net.ipv4.tcp_syn_retries = 1 net.ipv4.tcp_mem = 94500000 915000000 927000000 # 启用 MTU 探测、最大传输单元 (MTU)越长，性能越好，但可靠性越差 # net.ipv4.tcp_mtu_probing = 1 # 更改 TCP 保活参数、当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时 net.ipv4.tcp_keepalive_time = 60 net.ipv4.tcp_keepalive_intvl = 10 net.ipv4.tcp_keepalive_probes = 6 net.ipv4.tcp_keepalive_time = 30 # 增加临时端口范围、允许系统打开的端口范围 net.ipv4.ip_local_port_range = 1024 65000 # 修改防火墙表大小，默认65536 # net.netfilter.nf_conntrack_max=655350 # net.netfilter.nf_conntrack_tcp_timeout_established=1200 # 可选值：0、1、2，1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何 vm.overcommit_memory=1 vm.swappiness = 0 # 禁用 ICMP 重定向、确保无人能修改路由表 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.all.secure_redirects = 0 net.ipv4.conf.default.secure_redirects = 0 net.ipv6.conf.all.accept_redirects = 0 net.ipv6.conf.default.accept_redirects = 0 # 在非路由器上禁用 ICMP 重定向发送 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 # Other tunings net.ipv4.tcp_no_metrics_save = 1 vm.min_free_kbytes = 65536 # 启用 BBR 拥塞控制算法可以帮助实现更高的带宽和更低的互联网流量延迟。首先，加载模块tcp_bbr。 # net.core.default_qdisc = cake # net.ipv4.tcp_congestion_control = bbr # 将脏字节设置为足够小的值、例如 4M # vm.dirty_background_bytes = 4194304 # vm.dirty_bytes = 4194304 # 磁盘IO配置，linux会设置40%的可用内存用来做系统cache，当flush数据时这40%内存中的数据由于和IO同步问题导致超时(120s)，所将40%减小到10%，避免超时 # vm.dirty_ratio=10 # vm.dirty_background_ratio=5 # nfs fs.nfs.nfs_callback_tcpport = 32764 fs.nfs.nlm_tcpport = 32768 fs.nfs.nlm_udpport = 32768 \" \u003e\u003e /etc/sysctl.conf $ sysctl -p # 重载使之生效 修改系统Ulimit # 临时修改 $ ulimit -n 65535 # 写到配置文件永久生效 $ echo \" * soft nproc 65535 # soft 软限制 * hard nproc 65535 # hard 硬限制 root soft nofile 65535 # 针对用户单独做限制 root hard nofile 65535 * soft nofile 25535 * hard nofile 25535 * soft memlock unlimited * soft memlock unlimited \" \u003e\u003e/etc/security/limits.conf 修改sshd $ echo \"AllowUsers myadmin@0.0.0.0/0\" \u003e\u003e/etc/ssh/sshd_config $ echo \"AllowUsers myadmin@192.168.0.115\" \u003e\u003e/etc/ssh/sshd_config # 限制用指定IP登录 $ echo \"StrictHostKeyChecking no\" \u003e\u003e/etc/ssh/sshd_config # 关闭首次连接询问 # 禁止root用户远程登录服务器 $ sed -i \"s/#PermitRootLogin yes/PermitRootLogin no/g\" /etc/ssh/sshd_config $ systemctl restart sshd 优化系统服务Cgroup # 限制CPU $ mkdir /sys/fs/cgroup/cpu,cpuacct/cgroup_mysql $ echo \"30000\" \u003e/sys/fs/cgroup/cpu,cpuacct/cgroup_mysql/cpu.cfs_quota_us $ echo \"mysql pid\" \u003e/sys/fs/cgroup/cpu,cpuacct/cgroup_mysql/task # 限制内存， 限制单位为：字节(Bytes) $ mkdir /sys/fs/cgroup/memory/cgroup_mysql $ echo \"1073741824\" \u003e/sys/fs/cgroup/memory/cgroup_mysql/memory.limit_in_bytes # 1G 为：1073741824Bytes(字节) $ echo \"mysql pid\" \u003e/sys/fs/cgroup/memory/cgroup_mysql/task 优化HISTSIZE显示操作时间、连接IP以及用户 谁动了我的主机? 之活用History命令 下载GNU软件 # 监控登陆过系统的用户、IP地址、操作命令以及操作时间 $ echo \"export HISTTIMEFORMAT=\"%F %T `who \\-u am i 2\u003e/dev/null | awk '{print $NF}' | sed \\-e 's/[()]//g'` `whoami` \"\" \u003e\u003e/etc/profile.d/history.sh Ubuntu安装messages $ sudo apt-get install --reinstall rsyslog $ cat \u003e/etc/rsyslog.d/50-default.conf\u003c\u003c-EOF *.=info;*.=notice;*.=warn;\\ # 31 行左右取消注释 auth,authpriv.none;\\ cron,daemon.none;\\ mail,news.none -/var/log/messages EOF $ sudo service rsyslog restart 3.1 Ubuntu安装bash $ sudo wget https://ftp.gnu.org/gnu/bash/bash-5.2.tar.gz $ sudo tar zxvf bash-5.2.tar.gz # 修改配置文件 $ cat \u003e/usr/local/src/bash-5.2/bashhist.c\u003c\u003c-EOF hdrlen = snprintf (loghdr, sizeof(loghdr), \"HISTORY: PID=%d UID=%d User=%s \", getpid(), current_user.uid, current_user.user_name, line); # 843 行左右添加 User=%s current_user.user_name, line EOF $ cat \u003e/usr/local/src/bash-5.2/config-top.h\u003c\u003c-EOF /* #define SSH_SOURCE_BASHRC */ # 113 行左右复制一份 去掉注释 #define SSH_SOURCE_BASHRC /* #define SYSLOG_HISTORY */ # 128 行左右复制一份 去掉注释 #define SYSLOG_HISTORY EOF # 配置、编译、安装 $ sudo ./configure --prefix=/usr/local/bash $ sudo make $ sudo make install # 修改用户环境文件 $ cat \u003e/etc/passwd\u003c\u003c-EOF user_name:x:1000:1000:user_name:/home/user_name:/usr/local/bash/bin/bash EOF 安装配置Linux系统的IRQ均衡工具Irqbalance 安装配置 $ sudo apt-get update $ sudo apt-get install irqbalance $ sudo cat \u003e\u003e/etc/default/irqbalance\u003c\u003c-EOF ENABLED=\"1\" # ENABLED=1 表示启用 BALANCE_INTERVAL=1 # BALANCE_INTERVAL=1 表示每秒进行一次 IRQ 均衡 EOF $ sudo systemctl restart irqbalance.service # 检查是否生效 $ cat /proc/interrupts 关闭透明大页 修改grub.conf文件 # 确实是否开启 $ cat /sys/kernel/mm/redhat_transparent_hugepage/enabled [always] madvise never # [always] 表示开启 $ grep HugePage /proc/meminfo AnonHugePages: 585728 kB # 不是 0 就代表启动 # 修改grub.conf文件 $ cat \u003e\u003e/etc/grub.conf\u003c\u003c-EOF kernel /vmlinuz-2.6.32-431.el6.x86_64 ro root=/dev/mapper/vg_linuxbase-lv_root rd_NO_LUKS LANG=en_US.UTF-8 rd_LVM_LV=vg_linuxbase/lv_root rd_NO_MD rd_LVM_LV=vg_linuxbase/lv_swap SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet transparent_hugepage=never # 在kernel 行新添参数配置 EOF # 重启主机 $ shutdown -Fr now 使用脚本方式 if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag fi 调节CPU频率 不安装工具方式 $ sudo cat /proc/cpuinfo | sudo grep MHz $ sudo echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor \u003e/dev/null 使用cpupower工具 $ sudo apt-get install linux-cpupower -y 或者 apt-get install -y linux-tools-$(uname -r) $ sudo cpupower -c all frequency-set -g performance # 设置所有CPU为性能模式 $ sudo cpupower -c all frequency-set -g powersave # 设置所有CPU为节能模式 $ sudo cpupower -c all frequency-info # 查看当前所有CPU的信息 $ sudo watch -n 1 cpupower monitor # CPU实时频率查看 修改系统I/O调度算法 $ sudo cat /sys/block/sda/queue/scheduler # sda 磁盘名称 [mq-deadline] none # 代表使用得是 [mq-deadline] # 临时修改为：noop 算法 $ echo noop \u003e/sys/block/sda/queue/scheduler # 永久生效 $ cp -p /boot/grub/menu.lst /boot/grub/menu.lst-backup # 提前备份配置文件 $ sudo cat \u003e\u003e/boot/grub/menu.lst\u003c\u003c-EOF kernel /vmlinuz-2.6.16.60-0.91.1-smp root=/dev/sysvg/root splash=silent splash=off showopts elevator=noop # 行最后添加 EOF ",
    "description": "Linux系统优化 系统初始化 $ yum -y install vim lrzsz epel-release $ yum -y update $ setenforce 0 \u0026\u0026 sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 优化系统内核 系统控制 $ echo \"# 所有配置都是：0：为关闭，1：为开启 # 关闭ipv6 net.",
    "tags": [],
    "title": "System_Optimization",
    "uri": "/systems/linux/use_linux/system_optimization/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": "System Architecture Planning Diagram 在线协同编写系统 MM-wiki WiKi.js Confluence GitBook多人协作文档、GitBook安装部署实操手册、CentOS7下部署GitBook MrDoc在线文档系统 MediaWiki Docsify Typecho DokuWiki 开源免费的Wiki系统 swagger API接口文档开发 MinDoc notion Go CMDB Kubernetes-蓝鲸CMDB 分享10个我常逛的国外技术社区、11个国外IT技术交流网站汇总 OnlyOffice LibreOffice Apache OpenOffice freeoffice Ngx、Youtube 我不是咕咕鸽Youtube 小马技术 $ docker pull swaggerapi/swagger-editor:v4.9.1 $ docker run -d -p 19090:8080 swaggerapi/swagger-editor:v4.9.1 把Kali Linux装进U盘使其可以在UEFI的机器上启动使用 CICD Network Architecture Client Online Process Initial Architecture Diagram Jnekins Process Jumpserver Master K8s Online process Lua-Games Online Process Server Code Online process Zabbix Monitor And Alert 运维体系 运维架构层级/运维角度",
    "description": "System Architecture Planning Diagram 在线协同编写系统 MM-wiki WiKi.js Confluence GitBook多人协作文档、GitBook安装部署实操手册、CentOS7下部署GitBook MrDoc在线文档系统 MediaWiki Docsify Typecho DokuWiki 开源免费的Wiki系统 swagger API接口文档开发 MinDoc notion Go CMDB Kubernetes-蓝鲸CMDB 分享10个我常逛的国外技术社区、11个国外IT技术交流网站汇总 OnlyOffice LibreOffice Apache OpenOffice freeoffice Ngx、Youtube 我不是咕咕鸽Youtube 小马技术 $ docker pull swaggerapi/swagger-editor:v4.",
    "tags": [],
    "title": "System_Architecture_Planning_Diagram",
    "uri": "/systems/linux/use_linux/system_architecture_planning_diagram/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": "正则表达式 正则表达式 运算符优先级 运算符 描述 \\ 转义符 ()，(?:)，(?=)，[] 圆括号和方括号 *，+，?，{n}，{n,}，{n,m} 限定符 ^，$，\\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，“或\"操作 字符具有高于替换运算符的优先级，使得m|food匹配m或food。若要匹配mood或food，请使用括号创建子表达式，从而产生(m|f)ood。 非打印字符 字符 描述 \\cx 匹配由x指明的控制字符。例如， \\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c 为一个原义的c字符。 \\f 匹配一个换页符。等价于\\x0c和\\cL。 \\n 匹配一个换行符。等价于\\x0a和\\cJ。 \\r 匹配一个回车符。等价于\\x0d和\\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。注意Unicode正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。等价于\\x09和\\cI。 \\v 匹配一个垂直制表符。等价于\\x0b和\\cK。 特殊字符 特别字符 描述 $ 匹配输入字符串的结尾位置。如果设置了RegExp对象的Multiline属性，则$也匹配\\n或\\r。要匹配$字符本身，请使用\\$。 () 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用\\(和\\)。 * 匹配前面的子表达式零次或多次。要匹配*字符，请使用\\*。 + 匹配前面的子表达式一次或多次。要匹配+字符，请使用\\+。 . 匹配除换行符\\n之外的任何单字符。要匹配.，请使用\\.。 [ 标记一个中括号表达式的开始。要匹配[，请使用\\[。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配?字符，请使用\\?。 \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， n匹配字符n。\\n匹配换行符。序列\\\\匹配\\，而\\(则匹配(。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配^字符本身，请使用\\^。 { 标记限定符表达式的开始。要匹配{，请使用\\{。 ` ` 限定符 字符 描述 * 匹配前面的子表达式零次或多次。例如zo\\能匹配z以及zoo。*等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+能匹配zo以及zoo，但不能匹配z。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)?可以匹配do、 does、doxy中的do和does。? 等价于{0,1} {n} n是一个非负整数。匹配确定的n次。例如，o{2}不能匹配Bob中的o，但是能匹配food中的两个o。 {n,} n是一个非负整数。至少匹配n次。例如，o{2,}不能匹配Bob中的o，但能匹配foooood中的所有o。o{1,}等价于o+。o{0,}则等价于o\\*。 {n,m} m和n均为非负整数，其中n \u003c= m。最少匹配n次且最多匹配m次。例如，o{1,3}将匹配fooooood中的前三个 o。o{0,1}等价于o?。请注意在逗号和两个数之间不能有空格。 定位符 字符 描述 ^ 匹配输入字符串开始的位置。如果设置了RegExp对象的Multiline属性，^还会与\\n或\\r之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了RegExp对象的Multiline属性，$还会与\\n或\\r之前的位置匹配。 \\b 匹配一个单词边界，即字与空格间的位置。 \\B 非单词边界匹配。 修饰符 修饰符 含义 描述 i ignore - 不区分大小写 将匹配设置为不区分大小写，搜索时不区分大小写: A和a没有区别。 g global - 全局匹配 查找所有的匹配项。 m multi line - 多行匹配 使边界字符^和$匹配每一行的开头和结尾，记住是多行，而不是整个字符串的开头和结尾。 s 特殊字符圆点 . 中包含换行符 \\n 默认情况下的圆点 . 是匹配除换行符\\n之外的任何字符，加上s修饰符之后, . 中包含换行符\\n。 元字符 字符 描述 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n匹配字符n。\\n匹配一个换行符。序列\\\\匹配 “\" 而\\(则匹配(。 ^ 匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配\\n或\\r之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配\\n或\\r之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo*能匹配z以及zoo。*等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，zo+能匹配zo以及zoo，但不能匹配z。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，do(es)?可以匹配do或does。? 等价于{0,1}。 {n} n是一个非负整数。匹配确定的n次。例如，o{2}不能匹配Bob中的o，但是能匹配food中的两个o。 {n,} n是一个非负整数。至少匹配n次。例如，o{2,}不能匹配Bob中的o，但能匹配foooood中的所有o。o{1,}等价于o+。o{0,}则等价于o*。 {n,m} m和n均为非负整数，其中n \u003c= m。最少匹配n次且最多匹配m次。例如，o{1,3}将匹配fooooood中的前三个o。o{0,1}等价于o?。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符(*, +, ?, {n}, {n,}, {n,m})后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 oooo，o+?将匹配单个o，而o+将匹配所有o。 . 匹配除换行符(\\n、\\r)之外的任何单个字符。要匹配包括\\n在内的任何字符，请使用像`(. (pattern) 匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用 SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用 \\(或\\)。 (?:pattern) 匹配pattern但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符`( (?=pattern) 正向肯定预查look ahead positive assert，在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，`Windows(?=95 (?!pattern) 正向否定预查negative assert，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如`Windows(?!95 (?\u003c=pattern) 反向look behind肯定预查，与正向肯定预查类似，只是方向相反。例如，`(?\u003c=95 (?\u003c!pattern) 反向否定预查，与正向否定预查类似，只是方向相反。例如`(?\u003c!95 `x y` [xyz] 字符集合。匹配所包含的任意一个字符。例如，[abc]可以匹配plain中的a。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如， [^abc]可以匹配plain中的p、l、i、n。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，[a-z]可以匹配a到z范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z]可以匹配任何不在a到z范围内的任意字符。 \\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， er\\b可以匹配never中的er，但不能匹配 verb中的er。 \\B 匹配非单词边界。er\\B能匹配verb中的er，但不能匹配never中的er。 \\cx 匹配由x指明的控制字符。例如， \\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的c字符。 \\d 匹配一个数字字符。等价于[0-9]。 \\D 匹配一个非数字字符。等价于 [^0-9]。 \\f 匹配一个换页符。等价于\\x0c和\\cL。 \\n 匹配一个换行符。等价于\\x0a和\\cJ。 \\r 匹配一个回车符。等价于\\x0d和\\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。等价于\\x09和\\cI。 \\v 匹配一个垂直制表符。等价于\\x0b和\\cK。 \\w 匹配字母、数字、下划线。等价于[A-Za-z0-9_]。 \\W 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]。 \\xn 匹配n，其中n为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\x41匹配 “A”。\\x041则等价于\\x04\u00261。正则表达式中可以使用 ASCII 编码。 \\num 匹配num，其中num是一个正整数。对所获取的匹配的引用。例如，(.)\\1匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字(0-7)，则n为一个八进制转义值。 \\nm 标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字(0-7)，则\\nm将匹配八进制转义值nm。 \\nml 如果n为八进制数字(0-3)，且m和l均为八进制数字(0-7)，则匹配八进制转义值nml。 \\un 匹配n，其中n是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配版权符号(?)。 ",
    "description": "正则表达式 正则表达式 运算符优先级 运算符 描述 \\ 转义符 ()，(?:)，(?=)，[] 圆括号和方括号 *，+，?，{n}，{n,}，{n,m} 限定符 ^，$，\\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，“或\"操作 字符具有高于替换运算符的优先级，使得m|food匹配m或food。若要匹配mood或food，请使用括号创建子表达式，从而产生(m|f)ood。 非打印字符 字符 描述 \\cx 匹配由x指明的控制字符。例如， \\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c 为一个原义的c字符。 \\f 匹配一个换页符。等价于\\x0c和\\cL。 \\n 匹配一个换行符。等价于\\x0a和\\cJ。 \\r 匹配一个回车符。等价于\\x0d和\\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。注意Unicode正则表达式会匹配全角空格符。 \\S 匹配任何非空白字符。等价于 [^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。等价于\\x09和\\cI。 \\v 匹配一个垂直制表符。等价于\\x0b和\\cK。 特殊字符 特别字符 描述 $ 匹配输入字符串的结尾位置。如果设置了RegExp对象的Multiline属性，则$也匹配\\n或\\r。要匹配$字符本身，请使用\\$。 () 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用\\(和\\)。 * 匹配前面的子表达式零次或多次。要匹配*字符，请使用\\*。 + 匹配前面的子表达式一次或多次。要匹配+字符，请使用\\+。 .",
    "tags": [],
    "title": "Regular_Expression",
    "uri": "/systems/linux/use_linux/regular_expression/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": "工具、软件 名称 描述 WindTerm 适用于DevOps的更快、更好的SSH/Telnet/Serial/Shell/Sftp客户端 FinalShell FinalShell是一体化的的服务器,网络管理软件,不仅是ssh客户端,还是功能强大的开发,运维工具,充分满足开发,运维需求 MobaXterm 带有X11服务器、选项卡式SSH客户端、网络工具等的增强型Windows终端 Termius Hyper Hyper是一个基于Electron的终端，基于HTML/CSS/JS构建，完全可扩展，从命令行安装主题和插件。hyper i hyper-rose-pine、hyper-rose-pine installed successfully! 社区、官网文档 名称 描述 TrueNAS 存储 博客 ",
    "description": "工具、软件 名称 描述 WindTerm 适用于DevOps的更快、更好的SSH/Telnet/Serial/Shell/Sftp客户端 FinalShell FinalShell是一体化的的服务器,网络管理软件,不仅是ssh客户端,还是功能强大的开发,运维工具,充分满足开发,运维需求 MobaXterm 带有X11服务器、选项卡式SSH客户端、网络工具等的增强型Windows终端 Termius Hyper Hyper是一个基于Electron的终端，基于HTML/CSS/JS构建，完全可扩展，从命令行安装主题和插件。hyper i hyper-rose-pine、hyper-rose-pine installed successfully!",
    "tags": [],
    "title": "Linux_Document",
    "uri": "/systems/linux/use_linux/linux_document/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": "Linux常用命令总结 生成密码 名称 描述 Rocky Linux Centos系统的替代品 Debian Stable Debian系统镜像 Alpine Linux Linux高山系统镜像 Linux Linux命令搜索 Linux命令大全(手册) Linux命令大全(手册) 菜鸟Linux命令大全 Dig命令 如果复制密钥到客户端后不生效， 优先排查宿主家目录权限 /home/user $ openssl rand -base64 10 $ gpg --gen-random --armor 1 14 $ gzip -d # 解压缩 $ kill -9 `ps -ef |grep xxx|awk '{print $2}' ` # 杀掉服务进程 # 谷歌云普通用户远程登录 $ chown -R user:user /home/user $ chmod 600 authorized_keys # 次文件一定属主读写，其他为0 yum命令 $ yum install -y nodejs # 安装node $ yum install -y chrony # 设置时间服务 $ yum install -y psmisc # 安装killall $ yum install -y epel-release # 安装epel源 $ yum whatprovides ifconfig # 查找某个命令属于那个rpm包 $ yum -y groupinstall \"GNOME Desktop\" # Linux命令行安装图形化 # 升级gcc到6.3版本 $ yum -y install centos-release-scl $ yum -y install devtoolset-6-gcc devtoolset-6-gcc-c++ devtoolset-6-binutils $ scl enable devtoolset-6 bash $ echo \"source /opt/rh/devtoolset-6/enable\" \u003e\u003e/etc/profile $ source /etc/profile # 高版本node.js需升级gcc、7.3版本 $ yum -y install centos-release-scl $ yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils $ scl enable devtoolset-7 bash $ echo \"source /opt/rh/devtoolset-7/enable\" \u003e\u003e/etc/profile $ source /etc/profile # 升级gcc到9版本 $ yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils $ echo 'scl enable devtoolset-9 bash' $ echo \"source /opt/rh/devtoolset-9/enable\" \u003e\u003e/etc/profile $ source /etc/profile node、npm命令 $ yum groupinstall \"Development Tools\" \"Development Libraries\" $ yum install make automake gcc gcc-c++ kernel-devel $ yum -y install install build-essential $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash # nvm 使用 $ nvm install 18.0.0 # 安装 nodejs 18.0.0 $ nvm ls # 列出已经安装的node版本 $ nvm use v12.13.0 # 切换node版本 $ nvm alias default v12.13.0 # 指定默认的node版本 $ npm install -g n # 安装n模块 $ n # 选择版本直接用n命令 $ n v10.16.0 # \"n\"加版本号,用n命令下载所需的版本 $ n latest # 下载最新版 $ n rm 版本号 # 删除版本 # build执行打包命令、如果dist目录存在删除、node_modules目录可选择删除或者保留 $ npm install $ npm run build # 安装wscat 测试websocket $ npm install -g wscat $ ./wscat --connect ws://192.168.2.210 $ curl -i \\ --header \"Upgrade: websocket\" \\ --header \"Sec-WebSocket-Key: AQIDBAUGBwgJCgsMDQ4PEA==\" \\ --header \"Sec-WebSocket-Version: 13\" \\ --header \"Connection: upgrade\" \\ #直接访问后端服务的 Websocket 需要带上该头部 http://192.168.1.141 Build complete. Tip: built files are meant to be served over an HTTP server. Opening index.html over file:// won't work. # 处理办法、在npm run build 运行完之后，再运行 $ cd dist $ npm install -g http-server # 该命令只需执行一次,安装过之后, 以后就不需要重复安装了.hs find命令 $ find . -type f -size +500M # 查询当前超过500M的文件 $ find . -type f -exec ls -l {} \\; # 查询当前文件，并以长格式列出 $ find . -type f -exec chmod 644 {} \\; # f:代表文件，设置644权限 $ find . -type d -exec chmod 755 {} \\; # d代表目录，设置755权限 $ find ./* -type f -mtime +15 | xargs ls -lt # 过滤出来文件按时间排序 $ find . -type f -mtime -30 -exec gzip -c ./* \u003e/tmp/nginx-wwwlogs-09-27.gz {} \\; # atime：最后一次访问时间，ctime：最后一次改变权限时间，mtime：最后一次修改时间 $ find . -name \"*.log\" -exec cp {} test \\; # 查找当前目录下以.log结尾文件， # 拷贝并且新文件重新命名为：test $ find . -name \"*.log\" -mtime +5 -ok rm {} \\; # 和-exec的作用相同， # 只不过以一种更为安全的模式来执行该参数所给出的shell命令， # 在执行每一个命令之前，都会给出提示，让用户来确定是否执行 $ find . -name \"*.log\" -mtime +6 -exec du -sh {} \\; # 查看当前目录下以.log结尾并超过七天的文件大小 $ find /etc -name \"passwd*\" -exec grep \"root\" {} \\; # 查找并且打包 $ find /your/directory/path -name \"*.tar\" -exec tar -xvf {} \\; # 查找并打包到指定目录 $ find /your/directory/path -name \"*.tar\" -exec tar -xvf {} -C /path/to/extracted/directory \\; 后台运行命令 名称 使用方式 描述 nohup $ nohup \u0026 使用nohup+ \u0026让服务后台运行 setsid $ setsid screen $ screen screen属于第三方工具需要单独安装 使用screen $ yum -y install screen # 安装 $ screen # 启动 $ screen ls # 查看 $ screen r 进程号 # 进入程序 使用：screen [-opts] [cmd [args]或：screen -r [host.tty] # 选项： -4 # 仅将主机名解析为IPv4地址。 -6 # 仅将主机名解析为IPv6地址。 -a # 强制所有功能进入每个窗口的termcap。 -A # - [r | R]使所有窗口适应新的显示宽度和高度。 -c # file读取配置文件而不是'.screenrc'。 -d # （-r）分离其他正在运行的屏幕（并在此处重新连接）。 -dmS # name作为守护程序启动：处于分离模式的屏幕会话。 -D # （-r）分离和注销远程（并在此处重新连接）。 -D # -RR执行屏幕会话所需的任何操作。 -e # xy更改命令字符。 -f # 流控制开启，-fn=关闭，-fa=auto。-h lines设置回滚历史记录缓冲区的大小。 -i # 当流量控制打开时，中断输出更快。 -l # 登录模式打开（update /var/run/utmp,-ln = off。 -ls # [匹配]或-list什么都不做，只列出我们的SockDir [在可能的比赛中]。 -L # 打开输出日志记录。 -m # 忽略$ STY变量，创建一个新的屏幕会话。 -O # 选择最佳输出而不是精确的vt100仿真。 -p # window预选指定的窗口（如果存在）。 -q # 安静的启动。如果不成功，则退出非零返回码。 -Q # Commands将响应发送到查询过程的stdout。 -r # [session]重新连接到分离的屏幕进程。 -R # 如果可能重新连接，否则启动新会话。 -s # shell shell执行而不是$ SHELL。 -S # sockname将此会话命名为\u003cpid\u003e .sockname而不是\u003cpid\u003e。\u003ctty\u003e。\u003chost\u003e。 -t # title设置标题。（窗口的名字）。 -T # 术语使用术语作为Windows的$ TERM，而不是“屏幕”。 -U # 告诉屏幕使用UTF-8编码。 -v # 打印“屏幕版本4.01.00devel（GNU）2-May-06”。 -wipe # [match]什么都不做，只是清理SockDir [在可能的比赛中]。 -x # 附加到未分离的屏幕。（多显示模式）。 -X # 在指定的会话中执行\u003ccmd\u003e作为屏幕命令。 系统排查、抓包、分析命令 iperf、 Linux命令、工具 $ ss # 连接查看工具 $ pidof nginx # 获取服务运行的pid $ tracert # 追踪路由命令 $ nethogs # 按进程查看流量占用 $ iptraf # 按连接/端口查看流量 $ ifstat # 按设备查看流量 $ strace -p pid # 查看进程工作 $ ethtool # 诊断工具 $ tcpdump # 抓包工具 $ tcptraceroute # 路由追踪工具 $ ifup/ifdown # 启动和停止网卡,可以接网卡名：ifup eth0。 # 其它排查命令: dstat, slurm, nload, bmon $ sudo opensnoop-bpfcc # 安装目录在：/usr/sbin/ $ iperf3 # 网络性能测试工具 Installing BCC BPF Compiler Collection (BCC) 快捷键 删除快捷键 名称 描述 ctrl + d 删除光标所在位置上的字符相当于VIM里x或者dl ctrl + h 删除光标所在位置前的字符相当于VIM里hx或者dh ctrl + k 删除光标后面所有字符相当于VIM里d shift+$ ctrl + u 删除光标前面所有字符相当于VIM里d shift+^ ctrl + w 删除光标前一个单词相当于VIM里db ctrl + y 恢复ctrl+u上次执行时删除的字符 ctrl + ? 撤消前一次输入 alt + r 撤消前一次动作 alt + d 删除光标所在位置的后单词 移动快捷键 名称 描述 ctrl + a 将光标移动到命令行开头相当于VIM里shift+^ ctrl + e 将光标移动到命令行结尾处相当于VIM里shift+$ ctrl + f 光标向后移动一个字符相当于VIM里l ctrl + b 光标向前移动一个字符相当于VIM里h ctrl + 方向键左键 光标移动到前一个单词开头 ctrl + 方向键右键 光标移动到后一个单词结尾 ctrl + x 在上次光标所在字符和当前光标所在字符之间跳转 alt + f 跳到光标所在位置单词尾部 替换快捷键 名称 描述 ctrl + t 将光标当前字符与前面一个字符替换 alt + t 交换两个光标当前所处位置单词和光标前一个单词 alt + u 把光标当前位置单词变为大写 alt + l 把光标当前位置单词变为小写 alt + c 把光标当前位置单词头一个字母变为大写 ^oldstr^newstr 替换前一次命令中字符串历史命令编辑 ctrl + p 返回上一次输入命令字符 ctrl + r 输入单词搜索历史命令 alt + p 输入字符查找与字符相接近的历史命令 alt + \u003e 返回上一次执行命令 其它操作 名称 描述 ctrl + c 另起一行 ctrl + r 输入单词搜索历史命令 ctrl + s 锁住终端 ctrl + q 解锁终端 ctrl + l 清屏相当于命令clear ctrl + c 另起一行 ctrl + i 类似TAB健补全功能 ctrl + o 重复执行命令 alt + 数字键 操作 systemctl命令 $ systemctl list-unit-files # 列出所有服务状态 $ systemctl list-dependencies # 列出所有服务以及依赖状态 $ systemctl list-unit-files --type=service|grep enabled # 查看开启的服务 安装KVM、VNC 安装KVM $ yum -y install virt-manager $ virsh list --all $ virsh start server_15 $ virsh autostart server_15 # 开机自启 # 检查在/etc/libvirt/qemu/autostart/下会生成一个（虚拟机名.xml）文件 安装vnc $ yum -y install vnc* $ vncserver $ netstat -nuptl $ firewall-cmd --add-port=5905/tcp --permanent $ firewall-cmd --reload 软件包 tigervnc-server-1.8.0-13.el7.x86_64 已安装并且是最新版本 软件包 tigervnc-1.8.0-13.el7.x86_64 已安装并且是最新版本 软件包 tigervnc-server-module-1.8.0-13.el7.x86_64 已安装并且是最新版本 其他命令 创建、删除用户以及用户组命令 $ useradd # 添加用户语法：useradd 用户名,例子:useradd oldboy # -u:指定uid，-g:添加主组，-G:添加用户附属组， # -s:指定登录的shell，-e:指定过期时间，-M:不创建家目录， # -D:修改/etc/default/useradd参数，一般用 vi 直接编辑。 $ usermod # -d:指定就改目录,-g:改主组,-G:附加组 $ chage # 设置或修改用户密码有效期限,-e:修改密码文件,-l:查看密码有效期 $ userdel # 删除用户,-r:删除家目录 $ groups # 查看用户属组 $ groupadd # 添加组group $ groupdel # 删除组 创建、修改密码 $ passwd # 为用户设置或修改密码,例子:passwd oldboy 为oldboy设置修改密码,直接passwd是当前用户修改密码。 $ echo \"123456\"|passwd --stdin username # 非交互式更改密码，一般用于脚本使用 权限、更改、授予操作 $ su # 切换用户身份 - 加载环境变量 -c以指定用户身份执行任务 $ sudo # 可以让普通用户拥有root权限去执行命令,sudo配置文件/etc/sudoers $ visudo # 通过visudo编辑/etc/sudoers,可以去检查配置文件的语法。 $ alias # 查看和设置别名,例子:查看别名直接输入alias,设置别名:alias cp='cp -i' $ unalias # 取消别名 unalias cp $ chmod # 更改及设置文件对应权限 $ chown # 更改及设置文件对应的用户和组 $ last # 显示用户登录信息， /var/log/wtmp数据文件 $ lastlog # 所有用户最近登录的情况 $ umask # 控制文件默认权限 查看、查找命令 jq命令用法总结 $ id # 查看用户信息和组信息、 $ w # 显示登录信息 及操作信息 $ who # 显示谁登录 $ ps # 查找启动的服务 $ cd # 切换目录，例子:cd /etc $ pwd # print work directory打印工作目录(显示当前所在路径) $ cat # 查看文件内容 例子:cat oldboy.txt,-n:显示行号 $ wc # 显示,-l(lines)总行数，-L:最大行的长度。 $ nl # nl - number lines显示行号 $ jq # 轻量级命令行JSON处理器，-r：去除字符串引号，\",\"：逗号执行多个参数，cat text.jsonl | jq -r '.status' $ ls # list(列表)列表目录文件例子：ls /，列出根目录下所有文件、目录 # -a(all)显示所有文件(包括隐藏文件)，默认不显示以\".\"开头的隐藏文件 # -l(long)长格式，-d(directorys)查看目录，-t:按修改时间排序，-r:反转排序(倒序)， # -p:给目录结尾加斜线，-F:给不同文件结尾加不同标识，-i:打印文件的索引号 # --color=auto:显示颜色，-h:人类可读,--time-style=long-iso $ iotop -oP # 时时查看磁盘IO情况 $ pgrep # 以名称为依据从运行进程队列中查找进程，并显示查找到的进程id，例如：pgrep mysqld $ date +%s # 获取时间戳 $ file # 查看文件的类型 $ stat # 显示文件和文件系统状态(查看文件属性)\t$ head # 头，头部读取文件的前n行,默认前10行,-n数字,习惯-5,忽略-n。 $ tail # 尾，尾巴输出文件的后n行,默认后10行,-n数字，习惯-5,忽略-n。 $ less # 和more相反回车一次一行，空格向下一次一屏，按b可以一次回退一屏。 $ more # 按页一次一屏。回车一次一行，空格向下一次一屏。不能回退。 $ history # 查看及清理历史记录-c清空所有,-d删除指定历史记录 $ tree # 大树的意思，显示目录树,-L layer层数,-d显示目录 $ xargs # 从标注你输入获取内容创建和执行命令-n数字,分组 $ which # 查看二进制命令所在路径(从PATH变量所在的路劲查找) $ whereis # 查找文件的帮助、源代码，-b:二进制54、 # locate find files by name 只能查updatedb库里内容， # locate从/var/lib/mlocate/mlocate.db查找目录。 $ find # -name 按名称查找， # -type 按类型查找， # f(file)文件，d(directory)目录，c(character)字符， # b(block)块设备，s(socket)，l(link)链接， # -mtime 按时间查找，+7:7天以前，-7最近7天， # -mtime -ctime -atime！取反， # -a:and并且，-o:or 或者，-maxdepth查找深度，－perm：按权限查找 $ netstat -lnutp -a $ lsof list open file 关机、重启命令 $ init # 按后面对应的数字切换运行级别，例如:init 6重启服务器 $ reboot # 等同于：init 6，以及：shutdown -r now：立即重启 $ poweroff # 关机 $ runlevel # 查看当前系统运行级别 $ shutdown # (halt、init 0)关机，shutdown -h now：立即关机， # -r：代表重启，可按需要定时重启， # -h：代表关机，可按需要定时关机。 $ chkconfig # 设置服务开机自启动命令, --list:查看自动服务，--level levels $ chkconfig --list # 列出所有服务开机在那个运行级别情况下启动或关闭 $ chkconfig --list network # 查看指定服务在运行级别下是否自启或关闭 $ chkconfig --level levels sshd off[on] 查看系统命令 $ dmesg # 命令用于显示开机信息 $ uname # 打印系统信息,-m32or64,-r内核版本,-a(all),-n(显示主机名)hostname 命令 $ hostname # 显示和设置主机名默认是显示主机名，设置主机名可以 hostname 名字(临时生效) 创建、修改文件命令 $ vi # 编辑器，例子：vi oldboy.txt $ vim # 复杂编辑器，功能复杂,高亮，写shell/python脚本用 $ mv # move 移动文件或目录 $ cp # copy拷贝文件或目录，默认不能拷贝目录， # -r:递归，用于复制目录。-a:相当于-pdr， # -p:连同档案的属性一起复制过去，而非使用默认属性。 $ rm # remove 删除目录和文件，-f(force)强制，-r(recursive)递归、用于删除多级目录， # 删除命令要慎用，非常危险，删除前一定要先备份一份。 $ touch # 创建文件或更新文件的时间戳，如果文件不存在创建新文件， # 如果存在改变文件的访问时间atime等时间戳信息。 $ echo # 打印输出内容，配合 \"\u003e\" 或 \"\u003e\u003e\" 可以为文件覆盖及追加内容， # 还有一个较复杂不常用的类似命令printf。-n:不换行输出,-e:可以一起使用：-e \"\\n\" $ mkdir # make directorys 创建目录，例子：mkdir /opt/data 在/opt目录下创建data目录， # -p：递归创建目录、mkdir -p /opt/{data/conf,logs}。 $ rsync -avz --exclude='*.out' --delete 磁盘命令 $ du # 查看文件和目录大小,-sh $ df # 查看磁盘信息：-i、-h、-T文件类型 $ dd # 转换或者复制文件 $ fsck # 磁盘检查 $ fdisk # 磁盘分区工具小于2T $ tune2fs # 修改文件系统信息 $ megacli # 查看raid信息 $ mount # -t type -o 选项 $ umount # 卸载，强制卸载：-lF $ parted # 分区工具（常用于2T的文件系统） $ mkswap # 格式化swap分区 $ dumpe2fs # 查看ext文件系统信息 $ dumper2fs # 查看文件系统内部信息(元数据) $ ipmitools # 查看硬件系统工具 $ resize2fs # 调整文件系统大小（LVM drbd） $ partprobe # 把分区表的修改变化通知内核 $ mkfs.ext4 # (mkfs -t ext4 )格式化 -b block -I inode $ swapon/swapoff # 使用swap分区，例如swapon /dev/sdb1 Linux三剑客 awk是命令还是编程语言 $ tr # 替换translate or delete characters(逐个字符替换) $ seq # sequence序列 -s指定分隔符,seq -s\" \" -f\"str%03g\" 9 11 str009 str010 str011 $ sed # stream editorlinux三剑客老二，流编辑器，实现对文件的增删改替换查， # 参数：-n:取消默认输出，-i:修改文件内容，-e:允许多项编辑功能，-p:打印， # s与g联合使用时,表示对当前行全局匹配替换，s:常说的查找并替换,用一个字符串替换成另一个 # \\：使用转义符 # sed -i s#oldboy#oldgirl#g a.txt #:是分隔符，可以用/@等替换。 $ sed -n '/10\\/Sep\\/2022:20:00:00/,/10\\/Sep\\/2022:21:00/p' app.jsonl | awk -F '[\",]+' '{print $10,$13}' |grep -v 200 | sort |uniq -c | sort -nr | head -10 $ awk # 过滤、输出内容，$1:第一列，$2:第二列依次类推，但$0:表示一行， # NR:行号，NF:表示最后结尾一列，-F:指定分隔符、使用：[]可以过滤多个参数， # awk -F '[:]' 'NR==1 {print $1,$4,$NF}' /etc/passwd $ awk '$0 \u003e= \"2023/12/01 00:00:00\" \u0026\u0026 $0 \u003c= \"2023/12/01 23:59:59\"' live_go_chat_pre.log \u003e 2023-12-01.txt $ cat nginx.jsonl | awk -F '\"' '{if($50 != \"XXXIP\" \u0026\u0026 $50 == \"XXXIP\") {print $0}}' $ grep # linux三剑客老三过滤需要的内容，例子：grep -v oldboy test.txt， # grep一般常用参数: # -a:在二进制文件中，以文件文件的方式搜素数据 # -c:计算找到'搜索字符串'的次数 # -o:仅显示出匹配regexp的内容(用于统计出现在文中的次数) # -i:不区分大小写，所以大小写视为相同 # -n:匹配的内容在其行首显示行号 # -v:反向选择，即显示没有'搜索字符串'内容的那一行 # -E:扩展的grep，即egrep # -v:后面接要排除的内容 # -n:对匹配的内容打印行号 # -w:按单词搜索，相当于\\ \\b。 # Context control: # -B:(before)除了显示匹配的一行之外,并显示该行之前的num行 # -A:(after)除了显示匹配的一行之外,并显示该行之后的num行 # -C:(Context)除了显示匹配的一行之外,并显示该行之前后各num行 # --color=auto:对过滤的匹配的字符串加颜色 $ sort # 排序命令，-n：依照数值的大小排序，-r：以相反的顺序来排序 $ uniq # 去重命令，-c或--count 在每列旁边显示该行重复出现的次数 其他命令 :set fileformat=unix # windows 换行符缓存Linux $ echo -e \"\\033[?25h\" # 显示光标 $ dos2unix bash.sh $ ln # 创建软硬连接,-s软(readlink)、修改软连接：ln -snf 源文件地址 链接名称， ln -s dist_commit pro，ln -s dist_commit pre， $ cut # 切割 取列,-d分隔符,-f取列,-c字符 $ tar # z:压缩、c:备份、v:屏幕输出过程、f:指定备份文件、j:bzip2压缩/解压缩、 # x:归档中提取文件 X N:日期格式、p:保留原来的文件权限与属性、 # P:使用文件名的绝对路径，不移除文件名称前的“/”号、 # C:仅压缩指定目录里的内容或解压缩到指定目录、 # --exclude=/usr/local/nginx/log:排除不需要打包目录 # tar -c --lzma -f nginx-logs.tar.lzma /opt/logs/nginx 极限压缩格式 # tar zcvf /opt/backup/nginx-$(date +%F).tar.gz --exclude=/usr/local/nginx/log nginx 忽略log 目录压缩 $ wget # 下载 -q 安静 -O 指定文件名 $ curl # -I查看响应header信息 -s安静的 -w获取 $ lynx # 命令行纯文本浏览器 $ test # 测试命令，-f:测试文件是否存在，-d:测试目录是否存在 $ crontab # 计划任务，如果任务没执行需要查看文件权限：/var/spool/cron/crontabs/root 是否为：600权限，以及组权限是否属于：crontab $ split # 手动切割日志、文件，-b：指定文件压缩后大小， # -d：指定文件命后缀使用数字(默认使用字母)， # -a 3：指定后缀文件名是三位数，举例： # split -b 200M nginx.log -d -a 3 nginx.log，按照nginx.log后缀添加命名 $ diff -c -a -r cms1 cms2 # -a:逐行比较文本文件、 # -c:显示全部内文，并标出不同之处、 # -r:比较子目录中的文件 获取公网IP $ curl ip.gs $ curl -4 ip.gs $ curl -6 ip.gs $ curl ip.sb $ curl -4 ip.sb $ curl -6 ip.sb $ curl cip.cc $ curl -4 cip.cc $ curl icanhazip.com $ curl -4 icanhazip.com $ curl -6 icanhazip.com $ curl api.ipify.org $ curl -4 api.ipify.org $ curl bot.whatismyipaddress.com $ curl -4 bot.whatismyipaddress.com $ curl -6 bot.whatismyipaddress.com $ curl ipinfo.io/ip $ curl -4 ipinfo.io/ip $ curl ipecho.net/plain $ curl -4 ipecho.net/plain $ curl ipinfo.io $ curl -4 ipinfo.io $ curl -4 myip.ipip.net $ curl -4 ifconfig.me $ curl -4 http://members.3322.org/dyndns/getip $ curl ifconfig.me $ curl icanhazip.com $ curl curlmyip.com $ curl ip.appspot.com $ curl ipinfo.io/ip $ curl ipecho.net/plain $ curl www.trackip.net/i # 补充 $ curl ip.sb $ curl ip.6655.com/ip.aspx $ curl whatismyip.akamai.com $ wget -qO - ifconfig.co $ dig +short myip.opendns.com @resolver1.opendns.com $ curl ident.me $ curl v4.ident.me $ curl v6.ident.me $ curl inet-ip.info # 返回IP和地区 $ curl ip.6655.com/ip.aspx?area=1 $ curl 1111.ip138.com/ic.asp $ curl ip.cn $ curl cip.cc history历史命令添加时间 # 显示时间 export HISTTIMEFORMAT=\"%F %T\" # 详细显示 export HISTTIMEFORMAT=\"%F %T $(who -u 2\u003e/dev/null | awk '{print $NF}'| sed 's/[()]//g') $(whoami)\" ",
    "description": "Linux常用命令总结 生成密码 名称 描述 Rocky Linux Centos系统的替代品 Debian Stable Debian系统镜像 Alpine Linux Linux高山系统镜像 Linux Linux命令搜索 Linux命令大全(手册) Linux命令大全(手册) 菜鸟Linux命令大全 Dig命令 如果复制密钥到客户端后不生效， 优先排查宿主家目录权限 /home/user $ openssl rand -base64 10 $ gpg --gen-random --armor 1 14 $ gzip -d # 解压缩 $ kill -9 `ps -ef |grep xxx|awk '{print $2}' ` # 杀掉服务进程 # 谷歌云普通用户远程登录 $ chown -R user:user /home/user $ chmod 600 authorized_keys # 次文件一定属主读写，其他为0 yum命令 $ yum install -y nodejs # 安装node $ yum install -y chrony # 设置时间服务 $ yum install -y psmisc # 安装killall $ yum install -y epel-release # 安装epel源 $ yum whatprovides ifconfig # 查找某个命令属于那个rpm包 $ yum -y groupinstall \"GNOME Desktop\" # Linux命令行安装图形化 # 升级gcc到6.",
    "tags": [],
    "title": "Linux_Conmmon_Commands",
    "uri": "/systems/linux/use_linux/linux_conmmon_commands/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Use_Linux",
    "content": " Cloud Foundry\nCloud Foundry是一个开源的平台即服务PaaS，它提供了一个统一的接口，可以让开发者使用任何语言、框架和工具，在任何云上快速部署和管理应用程序。 它的主要功能包括： 1. 多云支持：Cloud Foundry支持多种不同的云平台，包括Amazon Web Services（AWS）、Google Cloud Platform（GCP）、Microsoft Azure、IBM Cloud、OpenStack和VMWare vSphere等。 2. 自动伸缩：Cloud Foundry可以自动伸缩，根据负载情况增加或减少实例数量，以保证服务的可用性和性能。 3. 可靠的运行时环境：Cloud Foundry有一个功能强大的运行时环境，可以在多个云上提供稳定的服务。 4. 云服务支持：Cloud Foundry支持多种不同的云服务，包括数据库、存储、消息队列、监控等，可以让开发者更方便快捷地部署和管理应用程序。 5. 简化开发流程：Cloud Foundry提供了一个易于使用的命令行界面，可以让开发者轻松的部署和管理应用程序，简化开发流程",
    "description": "Cloud Foundry\nCloud Foundry是一个开源的平台即服务PaaS，它提供了一个统一的接口，可以让开发者使用任何语言、框架和工具，在任何云上快速部署和管理应用程序。 它的主要功能包括： 1. 多云支持：Cloud Foundry支持多种不同的云平台，包括Amazon Web Services（AWS）、Google Cloud Platform（GCP）、Microsoft Azure、IBM Cloud、OpenStack和VMWare vSphere等。 2.",
    "tags": [],
    "title": "Install_Cloud_Foundry",
    "uri": "/systems/linux/use_linux/install_cloud_foundry/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Work_Order",
    "content": "安装Ferry工单系统 名称地址 描述 Github Ferry 安装Ferry官方文档 以来服务版本要求 MySQL \u003e 5.7 Go \u003e= 1.14 Redis node \u003e= v12(稳定版本) npm \u003e= v6.14.8 若是安装出错，请先确认redis及MySQL是否安装配置成功 部署方式 名称地址 描述 手动部署 脚本自动部署 导航页 名称地址 描述 bk-sops 蓝鲸智云 部署导航页 自己搭建导航页 OP内部导航系统 威联通web导航页 部署一个简单的导航页 运维内部网址导航系统 ",
    "description": "安装Ferry工单系统 名称地址 描述 Github Ferry 安装Ferry官方文档 以来服务版本要求 MySQL \u003e 5.7 Go \u003e= 1.",
    "tags": [],
    "title": "Install_Ferry",
    "uri": "/systems/linux/work_order/install_ferry/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Web",
    "content": "网站优化 名称地址 描述 博客接入谷歌广告Google Ads hexo博客加入51LA网站流量统计 ",
    "description": "网站优化 名称地址 描述 博客接入谷歌广告Google Ads hexo博客加入51LA网站流量统计 ",
    "tags": [],
    "title": "Website_Optimization_Advertise",
    "uri": "/systems/linux/web/website_optimization_advertise/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Web",
    "content": "Web服务消息状态码 1xx代表：信息 消息 描述 100 Continue 服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求 101 Switching 服务器转换协议：服务器将遵守从客户的请求转换到另外一种协议 2XX代表：成功 消息 描述 200 OK 请求成功(其后是对GET和POST请求的应答文档。) 201 Created 请求被创建完成，同时新的资源被创建。 202 Accepted 供处理的请求已被接受，但是处理未完成 203 Non-authoritative information 文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝 204 No Content 没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面而Servlet可以确定用户文档足够新，这个状态代码是很有用的。 205 Reset 没有新文档。但浏览器应该重置它所显示的内容。用来强制浏览器清楚表单输入内容。 206 Partial Content 客户发送了一个带有Range的头GET请求，服务器完成了他 3XX代表：重定向 消息 描述 300 Multiple Choices 多重选择。链接列表。用户可以选择某链接达到目的地。最多允许五个地址。 301 MovedPermanently 所请求的页面已经转移至新的url 302 Found 所请求的页面已经临时转移至新的url 303 See Other 所请求的页面再别的url下被找到 303 Not Modified 未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求(一般是提供if-Modified-Since头表示客户只想比指定日期更新的文档)。服务器告诉客户，原来缓冲的文档还可以继续使用。 305 Use Proxy 客户请求的文档应该通过Location头所指明的代理服务器提取 306 Unused 此代码被用于前一版本。目前已不再使用，但是代码依然被保留 307 Temporary Redirect 被请求的页面已经临时移至新的url 4XX代表：客户端错误 消息 描述 400 Bad Request 服务器未能理解请求 401 Unauthorized 被请求的页面需要用户和密码 401.1 登录失败。 401.2 服务器配置导致登录失败。 401.3 由于ACL对资源的限制而未获得授权。 401.4 筛选器授权失败。 401.5 ISAPI/CGI应用程序授权失败 401.7 访问被Web服务器上的URL授权策略拒绝。这个错误代码为IIS 6.0所专用 402 Payment Required 此代码尚无法使用 403 Forbidden 对被请求页面的访问被禁止 403.1 执行访问被禁止 403.2 读访问被禁止 403.3 写访问被禁止 403.4 要求SSL 403.5 要求SSL 128 403.6 IP地址被拒绝 403.7 要求客户端证书 403.8 站点访问被拒绝 403.9 用户数过多 403.10 配置无效 403.11 密码更改 403.12 拒绝访问映射表 403.13 客户端证书被吊销 403.14 拒绝目录列表 403.15 超出客户端访问许可 403.16 客户端证书不受信任或无效 403.17 客户端证书已过期或尚未生效 403.18 再当前的应用程序池中不能执行所请求的URL。这个错误码为IIS 6.0所专用。 403.19 不能为这个应用程序池中的客户端执行CGI。这个错误代码为IIS 6.0所专用 403.20 Passport登录失败。这个错误代码为IIS 6.0所专用 404 Not Found 服务器无法找到被请求的页面 404.0 (无)-没有找到文件或目录 404.1 无法在所请求的端口上访问Web站点 404.2 Web服务扩展锁定策略组织本请求 404.3 MIME映射策略阻止本请求 405 Method Not Allowed 请求中指定的方法不被允许 406 Not Acceptable 服务器生成的响应无法被客户端所接受 407 Proxy Authentication Required 用户必须首先使用代理服务器进行验证，这样请求才会被处理 408 Request Timeout 请求超出了服务器的等待时间 409 Conflict 由于冲突，请求无法被完成 410 Gone 被请求的页面不可用 411 Length Required Centent-Length未被定义。如果无此内容，服务器不会接受请求 412 Precondition Failed 请求中的前提条件被服务器评估失败 413 Request Entity Too Large 由于所请求的实体的太大，服务器不会接受请求 414 Requst-url Too Long 由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况 415 Unsupported Medis Type 由于媒介类型不被支持，服务器不会接受请求 416 Requested Range Not Satisfiable 服务器不能满足客户在请求中指定的Range头 417 Expectation Failed 执行失败 423 锁定的错误 5XX代表：服务器错误 消息 描述 500 Internal Server Error 请求未完成。服务器遇到不可预知的情况 500.12 应用程序正忙于在Web服务器上重启 500.13 Web服务器太忙 500.15 不允许直接请求Global.asa 500.16 UNC授权凭据不正确。这个错误代码为IIS 6.0所专用 500.18 URL授权存储不能打开。这个错误代码为IIS 6.0所专用 500.100 内部ASP错误 501 Not Implemented 请求未完成。服务器不支持所请求的功能 502 Bad Gateway 请求未完成。服务器从上游服务器收到一个无效的响应 502.1 CGI应用程序超时 502.2 CGI应用程序出错 503 Service Unavailable 请求未完成。服务器临时过载或当机 504 Gateway Timeout 网关超时、后端服务执行超时（数据库取数据很慢的时候、后端负载很高、连接超时），Nginx默认的等待时间是60秒，超过60秒Nginx就会返回504 505 HTTP Version Not Supported 服务器不支持请求中指明的HTTP协议版本 ",
    "description": "Web服务消息状态码 1xx代表：信息 消息 描述 100 Continue 服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求 101 Switching 服务器转换协议：服务器将遵守从客户的请求转换到另外一种协议 2XX代表：成功 消息 描述 200 OK 请求成功(其后是对GET和POST请求的应答文档。) 201 Created 请求被创建完成，同时新的资源被创建。 202 Accepted 供处理的请求已被接受，但是处理未完成 203 Non-authoritative information 文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝 204 No Content 没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面而Servlet可以确定用户文档足够新，这个状态代码是很有用的。 205 Reset 没有新文档。但浏览器应该重置它所显示的内容。用来强制浏览器清楚表单输入内容。 206 Partial Content 客户发送了一个带有Range的头GET请求，服务器完成了他 3XX代表：重定向 消息 描述 300 Multiple Choices 多重选择。链接列表。用户可以选择某链接达到目的地。最多允许五个地址。 301 MovedPermanently 所请求的页面已经转移至新的url 302 Found 所请求的页面已经临时转移至新的url 303 See Other 所请求的页面再别的url下被找到 303 Not Modified 未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求(一般是提供if-Modified-Since头表示客户只想比指定日期更新的文档)。服务器告诉客户，原来缓冲的文档还可以继续使用。 305 Use Proxy 客户请求的文档应该通过Location头所指明的代理服务器提取 306 Unused 此代码被用于前一版本。目前已不再使用，但是代码依然被保留 307 Temporary Redirect 被请求的页面已经临时移至新的url 4XX代表：客户端错误 消息 描述 400 Bad Request 服务器未能理解请求 401 Unauthorized 被请求的页面需要用户和密码 401.",
    "tags": [],
    "title": "Website_HTTP_Status_Messages",
    "uri": "/systems/linux/web/website_http_status_messages/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Web",
    "content": "安装nginx 名称地址 描述 DedeCms Discuz! WordPress LaikeTui 来客推商城 CRMEB 商城 drupal CMS OpenResty Nginx-Tengine Nginx-OpenResty CentOS7上编译安装Tengine Metasploit渗透靶机 DVWA渗透测试靶机 红虎的黑客SQL注入 nginx documentation 每个开发人员都应该知道的基于Python的20大CMS 护卫神 安装依赖扩展包 # Debian 系统 $ sudo apt-get install libpcre3 libpcre3-dev zlib1g-dev $ yum -y install wget gcc gcc-c++ pcre-devel zlib-devel openssl openssl-devel root用户下载nginx安装 $ wget http://nginx.org/download/nginx-1.20.2.tar.gz -P /usr/local/src/ $ tar -zxvf /usr/local/src/nginx-1.20.2.tar.gz -C /usr/local/src/ 2.1 进入到解压后的目录进行编译安装 $ cd /usr/local/src/nginx-1.20.2 # 配置 $ ./configure --prefix=/usr/local/nginx --with-http_ssl_module \\ --with-http_v2_module --with-http_stub_status_module \\ --with-pcre --with-http_gzip_static_module --with-http_dav_module \\ --with-http_addition_module --with-http_sub_module \\ --with-http_flv_module --with-http_mp4_module # 编译、安装 $ make -j4 \u0026\u0026 make install 2.2 编写启动文件 $ echo '#!/bin/bash ## chkconfig: - 99 2 ## description: Nginx Service Control Script PROG=\"/usr/local/nginx/sbin/nginx\" PIDF=\"/usr/local/nginx/logs/nginx.pid\" case \"$1\" in start) $PROG ;; stop) kill -3 $(cat $PIDF) ;; restart) $0 stop \u0026\u003e /dev/null if [ $? -ne 0 ] ; then continue ; fi $0 start ;; reload) kill -1 $(cat $PIDF) ;; *) echo \"Userage: $0 { start | stop | restart | reload }\" exit 1 esac exit 0 ' \u003e/etc/init.d/nginx 2.3 赋予执行权限，并设置开机自启 $ chmod +x /etc/init.d/nginx $ chkconfig --add nginx $ chkconfig nginx on # 启动nginx服务 $ /usr/local/nginx/sbin/nginx $ netstat -nuplt | grep :80 非常规安装Nginx 3.1 判断用户是否存在，不存在创建，赋予权限 # 判断是否存在 $ id myadmin # 不存在创建 $ if [ $? -eq 0 ];then groupadd group \u0026\u0026 useradd -g myadmin myadmin echo \"password\"|passwd --stdin myadmin \u0026\u003e/dev/null fi # 赋予权限 $ echo \"##### Start/Stop Service ##### Cmnd_Alias MYADMIN_START_SERVICES = /opt/*, /usr/bin/kill, /etc/init.d/nginx, /opt/data/nginx/sbin/nginx myadmin ALL=(ALL)NOPASSWD:MYADMIN_START_SERVICES\" \u003e/etc/sudoers.d/myadmin $ chmod 660 /etc/sudoers.d/myadmin 3.2 创建目录,赋予权限 $ mkdir -p /opt/{apps,src,conf,scripts} $ chown -R admin:admin /opt/* 3.3 进入解压目录，配置、编译、安装 3.3.1 nginx-auth-ldap、--with-http_auth_request_module\n$ su admin -c \" cd /opt/src/ wget http://nginx.org/download/nginx-1.20.2.tar.gz tar -zxvf nginx-1.20.2.tar.gz cd nginx-1.20.2 ./configure --prefix=/opt/lucky/nginx \\ --with-http_stub_status_module --with-http_ssl_module \\ --with-http_gzip_static_module --with-ipv6 --with-stream \\ --with-stream_ssl_module --with-http_v2_module \\ --with-pcre --with-http_gzip_static_module \\ --with-http_dav_module --with-http_addition_module \\ --with-http_sub_module --with-http_flv_module \\ --with-http_mp4_module --with-stream --user=myadmin --group=myadmin· sleep 3 make -j4 \u0026\u0026 make install sleep 5 sudo /opt/data/nginx/sbin/nginx echo \"alias nginx='sudo /etc/init.d/nginx'\" \u003e\u003e/home/myadmin/.bashrc \" $ ss -unplt|grep 80 3.4 编写启动文件 $ cat \u003e/etc/init.d/nginx\u003c\u003c-EOF ## 目录 NGINX_PATH=\"/opt/apps/nginx\" ## start_nginx(){ ${NGINX_PATH}/sbin/nginx } stop_nginx(){ ${NGINX_PATH}/sbin/nginx -s stop } reload_nginx(){ ${NGINX_PATH}/sbin/nginx -s reload } check_nginx(){ ${NGINX_PATH}/sbin/nginx -t } ### Finally the input handling. case \"$1\" in start) start_nginx ;; stop) stop_nginx ;; reload) reload_nginx ;; -t) check_nginx ;; *) echo \"Usage: service nginx {start|stop|reload|-t}\" exit 1 ;; esac exit EOF $ chmod +x /etc/init.d/nginx $ chkconfig --add nginx $ chkconfig nginx on$ cat \u003e/usr/lib/systemd/system/nginx.service\u003c\u003c-EOF [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network-online.target remote-fs.target nss-lookup.target [Service] Type=forking PidFile=/var/run/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf ExecReload=/usr/local/nginx/sbin/nginx -s reload ExecStop=/usr/local/nginx/sbin/nginx -s stop ExecQuit=/usr/local/nginx/sbin/nginx -s quit # ExecReload=/bin/kill -s HUP $MAINPID # ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target EOF $ systemctl daemon-reload $ systemctl enable nginx.service \u0026\u0026 systemctl start nginx 添加系统环境变量、防火墙放行http、https服务 $ sed -i \"N;56iexport PATH=/usr/local/nginx/sbin:$PATH\" /etc/profile $ source /etc/profile $ firewall-cmd --zone=public --add-service={http,https} --permanent $ firewall-cmd --reload ",
    "description": "安装nginx 名称地址 描述 DedeCms Discuz! WordPress LaikeTui 来客推商城 CRMEB 商城 drupal CMS OpenResty Nginx-Tengine Nginx-OpenResty CentOS7上编译安装Tengine Metasploit渗透靶机 DVWA渗透测试靶机 红虎的黑客SQL注入 nginx documentation 每个开发人员都应该知道的基于Python的20大CMS 护卫神 安装依赖扩展包 # Debian 系统 $ sudo apt-get install libpcre3 libpcre3-dev zlib1g-dev $ yum -y install wget gcc gcc-c++ pcre-devel zlib-devel openssl openssl-devel root用户下载nginx安装 $ wget http://nginx.",
    "tags": [],
    "title": "Install Nginx",
    "uri": "/systems/linux/web/install-nginx/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Web",
    "content": "安装Nginx GeoIP2IP定位模块 GeoIP2模块依赖libmaxminddb库 GeoIP Legacy Databases 安装libmaxminddb库 $ wget -c https://github.com/maxmind/libmaxminddb/releases/download/1.7.1/libmaxminddb-1.7.1.tar.gz -P /usr/local/src # 下载到指定目录下:-c断点续传、-P下载指定目录， $ tar -zxvf /usr/local/src/libmaxminddb-1.7.1.tar.gz -C /usr/local/src/ $ cd /usr/local/src/libmaxminddb-1.7.1 $ ./configure $ make -j6 \u0026\u0026 make install 安装GeoIP2 $ git clone https://github.com/leev/ngx_http_geoip2_module.git /usr/local/nginx/ngx_http_geoip2_module $ ./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginx/ngx_http_geoip2_module 安装ngx_brotli压缩算法 # 下载算法包，执行更新ngx_brotli依赖算法，算法依赖自动下载 $ wget -c https://codeload.github.com/google/brotli/tar.gz/refs/tags/v1.1.0 -P /usr/local/src $ tar zxvf /usr/local/src/brotli-1.1.0.tar.gz -C /usr/local/src/ $ mv /usr/local/src/brotli-1.1.0/* /usr/local/nginx/ngx_brotli/deps/brotli/ # 下载安装模块 $ git clone https://github.com/google/ngx_brotli /usr/local/nginx/ngx_brotli $ cd /usr/local/nginx/ngx_brotli $ git submodule update --init # 更新ngx_brotli以来算法 # 动态编译 $ cd /usr/local/src/nginx-1.20.2 $ ./configure --with-compat --add-dynamic-module=/usr/local/src/ngx_brotli --prefix=/usr/local/nginx $ make modules # 拷贝模块和主程序到Nginx安装目录下新创建的文件夹内：modules $ cp /usr/local/src/nginx-1.20.2/objs/ngx_http_brotli_static_module.so /usr/local/nginx/modules/ngx_http_brotli_static_module.so $ cp /usr/local/src/nginx-1.20.2/objs/ngx_http_brotli_filter_module.so /usr/local/nginx/modules/ngx_http_brotli_filter_module.so $ cp /usr/local/src/nginx-1.20.2/objs/nginx /usr/local/nginx/sbin/ # 在ngixn.conf配置文件最上面动态加载模块 $ cat \u003e/usr/local/nginx/conf/nginx.conf\u003c\u003c-EOF load_module /usr/local/nginx/modules/ngx_http_brotli_filter_module.so; load_module /usr/local/nginx/modules/ngx_http_brotli_static_module.so; EOF # 静态编译 $ cd /usr/local/src/nginx-1.20.2 $ ./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginx/ngx_brotli 安装upstream_check后端服务端口检测模块 访问http://ip/status就看到监控页面 Tengine.taobao ngx_http_upstream_check_module $ git clone https://github.com/yaoweibin/nginx_upstream_check_module.git /usr/local/nginx/nginx_upstream_check_module # 下载检测包 $ cd /usr/local/src/nginx-1.20.2/ $ ./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginx/nginx_upstream_check_module 安装concat合并请求模块 Alibaba Concat请求合并模块 $ git clone https://github.com/alibaba/nginx-http-concat.git /usr/local/nginx/nginx-http-concat $ cd /usr/local/src/nginx-1.20.2/ $ ./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginx/nginx-http-concat 安装ngx_cache_purge缓存清理模块 Ngx_cache_purge 相同位置语法 http { proxy_cache_path /tmp/cache keys_zone=tmpcache:10m; server { location / { proxy_pass http://127.0.0.1:8000; proxy_cache tmpcache; proxy_cache_key $uri$is_args$args; proxy_cache_purge PURGE from 127.0.0.1; } } } 单独位置语法 http { proxy_cache_path /tmp/cache keys_zone=tmpcache:10m; server { location / { proxy_pass http://127.0.0.1:8000; proxy_cache tmpcache; proxy_cache_key $uri$is_args$args; } location ~ /purge(/.*) { allow 127.0.0.1; deny all; proxy_cache_purge tmpcache $1$is_args$args; } } } 安装Nginx-Redis2 Redis2-Nginx-Module 写入请求 location = /foo { default_type text/html; redis2_query auth password; set $value 'first'; # 设置一个变量 redis2_query set one $value; # 变量写入值 redis2_pass 127.0.0.1:6379; } get获取值 location = /get { default_type text/html; redis2_pass 127.0.0.1:6379; redis2_query auth password; set_unescape_uri $key $arg_key; # 第三方转义模块：ngx_set_misc 进行url编码转义 redis2_query get $key; # 获取键值 } 安装Nginx会话保持模块Sticky 名称地址 描述 官网Sticky文档 Github代码托管Sticky文档 Google开发Sticky模块托管在Bitbuckey $ git clone git clone https://huanggua1234@bitbucket.org/nginx-goodies/nginx-sticky-module-ng.git $ ./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginx/nginx_goodies-nginx-sticky-module-ng-c78b7dd79d0d $ make $ make upgrade # 检测甄别第三方模块，检查好后拷贝替换make后的可执行文件 openssl编译报错修改原文件，在第12行添加一下两行内容 $ cat \u003engx_http_sticky_misc.c\u003c\u003c-EOF #include \u003copenssl/sha.h\u003e #include \u003copenssl/md5.h\u003e EOF 使用Sticky name=route下发cookie名称 expires=6h;定义过期时间 $ cat \u003eupstream.conf\u003c\u003c-EOF sticky; server 192.168.1.1:8080; server 192.168.1.2:8080; EOF Nginx配置Json日志格式 变量名 描述 举例 '\"@timestamp\":\"$time_iso8601\",' ISO 8601标准格式的当地时间 '\"uri\":\"$uri\",' '\"args\":\"$args\",' '\"host\":\"$host\",' '\"https\":\"$https\",' '\"scheme\":\"$scheme\",' '\"domain\":\"$domain\",' '\"status\":\"$status\",' HTTP请求状态码 200 403 499 502 503 '\"request\":\"$request\",' 请求的URI和HTTP协议 \"GET /api/img/home/logo-aipay.png HTTP/1.1\" '\"hostname\":\"$hostname\",' '\"http_host\":\"$http_host\",' 访问的域名或者IP www.domain.com192.168.1.1 '\"time_local\":\"$time_local\",' 通用日志格式中的本地时间 18/Jul/2021:13:00:00 +0800 '\"ssl_cipher\":\"$ssl_cipher\",' 交换数据中的算法 RC4-SHA '\"requesturl\":\"$request_uri\",' '\"remote_addr\":\"$remote_addr\",' 客户端地址 '\"remote_user\":\"$remote_user\",' 客户端用户名称 '\"server_addr\":\"$server_addr\",' '\"http_cookie\":\"$http_cookie\",' '\"http_gp_xreal\":\"$http_GP_IP\",' '\"ssl_protocol\":\"$ssl_protocol\",' SSL协议版本 TLSv1 '\"request_body\":\"$request_body\",' '\"request_time\":\"$request_time\",' 整个请求的总时间 '\"http_referer\":\"$http_referer\",' 跳转来源 '\"client_realip\":\"$clientRealIp\",' '\"upstream_addr\":\"$upstream_addr\",' upstream代理的后端服务地址 java tomcat php '\"request_length\":\"$request_length\",' '\"upstream_status\":\"$upstream_status\",' upstream状态码 200 403 499 502 503 '\"body_bytes_sent\":\"$body_bytes_sent\",' 发送给客户的文件大小 '\"http_user_agent\":\"$http_user_agent\",' 用户浏览器访问类型 '\"http_wangsu_xreal\":\"$http_cdn_src_IP\",' '\"http_ali_xreal\":\"$http_Ali_CDN_Real_IP\",' '\"http_cf_xreal\":\"$http_CF_Connecting_IP\",' '\"http_x_forwarded_for\":\"$http_x_forwarded_for\",' — '\"upstream_response_time\":\"$upstream_response_time\",' 请求过程中，upstream响应时间 — '\"proxy_add_x_forwarded_for\":\"$proxy_add_x_forwarded_for\",' — — log_format json escape=json '{\"@timestamp\":\"$time_iso8601\",' '\"client_realip\":\"$clientRealIp\",' '\"remote_addr\":\"$remote_addr\",' '\"status\":\"$status\",' '\"upstream_status\":\"$upstream_status\",' '\"request_time\":\"$request_time\",' '\"upstream_response_time\":\"$upstream_response_time\",' '\"upstream_addr\":\"$upstream_addr\",' '\"host\":\"$host\",' '\"uri\":\"$uri\",' # '\"request_body\":\"$request_body\",' '\"body_bytes_sent\":\"$body_bytes_sent\",' '\"request\":\"$request\",' '\"request_length\":\"$request_length\",' '\"http_referer\":\"$http_referer\",' '\"http_wangsu_xreal\":\"$http_cdn_src_IP\",' '\"http_ali_xreal\":\"$http_Ali_CDN_Real_IP\",' '\"http_cf_xreal\":\"$http_CF_Connecting_IP\",' '\"http_gp_xreal\":\"$http_GP_IP\",' '\"http_x_forwarded_for\":\"$proxy_add_x_forwarded_for\",' '\"http_user_agent\":\"$http_user_agent\",' '}'; # 这里注意使用下划线， ",
    "description": "安装Nginx GeoIP2IP定位模块 GeoIP2模块依赖libmaxminddb库 GeoIP Legacy Databases 安装libmaxminddb库 $ wget -c https://github.",
    "tags": [],
    "title": "Install_Nginx_Third_Party_Modules",
    "uri": "/systems/linux/web/install_nginx_third_party_modules/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Web",
    "content": "配置Nginx 名称地址 描述 免费域名申请 Vercel CDN 工信部备案查询 查找便宜服务器 随笔分类 - Nginx fly.io边缘服务器 Porkbun域名购买商 Domcomp域名价格对比网站 TLD List域名价格对比网站 Oneinstack 服务安装脚本 ab压力测试工具，Charles抓包工具 $ yum -y install httpd-tools $ ab -n 50 -c 20 http://127.0.0.1/index.html # -n：总共发起的请求数，这里设置为50、 # -c：同时并发的请求，这里设置为20个、 # -k：是否开启长连接 ab探测到性能指标 Concurrency Level：设定的并发数 Time taken for tests：压测总共花费的时间 Complete requests：总请求数 Failed requests：失败的个数 Requests per second：每秒请求数TPS Time per request：从客户端来看，一个请求需要用到的时间 Time per request`：从服务端来看，处理一个请求要花费的时间 Transfer rate：传输的速率 Nginx基于Lua做Waf规则过滤 ngx_lua_waf man logrotate查看logrodate使用详情 # 新增nginx log 每日切割 $ grep \"nginx\" /etc/logrotate.d/nginx \u0026\u003e /dev/null $ vim /etc/logrotate.d/nginx /opt/apps/nginx/logs/*.log{ copytruncate # 用于还在打开中的日志文件，把当前日志备份并截断 daily # 安日期轮转日志：daily(天)、weekly(月)、monthly(月)、yearly(年)。 dateext # 文件后缀是日期格式,也就是切割后文件是:xxx.log-20150828.gz rotate 7 # 指定日志文件删除之前转储的次数，0指没有备份，7指保留7个备份 missingok # 如果日志不存在则忽略该警告信息 compress # 通过gzip压缩转储以后的日志（gzip -d xxx.gz解压） notifempty # 如果是空文件的话，不转储 size 100k\t# 在日志大小大于 logsize（例如 100K，4M）时轮换 su root root } # 手动调试验证：-d $ /usr/sbin/logrotate -d /etc/logrotate.d/nginx # 手动强制执行：-f $ /usr/sbin/logrotate -f /etc/logrotate.d/nginx # 新增刪除7天以前log定時腳本 $ echo \"###nginx超過七天log刪除 1 0 * * * /bin/bash /opt/scripts/DEL_NGINX.sh \u003e\u003e ~/del_tom.log 2\u003e\u00261\" \u003e\u003e /var/spool/cron/admin 系统排查 # URL解码、编码 $ yum -y install gridsite-clients $ tail -n10 nginx.logs | awk -F '[:]' '{print $24}' | xargs urlencode -d decode # 后台加白 $ sed -Ei \"s@((([0-9]{1,3}\\.?){4})+)@\\1|{{ ip }}@\" /usr/local/nginx/conf/vhosts/ white_list.ini # 删除加白 $ sed -Ei \"s@((\\|?){{ ip }}\\|?)@\\2@\" /usr/local/nginx/conf/vhosts/ white_list.ini # 排查系统中内存占用前 5 的进程 $ ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem |head -5 # nginx $ netstat -ntu|awk '{print $5}'|cut -d: -f1|wc -l # 查看文件打开数量 $ netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' # 查看服务器网络负载 $ sed -n '/01\\/Oct\\/2021/,/01\\/Oct\\/2021p' access.log \u003e/tmp/access.log $ sed -n ‘/2010-11-17 09:25:55/,/2010-11-17 09:25:55/p’ $ tail -n100 /opt/lucky/logs/nginx/web_access.log |awk '{print $1}' |sort -rn |uniq -c |sort -rn |head $ awk '$0 \u003e= \"2023/12/01 00:00:00\" \u0026\u0026 $0 \u003c= \"2023/12/01 23:59:59\"' gitlab.log \u003e 2023-12-01_gitlab.txt $ cat /var/log/nginx/gitlab_access.log | awk -F '\"' '{if($3 == \"x.x.x.x\" \u0026\u0026 $6 != \"403\") {print $0}}' | jq # 命令行跨域测试 -i：被允许跨域域名，-H：访问跨域域名 $ curl -i https://baidu.com/text.txt -H \"Origin: http://www.example.com\" 打开浏览器按F12然后访问跨域域名，查看是否显示有：access-control-allow-origin: *跨域参数 Nginx子配置conf配置文件 名称地址 描述 Nginx主配置文件参考资料 Java配置文件 $ cat \u003eht.domain.conf\u003c\u003cEOF # 后台 server { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Headers X-Requested-With; add_header Access-Control-Allow-Methods GET,POST,OPTIONS; listen 80; listen 443 ssl; listen 8443 ssl proxy_protocol; ssl on; server_name ht.domain.app; root /data/web/red; # http强跳443， 或使用 $host 字段 if ( $scheme = http ){ return 301 https://$server_name$request_uri; } ssl_certificate\tcert/ht.domain.app/ht.domain.app.pem; ssl_certificate_key\tcert/ht.domain.app/ht.domain.app.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4:!DH:!DHE; ssl_prefer_server_ciphers on; location / { index index.html index.htm; proxy_set_header Host $host; proxy_pass http://127.0.0.1:8082; proxy_http_version 1.1; # 设置http版本为1.1 proxy_set_header Connection \"\"; # 设置Connection为长连接（默认为no） proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 过滤只允许GET，HEAD和POST方法请求 if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 444; } } location ^~ /images/ { proxy_pass http://127.0.0.1:8082; proxy_redirect default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; add_header Nginx-Cache “$upstream_cache_status”; expires 30d; } location ^~ /js/ { proxy_pass http://127.0.0.1:8082; proxy_redirect default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; add_header Nginx-Cache “$upstream_cache_status”; expires 30d; } location ^~ /css/ { proxy_pass http://127.0.0.1:8082; proxy_redirect default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; add_header Nginx-Cache “$upstream_cache_status”; expires 30d; } location ^~ /websocket { proxy_pass http://XHD/websocket; proxy_http_version 1.1; proxy_connect_timeout 15s; proxy_read_timeout 600s; proxy_send_timeout 60s; # 启用支持websocket连接 proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; } location ~ /\\. { deny all; } ### 过滤只允许GET，HEAD和POST方法请求 if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 444; } ### 阻止User-Agents,如扫描器，机器人以及滥用你服务器的垃圾邮件发送者。 if ($http_user_agent ~* LWP::Simple|BBBike|wget) { return 405; } if ( $http_user_agent ~* \"Windows 5.1\" ) { return 445; } if ($time_iso8601 ~ \"^(\\d{4})-(\\d{2})-(\\d{2})\") { set $year $1; set $month $2; set $day $3; } access_log\tlogs/domain.access_$year-$month-$day.log main; error_log\tlogs/domain.error.log info; } EOF $ cat \u003emy.domain\u003c\u003c-EOF server { add_header Strict-Transport-Security \"max-age=31536000\"; listen 80; listen 443 ssl; server_name my.domain.com domain.com; root /data/web/comprehensive/dist/; ssl_certificate\t/cert/domain/domain.com.pem; ssl_certificate_key\tcert/domain/domain.com.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4:!DH:!DHE; ssl_prefer_server_ciphers on; # http强跳443 #\tif ( $scheme = http ){ # return 301 https://$server_name$request_uri; #\t} # 强跳主域名 if ( $host != 'domain.com' ) { rewrite ^(.*)$ https://domain.com/$1 permanent; }\tlocation / { index index.php index.html index.htm; location ^~ /api { rewrite ^/api/(.*)$ /$1 break; proxy_pass http://swofit/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; } location ~ .*\\.(js|css)?$ { expires 12h; } location ~ /\\. { deny all; } if ($time_iso8601 ~ \"^(\\d{4})-(\\d{2})-(\\d{2})\") { set $year $1; set $month $2; set $day $3; } error_page 404 http://domain.com; access_log /home/logs/nginx/domain.access_$year-$month-$day.log main; error_log /home/logs/nginx/domain.error.log info; } } EOF 配置Nginx根据访问终端跳转Web还是H5 名称地址 描述 Nginx区分手机端和PC段跳转不同目录 nginx配置手机端PC端访问不同的项目 nginx根据PC端还是手机端设置不同的网站根目录 location匹配规则以及优先级\n精确匹配和前缀匹配优先级是最高的，一旦匹配到一个就直接走此location，则不会再往下匹配。 正则匹配就算匹配到一个location，也还是会接着匹配，看时候还有比当前location更完整，更匹配的location存在，后面没有了，才匹配本身\n正则符号 描述 ~ 表示开始正则匹配 ~* 表示正则匹配不区分大小写 = 进行普通字符精确匹配，也就是完全匹配 ^~ 表示普通字符匹配，使用前缀匹配 ~ \\~* 表示执行一个正则匹配（） `/(xxx xxx $ 表示正则结束符号 $ cat \u003edomain.conf\u003c\u003c-EOF server { # add_header Strict-Transport-Security \"max-age=63072000; includeSubdomains; preload\"; # 没有证书直接拒绝访问 add_header Strict-Transport-Security \"max-age=31536000\"; listen 80; listen 80 default_server; # 泛解析配置， 可以不用配置：server_name的域名字段 server_name www.web.com ~^m\\..*\\.8862y\\.com$ .domain.comf; # .domail.com 代表主域名和www，*.domail.com root /data/web/comprehensive/dist/; # 配置证书部分 ssl_certificate certs/domain/domain.com.crt; ssl_certificate_key certs/domain/domain.com.key; ssl_trusted_certificate certs/domain/domain-bundle.crt; # 根级证书公钥，用于验证各个二级client ssl_verify_client on; # 开启 ssl_dhparam certs/domain/dhparam.pem; ssl_session_cache shared:SSL:10m; ssl_session_timeout 30m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS'; ssl_prefer_server_ciphers on; resolver 8.8.8.8 valid=300; resolver_timeout 10s; ssl_stapling on; ssl_stapling_verify on; # 配置http强跳443 #\tif ( $scheme = http ){ # return 301 https://$server_name$request_uri; #\t} # 配置强跳主域名 if ( $host != 'c277yy.com' ) { rewrite ^(.*)$ https://c277yy.com/$1 permanent; } location / { root /var/www/web/pc; index index.php index.html index.htm; location ^~ /api { rewrite ^/api/(.*)$ /$1 break; proxy_pass http://swofit/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 如果是手机移动端访问内容 if ( $http_user_agent ~* \"(MIDP)|(WAP)|(UP.Browser)|(Smartphone)|(Obigo)|(Mobile)|(AU.Browser)|(wxd.Mms)|(WxdB.Browser)|(CLDC)|(UP.Link)|(KM.Browser)|(UCWEB)|(SEMC-Browser)|(Mini)|(Symbian)|(Palm)|(Nokia)|(Panasonic)|(MOT-)|(SonyEricsson)|(NEC-)|(Alcatel)|(Ericsson)|(BENQ)|(BenQ)|(Amoisonic)|(Amoi-)|(Capitel)|(PHILIPS)|(SAMSUNG)|(Lenovo)|(Mitsu)|(Motorola)|(SHARP)|(WAPPER)|(LG-)|(LG/)|(EG900)|(CECT)|(Compal)|(kejian)|(Bird)|(BIRD)|(G900/V1.0)|(Arima)|(CTL)|(TDG)|(Daxian)|(DAXIAN)|(DBTEL)|(Eastcom)|(EASTCOM)|(PANTECH)|(Dopod)|(Haier)|(HAIER)|(KONKA)|(KEJIAN)|(LENOVO)|(Soutec)|(SOUTEC)|(SAGEM)|(SEC-)|(SED-)|(EMOL-)|(INNO55)|(ZTE)|(iPhone)|(ipad)|(Android)|(Windows CE)|(Wget)|(Java)|(curl)|(Opera)|(htc)|(blackberry)\" ) { root /var/www/web/mobile; } index index.html index.htm; try_files $uri $uri/ @router; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; } location ~ .*\\.(js|css)?$ { expires 12h; } location ~ /\\. { deny all; } if ($time_iso8601 ~ \"^(\\d{4})-(\\d{2})-(\\d{2})\") { set $year $1; set $month $2; set $day $3; } error_page 404 http://domian.com; access_log /home/logs/nginx/domain.access_$year-$month-$day.log main; error_log /home/logs/nginx/domain.error.log info; } # 或者使用下面方法、try_files用于按顺序检测文件是否存在，如果存在就返回文件内容，如果不存在，则进行配的对应规则 location / { root /opt/www/cms-web; index index.html index.htm; try_files $uri $uri/ /index.html; } location /m/ { alias /opt/www/cms-web/m/; index index.html index.htm; try_files $uri $uri/ /m/index.html; } } EOF Nginx代理转发Mysql 添加--with-stream模块支持TCP/UDP协议 1.1 Nginx代理转发Mysql $ nginx -V configure arguments: --prefix=/usr/local/nginx --with-stream 1.2 配置Nginx的conf文件中server字段 stream { upstream cloudsocket { hash $remote_addr consistent; server 192.168.182.155:3306 weight=5 max_fails=3 fail_timeout=30s; } server { listen 3306; # 数据库服务器监听端口 proxy_connect_timeout 10s; proxy_timeout 300s; # 设置客户端和代理服务之间的超时时间，如果5分钟内没操作将自动断开。 proxy_pass cloudsocket; } } # 负载均衡UDP转发 stream { upstream dns { ip_hash; # 每个请求按访问IP的hash结果分配、同一个IP固定访问同一个后端服务器 hash $request_uri; # 按照访问URL的hash结果分配请求、每个URL定向到同一个后端服务器 least_conn; # 最少连接数、分配给连接数最少的后端服务器 server 192.168.111.99:10086 down; # 当前server暂时不参与负载均衡 server 192.168.111.100:10086 backup; # 预留备份服务器，只有主参与节点down掉才启用 server 192.168.111.100:10086 weigh=3 max_fails=3 fail_timeout=10 max_conns=128; # weigh：加权轮询、值越大分配到访问几率越高，max_fails：允许请求失败次数，fail_timeout：经过max_fails失败后，服务暂定时间、mac_conns：限制最大连接数 } server { listen 192.168.111.98:10086 udp; proxy_responses 1; proxy_timeout 20s; proxy_bind $server_addr:$remote_port; proxy_pass dns; } } Nginx.conf中使用Lua脚本 set_by_lua修改Nginx变量 loa_by_lua日志 access_by_lua访问控制 rewrite_by_lua修改uri boy_filter_by_lua修改响应体 header_filter_by_lua修改响应头 server { listen 80; server_name lua.erge.com; location /lua { default_type text/html; # 直接使用lua语言方式 content_by_lua 'ngx_say(\"\u003cp\u003eHello World!!!\u003c/p\u003e\")'; # 引用lua脚本方式 content_by_lua_file conf/lua/hello.lua; } } lua脚本 $ cat \u003econf/lua/hello.lua\u003c\u003c-EOF ngx_say(\"\u003cp\u003eHello World!!!\u003c/p\u003e\") EOF 获取Nginx请求头信息 $ cat \u003econf/lua/headers.lua\u003c\u003c-EOF local headers = ngx_req.get_headers() ngx.say(\"Host : \", headers[\"Host\"], \"\u003cbr/\u003e\") ngx.say(\"user-agent : \", headers[\"user-agent\"], \"\u003cbr/\u003e\") ngx.say(\"user-agent : \", headers.user_agent, \"\u003cbr/\u003e\") for key, values in pairs(headers)do if type(values) == 'table' then ngx.say(key, \" : \", table.concat(values, \",\"), \"\u003cbr/\u003e\") else ngx.say(key, \" : \", values, \"\u003cbr/\u003e\") end end EOF 获取Post请求参数 $ cat \u003econf/lua/post.lua\u003c\u003c-EOF ngx.req.read_body() ngx.say(\"Post Args Begin\", \"\u003cbr/\u003e\") local post_args = ngx.req.get_post_args() for key,values in pairs(post_args) do if type(values) == \"table\" then ngx.say(key, \" : \", table.concat(values, \", \"), \"\u003cbr/\u003e\") else ngx.say(key, \" : \", values, \"\u003cbr/\u003e\") end end EOF 获取Nginx版本 $ cat \u003econf/lua/nginx_version.lua\u003c\u003c-EOF ngx.say(\"http_version : \", ngx.req.http_version(), \"\u003cbr/\u003e\") EOF 获取请求方法GET、POST、PUT $ cat \u003econf/lua/method.lua\u003c\u003c-EOF ngx.say(\"get_method : \", ngx.req.get_method(), \"\u003cbr/\u003e\") EOF 原始的请求内容 $ cat \u003econf/lua/original.lua\u003c\u003c-EOF ngx.say(\"raw_hader : \", ngx.req.raw_header(), \"\u003cbr/\u003e\") EOF body内容体 $ cat \u003econf/lua/body.lua\u003c\u003c-EOF ngx.say(\"get_body_date() : \", ngx.req.get_body_data(), \"\u003cbr/\u003e\") EOF Nginx全局内存缓存 $ cat \u003econf/lua/shared.lua\u003c\u003c-EOF local shared_data = ngx.shared.shared_data # 获取缓存 local key = shared_data:get(\"key\") # 缓存里面取值 if not key then key = 1 shared_data:set(\"key\", key) # 调用set 方法 ngx.say(\"lazy set key \", key, \"\u003cbr/\u003e\") # 等于什么 end key = shared_data:incr(\"key\", 1) # 自增加一 ngx.say(\"key=\", key, \"\u003cbr/\u003e\") EOF lua-resty-lrucache缓存 $ cat \u003econf/vhosts/server.conf\u003c\u003c-EOF server { listen 80; server_name lua.erge.com; location /lua { default_type text/html; # 直接使用lua语言方式 content_by_lua 'ngx_say(\"\u003cp\u003eHello World!!!\u003c/p\u003e\")'; # 引用lua脚本方式 content_by_lua_file conf/lua/hello.lua; content_by_lua_block { require(\"my/cache\").go() } } } EOF 配置Nginx禁止IP访问 Nginx禁止IP访问 只允许域名访问 方式一 # 在server段里插入如下正则： $ cat \u003edomain.conf\u003c\u003c-EOF listen 80; server_name www.yuyangblog.net; if ($host != 'www.yuyangblog.net'){ return 403; } EOF 方式二 3.1 添加一个server，新加的server（注意是新增，并不是在原有的server基础上修改） 3.1.1 rewrite重定向\n开始字符 描述 . 匹配除换行符以外的任意字符 ? 重复0次或1次 + 重复1次或多次 * 最少连接数、那个机器连接数少就分发 \\d 匹配数字 ^ 匹配字符串的开始 $ 匹配字符串的结束 {n} 重复n此 {n,} 重复n或更多次 [c] 匹配单个字符c [a-z]，[A-Z] 匹配a-z小写字母的任意一个，[^a-z]表示取反，匹配A-z大写字母中任意一个，[^A-Z]表示取反 [0-9] 匹配0-9数字的任意一个，[^0-9]表示取反 结尾定义字符 描述 last 匹配完成后，继续向下匹配新的location URL规则 break 匹配完成即停止向下匹配 redirect 返回302临时重定向、地址栏会显示跳转后地址 permanent 返回301永久重定向、地址栏会显示跳转后地址 $ cat \u003edomain.conf\u003c\u003c-EOF server { listen 80 dufault; server_name _; return 403; # 直接返回一个403 rewrite ^(.*) http://domain.com permanent; # 或者跳转到其他域名 } # 禁止IP访问 server { listen 80 default; server_name _; server_name xcn.cn; return 500; } EOF 配置Nginx用于下载查看日志 $ cat \u003edownload.conf\u003c\u003c-EOF server{ add_header Strict-Transport-Security \"max-age=31536000\"; listen 80; listen 443 ssl; server_name my.domain.com; root /data/web/app_download/; ssl_certificate\tcert/my.domain.com/my.domain.com.pem; ssl_certificate_key\tcert/my.domain.com/my.domain.com.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4:!DH:!DHE; ssl_prefer_server_ciphers on; autoindex on; autoindex_exact_size off; autoindex_localtime on; location ~ { } } EOF 配置Nginx代理Gitlab server{ listen 80; listen 443 ssl; listen 8081 ssl default_server; # 此域名是提供给最终用户的访问地址 server_name gitlab.com; # 解决vue刷新404问题 try_files $uri $uri/ /index.html; # 主页面不允许缓存（避免项目升级 空白页的问题） location /index.html { add_header Expires -1; add_header Cache-Control no-cache; } location / { # 这个非常重要，如果git库里有大文件，设置太小，文件push会失败，根据情况调整 client_max_body_size 50m; proxy_redirect off; # 以下确保 gitlab中项目的 url 是域名而不是 http://git，不可缺少 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 升级协议头 websocket proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; # 升级协议头为https proxy_set_header Upgrade-Insecure-Requests 1; proxy_set_header X-Forwarded-Proto https; add_header Content-Security-Policy upgrade-insecure-requests; # nginx 反向代理到 gitlab 容器暴露的端口 proxy_pass http://127.0.0.1:8080; index index.html index.htm; } error_page 404 http://gitlab.com; access_log /usr/local/nginx/logs/gitlab.access.log main; error_log /usr/local/nginx/logs/gitlab.error.log info; } nginx集群，反向代理 集群介绍 1.1 集群就是一组相互独立的计算机，利用高速相同的通信网络组成一个较大的计算机服务系统，每个集群节点都可以各自运行服务，并且能彼此通信，协同向客户提供服务。统一管理的模式。用户请求集群系统时，集群系统给用户的感受是一个单独的服务器，实际上用户请求的是一组集群服务器 1.2 打开谷歌、百度的页面，看到起来是好简单、也许你觉得几分钟可以制作出类似的网页，而实际上，这个页面背后是由成千上万台服务器协同工作的结果。那么多台服务器维护和管理，以及相互协调工作就是读者未来的工作职责 1.3 一般是指在集群中任意一个节点失效的情况下，该节点上的所有任务会自动转移到其他正常的节点上。此过程并不影响整个集群的运行 1.4 当集群中的一个节点系统发生故障时，运行着的集群服务会迅速做出反应，将该系统的服务分配到集群中其他正在工作的系统上运行。考虑到计算机硬件和软件的容错性，高可用性集群的主要目的是使集群的整体服务尽可能可用。如果高可用性集群中的主节点发生了故障，那么这段时间内将由备节点代替它。备节点通常是主节点的镜像。当它代替主节点时，它可以完全接管主节点（包括IP地址及其他资源）提供服务，因此，使集群系统环境对于用户来说是一致的，即不会影响用户的访问。高可用性集群使服务器系统的运行速度和响应速度会尽可能的快。它们经常利用在多台机器上运行的冗余节点和服务来相互跟踪。如果某个节点失败，它的替补者将在几秒钟或更短时间内接管它的职责。因此，对于用户而言，集群里的任意一台机器宕机，业务都不会受影响 1.5 高性能计算集群也称并行计算。通常，高性能计算集群涉及为集群开发的并行应用程序，以解决复杂的科学问题（天气预报、石油勘探、核反应模拟等）。高性能计算集群对外就好像一个超级计算机，这种超级计算机内部由数十至上万个独立服务器组成，并且在公共消息传递层上进行通信以运行并行应用程序。在老男孩的工作中实际是把任务切成蛋糕，然后下发到集群节点计算，计算后返回结果，然后继续领新任务计算，如此往复 集群的优势特点 2.1 高性能 2.2 廉价性 2.3 可伸缩性 2.4 高可用性 2.5 透明性 2.6 可管理性 2.7 可编程性 集群分类 3.1 负载均衡集群(Load balancing clusters)简称LBC或者LB 3.2 高可用性集群(High-availavlability (HA) clusters)简称HAC 3.3 高性能计算集群(Hight-perfomance (HPC) clusters)简称HPC 3.4 网格计算(Grid computing) 负载均衡集群 4.1 负载均衡集群为了强企业提供更为实用、性价比更高的系统架构解决方案。负载均衡集群可以将很多客户集中访问负载压力尽可能地平均分摊在计算机集群中处理。客户访问请求负载包括应用程序处理负载和网络流量负载。这样使同一组应用程序为大量用户提供服务的模式，每个节点都可以承担一定的访问求负载压力并且可以实现访问请求在各节点之间动态分配，以实现负载均衡 4.2 负载均衡（LoadBalance）集群提供了一种廉价、有效、透明的方法，来扩展网络设备和服务器的负载、带宽和吞吐量，同时加强了网络数据处理能力，提高了网络的灵活性和可用性 4.3 把单台计算机无法承受的大规模并发访问或数据流量分担到多台节点设备上，分别进行处理，减少用户等待响应的时间，提升用户体验 4.4 单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高 4.5 7×24小时的服务保证，任意一个或多个有限后面节点设备宕机，不能影响业务 4.6 在负载均衡集群中，同组集群的所有计算机节点都应该提供相同的服务。集群负载均衡器会截获所有对该服务的入站请求。然后将这些请求尽可能地平均地分配在所有集群节点上 负载均衡集群的作用 5.1 分担用户访问请求及数据流量（负载均衡） - 保持业务连续性，即7×24小时服务（高可用性） 5.2 于Web业务及数据库从库等服务器的业务 5.3 负载均衡集群典型的开源软件包括LVS、Nginx、Haproxy等 5.4 高可用性集群的作用 5.4.1 当一台机器宕机时，另外一台机器接管宕机的机器的IP资源和服务资源，提供服务 5.4.2 常用于不易实现负载均衡的应用，比如负载均衡器，主数据库、主存储对之间 5.4.3 高可用性集群常用的开源软件包括Keepalived、Heartbeat等 5.5 运维中常见的集群软硬件产品 5.5.1 互联网企业常用的开源集群软件有：Nginx、LVS、Haproxy、Keepalived、Heartbeat。互联网企业常用的商业集群硬件有：F5、Netscaler、Rad-ware、A10等，工作模式相当于Haproxy的工作模式。淘宝、赶集网、新浪等公司曾使用过Netscaler负载均衡产品。集群硬件Netscaler的产品 5.6 集群软硬件产品如何选型 5.6.1 当企业业务重要，技术力量又薄弱，并且希望出钱购买产品及获取更好的服务时，可以选择硬件负载均衡产品，如F5、Netscaler、Radware等，此类公司多为传统的大型非互联网企业，如银行、证券、金融业及宝马、奔驰公司等 5.6.2 对于门户网站来说，大多会并用软件及硬件产品来分担单一产品的风险，如淘宝、腾讯、新浪等。融资了的企业会购买硬件产品，如赶集等网站 5.6.3 中小型互联网企业，由于起步阶段无利润可赚或者利润很低，会希望通过使用开源免费的方案来解决问题，因此会雇佣专门的运维人员进行维护。例如：51CTO等 相比较而言，商业的负载均衡产品成本高，性能好，更稳定，缺点是不能二次开发，开源的负载均衡软件对运维人员的能力要求较高，如果运维及开发能力强，那么开源的负载均衡软件是不错的选择，目前的互联网行业更倾向于使用开源的负载均衡软件\n5.7 如何选择开源集群软件产品 5.7.1 中小企业互联网公司网站在并发访问和总访问量不是很大的情况下，建议首选Nginx负载均衡，理由是Nginx负载均衡配置简单、使用方便、安全稳定、社区活跃，使用的人逐渐增多，成为流行趋势，另外一个实现负载均衡的类似产品为Haproxy（支持L4和L7负载，同样优秀，但社区不如Nginx活跃） 5.7.2 如果要考虑Nginx负载均衡的高可用功能，建议首选Keepalived软件，理由是安装和配置简单，使用方便，安全稳定，与Keepalived服务类似的高可用软件还有Heartbeat（使用比较复杂，不建议初学者使用） 5.7.3 如果是大型企业互联网公司，负载均衡产品可以使用LVS+Keepalived在前端做四层转发（一般是主备或主主，如果需要扩展可以使用DNS或前端使用OSPF），后端使用Nginx或者Haproxy做7层转发（可以扩展到百台），再后面是应用服务器，如果是数据库与存储的负载均衡和高可用，建议选择LVS+Heart-beat，LVS支持TCP转发且DR模式效率很高，Heartbeat可以配合drbd，不但可以进行VIP的切换，还可以支持块设备级别的数据同步（drbd），以及资源服务的管理 反向代理与负载均衡概念 6.1 严格地说，Nginx仅仅是作为Nginx Proxy反向代理使用的，因为这个反向代理功能表现的效果是负载均衡集群的效果，所以本文称之为Nginx负载均衡。那么，反向代理和负载均衡有什么区别呢？ 6.2 普通负载均衡软件，例如大名鼎鼎的LVS，其实现的功能只是对请求数据包的转发（也可能会改写数据包）、传递，其中DR模式明显的特征是从负载均衡下面的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户，而反向代理就不一样了，反向代理接收访问用户的请求后，会代理用户重新发起请求代理下的节点服务器，最后把数据返回给客户端用户，在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器了，而非真实的网站访问用户 6.3 一句话，LVS等的负载均衡是转发用户请求的数据包，而Nginx反向代理是接收用户的请求然后重新发起请求去请求其后面的节点。2. 实现Nginx负载均衡的组件说明实现Nginx负载均衡的组件主要有两个 6.4 实现负载均衡组件说明 Nginx http功能模块 模块说明 ngx_http_proxy_module proxy代理模块，用户把请求抛给节点服务器或upstream服务池 ngx_http_upstream_module 负载均衡模块，可以实现网站负载均衡功能及节点健康检查 6.5 nginx upstream模块 6.5.1 Nginx的负载均衡基于ngx_http_upstream_module所支持的代理方式包括proxy_pass、fastcgi_pass、memcached_pass等 6.5.2 rr：轮询（性能相近，业务一样） 6.5.3 wrr：权重轮询 6.5.4 ip_hash;：每个请求按访问IP的hash结果分配、同一个IP固定访问同一个后端服务器 6.5.5 hash $request_uri;：每个请求按访问IP的hash结果分配、同一个IP固定访问同一个后端服务器，$cookie_jsessionid;按照后端分配JSESSIONID进行负载 6.5.6 least_conn;：最少连接数、分配给连接数最少的后端服务器 6.5.7 server IP:port xxx;：字段 6.5.7.1 down;： 当前server暂时不参与负载均衡 6.5.7.2 backup;：预留备份服务器，只有主参与节点down掉才启用 6.5.7.3 weigh=3;：加权轮询、值越大分配到访问几率越高 6.5.7.4 check=3：开启对该服务器健康检查 6.5.7.5 inter：设置连续两次健康检查的间隔时间，单位毫秒，默认值2000 6.5.7.6 rise：指定多少次连续成功健康检查后，即可认定服务器可用状态 6.5.7.7 max_fails=3：指定多少次不成功后，即认为宕机状态，默认值1 6.5.7.8 fail_timeout=10 ：经过max_fails失败后，在fail_timeout时间内不再去请求它，fail_timeout默认是10s 6.5.7.9 maxconn：： # 负载均衡UDP转发 stream { upstream dns { # 每个请求按访问IP的hash结果分配、同一个IP固定访问同一个后端服务器 ip_hash; # 最少连接数、分配给连接数最少的后端服务器 least_conn; # 当前server暂时不参与负载均衡 server 192.168.111.99:10086 down; # 预留备份服务器，只有主参与节点down掉才启用 server 192.168.111.100:10086 weigh=3 backup; # weigh：加权轮询、值越大分配到访问几率越高，max_fails：允许请求失败次数，fail_timeout：经过max_fails失败后，服务暂定时间、mac_conns：限制最大连接数 server 192.168.111.100:10086 weigh=3 max_fails=3 fail_timeout=10 max_conns=128; # 向上游服务器保留的连接数 keepalive 300; # 连接保留时间、默认60秒， keepalive_timeout 60; # 一个Tcp复用中可以并发接收的请求数 keepalive_requests 1000; } }check interval=3000 rise=2 fall=5 timeout=1000 type=http; # check interval=3000 rise=2 fall=5 timeout=1000 type=http; 上面配置的意思是，对static、upload、这个负载均衡条目中的所有节点，每隔3秒检测一次，请求2次正常则标记realserver状态为up，如果检测5次都失败，则标记realserver的状态为down，超时时间为1秒，检查的协议是http。 过滤登录和状态码 脚本使用nslookup命令获取用户IP地址的远程主机名，并使用curl命令获取远程主机的状态码。然后，它将检查远程主机的域名和状态码是否在允许的列表中。如果是，则显示Access granted否则显示Access denied #!/bin/bash # 定义允许登录的域名和状态码 ALLOWED_DOMAINS=(\"example.com\" \"example.org\") ALLOWED_STATUS_CODES=(\"200\" \"301\" \"302\") # 获取用户IP地址 USER_IP=$(echo $SSH_CLIENT | awk '{print $1}') # 获取用户登录时远程主机的域名和状态码 REMOTE_DOMAIN=$(nslookup $USER_IP | awk -F'=' '/name/{print $2}' | sed 's/\\.$//') REMOTE_STATUS_CODE=$(curl -s -o /dev/null -I -w \"%{http_code}\" http://$REMOTE_DOMAIN) # 检查远程主机的域名和状态码是否被允许 if [[ \" ${ALLOWED_DOMAINS[*]} \" =~ \" ${REMOTE_DOMAIN} \" ]] \u0026\u0026 [[ \" ${ALLOWED_STATUS_CODES[*]} \" =~ \" ${REMOTE_STATUS_CODE} \" ]]; then echo \"Access granted to $REMOTE_DOMAIN with status code $REMOTE_STATUS_CODE\" exit 0 else echo \"Access denied to $REMOTE_DOMAIN with status code $REMOTE_STATUS_CODE\" exit 1 fi 示例脚本，它会过滤网站后台登录的IP地址和状态码，将不在预定义文件列表中的IP地址发送到Telegram通知组。 脚本会检查远程主机的状态码是否为200。如果是，则它将从文件中检查远程主机的IP地址是否在允许的列表中。如果是，则显示Access granted，否则将发送Telegram告警，并显示Access denied。请注意，您需要将YOUR_TELEGRAM_API_TOKEN和YOUR_TELEGRAM_CHAT_ID替换为您自己的Telegram API Token和Chat ID。 #!/bin/bash # 预定义允许登录的IP地址列表文件 ALLOWED_IP_LIST=\"allowed_ips.txt\" # 定义Telegram通知组的API Token和Chat ID TELEGRAM_API_TOKEN=\"YOUR_TELEGRAM_API_TOKEN\" TELEGRAM_CHAT_ID=\"YOUR_TELEGRAM_CHAT_ID\" # 获取用户IP地址 USER_IP=$(echo $SSH_CLIENT | awk '{print $1}') # 获取用户登录时远程主机的状态码 REMOTE_STATUS_CODE=$(curl -s -o /dev/null -I -w \"%{http_code}\" http://example.com/login) # 检查远程主机的状态码是否为200 if [[ \"$REMOTE_STATUS_CODE\" -eq \"200\" ]]; then # 检查远程主机的IP地址是否在允许的列表中 if grep -Fxq \"$USER_IP\" \"$ALLOWED_IP_LIST\"; then echo \"Access granted to $USER_IP with status code $REMOTE_STATUS_CODE\" exit 0 else # 发送Telegram告警 MESSAGE=\"Unauthorized login attempt from IP $USER_IP with status code $REMOTE_STATUS_CODE\" URL=\"https://api.telegram.org/bot$TELEGRAM_API_TOKEN/sendMessage\" curl -s -X POST $URL -d chat_id=$TELEGRAM_CHAT_ID -d text=\"$MESSAGE\" echo \"Access denied to $USER_IP with status code $REMOTE_STATUS_CODE\" exit 1 fi else echo \"Access denied to $USER_IP with status code $REMOTE_STATUS_CODE\" exit 1 fi 示例脚本，用于过滤网站后台登录URL的IP地址和状态码，将不在预定义文件列表中的IP地址发送到Telegram通知组。 脚本会发送一个HTTP请求来检查网站后台登录URL的IP地址和状态码。如果状态码为200，则它将从HTTP响应中提取远程主机的IP地址，并从文件中检查它是否在允许的列表中。如果是，则显示Access granted，否则将发送Telegram告警，并显示Access denied。请注意，您需要将YOUR_TELEGRAM_API_TOKEN和YOUR_TELEGRAM_CHAT_ID替换为您自己的Telegram API Token和Chat ID，并根据需要修改LOGIN_URL和REQUEST_HEADERS。 #!/bin/bash # 预定义允许登录的IP地址列表文件 ALLOWED_IP_LIST=\"allowed_ips.txt\" # 定义需要检查的网站后台登录URL和请求头信息 LOGIN_URL=\"http://example.com/admin/login\" REQUEST_HEADERS=\"-H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0' -H 'Accept-Language: en-US,en;q=0.5'\" # 定义Telegram通知组的API Token和Chat ID TELEGRAM_API_TOKEN=\"YOUR_TELEGRAM_API_TOKEN\" TELEGRAM_CHAT_ID=\"YOUR_TELEGRAM_CHAT_ID\" # 获取用户IP地址 USER_IP=$(curl -s -o /dev/null -w \"%{http_code}:%{remote_ip}\" $LOGIN_URL -H \"$REQUEST_HEADERS\") # 获取远程主机的状态码 REMOTE_STATUS_CODE=$(echo \"$USER_IP\" | cut -d':' -f1) # 检查远程主机的状态码是否为200 if [[ \"$REMOTE_STATUS_CODE\" -eq \"200\" ]]; then # 获取远程主机的IP地址 REMOTE_IP=$(echo \"$USER_IP\" | cut -d':' -f2) # 检查远程主机的IP地址是否在允许的列表中 if grep -Fxq \"$REMOTE_IP\" \"$ALLOWED_IP_LIST\"; then echo \"Access granted to $REMOTE_IP with status code $REMOTE_STATUS_CODE\" exit 0 else # 发送Telegram告警 MESSAGE=\"Unauthorized login attempt from IP $REMOTE_IP with status code $REMOTE_STATUS_CODE\" URL=\"https://api.telegram.org/bot$TELEGRAM_API_TOKEN/sendMessage\" curl -s -X POST $URL -d chat_id=$TELEGRAM_CHAT_ID -d text=\"$MESSAGE\" echo \"Access denied to $REMOTE_IP with status code $REMOTE_STATUS_CODE\" exit 1 fi else echo \"Access denied with status code $REMOTE_STATUS_CODE\" exit 1 fi 稍微修改的脚本，用于过滤网站后台登录日志文件中的URL、IP地址和状态码，将不在预定义文件列表中的IP地址发送到Telegram通知组： 该脚本会从日志文件中过滤出登录URL、IP地址和状态码信息，并遍历这些信息。对于每个IP地址和状态码，它将检查状态码是否为200，然后检查IP地址是否在允许的列表中。如果是，则显示Access granted，否则将发送Telegram告警，并显示Access denied。请注意，您需要将YOUR_TELEGRAM_API_TOKEN和YOUR_TELEGRAM_CHAT_ID替换为您自己的Telegram API Token和Chat ID，并根据需要修改ALLOWED_IP_LIST和LOG_FILE。 #!/bin/bash # 预定义允许登录的IP地址列表文件 ALLOWED_IP_LIST=\"allowed_ips.txt\" # 定义需要检查的网站后台登录日志文件 LOG_FILE=\"/var/log/nginx/access.log\" # 定义Telegram通知组的API Token和Chat ID TELEGRAM_API_TOKEN=\"YOUR_TELEGRAM_API_TOKEN\" TELEGRAM_CHAT_ID=\"YOUR_TELEGRAM_CHAT_ID\" # 使用grep命令从日志文件中过滤出登录URL、IP地址和状态码 LOG_FILTER=$(grep -E '\\/admin\\/login.*HTTP\\/1\\.[01]\" 200' $LOG_FILE | awk '{print $1, $7, $9}') # 遍历过滤出的日志信息 while read -r log_info; do # 分别提取IP地址和状态码 REMOTE_IP=$(echo \"$log_info\" | awk '{print $1}') REMOTE_STATUS_CODE=$(echo \"$log_info\" | awk '{print $2}') # 检查状态码是否为200 if [[ \"$REMOTE_STATUS_CODE\" -eq \"200\" ]]; then # 检查IP地址是否在允许的列表中 if grep -Fxq \"$REMOTE_IP\" \"$ALLOWED_IP_LIST\"; then echo \"Access granted to $REMOTE_IP with status code $REMOTE_STATUS_CODE\" else # 发送Telegram告警 MESSAGE=\"Unauthorized login attempt from IP $REMOTE_IP with status code $REMOTE_STATUS_CODE\" URL=\"https://api.telegram.org/bot$TELEGRAM_API_TOKEN/sendMessage\" curl -s -X POST $URL -d chat_id=$TELEGRAM_CHAT_ID -d text=\"$MESSAGE\" echo \"Access denied to $REMOTE_IP with status code $REMOTE_STATUS_CODE\" fi fi done \u003c\u003c\u003c \"$LOG_FILTER\" ",
    "description": "配置Nginx 名称地址 描述 免费域名申请 Vercel CDN 工信部备案查询 查找便宜服务器 随笔分类 - Nginx fly.",
    "tags": [],
    "title": "Configure_Nginx",
    "uri": "/systems/linux/web/configure_nginx/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Storage",
    "content": "NFS部署 安装服务 $ sudo apt-get install nfs-kernel-server # Debian系统 $ yum install -y nfs-utils rpcbind # CentOS系统 $ yum -y install nfs-utils # 目录挂载节点只安装不启动 修改使用的默认端口 # $ rpcinfo -p localhost # Centos $ cat \u003e\u003e/etc/sysconfig/nfs\u003c-EOF STATD_PORT=4004 MOUNTD_PORT=2049 RQUOTAD_PORT=4001 LOCKD_TCPPORT=32768 LOCKD_UDPPORT=32768 EOF $ systemctl restart nfs # Debian $ cat \u003e/etc/default/nfs-kernel-server\u003c\u003c-EOF RPCMOUNTDOPTS=\"--port 2045\" EOF $ systemctl restart rpcbind.service $ systemctl restart nfs-server.service $ systemctl restart nfs-kernel-server 准备挂载目录，授权 $ mkdir -pv /opt/data/nfs # 准备共享目录 $ chown -R user_naem:user_name /opt/data \u0026\u0026 chmod 755 -R /opt/data/ 挂载目录实现共享 访问权限设置 ro：设置输出目录：只读 rw：设置输出目录：读写 用户映射选项 all_squash：将远程访问的所有普通用户及所属组都映射为匿名用户或用户组nfsnobody no_all_squash：与all_squash取反：默认设置 root_squash：root用户对共享目录只有普通用户权限，限制root：默认设置 no_root_squash：有此选项，root用户对共享目录拥有至高权限，就像对本机目录一样操作 anonuid=xxx：将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户UID=xxx anongid=xxx：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户GID=xxx 其他选项 secure：NFS通过1024以下的安全TCP/IP端口发送：默认设置 insecure：NFS通过1024以上端口发送 sync：同步模式，内存中的数据时时写入磁盘 async：不同步，把内存中的数据定期写入磁盘 wdelay：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率：默认设置 no_wdelay：若有写操作则立即执行，应与sync配合使用 subtree：若输出目录是一个子目录，则NFS服务器将检查其父目录的权限：默认设置 no_subtree：即使输出目录是一个子目录，NFS服务器也不检查其父目录的权限，这样可以提高效率 授予多个IP网段访问NFS需要使用空格分隔192.168.80.0/24 172.16.8.0/24 $ cat \u003e\u003e/etc/exports\u003c\u003c-EOF /opt/logs 192.168.80.0/32(rw,sync,no_root_squash,no_all_squash,no_subtree_check) /opt/data/redis 192.168.80.0/24 172.16.8.0/24(rw,sync,no_root_squash,no_all_squash,no_subtree_check) EOF 加载配置、启动服务 $ exportfs -r # 加载配置 $ systemctl start rpcbind \u0026\u0026 systemctl enable rpcbind $ systemctl start nfs \u0026\u0026 systemctl enable nfs # 修改/etc/exports 配置文件后要重启nfs # Debian 系统 $ sudo systemctl restart nfs-server 检测是否挂载成功 $ sudo showmount -e 192.168.18.100 # 测试目录是否挂载成功 高可用备份方式，在所有节点执行如下挂载命令 $ mount -t nfs 192.168.18.100:/opt/data/redis /opt/data/redis $ mount -t nfs 192.168.18.100:/opt/data/jenkins /opt/data/jenkins 网络远程挂载，然后再执行mount挂载命令 $ cat \u003e\u003e/etc/fstab\u003c\u003c-EOF IP地址:/opt/nginx/logs /opt/nginx/logs nfs defaults 0 0 EOF $ mount -t nfs 192.168.18.100:/opt/data/redis /opt/data/redis $ mount -t nfs 192.168.18.100:/opt/data/jenkins /opt/data/jenkins 查看挂载情况 # 以树结构方式列出：apt install util-linux $ findmnt # -t：指定文件类型，例如：findmnt -t nfs4 $ lsblk -f $ mount 卸载挂载的目录 $ umount -l /opt/data/jenkins # -l：强制，加本地目录 ",
    "description": "NFS部署 安装服务 $ sudo apt-get install nfs-kernel-server # Debian系统 $ yum install -y nfs-utils rpcbind # CentOS系统 $ yum -y install nfs-utils # 目录挂载节点只安装不启动 修改使用的默认端口 # $ rpcinfo -p localhost # Centos $ cat \u003e\u003e/etc/sysconfig/nfs\u003c-EOF STATD_PORT=4004 MOUNTD_PORT=2049 RQUOTAD_PORT=4001 LOCKD_TCPPORT=32768 LOCKD_UDPPORT=32768 EOF $ systemctl restart nfs # Debian $ cat \u003e/etc/default/nfs-kernel-server\u003c\u003c-EOF RPCMOUNTDOPTS=\"--port 2045\" EOF $ systemctl restart rpcbind.",
    "tags": [],
    "title": "Install_NFS",
    "uri": "/systems/linux/storage/install_nfs/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Storage",
    "content": "MooseFS MooseFS\nMooseFS[MFS]是一个具有容错性，高可用，高性能，扩展性强的网络分布式文件系统。他将数据分布在多个存储物理服务器上，这些存储服务器对用户而言就是一块虚拟磁盘，它符合POSIX并且像任何其他类UNIX文件系统一样支持",
    "description": "MooseFS MooseFS\nMooseFS[MFS]是一个具有容错性，高可用，高性能，扩展性强的网络分布式文件系统。他将数据分布在多个存储物理服务器上，这些存储服务器对用户而言就是一块虚拟磁盘，它符合POSIX并且像任何其他类UNIX文件系统一样支持",
    "tags": [],
    "title": "Install_MooseFS",
    "uri": "/systems/linux/storage/install_moosefs/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Storage",
    "content": "Minio部署 名称地址 描述 Minio Linux安装Minio ",
    "description": "Minio部署 名称地址 描述 Minio Linux安装Minio ",
    "tags": [],
    "title": "Install_Minio",
    "uri": "/systems/linux/storage/install_minio/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Storage",
    "content": "FastDFS分布式文件系统 参考文档 名称地址 描述 FastDFS海量数据分布式存储方案 Fastdfs分布式文件系统之文件同步机制 FastDFS环境配置及php FastDFS扩展安装 FastDFS访问流程图 下载安装FastDFS以及扩展安装包 下载安装libfastcommon扩展包 $ $ yum -y install gcc gcc-c++ wget $ mkdir -p /opt/fastdfs/{client,data,logs} # -S打印服务器响应、-O将文件写入文件、-P 大P将文件下载指定目录 $ wget -P -S -O /usr/local/src/libfastcommon.tar.gz https://github.com/happyfish100/libfastcommon/archive/refs/tags/V1.0.45.tar.gz $ tar -zxvf /usr/local/src/libfastcommon.tar.gz -C /usr/local/src/ # 安装libfastcommon $ cd /usr/local/src/libfastcommon-1.0.45/ $ ./make.sh $ ./make.sh install 下载安装FastDFS主包 $ wget -P -S -O /usr/local/src/fastdfs.tar.gz https://github.com/happyfish100/fastdfs/archive/refs/tags/V6.07.tar.gz $ tar -zxvf /usr/local/src/fastdfs.tar.gz -C /usr/local/src/ 修改FastDFS配置文件 修改make.sh定义默认工作目录 # 修改默认主目录：TARGET_PREFIX=$DESTDIR/usr 3行左右 $ sed -ri \"s#IR/usr#IR/opt/fastdfs#\" /usr/local/src/fastdfs-6.07/make.sh # 修改默认配置文件目录 ：TARGET_CONF_PATH=$DESTDIR/etc/fdfs 4行左右 $ sed -ri \"s#IR/etc/fdfs#IR/opt/fastdfs#\" /usr/local/src/fastdfs-6.07/make.sh # 编译安装 $ cd /usr/local/src/fastdfs-6.07/ $ ./make.sh $ ./make.sh install $ \\cp /usr/local/src/fastdfs-6.07/conf/* /opt/fastdfs/ 修改tracker.conf文件配置 # 替换存储数据和日志文件的基本路径，23行左右 $ sed -i \"s#/home/yuqing/fastdfs#/opt/fastdfs/data#g\" /opt/fastdfs/tracker.conf 2.1.3 修改storage.conf配置文件 # 工作目录 49行左右 $ sed -i \"s#/home/yuqing/fastdfs#/opt/fastdfs#g\" /opt/fastdfs/storage.conf # 修改配置tracker服务器，虽然是同一台机器上，但是不能写127.0.0.1。这项配置可以出现一次或多次，145行左右 $ sed -ri \"/tracker_server = /c\\\\tracker_server = ${FastDFS服务所在服务器IP}:22122\" /etc/fdfs/storage.conf 修改client.conf配置文件 $ sed -i \"s#/home/yuqing/fastdfs#/opt/fastdfs#g\" /opt/fastdfs/client.conf $ sed -ri \"/tracker_server = /c\\\\tracker_server = ${FastDFS服务所在服务器IP}:22122\" /opt/fastdfs/client.conf http.tracker_server_port=9270 # 根据需要修改端口号 修改mod_fastdfs.conf配置文件 配置mod_fastdfs.conf文件注意一些问题 mod_fastdfs.conf文件中tracker_server的端口应该跟tracker.conf中port一致 mod_fastdfs.conf文件中storage_server_port的端口应该跟storage.conf中port一致 $ cp /usr/local/src/fastdfs-6.07/docker/dockerfile_local/conf/mod_fastdfs.conf /opt/fastdfs/ $ sed -i \"s#/home/dfs#/opt/fastdfs#g\" /opt/fastdfs/mod_fastdfs.conf $ sed -ri \"/tracker_server=/c\\\\tracker_server=${FastDFS服务所在服务器IP}:22122\" /opt/fastdfs/mod_fastdfs.conf 其他配置或文件虽然不用修改，fastdfs-nginx-module模块会用到一些配置 anti-steal.jpg http.conf mime.types 启动tracker和storage $ fdfs_trackerd /opt/fastdfs/tracker.conf start $ fdfs_storaged /opt/fastdfs/storage.conf start # 查看日志 $ tail -n10 /opt/fastdfs/logs/storaged.log mkdir data path: F7 ... mkdir data path: F8 ... mkdir data path: F9 ... mkdir data path: FA ... mkdir data path: FB ... 用fdfs_test测试上传 $ /usr/bin/fdfs_upload_file /etc/fdfs/client.conf ~/512x512bb.jpg group1/M00/00/00/wKjVgWCEOCaABaIQAABPt05CHsw699.jpg 下载安装fastdfs-nginx-module nginx编译添加支持模块 # 下载支持nginx插件 $ wget -P -S -O /usr/local/src/fastdfs-nginx-module.tar.gz https://github.com/happyfish100/fastdfs-nginx-module/archive/refs/tags/V1.22.tar.gz $ tar -zxvf /usr/local/src/fastdfs-nginx-module.tar.gz -C /usr/local/src/ # 添加模块 $ ./configure --add-module=../fastdfs-nginx-module-master/src # 配置文件添加配置启用模块 $ vim /usr/local/nginx/conf/nginx.conf # 80端口中添加 location ~/group([0-9])/M00 { ngx_fastdfs_module; } # 添加如下行，将 /group1/M00 映射到 /ljzsg/fastdfs/file/data location /group1/M00 { alias /ljzsg/fastdfs/file/data; } ",
    "description": "FastDFS分布式文件系统 参考文档 名称地址 描述 FastDFS海量数据分布式存储方案 Fastdfs分布式文件系统之文件同步机制 FastDFS环境配置及php FastDFS扩展安装 FastDFS访问流程图 下载安装FastDFS以及扩展安装包 下载安装libfastcommon扩展包 $ $ yum -y install gcc gcc-c++ wget $ mkdir -p /opt/fastdfs/{client,data,logs} # -S打印服务器响应、-O将文件写入文件、-P 大P将文件下载指定目录 $ wget -P -S -O /usr/local/src/libfastcommon.",
    "tags": [],
    "title": "Install_FastDFS",
    "uri": "/systems/linux/storage/install_fastdfs/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Storage",
    "content": "存储 名称地址 描述 Ceph MinIO Hadoop MooseFS GlusterFS ",
    "description": "存储 名称地址 描述 Ceph MinIO Hadoop MooseFS GlusterFS ",
    "tags": [],
    "title": "Configur_Storage",
    "uri": "/systems/linux/storage/configur_storage/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Service_Management",
    "content": "Nacos部署 Nacos下载地址\n环境准备\nNacos依赖Java环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用:\n64 bit OS，支持Linux/Unix/Mac/Windows，推荐选用Linux/Unix/Mac。 64 bit JDK 1.8+下载 \u0026 配置。 Maven 3.2.x+下载\u0026配置。 下载安装包、解压、配置 $ wget https://github.com/alibaba/nacos/releases/download/2.0.4/nacos-server-2.0.4.tar.gz $ tar -zxvf nacos-server-2.0.4.tar.gz # 创建数据库、导入模板数据 mysql\u003e source nacos/conf/nacos-mysql.sql # 修改配置 $ vim nacos/conf/application.properties db.url.0=jdbc:mysql://127.0.0.1:16303/nacos?characterEncoding=utf8\u0026connectTimeout=1000\u0026socketTimeout=3000\u0026autoReconnect=true\u0026useUnicode=true\u0026useSSL=false\u0026serverTimezone=UTC # 配置连接数据库地址 db.user=nacos # 连接数据库用户 db.password=password # 连接数据库密码 Nacos单节点启动 # 单节点启动(standalone代表着单机模式运行) $ sh startup.sh -m standalone # 服务注册 $ curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName\u0026ip=20.18.7.10\u0026port=8080' # 服务发现 $ curl -X GET 'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName' # 发布配置 $ curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId\u0026group=test\u0026content=HelloWorld\" # 获取配置 $ curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId\u0026group=test\" # 关闭服务器 $ sh shutdown.sh Nacos集群部署 节点之间防火墙开放9849、8848、7848、1001端口， 9849、1001服务端gRPC请求服务端端口，用于服务间同步等 修改nacos集群配置文件 $ vim nacos/conf/cluster.conf 192.168.1.10:8848 192.168.1.11:8848 192.168.1.12:8848 修改配置文件以及配置数据库连接 $ vim nacos/conf/application.properties ### Specify local server's IP: nacos.inetutils.ip-address=192.168.30.144 # 本机服务器IP #*************** Config Module Related Configurations ***************# ### If user MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 db.url.0=jdbc:mysql://127.0.0.1:16303/nacos?characterEncoding=utf8\u0026connectTimeout=1000\u0026socketTimeout=3000\u0026autoReconnect=true\u0026useUnicode=true\u0026useSSL=false\u0026serverTimezone=UTC # 配置连接数据库地址 db.user=nacos # 连接数据库用户 db.password=password # 连接数据库密码 集群启动（使用外置数据库） $ bash startup.sh Kubernetes部署Nacos Kubernetes部署Nacos ",
    "description": "Nacos部署 Nacos下载地址\n环境准备\nNacos依赖Java环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用:\n64 bit OS，支持Linux/Unix/Mac/Windows，推荐选用Linux/Unix/Mac。 64 bit JDK 1.",
    "tags": [],
    "title": "Install_Nacos",
    "uri": "/systems/linux/service_management/install_nacos/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Service_Management",
    "content": "Apache Mesos Apache Mesos\nMesos是一个开源的集群管理框架，它可以将数据中心/集群放在一台电脑里运行，对外提供简单的API，同时隐藏内部的很多复杂架构",
    "description": "Apache Mesos Apache Mesos\nMesos是一个开源的集群管理框架，它可以将数据中心/集群放在一台电脑里运行，对外提供简单的API，同时隐藏内部的很多复杂架构",
    "tags": [],
    "title": "Install_Mesos",
    "uri": "/systems/linux/service_management/install_mesos/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Service_Management",
    "content": "Apache Hive Apache Hive\nApache Hive是可实现大规模分析的分布式容错数据仓库系统。该数据仓库集中存储信息，您可以轻松对此类信息进行分析，从而做出明智的数据驱动决策。Hive让用户可以利用SQL读取、写入和管理PB级数据。\nHive建立在Apache Hadoop基础之上，后者是一种开源框架，可被用于高效存储与处理大型数据集。因此，Hive与Hadoop紧密集成，其设计可快速对PB级数据进行操作。Hive的与众不同之处在于它可以利用Apache Tez或MapReduce通过类似于SQL的界面查询大型数据集。",
    "description": "Apache Hive Apache Hive\nApache Hive是可实现大规模分析的分布式容错数据仓库系统。该数据仓库集中存储信息，您可以轻松对此类信息进行分析，从而做出明智的数据驱动决策。Hive让用户可以利用SQL读取、写入和管理PB级数据。\nHive建立在Apache Hadoop基础之上，后者是一种开源框架，可被用于高效存储与处理大型数据集。因此，Hive与Hadoop紧密集成，其设计可快速对PB级数据进行操作。Hive的与众不同之处在于它可以利用Apache Tez或MapReduce通过类似于SQL的界面查询大型数据集。",
    "tags": [],
    "title": "Install_Hive",
    "uri": "/systems/linux/service_management/install_hive/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Service_Management",
    "content": "Consul Consul\n5分钟看懂微服务Consul特性及搭建\nConsul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置",
    "description": "Consul Consul\n5分钟看懂微服务Consul特性及搭建\nConsul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置",
    "tags": [],
    "title": "Install_Consul",
    "uri": "/systems/linux/service_management/install_consul/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Script",
    "content": "Shell脚本编写 执行方式 sh -n bash.sh调试模式运行：-n sh -vx bash.sh打印调试模式运行日志：-vx bash执行环境 登录bash执行 系统级 /etc/profile /etc/bashrc 用户级 ~/.bash_profile ~/.bashrc 退出bash执行 ~/.bash_history ~/.bash_logout 获取文件名 $ basename # 获取最后文件名: basename /etc/passwd $ dirname # 获取文件名前缀 脚本补全、小游戏 $ yum install bash-completion # 脚本补全服务 $ sudo apt-get install jq # 安装json格式查看服务 $ yum -y install sl # 小火车 $ vim scripts.sh :set ff=unix # 转换换行符 :set paste # 解决文本粘贴后错乱 当前执行shell脚本以及嵌入其他语言 $ source shell.sh $ echo \"#!/usr/bin/bash echo \"hello bash\" . shell.sh # 在其他脚本中引用此脚本 # 嵌入python脚本 /usr/bin/python \u003c\u003c-EOF #\"-\"支持Tab键, print \"hello python\" EOF \"\u003ebash.sh crontab计划任务 crontab计划任务 $ man crontab @reboot ：重启后运行一次。 @yearly ：每年运行一次，即。 “0 1 1 *”。 @annually ：每年运行一次，即。 “0 1 1 *”。 @monthly ：每月运行一次，即。 “0 1 * *”。 @weekly ：每周运行一次，即。 “0 * * 0”。 @daily ：每天运行一次，即。 “0 * * *”。 @hourly ：每小时运行一次，即。 “* * * *”。 $ ls -l /var/spool/cron/root $ ls -l /var/spool/cron/crontabs/root # Debian系统 test条件测试 $ man test Shell脚本颜色 若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出需要使用：-e\n脚本文字颜色\n30m:灰色、31m:红色、32m:绿色、33m:黄色、34m:蓝色、35m:紫色、36m:浅蓝色、37m:白色 # 文字颜色 $ echo -e \"\\e[1;30m我是灰色 \\e[0m\" # 文字色号30~37，\"\\e[0m\":恢复原本色号 脚本背景颜色 40m:灰色、41m:红色、42m:绿色、43m:黄色、44m:蓝色、45m:紫色、46m:浅蓝色、47m:白色 # 背景颜色 $ echo -e \"\\e[1;40m我是灰色 \\e[0m\" # 背景色号40~47，\"\\e[0m\":恢复原本色号 文本格式控制 1m:粗体、4m:下划线、7m:反显、25h:显示光标 echo -e \"\\033[?25h\" 显示光标 echo -e \"\\033[?25l\" 隐藏光标 变量 IP=192.168.1.1 # 显示赋值 echo $IP read -p \"请输入 IP: \" IP # 键盘读入赋值: IP:为变量名, 一次性可以定义多个变量名：read -p \"请输入你的姓名，年龄，性别: \" name age sex ./ping.sh 192.168.1.1 192.168.1.2 $1 $2 # 位置变量 # 环境变量(系统变量) 设置环境变量 export IP=192.168.1.1 export IP # 变量名 # /etc/profile PATH=$PATH:/new/bin export PATH # 自定义变量 变量运算 整数运算 方式一expr $ expr 2 \\* 2 方式二$(())# 脚本常用 $ echo $((2*2)) 方式三let # 脚本常用 let i++ # 先赋值,后运算: x=i :x=1、i=2 i=1 let x=i++ # 先运算,后赋值: ++j :y=2、j=2 j=1 let y=++j 小数运算 $ echo \"2*4\" |bc $ echo \"2^4\" |bc # bc的次方: ^ $ echo \"scale=2;6/4\" |bc $ awk 'BEGIN{print 1/2}' 删除、替换变量 # # 从头往后删除 % # 从后往头删除 {:0:3} # 切片 / # 内容替换 - # 变量替代 :- #变量替代，可替代空值、+、:+、=、:=、?、:?、 # 百度域名举例:www.baidu.com url=www.baidu.com $ echo ${url#*.} baidu.com $ echo ${url#*bai} du.com $ echo ${url##*.} com expect使用 **Expect**是一个自动化工具，用于与交互式程序进行交互。它允许你编写脚本来模拟人类用户与程序的交互过程，从而自动化执行那些通常需要人工干预的任务 主要特点和用途： 自动化交互：\nExpect脚本可以编写为模拟用户输入和处理程序输出的行为。它通过捕获和分析程序的输出，并根据预定义的规则自动响应，来执行所需的操作。\n与交互式程序集成：\n适用于需要用户输入或期望特定响应的程序，例如配置管理工具、网络设备配置、数据库管理等。\n简化复杂任务：\n可以通过Expect自动化执行复杂的系统管理任务，如安装和配置软件、执行备份和恢复操作、模拟用户会话等。\n基于TCL语言：\nExpect的脚本语言基于TCL（Tool Command Language），这使得它结合了TCL的强大编程能力和Expect提供的交互式自动化功能。\n使用场景： 系统管理和自动化运维：\n批量配置和管理服务器和网络设备。\n测试和仿真：\n自动化测试脚本，模拟用户行为以测试程序的交互性。\n应用程序部署：\n在多个环境中自动化部署和配置应用程序。\n远程管理：\n通过SSH或Telnet等协议进行远程管理和操作。\n示例： #!/usr/bin/expect set username \"your_username\" set password \"your_password\" set hostname \"remote_host\" spawn ssh $username@$hostname expect \"password:\" send \"$password\\r\" expect \"$ \" send \"ls -l\\r\" expect \"$ \" send \"exit\\r\" expect eof $ cat \u003eexpect.sh\u003c\u003c-EOF #!/use/bin/expect spawn ssh root@192.168.1.1 # spawn:开启一个会话 expect { \"yes/no\" { send \"yes\\r\"; exp_continue } # send:传送参数，\\r:回车键, exp_continue:没出现\"yes/no\"也提交 第二次连接不会出现， \"password:\" { send \"密码\\r\" }; } interact # 停留在被连接系统中 EOF 运算符使用 关系(数值)运算符 关系(数值)运算符 说明 举例 -eq、== 等于：检测两个数是否相等，相等返回true [ $a -eq $b ] 返回：false -ne、!= 不等于： 检测两个数是否不相等，不相等返回true [ $a -ne $b ] 返回：true -gt、\u003e 大于：检测左边的数是否大于右边的数，如果是返回：true [ $a -gt $b ] 返回：false -lt、\u003c 小于：检测左边的数是否小于右边的，如果是返回：true [ $a -lt $b ] 返回：true -ge、\u003e= 大于等于：检测左边的数是否大于等于右边的，如果是返回：true [ $a -ge $b ] 返回：false -le、\u003c= 小于等于：检测左边的数是否小于等于右边的，如果是返回：true [ $a -le $b ] 返回：frue 字符串运算符 字符串都用双引号引起来\" \" 字符串运算符 说明 举例 = 等于：检测两个字符串是否相等，相等返回：true [ \"$a\" = \"$b\" ] 返回：false != 不等于：检测两个字符串是否相等，不相等返回：true [ \"$a\" != \"$b\" ] 返回：true -z 表示 0：检测字符串长度是否为0，为0返回：true [ -z \"$a\" ] 返回：false -n 表示非0：检测字符串长度是否为0，不为0返回：true [ -n \"$a\" ] $ 不为空：检测字符串是否为空，不为空返回：true [ $a ] 返回：true str 检测str是否不是空字符串，如果为空返回：false [ $a ] 不是假的 逻辑运算符 逻辑运算符 说明 举例 \u0026\u0026 逻辑的：and，和/并且：的意思 [[ $a -lt 100 \u0026\u0026 $b -gt 100 ]] 返回：false，./configure \u0026\u0026 make \u0026\u0026 make install || 逻辑的：or，或者/否则：的意思 [[ $a -lt 100 || $b -gt 100 ]] 返回：true， cat /opt/a.txt || touch /opt/a.txt 布尔运算符 布尔运算符只有：真(True)/假(False) 布尔运算符 说明 举例 ! 非：运算符：表达式为true则返回false， 否则返回：true [ ! false ] 返回：true -o 或：运算符：有一个表达式为：true则返回true [ $a -lt 20 -o $b -gt 100 ]， 返回：true -a 与：运算符：两个表达式都为：true才返回：true [ $a -lt 20 -a $b -gt 100 ]， 返回：false 算数运算符 算数运算符 说明 举例 + 加法，Python中支持：字符串、列表、元组合并 expr $a + $b结果为30 - 减法，Python中支持：集合，求差异 expr $a - $b结果为-10 * 乘法，Python中支持：字符串、列表、元组，复制 expr $a \\* $b结果为200 / 除法，Python中整数相除得到浮点数float，//为整除 expr $b / $a结果为2 % 取余(模余) expr $b % $a结果为0 = 赋值 a=$b将把变量b赋值给a == 相等：用于比较两个数字，相同则返回：true [ $a == $b ] 返回：false ** 幂运算，几的次方 2的5次方=2*2=4*2=8*2=16*2=32 文件测试 文件参数 说明 举例 -e 如果文件存在则为真 `[ -e dir -r 如果文件存在且当前用户可读则为真，是否可以读取 [ -r $file ] -w 如果文件存在且当前用户可写则为真，是否有可以写入 — -x 如果文件存在且当前用户可执行则为真，是否有执行权限 — -s 如果文件存在且至少有一个字符则为真 — -d 如果文件存在且为目录则为真 [ -d /home ] 是否为目录[ ! -d /home ] 取反 -f 如果文件存在且为普通文件则为真 — -c 如果文件存在且为字符型特殊文件则为真 — -b 如果文件存在且为块特殊文件则为真 — -g 如果文件存在且设置SGID则为真 — -k 如果文件存在且设置了粘着位(Sticky Bit)则为真 — -p 如果文件存在且是：名管道，则为真 — -u 如果文件存在且设置SUID则为真 — -t 如果文件存在且文件描述符已打开并与终端关联则为真 — -z 如果文件存在且大于0则为真 — -o 如果文件存在且当前用户是文件所有者则为真 — -S 如果文件存在且是socket文件则为真 — -L 如果文件存在且是连接文件则为真 — 传参参数处理 参数处理 说明 举例 $# 传入脚本的参数个数 [ $# -eq 0 ] $* 传入脚本的所有参数 如\"$*\"用\" \"括起来的情况，以\"$1 $2 ... $n\"的形式输出所有参数 $$ 当前shell的进程号，对于shell脚本，这是它们执行的进程ID — $! Shell后台运行的最后一个进程Process的PID — $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数，如\"$@\"用\" \"括起来，以\"$1\" \"$2\" ... \"$n\"的形式输出所有参数 其中$@与$*正常情况下一样，当在脚本中将$*加上双引号作为“$*”引用时，此时将输入的所有参数当做一个整体字符串对待。比如输入参数有a b c三个参数，则“$*”表示“a b c”一个字符串 $- 显示shell使用的当前选项，与set命令功能相同 — $? 显示最后命令退出状态，0表示没有错误，其他任何值表明有错误 — $0 当前脚本文件名 — $1～$n 这些变量对应调用脚本的参数，这里的n是对应于参数位置的正十进制数(第一个参数是$1，第二个参数是$2，依此类推) — $# 提供给脚本的参数数量 — $ 当前运行脚本的进程ID号 — Printf的转义序列 printf的转义序列 说明 举例 \\a 警告字符，通常为ASCII的BEL字符 — \\b 后退 — \\c 抑制(不显示)输出结果中任何结尾的换行字符(只在%格式指示符控制下的参数字符串中有效)，而且任何留在参数里的字符，任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 — \\f 换页formfedd — \\n 换行 — \\r 回车Carriage return — \\t 水平制表符，类似：Tab键，四个空格键 — \\v 垂直制表符 — \\\\ 一个字面上的反斜杠字符 — \\ddd 表示1到3位数八进制值得字符，仅在格式字符串中有效 — \\0ddd 表示1到3位得八进制字符 — # 格式化输出两种方式 # 第一种 $ echo -e \"a\\tb\"，\\t:Tab(键) # 第二种 $ printf \"%-10s %-8s %-4s\\n\" 姓名 性别 体重kg $ printf \"%-10s %-8s %-4.2f\\n\" 郭靖 男 66.1234 $ printf \"%-10s %-8s %-4.2f\\n\" 杨过 男 48.6543 %s %c %d %f # 都是格式替代符， ％s # 输出一个字符串， ％d # 整型输出， ％c # 输出一个字符， ％f # 输出实数，以小数形式输出。 %-10s # 指一个宽度为 10 个字符（- 表示左对齐，没有则表示右对齐），任何字符都会被显示在 10 个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。 %-4.2f # 指格式化为小数，其中 .2 指保留2位小数。 $ printf \"\\e[?2004l\" # 解决命令行终端复制粘贴出现 0~ 1~ 问题，括号粘贴模式。 或者：reset 运算符描述 运算符描述 说明 举例 () 改变优先顺序， 小括号子shell中执行命令：(ls) (()) 数值比较，运算 — $() 命令替换、相当于反撇号: `` — $(()) 整数运算 — [] 条件测试、匹配方括号中任意一个字符 [a-z] [0-9] [a-zA-Z0-9] 取反:[^a-zA-Z0-9] [[]] 条件测试，支持正则 =~ — $[] 整数运算 — {} 打括号使用方式 mkdir -pv /opt/{aaa/{111,222},bbb}、cp nginx.conf{,.bak}、{1..9} ${} — — ~1 的补充 — ! 逻辑否定 — !~ 逻辑否定：二进制反转（一个补码） — \u003c\u003c 左移 — \u003e\u003e 右移 — =~ 匹配模式 — \u0026 Bitwise和 — ^ 按位\"独占或\" — | 按位\"包容性\" 或 — ++ 递增 — --- 递减 — *= 左侧乘以右侧并更新左侧 — /= 将左侧除以 — += 将左侧添加到右侧并更新左侧 — -+ 将右侧减去左侧并更新左侧 — ^= “独占或\"左侧到右侧并更新左侧 — %= 左侧除以右侧，余数更新再左侧 — ; 执行多个命令 cat /etc/passwd; ls \\ 转意符 \"touch linux\\ nginx、\\t:Tab(键)、\\n:(换行)、\\c:(不换行输出)\" true 永远返回为真0 — false 永远返回为假1 — 条件语句 条件语句 说明 举例 if 如果什么什么 — then 然后怎么怎么 — elif 其它怎么怎么，elif是if有多个语句条件 — else 否则怎么怎么 — fi 结束：if判断句结束语 — case 循环语句开始定义 — esac 循环语句结束定义 — while 条件为真循环 外循环控制行数，内循环控制列数，内循环小于等于外循环 unitl 条件为假循环 — select 循环、查询 — in 在什么什么 Python中支持：字符串、列表、元组、字典，检测元素是否存在，与之相反的是：not in do 做/执行什么什么 — done 结束循环 — unset 删除变量 — readonly 只读变量 — read 读取输入变量名 — clear 删除、清除 — break 跳出整个循环，n指定的第n个封闭循环，退出可以是1、2、3 — continue 当前迭代循环退出 — 重定向参数 重定向 说明 举例 command \u003e file 将输出重定向到：file — command \u003c file 将输入重定向到：file — command \u003e\u003e file 将输出以追加的方式重定向到：file — n \u003e file 将文件描述符为n的文件重定向到：file — n \u003e\u003e file 将文件描述符为n的文件以追加的方式重定向到：file — n \u003e\u0026 m 将输出文件m和n合并 — n \u003c\u0026 m 将输入文件m和n合并 — \u003c\u003c tag 将开始标记tag和结束标记tag之间的内容作为输入 — 多行注释 :\u003c\u003cEOF EOF :\u003c\u003c' ' :\u003c\u003c! ! 实战脚本 实战脚本一 $ echo '#!/usr/bin/bash # 提示用户没有加参数 if [ $# -eq 0 ]; then echo \"执行方式: `basename $0` 文件名(file)\" exit # 退出 fi # 提示输入的不是文件: ! 取反:不是文件 if [ ! -f $1 ];then echo \"错误的文件名\" exit fi # 正确执行 for IP in `cat $1` do ping -c1 $IP \u0026\u003e/dev/null if [ $? -eq 0 ];then echo \"${IP} is up\" else echo \"${IP} is down\" fi done ' \u003eping.sh $ ./ping.sh ip.txt 实战脚本二 $ echo '#!/usr/bin/bash read -p \"请输入数字: \" num while true do if [[ \"$num\" =~ ^[0-9]+$ ]];then break # 跳出循环 else echo \"你输入的不是数字！！！\" read -p \"输入错误，请重新输入: \" num fi done read -p \"请输入创建的用户首字母: \" prefix if [ -z \"$prefix\" ];then echo \"错误的首字母(prefix)\" exit fi for i in `seq $num` do user=$prefix$i useradd $user echo \"123\" |passwd --stdin $user \u0026\u003e/dev/null if [ $? -eq 0 ];then echo \"$user 创建成功\" fi done ' \u003euseradd.sh 实战脚本三 清理Nginx缓存 $ echo '/opt/delete-cache.sh' \u003e\u003e/home/neek/.bash_profile # 登录即执行脚本 $ cat \u003edelete-cache.sh\u003c\u003c-EOF #!/usr/bin/bash #trap \"\" HUP INT OUIT TSTP #防止在脚本中退出 #clear directory=/opt/data/cache /usr/bin/ansible web -i /etc/ansible/hosts -m shell -a \"/usr/bin/rm -rf ${directory}/directory.log\" -f 5 \u0026\u003e/dev/null /usr/bin/rm -rf /opt/data/Tenant.txt sleep 1 /usr/bin/ls ${directory}/ |tee /opt/data/Tenant.txt echo -e \"\\e[1;36m \\t\\t\\t+------------------------------------------+\\t\\t\\t \\e[0m\" echo -e \"\\e[1;31m \\t\\t\\t|\t清理租户缓存\t|\\t\\t\\t \\e[0m\" echo -e \"\\e[1;36m \\t\\t\\t+------------------------------------------+\\t\\t\\t \\e[0m\" echo -e \"\\e[1;36m \\t\\t\\t| (0) 退出\t|\\t\\t\\t \\e[0m\" echo -e \"\\e[1;33m \\t\\t\\t| (1)输入要删除的目录例如：h5、web、ldy。|\\t\\t\\t \\e[0m\" echo -e \"\\e[1;31m \\t\\t\\t| (2)输入'2'删除租户目录下所有缓存\t|\\t\\t\\t \\e[0m\" echo -e \"\\e[1;31m \\t\\t\\t| (3)输入'3'删除所有租户缓存\t|\\t\\t\\t \\e[0m\" echo -e \"\\e[1;36m \\t\\t\\t+------------------------------------------+\\t\\t\\t \\e[0m\" echo -en \"\\e[1;36m选择要清理的租户缓存[0-3]: \\e[0m\" read ID while :;do if [[ \"$ID\" =~ ^[0-9]$ ]];then break else echo -en \"\\e[1;31m输入错误请重新输入[0-3]: \\e[0m\" read ID fi done while :;do case $ID in 0) exit;; 1) echo -en \"\\e[1;36m请输入租户目录: \\e[0m\" read Name /usr/bin/ls ${directory}/${Name} echo -en \"\\e[1;36m请输入要清理缓存的终端:h5、web、ldy中的一个： \\e[0m\" read cache if [ -d ${directory}/${Name}/${cache}/ ];then /usr/bin/ansible web -i /etc/ansible/hosts -m shell -a \"rm -rf ${directory}/${Name}/${cache}\" -f 5 \u0026\u003e/dev/null echo \"已清理租户${Name}目录下${cache}目录中的缓存\" exit else echo \"目录不存在\" exit fi;; 2) echo -en \"\\e[1;36m请输入要清理缓存的租户目录: \\e[0m\" read Name if [ -d ${directory}/${Name} ];then /usr/bin/ansible web -i /etc/ansible/hosts -m shell -a \"rm -rf ${directory}/${Name}/*\" -f 5 \u0026\u003e/dev/null echo \"已清理租户${Name}目录下所有缓存\" exit fi;; 3) echo -en \"\\e[1;31m确认要清理所有租户缓存吗[y/n]: \\e[0m\" read y if [ \"$y\" = \"y\" ];then /usr/bin/ansible web -i /etc/ansible/hosts -m shell -a \"rm -rf ${directory}/*\" -f 5 \u0026\u003e/dev/null echo \"已清理所有租户缓存\" for mk in `cat /opt/data/Tenant.txt` do /usr/bin/ansible web -i /etc/ansible/hosts -m shell -a \"/usr/bin/mkdir -pv ${directory}/${mk} \u003e\u003e${directory}/directory.log\" -f 5 \u0026\u003e/dev/null if [ $? -eq 0 ];then echo \"${mk} create ok\" else echo \"${mk} create error\" fi done exit else echo \"输入不是’y‘退出\" exit fi;; esac done EOF 实战脚本四 修改系统IP $ cat \u003eUpdate-Ip.sh\u003c\u003c-EOF echo \"###input ip you want change to ### \" ipfront=192.168.0. read -p \"请输入结尾IP:\" ip1 ip=\"${ipfront}${ip1}\" echo \"###ip====\" $ip \"###\" eth=`find /etc/sysconfig/network-scripts/ -name \"ifcfg-e*\" |sort |head -1 |awk -F/ '{print $5}'` ethfile=\"/etc/sysconfig/network-scripts/$eth\" echo \"${ethfile}\" sed -i \"s/BOOTPROTO='dhcp'/BOOTPROTO='static'/g\" \"${ethfile}\" sed -i \"s/^ONBOOT=no/ONBOOT=yes/g\" \"${ethfile}\" testfile=\"/etc/sysconfig/network-scripts/test\" echo \"IPADDR=${ip}\" \u003e\u003e${ethfile} echo \"NETMASK=255.255.255.0\" \u003e\u003e${ethfile} echo \"GATEWAY=192.168.0.1\" \u003e\u003e${ethfile} echo \"DNS1=8.8.8.8\" \u003e\u003e${ethfile} echo \"DNS2=1.1.1.1\" \u003e\u003e${ethfile} sleep 3 systemctl restart network echo $? EOF 配置Linux系统登录告警 配置sshd登录告警 $ cat \u003e/etc/ssh/sshrc\u003c\u003c-EOF #!/bin/sh TELEGRAM_TOKEN=\"\" TELEGRAM_GROUP_ID=\"\" # 获取用户、IP地址、时间和服务器信息 USER_NAME=$USER HOST_NAME=$(hostname -s) DATA_TIME=$(date +\"%F %H:%M:%S\") LOCALHOST=$(hostname -I | awk '{print $1}') LOGGIN_IP=$(echo $SSH_CLIENT | awk '{print $1}') # 构造通知消息 msg=\"有白名单之外的 IP 登录服务器，请验证: User: ${USER_NAME} Host: ${LOCALHOST} Login IP: ${LOGGIN_IP} Login Time: ${DATA_TIME} Host Name: ${HOST_NAME}\" # 定义信任的IP地址列表 IP_WhiteList='192.168.1.100' result=$(echo ${IP_WhiteList} | grep \"${LOGGIN_IP}\") if [ \"${result}\" != \"\" ]; then exit 0 # 如果在信任列表中，退出脚本 else curl -X POST \"https://api.telegram.org/bot${TELEGRAM_TOKEN}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=${msg}\" \u003e /dev/null fi EOF ",
    "description": "Shell脚本编写 执行方式 sh -n bash.sh调试模式运行：-n sh -vx bash.sh打印调试模式运行日志：-vx bash执行环境 登录bash执行 系统级 /etc/profile /etc/bashrc 用户级 ~/.",
    "tags": [],
    "title": "How_To_Write_Shell_Scripts",
    "uri": "/systems/linux/script/how_to_write_shell_scripts/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Rsyncd",
    "content": "部署时间同步服务 部署NTP时间同步服务 下载安装包、解压、配置、安装NTP官网 $ cd /usr/local/src/ $ curl -O https://www.eecis.udel.edu/~ntp/ntp_spool/ntp4/ntp-4.2.8p13.tar.gz $ tar zxvf ntp-4.2.8p13.tar.gz $ cd ntp-4.2.8p13 $ ./configure --prefix=/usr/local/ntp --enable-all-clocks --enable-parse-clocks $ make \u0026\u0026 make install # 注：如以上下载地址无法访问,请从ntp官方手动下载：http://www.ntp.org/downloads.html 修改ntp.conf配置文件 restrict default nomodify notrap noquery替换为restrict default nomodify允许任何客户机IP进行时间同步 在restrict default nomodify notrap noquery默认拒绝所有之后增加一行：restrict 192.168.18.0 mask 255.255.255.0 nomodify $ vim /etc/ntp.conf # 方式一、使用域名连接，要经过DNS解析，速度慢。 ntpdate pool.ntp.org # 方式二、使用IP连接，超级快。 ntpdate 120.24.81.91 以守护进程启动ntpd ntpd启动后，客户机要等几分钟再与其进行时间同步，否则会提示no server suitable for synchronization found错误 $ /usr/local/ntp/bin/ntpd -c /etc/ntp.conf -p /tmp/ntpd.pid 在客户机器配置计划任务 每天的5点13分、9点13分、14点13分、19点13分与时间同步服务器进行同步 $ yum install -y ntpdate $ echo \"13 5,9,14,19 * * * /usr/sbin/ntpdate 192.168.18.2\" \u003e\u003e/var/spool/cron/root 部署Chrony时间同步服务。将替代NTP服务 Chrony $ yum -y install chrony $ systemctl enable chronyd.service \u0026\u0026 systemctl start chronyd.service ",
    "description": "部署时间同步服务 部署NTP时间同步服务 下载安装包、解压、配置、安装NTP官网 $ cd /usr/local/src/ $ curl -O https://www.eecis.udel.edu/~ntp/ntp_spool/ntp4/ntp-4.2.8p13.tar.gz $ tar zxvf ntp-4.",
    "tags": [],
    "title": "Install_TimeSyncd",
    "uri": "/systems/linux/rsyncd/install_timesyncd/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Rsyncd",
    "content": "Rsync部署 注意：两台服务器都需要安装Rsync服务， 只启动源服务器上的Rsync 选项 描述 -a 包含：-rtplgoD 等选项 -r 同步目录选项 -v 显示同步的目录文件信息 -l 保留软连接 -L 同步软链接时把源文件也给同步 -p 保持文件权限属性 -o 保持文件属主 -g 保持文件属组 -D 保持设备文件信息 -t 保持文件时间属性 -delete 删除目标服务器目录中源服务器没有的文件 -exclude 忽略不需要同步的目录文件 -P 显示同步过程，速率等，比-v更加详细 -u 如果目标服务器比源服务器目录文件新则不同步 -z 同步时压缩目录文件 源服务器 $ echo \"username:password\" \u003e\u003e/etc/rsyncd.namelist # 创建一个虚拟用户密码 $ cat \u003e/etc/rsyncd.conf\u003c\u003c-EOF # sample rsyncd.conf configuration file # GLOBAL OPTIONS 全局配置 # motd file=/etc/motd # log file=/var/log/rsyncd # for pid file, do not use /var/run/rsync.pid if # you are going to run rsync out of the init.d script. # The init.d script does its own pid file handling, # so omit the \"pid file\" line completely in that case. # pid file=/var/run/rsyncd.pid # syslog facility=daemon # socket options= # MODULE OPTIONS 按组配置选项 [ftp] comment = public archive # 要同步的目录 path = /var/www/pub use chroot = yes # max connections=10 lock file = /var/lock/rsyncd # 默认只读，如果源要推送目录文件到目标服务器， 目标服务器上需要修改为： read only = yes list = yes uid = nobody gid = nogroup # exclude = # exclude from = # include = # include from = # 授权访问的用户名 # auth users = username # 授权访问的用户的密码文件 # secrets file = /etc/rsyncd.secrets strict modes = yes # hosts allow = # hosts deny = ignore errors = no ignore nonreadable = yes transfer logging = no # log format = %t: host %h (%a) %o %f (%l bytes). Total %b bytes. timeout = 600 refuse options = checksum dry-run dont compress = *.gz *.tgz *.zip *.z *.rpm *.deb *.iso *.bz2 *.tbz EOF # 权限一定要限制为最小， $ chmod 600 /etc/rsyncd.namelist # kill进程重启 $ kill -9 rsync # 依后台运行方式启动 $ rsync --daemon 目标服务器 查看源服务器下目录资源 $ rsync --list-only 源服务器IP::ftp/ # ftp 为组名 同步源目录下资源 $ rsync -avz 源服务器IP::ftp/ /usr/local/nginx/html 使用用户密码方式查看源服务器资源 $ rsync --list-only username@源服务器IP::ftp/ # ftp 为组名 # 客户端保存密码 $ echo \"password\" \u003e\u003e/etc/rsyncd.passwordlist $ chmod 600 /etc/rsyncd.passwordlist $ rsync --list-only --password-file=/etc/rsyncd.passwordlist username@源服务器IP::ftp/ # ftp 为组名 安装配置Inotify时时检测服务 安装以及配置监控目录 选项 完整参数 描述 -r --recursive 递归查询目录 -q --qulet 只打印监控事件信息 -m --monitor 始终保持监控状态 --excludel 排除文件或目录，不区分大小写 --timefmt 指定事件输出格式 --format 使用指定的输出类似字符串格式 -e `–event[-e –event …]accessmodifyattrb` $ wget https://github.com/inotify-tools/inotify-tools/releases/download/3.20.2.2/inotify-tools-3.20.2.2.tar.gz $ tar zxvf inotify-tools-3.20.2.2.tar.gz $ cd inotify-tools-3.20.2.2/ $ ./configure --prefix=/usr/local/inotify $ make \u0026\u0026 make install # 监控目录 $ inotifywait -mrq --timefmt '%Y-%m-%d %H:%M:%S' --format '%T %w%f %e' -e close_write,modify,delete,create,attrib,move //usr/local/nginx/html/ 使用脚本监控 $ cat \u003einotifywait_rsync.sh\u003c\u003c-EOF #!/bin/bash # 监控目录， 有变化推送到目标服务器 inotifywait -mrq --timefmt '%Y-%m-%d %H:%M:%S' --format '%T %w%f %e' -e close_write,modify,delete,create,attrib,move //usr/local/nginx/html/ | while read file do rsync -az --delete --password-file=/etc/rsyncd.passwordlist /usr/local/nginx/html username@源服务器IP::ftp/ done EOF ",
    "description": "Rsync部署 注意：两台服务器都需要安装Rsync服务， 只启动源服务器上的Rsync 选项 描述 -a 包含：-rtplgoD 等选项 -r 同步目录选项 -v 显示同步的目录文件信息 -l 保留软连接 -L 同步软链接时把源文件也给同步 -p 保持文件权限属性 -o 保持文件属主 -g 保持文件属组 -D 保持设备文件信息 -t 保持文件时间属性 -delete 删除目标服务器目录中源服务器没有的文件 -exclude 忽略不需要同步的目录文件 -P 显示同步过程，速率等，比-v更加详细 -u 如果目标服务器比源服务器目录文件新则不同步 -z 同步时压缩目录文件 源服务器 $ echo \"username:password\" \u003e\u003e/etc/rsyncd.",
    "tags": [],
    "title": "Install_Rsync",
    "uri": "/systems/linux/rsyncd/install_rsync/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Rsyncd",
    "content": "Lsyncd部署 **Lsyncd**是一个实时文件同步工具，它可以监视指定的目录树，一旦文件发生变化（如创建、修改、删除），就会立即将这些变化同步到另一个目标位置。它主要用于在多个服务器之间保持文件夹内容同步，并且可以实现高效的增量同步 主要特点和用途： 实时监控和同步：\nLsyncd使用轮询或文件系统的通知机制（如inotify）来实时监控文件系统的变化。\n当监控的目录发生变化时，它可以快速响应并将变更内容同步到目标位置。\n增量同步：\nLsyncd不会简单地全量复制文件，而是通过增量方式同步文件变更，提高了同步效率。\n灵活的配置：\n可以通过简单的配置文件定义监控源目录和目标位置，以及定义同步规则和行为。\n支持通过Lua脚本来自定义处理逻辑，如过滤器、排除规则等。\n跨平台支持：\nLsyncd可以运行在多种操作系统上，包括Linux、BSD和macOS等。\n高可靠性和可扩展性：\nLsyncd设计用于高可靠性的文件同步，可以处理大量的文件系统变更和同步任务。\n可以配置成为集群环境下的一部分，以实现更复杂的同步和备份策略。\n使用场景： 分布式系统的文件同步：\n在多台服务器之间同步重要文件，确保文件内容的一致性和可用性。\n实时备份和数据保护：\n将重要数据即时备份到另一个位置，以应对意外数据丢失或损坏的情况。\n网站和应用程序部署：\n在不同的服务器上部署相同的网站或应用程序代码，确保所有服务器上的内容始终保持同步。\n安装扩展工具 $ yum -y install expect epel-release lsyncd 生成密钥实现绵密登录 $ ssh-keygen -t rsa -P \"\" -f ~/.ssh/id_rsa # -t指定SSH密钥的算法为RSA算法，-P设置密码为空，-f指定生成的密钥文件存放位置 使用expect工具使脚本推送密钥 $ expect \u003c\u003c-EOF spawn ssh-copy-id myadmin@$IP expect \"(yes/no)?\" {send \"yes\\r\"} expect \"password:\" {send \"$passwd\\r\"} expect \"#\" {send \"exit\\r\"} EOF 给予普通用户授权，使普通用户可以使用Lsyncd $ echo \"##### Start/Stop Service ##### Cmnd_Alias MYADMIN_START_SERVICES = /etc/lsyncd.conf, /usr/bin/lsyncd, /bin/rsync, /var/log/lsyncd/* myadmin ALL=(ALL)NOPASSWD:MYADMIN_START_SERVICES \" \u003e\u003e/etc/sudoers.d/myadmin $ chmod 660 /etc/sudoers.d/myadmin 编写Lsyncd.conf文件 $ echo \"--insist：继续运行，即使有失败的目标。 --statusInterval：多少秒写入文件，默认是10s --sync为同步配置，部分参数如下： --source：本地文件目录 --host：远程服务器地址 --targetdir：远程目标目录 --port：目前主机SSH端口号，默认为22 settings { --settings为全局配置 logfile = \"/var/log/lsyncd/lsyncd.log\", --logfile：日志文件路径 statusFile = \"/var/log/lsyncd/lsyncd.status\", --statusFile：进程路径 inotifyMode = \"CloseWrite or Modify\", maxProcesses = 100, --ssh同步修改为\"1\" maxDelays = 10, } sync { default.rsyncssh, --# ssh同步方式 source = \"/opt/backup\", --源服务器目录 host=\"192.168.40.198\", targetdir=\"/opt/backup/\", --目标服务器目录，源服务器和目标服务器相同 delay = 1, rsync = { binary = \"/usr/bin/rsync\", archive = true, compress = false, verbose = true, } } sync { default.rsync, source = \"/data/nginx/cache\", target =\"root@192.168.32.11:/data/nginx/cache\", delay = 1, rsync = { binary = \"/usr/bin/rsync\", archive = true, compress = false, verbose = true } } \"\u003e\u003e/etc/lsyncd.conf 给予权限， 启动Lsyncd $ chown -R myadmin. /var/log/lsyncd $ lsyncd -nodaemon /etc/lsyncd.conf # 运行查看下是否有报错 $ systemctl enable lsyncd \u0026\u0026 systemctl start lsyncd ",
    "description": "Lsyncd部署 **Lsyncd**是一个实时文件同步工具，它可以监视指定的目录树，一旦文件发生变化（如创建、修改、删除），就会立即将这些变化同步到另一个目标位置。它主要用于在多个服务器之间保持文件夹内容同步，并且可以实现高效的增量同步 主要特点和用途： 实时监控和同步：\nLsyncd使用轮询或文件系统的通知机制（如inotify）来实时监控文件系统的变化。\n当监控的目录发生变化时，它可以快速响应并将变更内容同步到目标位置。\n增量同步：\nLsyncd不会简单地全量复制文件，而是通过增量方式同步文件变更，提高了同步效率。\n灵活的配置：\n可以通过简单的配置文件定义监控源目录和目标位置，以及定义同步规则和行为。",
    "tags": [],
    "title": "Install_Lsyncd",
    "uri": "/systems/linux/rsyncd/install_lsyncd/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "Scylladb部署 单节点部署Scylladb 名称地址 系统要求 ScyllaDB ScyllaDB文档 Github-Scylla Scylla使用端口 端口 协议 描述 9042 TCP CQL、本地传输端口： native_transport_port 9142 TCP SSL CQL使用加密方式由客户端到节点 7000 TCP Inter-node communication (RPC) 节点间通信 7001 TCP SSL inter-node communication (RPC) 使用SSL节点间通信 7199 TCP JMX management、JMX管理 10000 TCP Scylla REST API 9180 TCP Prometheus API普罗米修斯API 9100 TCP node_exporter (Optionally：可选) 9160 TCP Scylla client port (Thrift) Scylla客户端端口 19042 TCP Native shard-aware transport port本机分片感知传输端口 19142 TCP Native shard-aware transport port (ssl) 本机分片感知传输端口 (ssl) Install Openjdk 8 or 11 $ mkdir -p /etc/apt/keyrings $ gpg --homedir /tmp --no-default-keyring --keyring /etc/apt/keyrings/scylladb.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys d0a112e067426ab2 $ wget -O /etc/apt/sources.list.d/scylla.list http://downloads.scylladb.com/deb/debian/scylla-5.1.list 安装scylla安装包 $ apt-get update $ apt-get install -y scylla 列出可用安装包 $ apt-cache madison scylla 开始安装 $ apt-get install scylla{,-server,-jmx,-tools,-tools-core,-kernel-conf,-node-exporter,-conf,-python3}=4.6.1-0.20220328.2309d6b51-1 # 4.6.1-0.20220328.2309d6b51-1 为安装包 1.4 将Java设置为1.8版本 $ apt-get update $ apt-get install -y openjdk-8-jre-headless $ update-java-alternatives --jre-headless -s java-1.8.0-openjdk-amd64 运行scylla_setup脚本来调整系统设置 $ scylla_setup Do you want to run check your kernel version? Yes - runs a script to verify that the kernel for this instance qualifies to run Scylla. No - skips the kernel check. [YES/no]YES # 是否检查内核版本 Do you want to verify the ScyllaDB packages are installed? Yes - runs a script to confirm that ScyllaDB is installed. No - skips the installation check. [YES/no]YES # 是否验证 ScyllaDB 软件包已安装 Do you want the Scylla server service to automatically start when the Scylla node boots? Yes - Scylla server service automatically starts on Scylla node boot. No - skips this step. Note you will have to start the Scylla Server service manually. [YES/no]YES # 是否允许Scylla开机自启 Created symlink /etc/systemd/system/multi-user.target.wants/scylla-server.service → /lib/systemd/system/scylla-server.service. Do you want to enable Scylla to check if there is a newer version of Scylla available? Yes - start the Scylla-housekeeping service to check for a newer version. This check runs periodically. No - skips this step. [YES/no]NO # 是否检查Scylla 是不是最新版本 Do you want to setup Network Time Protocol(NTP) to auto-synchronize the current time on the node? Yes - enables time-synchronization. This keeps the correct time on the node. No - skips this step. [YES/no]YES # 是否启用NTP时间同步 Do you want to setup RAID and XFS? It is recommended to use RAID and XFS for Scylla data. If you select yes, you will be prompted to choose the unmounted disks to use for Scylla data. Selected disks are formatted as part of the process. Yes - choose a disk/disks to format and setup for RAID and XFS. No - skip this step. [YES/no]YES # 是否设置RAID和XFS 是：将会格式化磁盘 Do you want to enable coredumps? Yes - sets up coredump to allow a post-mortem analysis of the Scylla state just prior to a crash. No - skips this step. [YES/no] # 是否允许coredump在崩溃之前对Scylla状态进行事后分析 Do you want to setup a system-wide customized configuration for Scylla? Yes - setup the sysconfig file. No - skips this step. [YES/no]YES # 是否为Scylla设置系统范围自定义配置 Do you want IOTune to study your disks IO profile and adapt Scylla to it? (*WARNING* Saying NO here means the node will not boot in production mode unless you configure the I/O Subsystem manually!) Yes - let iotune study my disk(s). Note that this action will take a few minutes. No - skip this step. [YES/no]YES # 是否让IOTune研究您的磁盘IO配置文件并使Scylla适应它，否”意味着手动配置 I/O 子系统，否则节点将不会以生产模式启动 Do you want to set the CPU scaling governor to Performance level on boot? Yes - sets the CPU scaling governor to performance level. No - skip this step. [YES/no]YES # 是否允许在引导时将CPU缩放调控器设置为性能级别 Do you want to enable fstrim service? Yes - runs fstrim on your SSD. No - skip this step. [yes/NO]YES # 是否启用fstrim 服务 Will Scylla be the only service on this host? Answer yes to lock all memory to Scylla, to prevent swapout. Answer no to do nothing. [YES/no]YES # Scylla是不是该主机上的唯一服务，是：将内存锁定到Scylla，以防止换出 Do you want to configure rsyslog to send log to a remote repository? Answer yes to setup rsyslog to a remote server, Answer no to do nothing. [YES/no]no # 是否配置rsyslog将日志发送到远程存储库 启动Scylla数据库服务 $ systemctl start scylla-server # 查看是否启动 $ systemctl status scylla-server 检查节点状态 $ nodetool status # 运行cqlsh 连接到数据库 $ cqlsh $ cqlsh\u003e help # 使用help帮助命令 # 运行 cassandra-stress $ cqlsh\u003e cassandra-stress write -mode cql3 native 部署Scylladb集群 单数据中心Scylla集群模式 名称地址 描述 创建Scylla集群 - 单数据中心 DC 多数据中心Scylla集群模式 名称地址 描述 创建Scylla集群 - 多数据中心 DC ",
    "description": "Scylladb部署 单节点部署Scylladb 名称地址 系统要求 ScyllaDB ScyllaDB文档 Github-Scylla Scylla使用端口 端口 协议 描述 9042 TCP CQL、本地传输端口： native_transport_port 9142 TCP SSL CQL使用加密方式由客户端到节点 7000 TCP Inter-node communication (RPC) 节点间通信 7001 TCP SSL inter-node communication (RPC) 使用SSL节点间通信 7199 TCP JMX management、JMX管理 10000 TCP Scylla REST API 9180 TCP Prometheus API普罗米修斯API 9100 TCP node_exporter (Optionally：可选) 9160 TCP Scylla client port (Thrift) Scylla客户端端口 19042 TCP Native shard-aware transport port本机分片感知传输端口 19142 TCP Native shard-aware transport port (ssl) 本机分片感知传输端口 (ssl) Install Openjdk 8 or 11 $ mkdir -p /etc/apt/keyrings $ gpg --homedir /tmp --no-default-keyring --keyring /etc/apt/keyrings/scylladb.",
    "tags": [],
    "title": "Install_Scylladb",
    "uri": "/systems/linux/nosql/install_scylladb/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "Redis安装 名称地址 描述 Redis安装包 Redis依赖gcc与gcc-c++，而Redis5.0以上需要更高版本gcc 安装Gcc # Debian系统 $ sudo apt-get install wget gcc make pkg-config $ yum -y install gcc gcc-c++ centos-release-scl wget git 安装高版本gcc $ yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils # 临时生效 $ echo 'scl enable devtoolset-9 bash' # 添加到环境变量永久生效 $ echo \"source /opt/rh/devtoolset-9/enable\" \u003e\u003e/etc/profile $ source /etc/profile $ echo 'scl enable devtoolset-9 bash' \u003e\u003e ~/.bashrc $ source ~/.bashrc # 使更改生效 # 如果出现不能跳转root执行 $ sudo scl enable devtoolset-9 bash 安装Redis 下载tar包到指定目并解压 $ wget -P /usr/local/src/ https://download.redis.io/releases/redis-6.2.6.tar.gz # 下载到指定目录 $ sudo wget -P /usr/local/src/ https://download.redis.io/redis-stable.tar.gz 解压到指定目录并重命名 $ mkdir -p /usr/local/redis \u0026\u0026 tar zxvf /usr/local/src/redis-6.2.6.tar.gz -C /usr/local/redis --strip-components 1 配置redis $ cd /usr/local/redis $ make MALLOC=libc BUILD_TLS=yes # 有些版本或者云需要 BUILD_TLS=yes 参数 执行安装 $ make PREFIX=/usr/local/redis install 修改配置文件daemonize参数能后台启动以及使用密码连接注释不可以在行尾 $ echo '# redis后台运行 daemonize yes # Redis的pid文件存放位置 pidfile /usr/local/redis/logs/redis_6379.pid # Redis的日志文件存放位置 logfile /usr/local/redis/logs/redis_6379.log # 端口号 port 6379 # 最好是本机IP bind 192.168.176.131 # 超时时间300秒 timeout 300 # 缓存库的个数 databases 8 # 将数据库转储到的文件名 dbfilename dump-16379.db # 数据存放目录 dir /opt/data/redis/ # 主库密码 masterauth password # 连接密码 requirepass password '\u003e /usr/local/redis/redis.conf 启动Redis $ /usr/local/redis/bin/redis-server /usr/local/redis/redis.conf 编写常规启动文件 $ echo '#!/bin/sh # Simple Redis init.d script conceived to work on Linux systems # as it does use of the /proc filesystem. # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database REDISPORT=6379 EXEC=/usr/local/redis/bin/redis-server CLIEXEC=/usr/local/redis/bin/redis-cli $CLIEXEC -a \"Redis\" -p $REDISPORT shutdown PIDFILE=/var/run/redis_${REDISPORT}.pid CONF=\"/usr/local/redis/redis.conf\" case \"$1\" in start) if [ -f $PIDFILE ] then echo \"$PIDFILE exists, process is already running or crashed\" else echo \"Starting Redis server...\" $EXEC $CONF fi ;; stop) if [ ! -f $PIDFILE ] then echo \"$PIDFILE does not exist, process is not running\" else PID=$(cat $PIDFILE) echo \"Stopping ...\" $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/${PID} ] do echo \"Waiting for Redis to shutdown ...\" sleep 1 done echo \"Redis stopped\" fi ;; *) echo \"Please use start or stop as first argument\" ;; esac' \u003e /etc/init.d/redis $ chmod +x /etc/init.d/redis $ chkconfig redis on # 启动并查看端口号 $ service redis start $ netstat -nuplt | grep 6379 编写指定目录启动文件 $ echo '## 目录 REDIS_PATH=\"/opt/apps/redis\" sql_conf_dir='/opt/apps/redis' sql_conf_file=$(ls $sql_conf_dir/* |egrep conf$) sql_user='admin' ## start_redis(){ sql_pid=$(ps -ef |egrep redis-server |egrep -v root |awk '{print $2}') [ ! -z ${sql_pid} ] \u0026\u0026 echo -e \"\\n\\033[31mredis running...\\033[0m\\n\" \u0026\u0026 exit su ${sql_user} -s /bin/bash -c \"${REDIS_PATH}/bin/redis-server ${sql_conf_file}\" } stop_redis(){ sql_pid=$(ps -ef |egrep redis-server |egrep -v root |awk '{print $2}') [ -z ${sql_pid} ] \u0026\u0026 echo -e \"\\n\\033[31mredis not run...\\033[0m\\n\" \u0026\u0026 exit su swadmin -s /bin/bash -c \"kill ${sql_pid}\" } ### Finally the input handling. case \"$1\" in start) start_redis ;; stop) stop_redis ;; *) echo \"Usage: service redis {start|stop}\" exit 1 ;; esac exit '\u003e /etc/init.d/redis $ chmod +x /etc/init.d/redis $ chkconfig redis on 部署脚本 $ cat \u003eredis-install.sh\u003c\u003cEOF #!/bin/bash sed -i \"N;56isource /opt/rh/devtoolset-9/enable\" /etc/profile id swadmin if [ $? -ne 0 ];then # 创建普通用户部署运行Redis groupadd swadmin \u0026\u0026 useradd -g swadmin swadmi sleep 1 echo \"20210623@123\"|passwd --stdin2 swadmin \u0026\u003e/dev/null # 给swadmin用户设置密码 fi mkdir -p /opt/{src,conf,data,apps} /opt/data/{data_17693,data_17694,data_17695,data_16303} chown -R swadmin. /opt/* echo \"##### Start/Stop Service ##### Cmnd_Alias SWADMIN_START_SERVICES = /etc/init.d/redis, /opt/* # 授予普通用户启动停止权限 swadmin ALL=(ALL)NOPASSWD:SWADMIN_START_SERVICES\" \u003e/etc/sudoers.d/swadmin chmod 660 /etc/sudoers.d/swadmin # Redis依赖gcc 与gcc-c++,#Redis5.0以上需要高版本gcc yum -y install gcc gcc-c++ centos-release-scl wget git yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils echo 'scl enable devtoolset-9 bash' echo \"source /opt/rh/devtoolset-9/enable\" \u003e\u003e/etc/profile source /etc/profile ## 如遇因缺少gcc报错先执行 ## make distclean 再meke su swadmin -c \" git clone https://admin:\"frTd3KbJct_pgoBstA5f\"@gitlab.com/usererge/redis-conf.git /opt/conf/ wget -P /opt/src/ http://download.redis.io/releases/redis-5.0.7.tar.gz mkdir -p /opt/apps/redis \u0026\u0026 tar zxvf /opt/src/redis-5.0.7.tar.gz -C /opt/apps/redis --strip-components 1 cd /opt/apps/redis/ make MALLOC=libc make PREFIX=/opt/apps/redis install /opt/apps/redis/src/redis-server /opt/conf/redis-conf/re_17693.conf \u0026 \" source /etc/profile EOF ",
    "description": "Redis安装 名称地址 描述 Redis安装包 Redis依赖gcc与gcc-c++，而Redis5.0以上需要更高版本gcc 安装Gcc # Debian系统 $ sudo apt-get install wget gcc make pkg-config $ yum -y install gcc gcc-c++ centos-release-scl wget git 安装高版本gcc $ yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils # 临时生效 $ echo 'scl enable devtoolset-9 bash' # 添加到环境变量永久生效 $ echo \"source /opt/rh/devtoolset-9/enable\" \u003e\u003e/etc/profile $ source /etc/profile $ echo 'scl enable devtoolset-9 bash' \u003e\u003e ~/.",
    "tags": [],
    "title": "Install_Redis",
    "uri": "/systems/linux/nosql/install_redis/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "Redis集群部署 Redis主从模式 单节点主从模式需要修改端口以及配置文件 主节点redis.conf配置文件 daemonize yes # redis后台运行 pidfile /usr/local/redis/logs/redis_6379.pid # Redis的pid文件存放位置 logfile /usr/local/redis/logs/redis_6379.log # Redis的日志文件存放位置 port 6379 # 端口号 bind 192.168.176.131 # 最好是本机IP timeout 300 # 超时时间300秒 databases 8 # 缓存库的个数 dbfilename dump-16379.db # 将数据库转储到的文件名 dir ./ # 数据存放目录 masterauth password # 主库密码 requirepass password # 登录连接密码 从节点redis.conf配置文件，第二台从节点修改：bind为自己服务器本身ip daemonize yes # redis后台运行 pidfile /usr/local/redis/logs/redis_6379.pid # 不同实例修改为对应pid文件 logfile /usr/local/redis/logs/redis_6379.log port 6379 bind 192.168.176.132 timeout 300 databases 16 dbfilename dump-16379.db dir ./ # 数据存放目录 masterauth 123456 # 填写主库密码 requirepass 123456 # 登录连接密码 slaveof 192.168.176.131 6379 # 连接的主库IP和端口号 Redis Cluster模式 集群模式最少6个节点 修改配置文件 dir /usr/local/redis-cluster/data/redis-6379 # 修改为对应实例数据存放目录 pidfile /usr/local/redis-cluster/logs/redis_6379.pid # 修改为对应实例：Pid logfile /usr/local/redis-cluster/logs/redis_6379.log # 修改为对应实例 port 6379 # 端口号 cluster-enabled yes # 开启集群模式，把注释#去掉 cluster-config-file /usr/local/redis-cluster/conf/redis_16379.conf # 不同实例修改为对应 cluster-node-timeout 10000 # 请求超时，设置10秒 appendonly yes # aof日志开启，有需要就开启，它会每次写操作都记录一条日志 Redis5.0以上版本使用Redis-cli客户端部署 部署集群需要防火墙开放集群端口互通如端口是：6379 集群端口就是：16379 $ /opt/apps/redis/bin/redis-cli -a password --cluster create --cluster-replicas 1 \\ 192.168.213.128:6379 192.168.213.128:6380 192.168.213.128:6381 \\ 192.168.213.129:6379 192.168.213.129:6380 192.168.213.129:6381 脚本部署Redis-Cluster $ echo '#!bin/bash pkill redis-server cd /opt/conf/redis-conf/ sed -i 's/^#cluster-enabled/cluster-enabled/' re_17693.conf cat re_17693.conf |tee re_1769{4..5}.conf chown -R swadmin. * sed -i \"s/17693/17694/g\" re_17694.conf sed -i \"s/17693/17695/g\" re_17695.conf /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17693.conf \u0026 /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17694.conf \u0026 /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17695.conf \u0026 firewall-cmd --permanent --new-ipset=redis_whitelist --type=hash:ip firewall-cmd --permanent --add-rich-rule 'rule family=ipv4 source ipset=redis_whitelist port protocol=tcp port=27693-27695 accept' firewall-cmd --permanent --add-rich-rule 'rule family=ipv4 source ipset=redis_whitelist port protocol=tcp port=17693-17695 accept' read -p \"请输入对方服务器IP:\" IP firewall-cmd --permanent --ipset=redis_whitelist --add-entry=$IP firewall-cmd --reload #echo 'yes' |/opt/apps/redis/bin/redis-cli -a \\ 9tN6GFGK60Jk8BNkBJM611GwA66uDFeG \\ --cluster create --cluster-replicas 1 \\ 192.168.213.128:17693 192.168.213.128:17694 \\ 192.168.213.128:17695 192.168.213.129:17693 \\ 192.168.213.129:17694 192.168.213.129:17695 #创建集群命令根据IP和端口修改 '\u003eredis-cluster.sh docker部署Redis集群 Docker方式部署redis-cluster $ cat \u003edocker-install-redis-cluster.sh\u003c\u003c-EOF #!/bin/bash #------------ bootstrap the cluster nodes -------------------- start_cmd='redis-server --port 6379 --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes --masterauth Redis --requirepass Redis' redis_image='redis:5.0-rc' network_name='redis_cluster_net' docker network create $network_name echo $network_name \" created\" #---------- create the cluster ------------------------ for port in `seq 6379 6384`; do \\ docker run -d --name \"redis-\"$port -p $port:6379 --net $network_name $redis_image $start_cmd; echo \"created redis cluster node redis-\"$port done cluster_hosts='' for port in `seq 6379 6384`; do \\ hostip=`docker inspect -f '{{(index .NetworkSettings.Networks \"redis_cluster_net\").IPAddress}}' \"redis-\"$port`; echo \"IP for cluster node redis-\"$port \"is\" $hostip cluster_hosts=\"$cluster_hosts$hostip:6379 \"; done echo \"cluster hosts \"$cluster_hosts echo \"creating cluster....\" echo 'yes' | docker run -i --rm --restart=always -v /etc/localtime:/etc/localtime --net $network_name $redis_image redis-cli -a Redis --cluster create $cluster_hosts --cluster-replicas 1; EOF Redis 5.0以下版本 名称地址 描述 如何在CentOS 7上安装Ruby CentOS 7安装Ruby on Rails Linux安装Ruby详解(在线和离线安装) CentOS 7通过RVM来安装指定版本的Ruby 安装Ruby Redis 5.0以下版本使用Ruby方式安装Redis集群 $ echo '#!/bin/bash yum install gcc-c++ patch readline readline-devel zlib zlib-devel libyaml-devel libffi-devel openssl-devel make bzip2 autoconf automake libtool bison iconv-devel -y #安装依赖库 gpg2 --keyserver hkp://keys.gnupg.net --recv-keys D39DC0E3 #安装RVM curl -sSL https://rvm.io/mpapis.asc | gpg2 --import - curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import - curl -L get.rvm.io | bash -s stable sleep 2 source /etc/profile.d/rvm.sh #设定rvm环境 sleep 3 rvm -v #查看是否安装正常 rvm list known #查询当前Ruby的版本列表 rvm install 2.4.6 #安装指定版本的Ruby ruby -v #测试是否成功 rvm use 2.4.6 --default #在安装多个版本ruby环境下指定默认版本：这里讲2.4.6 作为默认ruby版本 rvm system --default #使用会系统默认版本Ruby gem install redis 准备rubygem redis依赖 ' \u003einstall-ruby.sh 拷贝redis-trib.rb到集群根目录 redis-trib.rb 是redis官方推出的管理redis集群 的工具，集成在redis的源码src目录下，将基于 redis提供的 集群命令 封装成 简单、便捷、实用 的 操作工具 $ cp /opt/apps/redis/src/redis-trib.rb /opt/apps/redis/ 查看redis-trib.rb命令环境是否正确，输出如下 $ ./redis-trib.rb Usage: redis-trib \u003ccommand\u003e \u003coptions\u003e \u003carguments ...\u003e create host1:port1 ... hostN:portN --replicas \u003carg\u003e check host:port info host:port fix host:port --timeout \u003carg\u003e reshard host:port --from \u003carg\u003e --to \u003carg\u003e --slots \u003carg\u003e --yes --timeout \u003carg\u003e --pipeline \u003carg\u003e rebalance host:port --weight \u003carg\u003e --auto-weights --use-empty-masters --timeout \u003carg\u003e --simulate --pipeline \u003carg\u003e redis-trib.rb是redis作者用ruby完成的。redis-trib.rb命令行工具 的具体功能如下: 命令 作用 create 创建集群 check 检查集群 info 查看集群信息 fix 修复集群 reshard 在线迁移slot rebalance 平衡集群节点slot数量 add-node 将新节点加入集群 del-node 从集群中删除节点 set-timeout 设置集群节点间心跳连接的超时时间 call 在集群全部节点上执行命令 import 将外部redis数据导入集群 运行命令启动所有节点 $ /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17693.conf \u0026 $ /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17694.conf \u0026 $ /opt/apps/redis/bin/redis-server /opt/conf/redis-conf/re_17695.conf \u0026 在每个redis节点的redis.conf文件中，我们都配置了cluster-config-file的文件路径，集群启动时conf目录会新生成 集群 节点配置文件。查看文件列表如下： $ yum -y install tree $ tree -L 3 . . ├── bin │ ├── redis-benchmark │ ├── redis-check-aof │ ├── redis-check-rdb │ ├── redis-cli │ ├── redis-sentinel -\u003e redis-server │ └── redis-server ├── nodes-6379.conf ├── redis.conf └── redis-trib.rb 配置密码 $ vim /usr/local/rvm/gems/ruby-2.4.6/gems/redis-4.1.3/lib/redis/client.rb # frozen_string_literal: true require_relative \"errors\" require \"socket\" require \"cgi\" class Redis class Client DEFAULTS = { :url =\u003e lambda { ENV[\"REDIS_URL\"] }, :scheme =\u003e \"redis\", :host =\u003e \"127.0.0.1\", :port =\u003e 6379, :path =\u003e nil, :timeout =\u003e 5.0, :password =\u003e Redis, # 配置密码 :db =\u003e 0, :driver =\u003e nil, :id =\u003e nil, :tcp_keepalive =\u003e 0, :reconnect_attempts =\u003e 1, :reconnect_delay =\u003e 0, :reconnect_delay_max =\u003e 0.5, :inherit_socket =\u003e false } redis-trib关联集群节点 按照从主到从的方式从左到右依次排列 6 个redis节点，如果不通两个问题：密码、防火墙 $ echo 'yes'|./redis-trib.rb create --replicas 1 192.168.176.142:6379 192.168.176.143:6379 192.168.176.144:6379 192.168.176.145:6379 192.168.176.142:6380 192.168.176.143:6380 192.168.176.144:6380 192.168.176.145:6380 \u003e\u003e\u003e Creating cluster \u003e\u003e\u003e Performing hash slots allocation on 8 nodes... Using 4 masters: 192.168.176.142:6379 192.168.176.143:6379 192.168.176.144:6379 192.168.176.145:6379 Adding replica 192.168.176.143:6380 to 192.168.176.142:6379 Adding replica 192.168.176.142:6380 to 192.168.176.143:6379 Adding replica 192.168.176.145:6380 to 192.168.176.144:6379 Adding replica 192.168.176.144:6380 to 192.168.176.145:6379 M: 157bd250dd382b95a9289d8b44fd2cfd466fea98 192.168.176.142:6379 slots:0-4095 (4096 slots) master M: c6df79e7c60c03921b69e4d4342507e8d4d2afbd 192.168.176.143:6379 slots:4096-8191 (4096 slots) master M: a463232f96c66cd7f27395253b65d0be8909656e 192.168.176.144:6379 slots:8192-12287 (4096 slots) master M: 44b244a188185835b42d4489eac614e7f81b4cf8 192.168.176.145:6379 slots:12288-16383 (4096 slots) master S: 1cafdeeb6cb52bb96dd16ac84d2242f59973f83a 192.168.176.142:6380 replicates c6df79e7c60c03921b69e4d4342507e8d4d2afbd S: a6d87fb995f3f5e98e2a09f4b5a3078f7221a257 192.168.176.143:6380 replicates 157bd250dd382b95a9289d8b44fd2cfd466fea98 S: 31a3f0b03244d30bbc7e47acc0ec06d327b62860 192.168.176.144:6380 replicates 44b244a188185835b42d4489eac614e7f81b4cf8 S: fc22025eb5db7cc0d55fe7dc11a3c368daa468bb 192.168.176.145:6380 replicates a463232f96c66cd7f27395253b65d0be8909656e Can I set the above configuration? (type 'yes' to accept): yes #此处输入：yes、然后redis-trib.rb 开始执行 节点握手 和 槽分配 操作，输出如下： \u003e\u003e\u003e Nodes configuration updated \u003e\u003e\u003e Assign a different config epoch to each node \u003e\u003e\u003e Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join.... \u003e\u003e\u003e Performing Cluster Check (using node 192.168.176.142:6379) M: 157bd250dd382b95a9289d8b44fd2cfd466fea98 192.168.176.142:6379 slots:0-4095 (4096 slots) master 1 additional replica(s) S: 31a3f0b03244d30bbc7e47acc0ec06d327b62860 192.168.176.144:6380 slots: (0 slots) slave replicates 44b244a188185835b42d4489eac614e7f81b4cf8 M: a463232f96c66cd7f27395253b65d0be8909656e 192.168.176.144:6379 slots:8192-12287 (4096 slots) master 1 additional replica(s) M: 44b244a188185835b42d4489eac614e7f81b4cf8 192.168.176.145:6379 slots:12288-16383 (4096 slots) master 1 additional replica(s) S: fc22025eb5db7cc0d55fe7dc11a3c368daa468bb 192.168.176.145:6380 slots: (0 slots) slave replicates a463232f96c66cd7f27395253b65d0be8909656e M: c6df79e7c60c03921b69e4d4342507e8d4d2afbd 192.168.176.143:6379 slots:4096-8191 (4096 slots) master 1 additional replica(s) S: a6d87fb995f3f5e98e2a09f4b5a3078f7221a257 192.168.176.143:6380 slots: (0 slots) slave replicates 157bd250dd382b95a9289d8b44fd2cfd466fea98 S: 1cafdeeb6cb52bb96dd16ac84d2242f59973f83a 192.168.176.142:6380 slots: (0 slots) slave replicates c6df79e7c60c03921b69e4d4342507e8d4d2afbd [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. redis集群完整性检 使用redis-trib.rb check命令检测之前创建的 两个集群 是否成功，check命令只需要给出集群中 任意一个节点地址 就可以完成 整个集群 的 检查工作，命令如下： $ ./redis-trib.rb check 192.168.176.145:6379 \u003e\u003e\u003e Performing Cluster Check (using node 192.168.176.142:6379) M: 157bd250dd382b95a9289d8b44fd2cfd466fea98 192.168.176.142:6379 slots:0-4095 (4096 slots) master 1 additional replica(s) S: 31a3f0b03244d30bbc7e47acc0ec06d327b62860 192.168.176.144:6380 slots: (0 slots) slave replicates 44b244a188185835b42d4489eac614e7f81b4cf8 M: a463232f96c66cd7f27395253b65d0be8909656e 192.168.176.144:6379 slots:8192-12287 (4096 slots) master 1 additional replica(s) M: 44b244a188185835b42d4489eac614e7f81b4cf8 192.168.176.145:6379 slots:12288-16383 (4096 slots) master 1 additional replica(s) S: fc22025eb5db7cc0d55fe7dc11a3c368daa468bb 192.168.176.145:6380 slots: (0 slots) slave replicates a463232f96c66cd7f27395253b65d0be8909656e M: c6df79e7c60c03921b69e4d4342507e8d4d2afbd 192.168.176.143:6379 slots:4096-8191 (4096 slots) master 1 additional replica(s) S: a6d87fb995f3f5e98e2a09f4b5a3078f7221a257 192.168.176.143:6380 slots: (0 slots) slave replicates 157bd250dd382b95a9289d8b44fd2cfd466fea98 S: 1cafdeeb6cb52bb96dd16ac84d2242f59973f83a 192.168.176.142:6380 slots: (0 slots) slave replicates c6df79e7c60c03921b69e4d4342507e8d4d2afbd [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. Redis Sentinel模式 Redis Sentinel哨兵模式 节点-1sentinel_16380.conf protected-mode no bind 192.168.176.131 # 本机IP port 16380 daemonize yes sentinel monitor master 192.168.176.131 6379 2 # 主IP与端口号 sentinel down-after-milliseconds master 5000 # 指定主节点应答哨兵sentinel的最大时间间隔，超过这个时间，哨兵主观上认为主节点下线，默认30秒 sentinel failover-timeout master 180000 # 故障转移的超时时间failover-timeout，默认三分钟，可以用在以下这些方面 sentinel parallel-syncs master 1 # 指定了在发生failover主备切换时，最多可以有多少个slave同时对新的master进行同步。这个数字越小，完成failover所需的时间就越长；反之，但是如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为1，来保证每次只有一个slave，处于不能处理命令请求的状态。 sentinel auth-pass master 123456 # 当在Redis实例中开启了requirepass \u003cfoobared\u003e，所有连接Redis实例的客户端都要提供密码 logfile /var/log/redis/sentinel_16380.log 节点2~3centinel_16380.conf protected-mode no bind 192.168.176.132 # 此处修改为本机IP port 16380 daemonize yes sentinel monitor master 192.168.176.131 6379 2 # 主IP与端口号 sentinel down-after-milliseconds master 5000 sentinel failover-timeout master 180000 sentinel parallel-syncs master 1 sentinel auth-pass master 123456 logfile /var/log/redis/sentinel_16380.log ",
    "description": "Redis集群部署 Redis主从模式 单节点主从模式需要修改端口以及配置文件 主节点redis.conf配置文件 daemonize yes # redis后台运行 pidfile /usr/local/redis/logs/redis_6379.pid # Redis的pid文件存放位置 logfile /usr/local/redis/logs/redis_6379.",
    "tags": [],
    "title": "Install_Redis_Cluster",
    "uri": "/systems/linux/nosql/install_redis_cluster/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "Cassandra 名称地址 描述 开源NoSQL数据库Cassandra ",
    "description": "Cassandra 名称地址 描述 开源NoSQL数据库Cassandra ",
    "tags": [],
    "title": "Install_Cassandra",
    "uri": "/systems/linux/nosql/install_cassandra/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "Aerospike 名称地址 描述 Aerospike Aerospike安装文档 ",
    "description": "Aerospike 名称地址 描述 Aerospike Aerospike安装文档 ",
    "tags": [],
    "title": "Install_Aerospike",
    "uri": "/systems/linux/nosql/install_aerospike/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Nosql",
    "content": "编写启动文件 名称地址 描述 深入剖析Redis系列 深入学习Redis持久化 Redis集群增加节点和删除节点 RedisShake、redis-shake-linux-amd64.tar.gz Redis迁移工具 redis-shake使用RDB文件迁移数据 Redis桌面连接工具 https://github.com/uglide/RedisDesktopManager/releases/tag/0.8.8 # 下载客户端连接工具 Redis 0.8.8 https://github.com/uglide/RedisDesktopManager/releases/tag/0.9.3 # 下载客户端连接工具 Redis 0.9.3 https://github.com/qishibo/AnotherRedisDesktopManager/releases # windows系统远程连接工具 https://github.com/quick123official/quick_redis_blog/releases Redis常用命令 # 查看Redis具体IP连接数 $ netstat -n |grep 17693 |awk '/^tcp/ {print $5}'| awk -F: '{print $1}'|sort | uniq -c | sort -rn # 统计Redis在线人数 $ redis-cli -h 127.0.0.1 -p 6379 -c -a \"password\" KEYS SPORTS:session:* 2\u003c/dev/null | awk \"{print $2}\"| awk -F\":\" ' {print $2,$3}'| sed -e \"s/^/${date}: /g\" 127.0.0.1:6379\u003e type 键值 # 查看值的类型 127.0.0.1:6379\u003e HGET # 获取键值数据 127.0.0.1:6379\u003e HGETALL # 获取键值数据 127.0.0.1:6379\u003e CONFIG GET databases # 数据库的数量 127.0.0.1:6379\u003e INFO keyspace # 使用以下命令列出定义了某些键的数据库 127.0.0.1:6379\u003e SELECT 14 # 切换14db 127.0.0.1:6379\u003e info clients # 查看客户端连接 127.0.0.1:6379\u003e client list # 列出所有连接 127.0.0.1:6379\u003e CONFIG GET maxclients # 获取支持最大连接数 # 127.0.0.1:6379\u003e save # 收到触发rdb存储数据 OK 127.0.0.1:6379\u003e CONFIG SET appendonly yes # 动态配置 OK 127.0.0.1:6379\u003e save OK 127.0.0.1:6379\u003e shutdown save # 安全退出并存储数据 not connected\u003e ",
    "description": "编写启动文件 名称地址 描述 深入剖析Redis系列 深入学习Redis持久化 Redis集群增加节点和删除节点 RedisShake、redis-shake-linux-amd64.tar.gz Redis迁移工具 redis-shake使用RDB文件迁移数据 Redis桌面连接工具 https://github.",
    "tags": [],
    "title": "Configure_Redis",
    "uri": "/systems/linux/nosql/configure_redis/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "部署Zabbix监控系统 基础配置环境要求 名称地址 描述 Zabbix部署文档 下载安装Zabbix 部署Zabbix硬件要求 名称 平台 CPU/内存 数据库 受监控的主机 小型 CentOS 虚拟设备 MySQL InnoDB 100 中型 CentOS 2个CPU内核/2GB MySQL InnoDB 500 大型 RedHat Enterprise Linux 4个CPU内核/8GB RAID10 MySQL InnoDB或 PostgreSQL \u003e1000 超大型 RedHat Enterprise Linux 8个CPU内核/16GB RAID10 MySQL InnoDB或 PostgreSQL \u003e10000 部署Zabbix数据库版本要求 数据库 支持版本 推荐版本 备注 MySQL/Percona 5.7.28-8.0.X 8.0.X 如果MySQL或Percona用作Zabbix后端数据库，则需要。需要InnoDB引擎。我们建议使用MariaDB Connector/C库来构建服务器/代理 MariaDB 10.0.37-10.6.X 10.5.X InnoDB引擎是必需的。我们建议使用MariaDB Connector/C 库来构建服务器/代理 PostgreSQL 10.9-13.X 12.X.X或更新 使用PostgreSQL作为Zabbix后端数据库。建议使用PostgreSQL 8.3以上的版本, 以 提供更好的VACUUM性能。 SQLite 3.3.5-3.34.X 3.3X.X 仅支持Zabbix代理。如果SQLite用作Zabbix代理数据库 $ systemctl start mariadb $ mysql -uroot -e \"create database zabbix character set utf8mb4 collate utf8mb4_bin;\" $ mysql -uroot -e \"create user 'zabbix'@'localhost' identified by 'zabbix';\" $ mysql -uroot -e \"grant all privileges on zabbix.* to 'zabbix'@'localhost';\" $ mysql -uroot -e \"flush privileges;\" 安装Zabbix前准备 卸载原有数据库，安装高版本 $ yum remove -y mariadb* 创建用户 $ groupadd --system zabbix $ useradd --system -g zabbix -d /usr/lib/zabbix -s /sbin/nologin -c \"Zabbix Monitoring System\" zabbix 创建所需目录 $ mkdir /opt/{src,zabbix} $ chown zabbix:zabbix /opt/* 3.4 安装依赖 $ yum -y install epel-release wget unixODBC-devel net-snmp-devel libevent-devel \\ libxml2-devel libcurl-devel java-1.6.0-openjdk-devel gcc gcc-c++ \\ mariadb mariadb-server mariadb-devel $ yum -y install go # Debian 系统 $ sudo apt-get install libxml2 libxml2-dev libsnmp-dev libevent-dev openjdk-11-jdk \\ libcurl4-openssl-dev 安装Zabbix Server 下载Zabbix Server编译安装包 $ wget -P /opt/src/ https://cdn.zabbix.com/zabbix/sources/stable/6.0/zabbix-6.0.14.tar.gz 解压配置Zabbix Server安装包 $ tar -zxvf /opt/src/zabbix-6.0.14.tar.gz -C /opt/src/ $ cd /opt/src/zabbix-6.0.14/ # 编译安装路径 $ ./configure --prefix=/opt/zabbix --enable-server --enable-agent --enable-ipv6 \\ --with-net-snmp --with-libcurl --with-libxml2 --enable-java --with-openssl \\ --with-mysql=/usr/local/mysql/bin/mysql_config $ make -j2 \u0026\u0026 make install 拷贝Zabbix Server启动文件给予执行权限 $ cp /opt/src/zabbix-6.0.14/misc/init.d/fedora/core/zabbix_* /etc/init.d/ $ chmod +x /etc/init.d/zabbix_* 启动数据库导入Zabbix SQL文件后再启动Zabbix Server $ ll /opt/src/zabbix-6.0.14/database/mysql/ | grep *.sql $ mysql -uzabbix -p'zabbix' zabbix \u003c /opt/src/zabbix-6.0.14/database/mysql/schema.sql $ mysql -uzabbix -p'zabbix' zabbix \u003c /opt/src/zabbix-6.0.14/database/mysql/images.sql $ mysql -uzabbix -p'zabbix' zabbix \u003c /opt/src/zabbix-6.0.14/database/mysql/data.sql $ mysql -uzabbix -p'zabbix' zabbix \u003c /opt/src/zabbix-6.0.14/database/mysql/double.sql $ mysql -uzabbix -p'zabbix' zabbix \u003c /opt/src/zabbix-6.0.14/database/mysql/history_pk_prepare.sql 修改zabbix_server配置文件 $ cat \u003e/opt/zabbix/etc/zabbix_server.conf\u003c\u003c-EOF DBHost=localhost # 数据库地址 DBName=zabbix # 数据库名 DBUser=root # 连接数据库的用户 DBPassword=123456 # 密码 DBSocket=/home/ops/opt/mysql/mysql.sock # 数据库sock文件路径 DBPort=3306 # 端口 LogFile=/opt/zabbix_server/logs/zabbix_server.log # 日志文件 PidFile=/opt/zabbix_server/logs/zabbix_server.pid # 保存pid的文件 SocketDir=/opt/zabbix/logs EOF 拷贝Zabbix前端文件，到Nginx的web目录 $ sudo cp -rf /opt/src/zabbix-6.0.14/ui/* /usr/local/nginx/html/zabbix/ Docker安装Zabbix Server 从Docker容器安装、欢迎使用Leeks的笔记 创建专用于Zabbix组件容器的网络 $ docker network create --subnet 172.20.0.0/16 \\ --ip-range 172.20.100.0/20 zabbix-net 启动空MySQL服务器实例数据库8.0以上 $ docker run -v /etc/localtime:/etc/localtime \\ --name mysql-server -t \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=${zabbix_pwd} \\ -e MYSQL_ROOT_PASSWORD=${root_pwd} \\ --network=zabbix-net \\ --restart unless-stopped \\ -d mysql:8.0 \\ --character-set-server=utf8 --collation-server=utf8_bin \\ --default-authentication-plugin=mysql_native_password 启动Zabbix Java网关实例 $ docker run -v /etc/localtime:/etc/localtime \\ --name zabbix-java-gateway -t \\ --network=zabbix-net \\ --restart unless-stopped \\ -d zabbix/zabbix-java-gateway:alpine-6.0-latest 启动Zabbix服务器实例并将该实例与创建的MySQL服务器实例链接 启动Zabbix服务器实例并将该实例与创建的MySQL服务器实例链接 $ docker volume create zabbix-server-volume $ docker run -v /etc/localtime:/etc/localtime \\ --name zabbix-server-mysql -t \\ --link zabbix-web-service:zabbix-web-service \\ -e DB_SERVER_HOST=\"mysql-server\" \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=${zabbix_pwd} \\ -e MYSQL_ROOT_PASSWORD=${root_pwd} \\ -e ZBX_JAVAGATEWAY=\"zabbix-java-gateway\" \\ -e ZBX_STARTREPORTWRITERS=\"2\" \\ -e ZBX_WEBSERVICEURL=\"http://zabbix-web-service:10053/report\" \\ -v zabbix-server-volume:/etc/zabbix \\ -v ${server_dir}/server/alertscripts:/usr/lib/zabbix/alertscripts \\ -v ${server_dir}/server/externalscripts:/usr/lib/zabbix/externalscripts \\ -v ${server_dir}/server/modules:/usr/lib/zabbix/modules \\ --network=zabbix-net \\ -p 10051:10051 \\ --restart unless-stopped \\ -d zabbix/zabbix-server-mysql:alpine-6.0-latest 启动Zabbix Web界面并将实例与创建的MySQL服务器和Zabbix服务器实例链接 Zabbix Web界面实例向主机公开80/TCP端口 HTTP $ docker run -v /etc/localtime:/etc/localtime \\ --name zabbix-web-nginx-mysql -t \\ -e ZBX_SERVER_HOST=\"zabbix-server-mysql\" \\ -e DB_SERVER_HOST=\"mysql-server\" \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=${zabbix_pwd} \\ -e MYSQL_ROOT_PASSWORD=${root_pwd} \\ -e ZBX_SERVER_NAME=\"${zabbix_server_name}\" \\ --network=zabbix-net \\ -p 8080:8080 \\ --restart unless-stopped \\ -d zabbix/zabbix-web-nginx-mysql:alpine-6.0-latest 安装Zabbix Proxy服务 $ docker run --name zabbix-proxy-mysql \\ -e DB_SERVER_HOST=\"mysql-server\" \\ -e MYSQL_USER=\"user\" \\ -e MYSQL_PASSWORD=\"some-password\" \\ -e ZBX_HOSTNAME=some-hostname \\ -e ZBX_SERVER_HOST=some-zabbix-server \\ -d zabbix/zabbix-proxy-mysql:alpine-6.0-latest 配置Nginx使浏览器访问Zabbix $ sudo cat \u003e/usr/local/nginx/conf/vhosts/zabbix.conf\u003c\u003c-EOF server{ listen 80; server_name zabbix.com; location / { root /usr/local/nginx/html/zabbix; index index.php index.html index.htm; # 添加\"index.php\" } # tcp socket 通信模式 location ~ \\.php$ { root\t/usr/local/nginx/html/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param行改成这个。 include fastcgi_params; } # Unix socke 通信模式 location ~ \\.php(.*)$ { root\t/usr/local/nginx/html/zabbix; fastcgi_pass unix:/tmp/php7.sock; fastcgi_index index.php; fastcgi_split_path_info ^((?U).+\\.php)(/?.+)$; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; include fastcgi_params; } error_page 404 http://zabbix.com; access_log /usr/local/nginx/logs/zabbix-access.log main; error_log /usr/local/nginx/logs/zabbix-error.log info; } EOF 启动Zabbix服务端和客户端 # Debian 系统需执行 $ sudo ln -s /usr/local/mysql/lib/libmysqlclient.so.20 /usr/lib/libmysqlclient.so.20 $ /opt/zabbix/sbin/zabbix_server # 启动 Zabbix Server $ /opt/zabbix/sbin/zabbix_agentd # 启动 Zabbix Agentd 处理访问页面后没有中文选项 # 列出说有支持的语言 $ locale -a # 如果没有想要的语言环境，打开下方文件找到需要的语言取消注释 $ sudo cat \u003e/etc/locale.gen\u003c\u003c-EOF # zh_CN.UTF-8 UTF-8 EOF # 重载语言环境 $ sudo locale-gen # 重启PHP使配置生效，然后刷新浏览器 $ sudo /etc/init.d/php-fpm restart web页面配置zabbix 下方图片显示要修改的PHP配置文件,修改后重启php-fpm $ sed -i \"s/post_max_size = 8M/post_max_size = 16M/g\" /usr/local/php/etc/php.ini $ sed -i \"s/max_execution_time = 30/max_execution_time = 300/g\" /usr/local/php/etc/php.ini $ sed -i \"s/max_input_time = 60/max_input_time = 300/g\" /usr/local/php/etc/php.ini 连接数据库报错 $ ln -s /var/lib/mysql/mysql.sock /tmp/ 默认帐户：Admin，默认密码：zabbix 处理图形汉字乱码 $ rz /usr/local/nginx/html/assets/fonts $ mv simhei.ttf DejaVuSans.ttf 编译安装Zabbix Agent 部署前准备 $ mkdir /opt/{src,zabbix-agent} 下载安装包 $ yum -y install wget $ wget -P /opt/src/ https://cdn.zabbix.com/zabbix/binaries/stable/6.0/6.0.14/zabbix_agent-6.0.14-linux-3.0-amd64-static.tar.gz $ tar -zxvf /opt/src/zabbix_agent-6.0.14-linux-3.0-amd64-static.tar.gz -C /opt/zabbix-agent 修改Zabbix Agent配置文件 $ cat \u003e/opt/zabbix-agent/conf/zabbix_agentd.conf\u003c\u003c-EOF Server=127.0.0.1 # 添加Zabbix Server服务器IP ServerActive=127.0.0.1 # 替换为Zabbix Server服务器IP Hostname=本机主机名 # 被监控端自己的主机名 AllowKey=system.run[*] # 监控异常后，是否允许服务器远程过来执行命令，如重启某个服务 UnsafeUserParameters=1 # 是否允许自定义key监控 EOF 启动Zabbix Agent $ /opt/zabbix-agent/sbin/zabbix_agentd -c /opt/zabbix-agent/conf/zabbix_agentd.conf 配置Zabbix通信加密 申请证书 # 生成ca私钥 $ openssl genrsa 2048 \u003e ca.key # 使用ca私钥建立ca证书 $ openssl req -new -x509 -nodes -days 1000 -key ca.key -subj /CN=Signing\\ CA/OU=Development\\ group/O=Zabbix\\ SIA/DC=zabbix/DC=com \u003e ca.crt # 生成服务器csr证书请求文件 $ openssl req -newkey rsa:2048 -days 1000 -nodes -keyout server.key -subj /CN=server/OU=Development\\ group/O=Zabbix\\ SIA/DC=zabbix/DC=com \u003e server.csr # 使用ca证书与私钥签发服务器证书 $ openssl x509 -req -in server.csr -days 1000 -CA ca.crt -CAkey ca.key -set_serial 01 \u003e server.crt # 生成客户端csr证书请求文件 $ openssl req -newkey rsa:2048 -days 1000 -nodes -keyout client.key -subj /CN=client/OU=Development\\ group/O=Zabbix\\ SIA/DC=zabbix/DC=com \u003e client.csr # 使用ca证书与私钥签发客户端证书 $ openssl x509 -req -in client.csr -days 1000 -CA ca.crt -CAkey ca.key -set_serial 01 \u003e client.crt 配置Zabbix Server服务端 $ cat \u003e/opt/zabbix/etc/zabbix_server.conf\u003c\u003c-EOF # 修改TLSCAFile配置 TLSCAFile=/opt/zabbix_server/zabbix_crt/ca.crt # 修改TLSCertFile配置 TLSCertFile=/opt/zabbix_server/zabbix_crt/server.crt # 修改TLSKeyFile配置 TLSKeyFile=/opt/zabbix_server/zabbix_crt/server.key EOF 配置Zabbix Agent端 配置PSK加密 $ cat \u003e/opt/zabbix-agent/conf/zabbix_agentd.conf\u003c\u003c-EOF TLSPSKIdentity= PSK Name # 一致性共享密钥名称 TLSPSKFile= PSK File # PSK 共享密钥文件存放路径 EOF 配置证书加密 $ cat \u003e/opt/zabbix-agent/conf/zabbix_agentd.conf\u003c\u003c-EOF # 修改agent连接模式 TLSConnect=cert # 修改传入数据连接模式 TLSAccept=cert # 修改TLSCAFile配置 TLSCAFile=/opt/zabbix_agent/zabbix_crt/ca.crt # 修改TLSCertFile配置 TLSCertFile=/opt/zabbix_agent/zabbix_crt/client.crt # 修改TLSKeyFile配置 TLSKeyFile=/opt/zabbix_agent/zabbix_crt/client.key EOF ",
    "description": "部署Zabbix监控系统 基础配置环境要求 名称地址 描述 Zabbix部署文档 下载安装Zabbix 部署Zabbix硬件要求 名称 平台 CPU/内存 数据库 受监控的主机 小型 CentOS 虚拟设备 MySQL InnoDB 100 中型 CentOS 2个CPU内核/2GB MySQL InnoDB 500 大型 RedHat Enterprise Linux 4个CPU内核/8GB RAID10 MySQL InnoDB或 PostgreSQL \u003e1000 超大型 RedHat Enterprise Linux 8个CPU内核/16GB RAID10 MySQL InnoDB或 PostgreSQL \u003e10000 部署Zabbix数据库版本要求 数据库 支持版本 推荐版本 备注 MySQL/Percona 5.",
    "tags": [],
    "title": "Install_Zabbix",
    "uri": "/systems/linux/monitor/install_zabbix/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": " Prometheus 名称地址 描述 Prometheus官网 prometheus-book Github-Prometheus Prometheus学习笔记 Prometheus介绍和使用 Prometheus+Grafana详解 Prometheus自定义监控部署 Prometheus CLIENT LIBRARIES 使用Prometheus+Grafana快速打造高逼格监控平台 概述 Prometheus是一个开源监控系统，它前身是SoundCloud的告警工具包。从2012年开始，许多公司和组织开始使用Prometheus。该项目的开发人员和用户社区非常活跃，越来越多的开发人员和用户参与到该项目中。目前它是一个独立的开源项目，且不依赖于任何公司。为了强调这点和明确该项目治理结构，Prometheus在2016年继Kurberntes之后，加入了Cloud Native Computing Foundation\n1.1 prometheus特点 多维度数据模型，一个时间序列由一个度量指标和多个标签键值对确定 灵活的查询语言，对收集的时许数据进行重组 强大的数据可视化功能，除了内置的浏览器，也支持grafana集成 高效存储，内存加本地磁盘，可通过功能分片和联盟来拓展性能 运维简单，只依赖于本地磁盘，go二进制安装包没有任何其他依赖 精简告警 非常多的客户端库 提供了许多导出器来收集常用系统指标 数据模型 Prometheus从根本上存储的所有数据都是时间序列数据（Time Serie Data，简称时序数据）。时序数据是具有时间戳的数据流，该数据流属于某个度量指标（Metric）和该度量指标下的多个标签（Label）。除了提供存储功能，Prometheus还可以利用查询表达式来执行非常灵活和复杂的查询。\n度量指标和标签\n每个时间序列（Time Serie，简称时序）由度量指标和一组标签键值对唯一确定。\n度量指标名称描述了被监控系统的某个测量特征（比如http_requests_total表示http请求总数）。度量指标名称由ASCII字母、数字、下划线和冒号组成，须匹配正则表达式[a-zA-Z_:][a-zA-Z0-9_:]*。\n标签开启了Prometheus的多维数据模型。对于同一个度量指标，不同标签值组合会形成特定维度的时序。Prometheus的查询语言可以通过度量指标和标签对时序数据进行过滤和聚合。改变任何度量指标上的任何标签值，都会形成新的时序。标签名称可以包含ASCII字母、数字和下划线，须匹配正则表达式[a-zA-Z_][a-zA-Z0-9_]*，带有 _ 下划线的标签名称保留为内部使用。标签值可以包含任意Unicode字符，包括中文。\n采样值(Sample)\n时序数据其实就是一系列采样值。每个采样值包括：\n一个64位的浮点数值 一个精确到毫秒的时间戳 注解(Notation) 一个注解由一个度量指标和一组标签键值对构成。形式如下：\n[metric name]{[label name]=[label value], ...} 例如，度量指标为api_http_requests_total，标签为method=\"POST\"、handler=\"/messages\"的注解表示如下：\napi_http_requests_total{method=\"POST\", handler=\"/messages\"} 度量指标类型 计数器(Counter) 计数器是一种累计\b型的度量指标，它是一个只能递增的数值。计数器主要用于统计类似于服务请求数、任务完成数和错误出现次数这样的数据 计量器(Gauge) 计量器表示一个既可以增加, 又可以减少的度量指标值。计量器主要用于测量类似于温度、内存使用量这样的瞬时数据 直方图(Histogram) 直方图对观察结果（通常是请求持续时间或者响应大小这样的数据）进行采样，并在可配置的桶中对其进行统计。有以下几种方式来产生直方图（假设度量指标为 ）： 按桶计数 相当于\u003cbasename\u003e_bucket{le=\"\u003cupper inclusive bound\u003e\"} 采样值总和 相当于 \u003cbasename\u003e_sum 采样值总数 相当于 \u003cbasename\u003e_count ，也等同于把所有采样值放到一个桶里来计数 \u003cbasename\u003e_bucket{le=\"+Inf\"} 汇总(Summary) 类似于直方图，汇总也对观察结果进行采样。除了可以统计\b采样值总和和总数，它还能够按分位数\b统计。有以下几种方式来产生汇总（假设度量指标为 ）： 采样值总和 相当于 \u003cbasename\u003e_sum 采样值总数 相当于 \u003cbasename\u003e_count 任务(Job)和实例(Instance) 在Prometheus里，可以从中抓取采样值的端点称为实例，为了性能扩展而复制出来的多个这样的实例形成了一个任务\n例如下面的api-server任务有四个相同的实例 job: api-server instance 1: 1.2.3.4:5670 instance 2: 1.2.3.4:5671 instance 3: 5.6.7.8:5670 instance 4: 5.6.7.8:5671​\tPrometheus抓取完采样值后，会自动给采样值添加下面的标签和值：\njob: \b抓取所属任务\ninstance： 抓取来源实例\n另外每次抓取时，Prometheus还会自动在以下时序里插入采样值：\nup{job=\"[job-name]\", instance=\"instance-id\"}：采样值为 1 表示实例健康，否则为不健康\nscrape_duration_seconds{job=\"[job-name]\", instance=\"[instance-id]\"}：采样值为本次抓取消耗时间\nscrape_samples_post_metric_relabeling{job=\"\u003cjob-name\u003e\", instance=\"\u003cinstance-id\u003e\"}：采样值为重新\b打标签后的采样值个数 scrape_samples_scraped{job=\"\u003cjob-name\u003e\", instance=\"\u003cinstance-id\u003e\"}：采样值\b为本次抓取到的采样值个数 Prometheus与其他监控系统对比 Prometheus vs Zabbix Zabbix使用的是C和PHP, Prometheus使用Golang整体而言Prometheus运行速度更快一点 Zabbix属于传统主机监控，主要用于物理主机、交换机、网络等监控，Prometheus不仅适用主机监控，还适用于Cloud、SaaS、Openstack、Container监控 Zabbix在传统主机监控方面，有更丰富的插件 Zabbix可以在WebGui中配置很多事情，Prometheus需要手动修改文件配置 Prometheus vs Nagios Nagios数据不支持自定义Labels, 不支持查询，告警也不支持去噪、分组, 没有数据存储，如果想查询历史状态，需要安装插件 Nagios是上世纪 90 年代的监控系统，比较适合小集群或静态系统的监控Nagios太古老，很多特性都没有Prometheus要优秀很多 Prometheus vs Sensu Sensu广义上讲是Nagios的升级版本，它解决了很多Nagios的问题，如果你对Nagios很熟悉，使用Sensu是个不错的选择 Sensu依赖RabbitMQ和Redis，数据存储上扩展性更好 Prometheus vs InfluxDB InflusDB是一个开源的时序数据库，主要用于存储数据，如果想搭建监控告警系统，需要依赖其他系统 InfluxDB在存储水平扩展以及高可用方面做的更好, 毕竟核心是数据库 altermanager核心概念 分组 分组将类似性质的警报分类为单个通知。在许多系统一次性失败并且数百到数千个警报可能同时发生的较大中断期间，这尤其有用 示例：发生网络分区时，群集中正在运行数十或数百个服务实例。一半的服务实例无法再访问数据库。Prometheus中的警报规则配置为在每个服务实例无法与数据库通信时发送警报。结果，数百个警报被发送到Alertmanager 作为用户，人们只想获得单个页面，同时仍能够确切地看到哪些服务实例受到影响。因此，可以将Alertmanager配置为按群集和alertname对警报进行分组，以便发送单个紧凑通知 通过配置文件中的路由树配置警报的分组，分组通知的定时以及这些通知的接收器 抑制 如果某些其他警报已经触发，则抑制是抑制某些警报的通知的概念。示例：正在触发警报，通知无法访问整个集群。Alertmanager可以配置为在该特定警报触发时将与该集群有关的所有其他警报静音。这可以防止数百或数千个与实际问题无关的触发警报的通知。通过Alertmanager的配置文件配置禁止 沉默 3沉默是在给定时间内简单地静音警报的简单方法。基于匹配器配置静默，就像路由树一样。检查传入警报它们是否匹配活动静默的所有相等或正则表达式匹配器。如果他们这样做，则不会发送该警报的通知。在Alertmanager的Web界面中配置了静音 客户端行为 Alertmanager对其客户的行为有特殊要求。这些仅适用于不使用Prometheus发送警报的高级用例 高可用 Alertmanager支持配置以创建用于高可用性的集群。这可以使用--cluster- *标志进行配置。重要的是不要在Prometheus和它的Alertmanagers之间加载平衡流量，而是将Prometheus指向所有Alertmanagers的列表 监控要点 监控方式 作用 硬件监控 温度、硬件故障等 系统监控 CPU、内存、硬盘、网卡流量、TCP状态、进程数 应用监控 Nginx、Tomcat、PHP、MySQL、Redis等 日志监控 系统日志、服务日志、访问日志、错误日志 安全监控 WAF、敏感文件监控 API监控 可用性、接口请求、相应时间 业务监控 例如电商网站、每分钟生成多少订单、注册用户多少、推广活动效果 流量分析 根据流量获取用户相关信息，例如用户地理位置、某页面访问状态、页面停留时间等 名称 作用 Counter 递增计数器 eg： API Gauge 可以任意变化的数值 eg. cpu占用率 Histogram 对一段时间范围内数据进行采样，并对所有数值求和与统计数量eg柱状图 Summary 与Histogram类似 安装部署 prometheus安装 docker安装 $ mkdir -p /opt/prometheus/{conf,logs,data} $ docker run --detach --name prometheus \\ --restart always --publish 19090:9090 \\ --volume /opt/prometheus/data:/data \\ --volume /opt/prometheus/conf:/etc/prometheus \\ --config.file=/opt/prometheus/conf/prometheus.yml \\ prom/prometheus:v2.40.0 # --config.file 使用额外卷 $ cat \u003e/opt/docker-compost/prometheus/docker-compose.yml\u003c\u003c-EOF version: \"3\" services: prometheus: container_name: prometheus # 启动后名称 image: 'prom/prometheus:v2.40.0' # image: 'prom/prometheus:v2.40.4' # image: 'prom/prometheus:v2.40.3' restart: always hostname: 'prometheus' environment: TZ: Asia/Shanghai ports: - '19090:9090' volumes: - '/opt/prometheus/data:/data' - '/opt/prometheus/conf:/etc/prometheus' EOF $ docker-compose up -d 二进制安装 $ cd /opt/src \u0026\u0026 wget https://github.com/prometheus/prometheus/releases/download/v2.40.0/prometheus-2.40.0.linux-amd64.tar.gz $ tar -zxf prometheus-2.40.0.linux-amd64.tar.gz $ mv prometheus-2.40.0.linux-amd64 prometheus $ chown root.root prometheus -R 2.1 编写启动文件 $ cat \u003e/usr/lib/systemd/system/prometheus.service \u003c\u003cEOF [Unit] Description=Prometheus Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml ExecReload=/bin/kill -HUP $MAINPID Restart=on-failure # 或者使用 always StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus User=user_name Group=user_name LimitNOFILE=65535 [Install] WantedBy=multi-user.target EOF 启动服务、以及设置开机自启 $ nohup ./prometheus --config.file=prometheus.yml 2\u003e\u00261 1\u003eprometheus.log \u0026 $ systemctl enable prometheus $ systemctl start prometheus 查看服务 $ netstat -lntup |grep prometheus tcp6 0 0 :::9090 :::* LISTEN 16655/prometheus 源码安装 $ go get github.com/prometheus/prometheus/cmd/... $ prometheus --config.file=your_config.yml # 或者make build $ mkdir -p $GOPATH/src/github.com/prometheus $ cd $GOPATH/src/github.com/prometheus $ git clone https://github.com/prometheus/prometheus.git $ cd prometheus $ make build $ ./prometheus --config.file=your_config.yml alertmanager安装 docker安装 Alertmanager $ mkdir -p /opt/alertmanager/{conf,logs,data} $ docker run --detach --name alertmanager \\ --restart always --publish 19093:9093 --publish 19094:9094 \\ --volume /opt/alertmanager/data:/data \\ --volume /opt/alertmanager/conf:/etc/alertmanager \\ quay.io/prometheus/alertmanager:latest $ cat \u003e/opt/docker-compost/alertmanager/docker-compose.yml\u003c\u003c-EOF version: \"3\" services: alertmanager: container_name: alertmanager # 启动后名称 image: 'quay.io/prometheus/alertmanager:latest' # image: 'quay.io/prometheus/alertmanager:v0.24.0' # image: 'quay.io/prometheus/alertmanager:v0.23.0' restart: always hostname: 'alertmanager' environment: TZ: Asia/Shanghai ports: - '19093:9093' - '19094:9094' volumes: - '/opt/alertmanager/data:/data' - '/opt/alertmanager/conf:/etc/alertmanager' EOF $ docker-compose up -d 二进制安装 $ cd /opt \u0026\u0026 wget -c https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0.linux-amd64.tar.gz $ tar zxf alertmanager-0.24.0.linux-amd64.tar.gz $ mv alertmanager-0.24.0.linux-amd64 alertmanager $ chown root.root alertmanager -R 编写启动文件 $ cat \u003e/usr/lib/systemd/system/alertmanager.service \u003c\u003cEOF [Unit] Description=Alertmanager Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/alertmanager/alertmanager --config.file=/opt/alertmanager/alertmanager.yml Restart=on-failure [Install] WantedBy=multi-user.target EOF 启动服务、以及设置开机自启 $ nohup ./alertmanager --config.file=alertmanager.yml 2\u003e\u00261 1\u003ealertmanager.log \u0026 $ systemctl enable alertmanager $ systemctl start alertmanager 查看启动服务的端口 $ netstat -lntup |grep alertmanager tcp6 0 0 :::9094 :::* LISTEN 17237/alertmanager tcp6 0 0 :::9093 :::* LISTEN 17237/alertmanager udp6 0 0 :::9094 :::* 17237/alertmanager 编译安装 $ GO15VENDOREXPERIMENT=1 go get github.com/prometheus/alertmanager/cmd/... # cd $GOPATH/src/github.com/prometheus/alertmanager $ alertmanager --config.file=\u003cyour_file\u003e # 手动源码构建 $ mkdir -p $GOPATH/src/github.com/prometheus $ cd $GOPATH/src/github.com/prometheus $ git clone https://github.com/prometheus/alertmanager.git $ cd alertmanager $ make build $ ./alertmanager --config.file=\u003cyour_file\u003e # amtool构建 $ make build BINARIES=amtool 节点安装node_export 利用node_export来监控主机，官方也提供了很多其他的export可以用来直接使用 EXPORTERS AND INTEGRATIONS 使用NODE EXPORTER监控LINUX主机指标 1 Node Exporter Dashboard 22/04/13 ConsulManager自动同步版 二进制安装 $ cd /opt \u0026\u0026 wget -c https://github.com/prometheus/node_exporter/releases/download/v1.4.0/node_exporter-1.4.0.linux-amd64.tar.gz $ tar zxvf node_exporter-1.4.0.linux-amd64.tar.gz $ mv node_exporter-1.4.0.linux-amd64 node_exporter $ chown root.root node_exporter -R 编写启动文件 $ cat \u003e/usr/lib/systemd/system/node_exporter.service \u003c\u003cEOF [Unit] Description=node_exporter Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/node_exporter/node_exporter Restart=on-failure [Install] WantedBy=multi-user.target EOF 启动服务、以及设置开机自启 $ nohup ./node_exporter --config.file=node_exporter.yml 2\u003e\u00261 1\u003enode_exporter.log \u0026 $ systemctl enable node_exporter $ systemctl start node_exporter 查看启动的服务端口 $ netstat -lntup |grep node_export tcp6 0 0 :::9100 :::* LISTEN 4551/node_exporter 部署cAdvisor采集源 Docker部署cAdvisor Docker and system monitoring Grafana dashboard Grafana Docker Dashboard docker container \u0026 OS node(node_exporter, cadvisor) $ docker run -d --name=cadvisor \\ -p 8080:8080 \\ -v /:/rootfs:ro \\ -v /var/run:/var/run:rw \\ -v /sys:/sys:ro \\ -v /var/lib/docker/:/var/lib/docker:ro \\ google/cadvisor:v0.33.0 查看指标 $ http://\u003c目标节点IP\u003e:8080/metrics 数据库服务器部署mysqld_exporter 1 Mysqld Exporter Dashboard 22/11/06中文版 二进制安装 $ cd /opt \u0026\u0026 wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.14.0/mysqld_exporter-0.14.0.linux-amd64.tar.gz $ tar zxvf mysqld_exporter-0.14.0.linux-amd64.tar.gz $ mv mysqld_exporter-0.14.0.linux-amd64 mysqld_exporter $ chown -R root. mysqld_exporter mysqld_exporter需要连接Mysql，首先为它创建用户并赋予所需的权限 GRANT REPLICATION CLIENT, PROCESS ON *.* TO 'exporter'@'localhost' identified by '123456'; GRANT SELECT ON performance_schema.* TO 'exporter'@'localhost'; flush privileges; 在数据库服务器mysqld_exporter目录下创建.my.cnf文件 $ cat \u003e/opt/mysqld_exporter/.my.cnf\u003c\u003c-EOF [client] user=mysql_monitor password=mysql_monitor EOF 编写启动文件 $ cat \u003e/usr/lib/systemd/system/mysqld_exporter.service \u003c\u003cEOF [Unit] Description=mysql_exporter Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/mysqld_exporter/mysqld_exporter --config.my-cnf=/opt/mysqld_exporter/.my.cnf Restart=on-failure [Install] WantedBy=multi-user.target EOF 启动服务、以及设置开机自启 $ ./mysqld_exporter --config.my-cnf=/opt/mysqld_exporter/.my.cnf $ systemctl enable mysqld_exporter $ systemctl start mysqld_exporter 查看启动的服务端口 $ ss -unplt|grep mysqld_exporter tcp LISTEN 0 128 [::]:9104 [::]:* users:((\"mysqld_exporter\",pid=7339,fd=3)) 部署pushgateway(推送网关) 二进制安装 $ cd /opt \u0026\u0026 wget -c https://github.com/prometheus/pushgateway/releases/download/v1.4.3/pushgateway-1.4.3.linux-amd64.tar.gz $ tar zxf pushgateway-1.4.3.linux-amd64.tar.gz $ mv pushgateway-1.4.3.linux-amd64 pushgateway $ chown root.root pushgateway -R 编写启动文件 $ cat \u003e/usr/lib/systemd/system/pushgateway.service \u003c\u003cEOF [Unit] Description=pushgateway Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/pushgateway/pushgateway Restart=on-failure [Install] WantedBy=multi-user.target EOF 启动服务、以及设置开机自启 $ nohup ./pushgateway --config.file=node_exporter.yml 2\u003e\u00261 1\u003enode_exporter.log \u0026 $ systemctl enable pushgateway $ systemctl start pushgateway 查看启动的服务端口 $ netstat -lntup |grep push tcp6 0 0 :::9091 :::* LISTEN 5982/pushgateway ",
    "description": "Prometheus 名称地址 描述 Prometheus官网 prometheus-book Github-Prometheus Prometheus学习笔记 Prometheus介绍和使用 Prometheus+Grafana详解 Prometheus自定义监控部署 Prometheus CLIENT LIBRARIES 使用Prometheus+Grafana快速打造高逼格监控平台 概述 Prometheus是一个开源监控系统，它前身是SoundCloud的告警工具包。从2012年开始，许多公司和组织开始使用Prometheus。该项目的开发人员和用户社区非常活跃，越来越多的开发人员和用户参与到该项目中。目前它是一个独立的开源项目，且不依赖于任何公司。为了强调这点和明确该项目治理结构，Prometheus在2016年继Kurberntes之后，加入了Cloud Native Computing Foundation",
    "tags": [],
    "title": "Install_Prometheus",
    "uri": "/systems/linux/monitor/install_prometheus/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "部署Open Falcon服务 Open-falcon架构 介绍 OpenFalcon是一款企业级、高可用、可扩展的开源监控解决方案。此项目最初由小米公司发起，小米运维团队从互联网公司的需求出发，根据多年的运维经验，结合SRE、SA、DEVS的使用经验和反馈，开发的一套面向互联网的企业级开源监控产品，最新版本为v2.0。目前有几十家公司不同程度使用OpenFalcon作为分布式系统的监控解决方案。\n优点 采集器自动发现，支持falcon-agent、snmp、支持用户主动push数据、用户自定义插件 支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询 高效的分区、支持监控策略模板、模板继承和覆盖、多种告警方式、支持告警回调 单节点能支持200万metric的上报、归档、存储 其存储采用rrdtool归档，秒级返回上百个metric一年的历史数据 多维度的数据展示，可由用户自定义Screen 通过各种插件目前支持Linux、Windows、Mysql、Redis、Memache、RabbitMQ和交换机监控 监控范围 OpenFalcon支持系统基础监控，第三方服务监控，JVM监控，业务应用监控 基础监控指Linux平台的系统指标监控，包括CPU、Load、内存、磁盘、IO、网络等，这些指标由OpenFalcon的agent节点直接支持，无需插件 JVM监控主要通过插件完成，插件通过JVM开放的JMX通信端口，获取到JVM参数指标，并推送到agent节点，再由agent发送到OpenFalcon 第三方服务监控指一些常见服务监控，包括MySQL、Redis、Nginx等，OpenFalcon官网提供了很多第三方服务的监控插件，也可以自己实现插件，定义采集指标。而采集到的指标，也是通过插件先发送给agent，再由agent发送到OpenFalcon 业务应用监控主要是监控企业自主开发的应用服务。由企业根据业务需要定义采集指标，自实现插件。将获取到的采集指标发送到agent，再由agent发送到OpenFalcon openfalcon数据流向 常见的OpenFalcon包含transfer、hbs、agent、judge、graph、API几个进程。但没有提供用户界面。用户界面的解决方案是OpenFalcon官方提供的Dashboard，由python编写的一个Web服务。Dashboard调用OpenFalcon的API节点REST，完成用户认证，查询历史等操作。 以下是各个节点的数据流向图，主数据流向是agent-\u003etransfer-\u003ejudge/graph： 模块 组件 Agent: 是用于采集被部署机器上的监控数据，每隔60秒push给Transfer模块。agent与Transfer建立的是长连接（毕竟每分钟发送一次，短连接开销太大）。每台要被监控的机器都要部署该模块，它消耗的资源很小，不用太担心这一点。同时agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer，在实际使用中，我们对于某些自己项目接口的监控就是通过此方式来进行上传的\ntransfer： 是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph和judge等组件\ngraph是存储绘图数据的组件。graph组件接收transfer组件推送上来的监控数据，同时处理query组件的查询请求、返回绘图数据\nquery组件，提供统一的绘图数据查询入口。query组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同监控项的数据，然后汇总拿到的数据，最后统一返回给用户\ndashboard是面向用户的查询界面。在这里，用户可以看到push到graph中的所有数据，并查看其趋势图\n邮件短信发送模块，这个组件没有代码，需要各个公司自行提供。监控系统产生报警事件之后需要发送报警邮件或者报警短信，各个公司可能有自己的邮件服务器，有自己的邮件发送方法；有自己的短信通道，有自己的短信发送方法。falcon为了适配各个公司，在接入方案上做了一个规范，需要各公司提供http的短信和邮件发送接口\nSender： 6 中提到各个公司会提供邮件、短信发送接口，但是产生了报警之后就立马调用这些接口发送报警，是不合适的。因为这些接口可能无法处理巨大的并发量，而且接口本身的处理速度可能也比较慢，这会拖慢我们的处理逻辑。所以一个比较好的方式是把邮件、短信发送这个事情做成异步的。Sender提供一个短信redis队列，提供一个邮件redis队列。当有短信要发送的时候，直接将短信内容写入短信redis队列即可，当有邮件要发送的时候，直接将邮件内容写入邮件redis队列。针对每个队列，后面有一个预设大小的worker线程池来处理。有了队列的缓冲，即便某个时刻产生了大量报警，造成邮件、短信发送的突发流量，也不会对邮件、短信发送接口造成冲击\nFe这是Go版本的UIC，也是一个统一的web入口，因为监控组件众多，记忆ip、port去访问还是比较麻烦。fe像是一个监控的hao123.就是为了用户使用方便配置的一个web浏览器操作界面\nPortal是用来配置报警策略的,和HBS一起描述\nHBS(Heartbeat Server)：\nPortal的数据库中有一个host表，维护了公司所有机器的信息，比如hostname、ip等等。HBS第一个功能：agent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表 Agent只采集用户配置的监控项。比如用户配置了对某个机器80端口的监控，我们才会去采集这个机器80端口的存活性。那agent如何知道自己应该采集哪些端口和进程呢？向HBS要，HBS去读取Portal的数据库，返回给agent Judge需要获取所有的报警策略，让Judge去读取Portal的DB么？不太好。因为Judge的实例数目比较多，如果公司有几十万机器，Judge实例数目可能会是几百个，几百个Judge实例去访问Portal数据库，也是一个比较大的压力。既然HBS无论如何都要访问Portal的数据库了，那就让HBS去获取所有的报警策略缓存在内存里，然后Judge去向HBS请求。这样一来，对Portal DB的压力就会大大减小 Judge Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。因为监控系统数据量比较大，一台机器显然是搞不定的，所以必须要有个数据分片方案。Transfer通过一致性哈希来分片，每个Judge就只需要处理一小部分数据就可以了。所以判断告警的功能不能放在直接的数据接收端Transfer，而应该放到Transfer后面的组件里，就有了Judge. Links是为报警合并功能写的组件。如果你不想使用报警合并功能，这个组件是无需安装的。一般不会用到 alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理，报警event的处理逻辑并非仅仅是发邮件、发短信这么简单。为了能够自动化对event做处理，alarm需要支持在产生event的时候回调用户提供的接口；有的时候报警短信、邮件太多，对于优先级比较低的报警，希望做报警合并，这些逻辑都是在alarm中做的 流程 目标服务器运行agent agent采集各类监控项数值，传给transfer transfer校验和整理监控项数值，做一致性hash分片，传给对应的judge模块以验证是否触发告警 transfer整理监控项数值，做一致性hash分片，传输给graph以进行数据的存储 judge根据具体报警策略或阈值进行告警判断，如触发告警则组装告警event事件，写入缓存队列 alarm和sender根据event事件中的判定结果，执行event，像用户组发送短信或邮件 graph收到监控项数据后，将数据存储成RRD文件格式，进行归档，并提供查询接口 query将调用graph的查询接口，将监控数据传送到dashboard以进行页面展示 dashboard则渲染页面，展示曲线报表图等 portal提供页面供用户配置机器分组、报警策略、表达式、nodata等配置 Open-falcon部署 Open-Falcon为前后端分离的架构，包含backend和frontend两部分 前端(客户端)和后端(服务端) 环境准备 安装redis $ yum install -y redis # 启动 $ redis-server \u0026 装mysql 解压到/usr/local目录 $ wget http://ftp.iij.ad.jp/pub/db/mysql/Downloads/MySQL-5.7/mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz 移动至该目录cd /usr/local/mysql $ mv mysql-5.7.22-linux-glibc2.12-x86_64 /usr/local/mysql rpm -qa | grep mariadb $ rpm -e mariadb-libs –nodeps 创建数据库目录 $ mkdir data 创建mysql系统组和系统用户并不建立家目录 $ groupadd -r mysql \u0026\u0026 useradd -r -g mysql -s /bin/false -M mysql 授权给mysql $ chown -R mysql:mysql . 做个软链接 $ ln -s /usr/local/mysql/bin/* /usr/local/bin 编写主配置文件 $ cat \u003e/etc/my.cnf\u003c\u003c-EOF [mysqld] basedir=/usr/local/mysql datadir=/usr/local/mysql/data pid-file=/usr/local/mysql/data/mysqld.pid socket=/usr/local/mysql/mysql.sock log-error=/usr/local/mysql/data/mysql.err [client] socket=/usr/local/mysql/mysql.sock EOF 初始化数据库 $ mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 移动至support-files目录下 $ cd support-files 复制启动服务至/etc/init.d/mysqld $ cp mysql.server /etc/init.d/mysqld 启动mysql服务 $ /etc/init.d/mysqld start 找密码 $ cat /usr/local/mysql/data/mysql.err 登录 $ mysql -uroot -p'密码' 修改密码 $ alter user root@localhost identified by '123'; 初始化mysql表结构 $ cd /tmp/ \u0026\u0026 git clone https://github.com/open-falcon/falcon-plus.git $ cd /tmp/falcon-plus/scripts/mysql/db_schema/ $ mysql -h 127.0.0.1 -u root -p \u003c 1_uic-db-schema.sql $ mysql -h 127.0.0.1 -u root -p \u003c 2_portal-db-schema.sql $ mysql -h 127.0.0.1 -u root -p \u003c 3_dashboard-db-schema.sql $ mysql -h 127.0.0.1 -u root -p \u003c 4_graph-db-schema.sql $ mysql -h 127.0.0.1 -u root -p \u003c 5_alarms-db-schema.sql $ rm -rf /tmp/falcon-plus/ 配置Go语言开发环境(需要epel源) $ yum install golang -y 查看go的安装路径 $ find / -name go 设置环境变量GOROOT和GOPATH $ export GOROOT=/usr/lib/golang $ export GOPATH=/home 下载编译好的二进制版本 $ wget https://github.com/open-falcon/falcon-plus/releases/download/v0.2.1/open-falcon-v0.2.1.tar.gz 启动后端 创建工作目录 $ export FALCON_HOME=/home/work $ export WORKSPACE=$FALCON_HOME/open-falcon $ mkdir -p $WORKSPACE 解压二进制包 $ tar -xzvf open-falcon-v0.2.1.tar.gz -C $WORKSPACE 在一台机器上启动所有的后端组件 修改配置文件cfg.json\n部分模块依赖连接数据库，因为如果不修改配置文件，aggregator模块会出现无法启动，graph、hbs、nodata、api、alarm模块会出现开启不报错但是状态为开启失败的情况。\n如果需要每个模块都能正常启动，需要将上面模块的cfg.json的数据库信息进行修改，需要修改配置文件所在的目录\n模块 配置文件所在路径 aggregator /home/work/aggregator/config/cfg.json graph /home/work/graph/config/cfg.json hbs /home/work/hbs/config/cfg.json nodata /home/work/nodata/config/cfg.json api /home/work/api/config/cfg.json alarm /home/work/alarm/config/cfg.json 启动 $ cd $WORKSPACE $ ./open-falcon start # 检查所有模块的启动状况 $ ./open-falcon check 安装前端 创建工作目录 $ export HOME=/home/work $ export WORKSPACE=$HOME/open-falcon $ mkdir -p $WORKSPACE $ cd $WORKSPACE 克隆前端组件diamante $ cd $WORKSPACE $ git clone https://github.com/open-falcon/dashboard.git 安装依赖包 $ yum install -y python-virtualenv $ yum install -y python-devel $ yum install -y openldap-devel $ yum install -y mysql-devel $ yum groupinstall \"Development tools\" $ cd $WORKSPACE/dashboard/ $ virtualenv ./env $ ./env/bin/pip install -r pip_requirements.txt -i https://pypi.douban.com/simple 修改配置 dashboard的配置文件为： 'rrd/config.py'，请根据实际情况修改 # API_ADDR 表示后端api组件的地址 API_ADDR = \"http://127.0.0.1:8080/api/v1\" # 根据实际情况，修改PORTAL_DB_*, 默认用户名为root，默认密码为\"\" # 根据实际情况，修改ALARM_DB_*, 默认用户名为root，默认密码为\"\" 在生产环境启动 $ bash control start # 停止 $ bash control stop # 查看日志 $ Bash control tail dashboard用户管理 dashbord没有默认创建任何账号包括管理账号，需要你通过页面进行注册账号。 想拥有管理全局的超级管理员账号，需要手动注册用户名为root的账号（第一个帐号名称为root的用户会被自动设置为超级管理员）。 超级管理员可以给普通用户分配权限管理。 小提示：注册账号能够被任何打开dashboard页面的人注册，所以当给相关的人注册完账号后，需要去关闭注册账号功能。只需要去修改api组件的配置文件cfg.json，将signup_disable配置项修改为true，重启api即可。当需要给人开账号的时候，再将配置选项改回去，用完再关掉即可。 被监控端配置agent agent需要部署到所有要被监控的机器上，比如公司有10万台机器，那就要部署10万个agent。agent本身资源消耗很少，不用担心 配置说明：配置文件必须叫cfg.json，可以基于cfg.example.json修改 { \"debug\": true, # 控制一些debug信息的输出，生产环境通常设置为false \"hostname\": \"\", # agent采集了数据发给transfer，endpoint就设置为了hostname，默认通过`hostname`获取，如果配置中配置了hostname，就用配置中的 \"ip\": \"\", # agent与hbs心跳的时候会把自己的ip地址发给hbs，agent会自动探测本机ip，如果不想让agent自动探测，可以手工修改该配置 \"plugin\": { \"enabled\": false, # 默认不开启插件机制 \"dir\": \"./plugin\", # 把放置插件脚本的git repo clone到这个目录 \"git\": \"https://github.com/open-falcon/plugin.git\", # 放置插件脚本的git repo地址 \"logs\": \"./logs\" # 插件执行的log，如果插件执行有问题，可以去这个目录看log }, \"heartbeat\": { \"enabled\": true, # 此处enabled要设置为true \"addr\": \"127.0.0.1:6030\", # hbs的地址，端口是hbs的rpc端口 \"interval\": 60, # 心跳周期，单位是秒 \"timeout\": 1000 # 连接hbs的超时时间，单位是毫秒 }, \"transfer\": { \"enabled\": true, \"addrs\": [ \"127.0.0.1:18433\" ], # transfer的地址，端口是transfer的rpc端口, 可以支持写多个transfer的地址，agent会保证HA \"interval\": 60, # 采集周期，单位是秒，即agent一分钟采集一次数据发给transfer \"timeout\": 1000 # 连接transfer的超时时间，单位是毫秒 }, \"http\": { \"enabled\": true, # 是否要监听http端口 \"listen\": \":1988\", \"backdoor\": false }, \"collector\": { \"ifacePrefix\": [\"eth\", \"em\"], # 默认配置只会采集网卡名称前缀是eth、em的网卡流量，配置为空就会采集所有的，lo的也会采集。可以从/proc/net/dev看到各个网卡的流量信息 \"mountPoint\": [] }, \"default_tags\": { }, \"ignore\": { # 默认采集了200多个metric，可以通过ignore设置为不采集 \"cpu.busy\": true, \"df.bytes.free\": true, \"df.bytes.total\": true, \"df.bytes.used\": true, \"df.bytes.used.percent\": true, \"df.inodes.total\": true, \"df.inodes.free\": true, \"df.inodes.used\": true, \"df.inodes.used.percent\": true, \"mem.memtotal\": true, \"mem.memused\": true, \"mem.memused.percent\": true, \"mem.memfree\": true, \"mem.swaptotal\": true, \"mem.swapused\": true, \"mem.swapfree\": true } } 进程管理 $ ./open-falcon start agent # 启动进程 $ ./open-falcon stop agent # 停止进程 $ ./open-falcon monitor agent # 查看日志 验证\n看var目录下的log是否正常，或者浏览器访问其1988端口。另外agent提供了一个--check参数，可以检查agent是否可以正常跑在当前机器上\n$ ./falcon-agent --check /v1/push接口\n设计初衷是不希望用户直接连到Transfer发送数据，而是通过agent的/v1/push接口转发，接口使用范例：\nts=`date +%s`; curl -X POST -d \"[{\\\"metric\\\": \\\"metric.demo\\\", \\\"endpoint\\\": \\\"qd-open-falcon-judge01.hd\\\", \\\"timestamp\\\": $ts,\\\"step\\\": 60,\\\"value\\\": 9,\\\"counterType\\\": \\\"GAUGE\\\",\\\"tags\\\": \\\"project=falcon,module=judge\\\"}]\" http://127.0.0.1:1988/v1/push ",
    "description": "部署Open Falcon服务 Open-falcon架构 介绍 OpenFalcon是一款企业级、高可用、可扩展的开源监控解决方案。此项目最初由小米公司发起，小米运维团队从互联网公司的需求出发，根据多年的运维经验，结合SRE、SA、DEVS的使用经验和反馈，开发的一套面向互联网的企业级开源监控产品，最新版本为v2.0。目前有几十家公司不同程度使用OpenFalcon作为分布式系统的监控解决方案。\n优点 采集器自动发现，支持falcon-agent、snmp、支持用户主动push数据、用户自定义插件 支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询 高效的分区、支持监控策略模板、模板继承和覆盖、多种告警方式、支持告警回调 单节点能支持200万metric的上报、归档、存储 其存储采用rrdtool归档，秒级返回上百个metric一年的历史数据 多维度的数据展示，可由用户自定义Screen 通过各种插件目前支持Linux、Windows、Mysql、Redis、Memache、RabbitMQ和交换机监控 监控范围 OpenFalcon支持系统基础监控，第三方服务监控，JVM监控，业务应用监控 基础监控指Linux平台的系统指标监控，包括CPU、Load、内存、磁盘、IO、网络等，这些指标由OpenFalcon的agent节点直接支持，无需插件 JVM监控主要通过插件完成，插件通过JVM开放的JMX通信端口，获取到JVM参数指标，并推送到agent节点，再由agent发送到OpenFalcon 第三方服务监控指一些常见服务监控，包括MySQL、Redis、Nginx等，OpenFalcon官网提供了很多第三方服务的监控插件，也可以自己实现插件，定义采集指标。而采集到的指标，也是通过插件先发送给agent，再由agent发送到OpenFalcon 业务应用监控主要是监控企业自主开发的应用服务。由企业根据业务需要定义采集指标，自实现插件。将获取到的采集指标发送到agent，再由agent发送到OpenFalcon openfalcon数据流向 常见的OpenFalcon包含transfer、hbs、agent、judge、graph、API几个进程。但没有提供用户界面。用户界面的解决方案是OpenFalcon官方提供的Dashboard，由python编写的一个Web服务。Dashboard调用OpenFalcon的API节点REST，完成用户认证，查询历史等操作。 以下是各个节点的数据流向图，主数据流向是agent-\u003etransfer-\u003ejudge/graph： 模块 组件 Agent: 是用于采集被部署机器上的监控数据，每隔60秒push给Transfer模块。agent与Transfer建立的是长连接（毕竟每分钟发送一次，短连接开销太大）。每台要被监控的机器都要部署该模块，它消耗的资源很小，不用太担心这一点。同时agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer，在实际使用中，我们对于某些自己项目接口的监控就是通过此方式来进行上传的",
    "tags": [],
    "title": "Install_Open_Falcon",
    "uri": "/systems/linux/monitor/install_open_falcon/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "Nightingale部署 Nightingale ",
    "description": "Nightingale部署 Nightingale ",
    "tags": [],
    "title": "Install_Nightingale",
    "uri": "/systems/linux/monitor/install_nightingale/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "部署Grafana 名称地址 描述 Download Grafana Download Grafana Docker安装 $ docker run -d --name=grafana -p 3000:3000 grafana/grafana-enterprise tar.gz二进制包安装 $ wget https://dl.grafana.com/enterprise/release/grafana-enterprise-9.4.7.linux-amd64.tar.gz $ tar -zxvf grafana-enterprise-9.4.7.linux-amd64.tar.gz $ mv grafana-enterprise-9.4.7 /opt/apps/grafana $ /opt/apps/grafana/bin/grafana-server rpm安装 $ wget https://dl.grafana.com/enterprise/release/grafana-enterprise-9.3.0-1.x86_64.rpm $ yum localinstall grafana-6.3.3-1.x86_64.rpm -y 设置开机自启：web页面3000登录信息：admin/admin $ systemctl enable grafana-server.service $ systemctl start grafana-server.service 安装插件 $ grafana-cli plugins install grafana-piechart-panel $ systemctl restart grafana-server ",
    "description": "部署Grafana 名称地址 描述 Download Grafana Download Grafana Docker安装 $ docker run -d --name=grafana -p 3000:3000 grafana/grafana-enterprise tar.",
    "tags": [],
    "title": "Install_Grafana",
    "uri": "/systems/linux/monitor/install_grafana/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "配置Zabbix Job Zabbix-Agen测试服务端、Zabbix监控配置 abbix_get：-s：客户端地址，-p：客户端端口，-k：键值 $ bin/zabbix_get -s \"zabbix_agent IP\" -k agent.ping -p 10050 # get value $ cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc nginx/html/zabbix/fonts/DejaVuSans.ttf 压力测试 $ ab -c 10 -n 1000000 http://192.168.56.11:8080/ 配置Zabbix用户 创建配置用户 创建主机或者主机组 配置Zabbix监控端口告警 监控端口 创建、配置监控项 创建、配置触发器 ",
    "description": "配置Zabbix Job Zabbix-Agen测试服务端、Zabbix监控配置 abbix_get：-s：客户端地址，-p：客户端端口，-k：键值 $ bin/zabbix_get -s \"zabbix_agent IP\" -k agent.",
    "tags": [],
    "title": "Configure_Zabbix",
    "uri": "/systems/linux/monitor/configure_zabbix/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "配置Zabbix+Grafana监控展示 名称地址 描述 Zabbix+Grafana Grafana Dashboards Grafana之telegram报警配置 ConsulManager实现Prometheus监控目标 Blackbox Exporter Dashboard 2022/04/12 1 Node Exporter Dashboard 22/04/13 ConsulManager自动同步版 配置Grafana中文界面 $ cat \u003e/opt/apps/grafana/conf/defaults.ini\u003c\u003c-EOF default_language = en-US # 修改为：default_language = zh-CN EOF $ grafana-cli plugins install grafana-zh-cn-panel Grafana安装Zabbix插件到指定目录 --pluginsDir=指定插件安装目录 alexanderzobnin-zabbix-app要安装的插件 $ /opt/apps/grafana/bin/grafana-cli --pluginsDir=/opt/apps/grafana/data/plugins plugins install alexanderzobnin-zabbix-app 安装Grafana Image Renderer图像插件 $ /opt/apps/grafana/bin/grafana-cli --pluginsDir=/opt/apps/grafana/data/plugins plugins install grafana-image-renderer 启用图片发送参数 $ cat \u003e/opt/apps/grafana/conf/defaults.ini\u003c\u003c-EOF capture = false # 修改为：true upload_external_image_storage = false # 修改为：true EOF Grafana页面配置Zabbix数据源 使用Zabbix数据源创建Grafana仪表盘 Grafana配置Telegram告警 ",
    "description": "配置Zabbix+Grafana监控展示 名称地址 描述 Zabbix+Grafana Grafana Dashboards Grafana之telegram报警配置 ConsulManager实现Prometheus监控目标 Blackbox Exporter Dashboard 2022/04/12 1 Node Exporter Dashboard 22/04/13 ConsulManager自动同步版 配置Grafana中文界面 $ cat \u003e/opt/apps/grafana/conf/defaults.",
    "tags": [],
    "title": "Configure_Zabbix_Grafana",
    "uri": "/systems/linux/monitor/configure_zabbix_grafana/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "配置Prometheus Prometheus的yaml文件编写 $ cat \u003e/opt/prometheus/prometheus.yaml\u003c\u003c-EOF # my global config global: # 全局配置 scrape_interval: 15s # 默认情况下，每15s拉取一次目标采样点数据 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: # 报警配置 alertmanagers: - static_configs: - targets: # - alertmanager:9093 #remote_write: # 用于远程存储写配置 #remote_read: # 用于远程读配置 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # 规则配置，主要是配置：报警规则 # - \"rules/*.yml\" # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # 抓取配置，主要配置抓取客户端相关 # The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] - job_name: 'node' # 任务名，使用node_export插件获取服务器监控数据 static_configs: - targets: - 'localhost:9100' - 'swoft_1:9100' - 'swoft_2:9100' - '175_web:9100' - '176_web:9100' - '177_admin:9100' - 'mysql_redis_0:9100' - 'mysql_redis_1:9100' - 'mysql_redis_2:9100' - 'mysql_redis_3:9100' - job_name: 'mysql' # 使用mysqld_exporter插件获取Mysql监控数据 static_configs: - targets: - 'mysql_redis_0:9104' - 'mysql_redis_1:9104' - 'mysql_redis_2:9104' - 'mysql_redis_3:9104' - job_name: 'container' # 使用cAdvisor 获取到的容器监控数据 static_configs: - targets: - '\u003c节点01的IP\u003e:8080' - '\u003c节点02的IP\u003e:8080' EOF 配置Prometheus web页面 浏览器访问：IP:9090\nshell命令创建\n$ echo \"some_metric 3.14\" | curl --data-binary @- http://localhost:9091/metrics/job/some_job 发送复杂数据 $ cat \u003c\u003cEOF | curl --data-binary @- http://localhost:9091/metrics/job/some_job/instance/some_instance # TYPE some_metric counter some_metric{label=\"val1\"} 42 # TYPE another_metric gauge # HELP another_metric Just an example. another_metric 2398.283 EOF 添加数据源 添加prometheus，填写prometheus的管理地址\n导入dashboard\n通过grafana官网仪表盘添加对应仪表盘\n常用仪表盘\n配置grafana grafana告警邮件配置 修改grafana配置文件，添加Email配置 Grafana Dashboards ConsulManager $ cat \u003e/etc/grafana/grafana.ini\u003c\u003c-EOF [smtp] enabled = true host = smtp.163.com:465 user = 18329903316 # If the password contains # or ; you have to wrap it with trippel quotes. Ex \"\"\"#password;\"\"\" password = xxxxxxxxxxxx ;cert_file = ;key_file = ;skip_verify = false from_address = 18329903316@163.com ;from_name = Grafana ;ehlo_identity = dashboard.exmple.com EOF grafana web界面配置Notification channels alter配置 ⚠️：Template variables are not supported in alert queries在查询中不能使用模版语法，不然无法创建告警 配置Prometheus监控Nginx 下载Nginx监控插件nginx-module-vts $ git clone git://github.com/vozlt/nginx-module-vts.git 重新编译Nginx支持插件nginx-module-vts $ ./configure --prefix=/usr/local/nginx-1.12.2 --user=nginx --group=nginx --with-http_stub_status_module --with-http_ssl_module \u003e --add-module=/usr/local/nginx-module-vts $ make 拷贝重新编译后的Nginx $ nginx -s stop $ \\cp ./objs/nginx /usr/local/nginx/sbin/ 修改Nginx主配置文件nginx.conf $ cat \u003enginx.conf\u003c\u003c-EOF http { ..... ### Prometheus 配置 vhost_traffic_status_zone; vhost_traffic_status_filter_by_host on; # 打开vhost过滤 ### Prometheus 配置 ..... server { location /status { # vhost_traffic_status off; vhost_traffic_status_display; vhost_traffic_status_display_format html; } } } EOF 下载nginx-vts-exporter监控插件 $ cd /opt \u0026\u0026 wget -c https://github.com/hnlq715/nginx-vts-exporter/releases/download/\u003e v0.10.3/nginx-vts-exporter-0.10.3.linux-amd64.tar.gz $ tar xf nginx-vts-exporter-0.10.3.linux-amd64.tar.gz ./nginx-vts-exporter -nginx.scrape_timeout 10 -nginx.scrape_uri http://10.10.16.107/status/format/json \u0026 # 启动nginx Vhost Traffic http://10.10.16.107/status # 访问nginx主机各节点状态 配置Alertmanager告警 告警规则 ALERTING RULES $ cat \u003erules/general.yml\u003c\u003c-EOF groups: - name: general.rules # 报警规则组名称 rules: # 任何实例5分钟内无法访问发出告警 - alert: InstanceDown expr: up == 0 for: 5m # 持续时间 ， 表示持续一分钟获取不到信息，则触发报警 labels: severity: page # 自定义标签 error annotations: summary: \"Instance {{ $labels.instance }} 停止工作 down\" # 自定义摘要 description: \"{{ $labels.instance }} of job {{ $labels.job }} 已经停止5分钟以上 has been down for more than 5 minutes.\" # 自定义具体描述 EOF$ cat \u003erules/node.yml\u003c\u003c-EOF groups: - name: node.rules rules: - alert: NodeFilesystemUsage expr: 100 - (node_filesystem_free_bytes{fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{fstype=~\"ext4|xfs\"} * 100) \u003e 80 for: 2m labels: severity: warning annotations: summary: \"{{$labels.instance}}: {{$labels.mountpoint }} 分区使用过高\" description: \"{{$labels.instance}}: {{$labels.mountpoint }} 分区使用大于 80% (当前值: {{ $value }})\" - alert: NodeMemoryUsage expr: 100 - (node_memory_MemFree_bytes+node_memory_Cached_bytes+node_memory_Buffers_bytes) / node_memory_MemTotal_bytes * 100 \u003e 80 for: 2m labels: severity: warning annotations: summary: \"{{$labels.instance}}: 内存使用过高\" description: \"{{$labels.instance}}: 内存使用大于 80% (当前值: {{ $value }})\" - alert: NodeCPUUsage expr: 100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) by (instance) * 100) \u003e 80 for: 2m labels: severity: warning annotations: summary: \"{{$labels.instance}}: CPU使用过高\" description: \"{{$labels.instance}}: CPU使用大于 80% (当前值: {{ $value }})\" # cat rules/reload.yml groups: - name: prometheus.rules rules: - alert: AlertmanagerReloadFailed expr: alertmanager_config_last_reload_successful == 0 for: 10m labels: severity: warning annotations: summary: \"{{$labels.instance}}: Alertmanager配置重新加载失败\" description: \"{{$labels.instance}}: Alertmanager配置重新加载失败\" - alert: PrometheusReloadFailed expr: prometheus_config_last_reload_successful == 0 for: 10m labels: severity: warning annotations: summary: \"{{$labels.instance}}: Prometheus配置重新加载失败\" description: \"{{$labels.instance}}: Prometheus配置重新加载失败\" EOFroute: receiver: 'default-receiver' group_wait: 30s group_interval: 5m repeat_interval: 4h group_by: [cluster, alertname] routes: - receiver: 'database-pager' group_wait: 10s match_re: service: mysql|cassandra - receiver: 'frontend-pager' group_by: [product, environment] match: team: frontend receivers: - name: ‘database-pager ' email_configs: - to: 'zhenliang369@163.com' - name: ‘frontend-pager ' email_configs: - to: 'zhenliang369@163.com' ",
    "description": "配置Prometheus Prometheus的yaml文件编写 $ cat \u003e/opt/prometheus/prometheus.yaml\u003c\u003c-EOF # my global config global: # 全局配置 scrape_interval: 15s # 默认情况下，每15s拉取一次目标采样点数据 evaluation_interval: 15s # Evaluate rules every 15 seconds.",
    "tags": [],
    "title": "Configure_Prometheus",
    "uri": "/systems/linux/monitor/configure_prometheus/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Monitor",
    "content": "Open-falcon配置 查看监控数据 Linux下smokeping网络监控环境部署记录\nagent只要部署到机器上，并且配置好了heartbeat和transfer就自动采集数据了，我们就可以去dashboard上面搜索监控数据查看了。dashboard是个web\u003e 项目，浏览器访问之。左侧输入endpoint搜索，endpoint是什么？应该用什么搜索？对于agent采集的数据endpoint都是机器名，去目标机器上执行hostname\u003e ，看到的输出就是endpoint，拿着hostname去搜索。\n选中前面的复选框，点击“查看counter列表”，可以列出隶属于这个endpoint的counter假如我们要查看cpu.busy，在counter搜索框中输入cpu\u003e 并回车。看到cpu.busy了吧，点击，会看到一个新页面，图表中就是这个机器的cpu.busy\u003e 的近一小时数据了，想看更长时间的？右上角有个小三角，展开菜单，可以选择更长的时间跨度\n配置报警策略 配置报警接收人\nfalcon的报警接收人不是一个具体的手机号，也不是一个具体的邮箱，因为手机号、邮箱都是容易发生变化的，如果变化了去修改所有相关配置那就太麻烦了。我们把用\u003e 户的联系信息维护在一个叫 帐户/Profile 里，以后如果要修改手机号、邮箱，只要修改自己的帐户信息即可。报警接收人也不是单个的人，而是一个组（Teams），比如\u003e falcon这个系统的任何组件出问题了，都应该发报警给falcon的运维和开发人员，发给falcon这个团队，这样一来，新员工入职只要加入falcon这个Team\u003e 即可；员工离职，只要从falcon这个Team删掉即可。\n添加报警组，添加成员 创建HostGroup 比如我们要对falcon-judge这个组件做端口监控，那首先创建一个HostGroup，把所有部署了falcon-judge\u003e 这个模块的机器都塞进去，以后要扩容或下线机器的时候直接从这个HostGroup增删机器即可，报警策略会自动生效、失效。咱们为这个HostGroup取名为：\u003e sa.dev.falcon.judge，这个名称有讲究，sa是我们部门，dev是我们组，falcon是项目名，judge\u003e 是组件名，传达出了很多信息，这样命名比较容易管理，推荐大家这么做 在往组里加机器的时候如果报错，需要检查portal的数据库中host表，看里边是否有相关机器。那host表中的机器从哪里来呢？agent有个heartbeat(hbs)\u003e 的配置，agent每分钟会发心跳给hbs，把自己的ip、hostname、agent version等信息告诉hbs，hbs负责写入host表。如果host\u003e 表中没数据，需要检查这条链路是否通畅 创建策略模板 portal最上面有个Templates链接，这就是策略模板管理的入口。我们进去之后创建一个模板，名称姑且也叫：sa.dev.falcon.judge.tpl，与HostGroup\u003e 名称相同，在里边配置一个端口监控，通常进程监控有两种手段，一个是进程本身是否存活，一个是端口是否在监听，此处我们使用端口监控 右上角那个加号按钮是用于增加策略的，一个模板中可以有多个策略，此处我们只添加了一个。下面可以配置报警接收人，此处填写的是falcon，这是之前在UIC\u003e 中创建的Team。 将HostGroup与模板绑定 一个模板是可以绑定到多个HostGroup的，现在我们重新回到HostGroups页面，找到sa.dev.falcon.judge这个HostGroup\u003e ，右侧有几个超链接，点击【templates】进入一个新页面，输入模板名称，绑定一下就行了 补充 上面步骤做完了，也就配置完了。如果judge组件宕机，端口不再监听了，就会报警。不过大家不要为了测试报警效果，直接把judge组件给干掉了，因为judge\u003e 本身就是负责判断报警的，把它干掉了，那就没法判断了……所以说falcon\u003e 现在并不完善，没法用来监控本身的组件。为了测试，大家可以修改一下端口监控的策略配置，改成一个没有在监听的端口，这样就触发报警了 上面的策略只是对falcon-judge做了端口监控，那如果我们要对falcon这个项目的所有机器加一些负载监控，应该如何做呢？ 创建一个HostGroup：sa.dev.falcon，把所有falcon的机器都塞进去 创建一个模板：sa.dev.falcon.common，添加一些像ping, df.bytes.free.percent, load.5min等策略 将sa.dev.falcon.common绑定到sa.dev.falcon这个HostGroup 配置策略表达式 策略表达式，即expression 上例中的配置传达出的意思是：endpoint=aggregator并且metric=cpu.busy的所有的监控指标，只要连续3次\u003e= 0.5则报警给falcon-test1\u003e 这个报警组。\nexpression无需绑定到HostGroup，enjoy it\nNodata配置 使用Nodata，需要进行两个配置: Nodata配置和策略配置。下面，我们以一个例子，讲述如何使用Nodata提供的服务 用户需求 当机器分组cop.xiaomi_owt.inf_pdl.falcon下的所有机器，其采集指标agent.alive 上报中断时，通知用户 nodata配置 进入Nodata配置主页，可以看到Nodata配置列表 点击右上角的添加按钮，添加nodata配置 进行完上述配置后，分组cop.xiaomi_owt.inf_pdl.falcon下的所有机器，其采集项 agent.alive\u003c\u003e font color=red\u003e上报中断后，nodata服务就会补发一个取值为-1.0、agent.alive\u003e 的监控数据给监控系统 策略配置 配置了Nodata后，如果有数据上报中断的情况，Nodata配置中的默认值就会被上报。我们可以针对这个默认值，设置报警；只要收到了默认值，就认为发生了数据上报\u003e 的中断（如果你设置的默认值，可能与正常上报的数据相等，那么请修改你的Nodata配置、使默认值有别于正常值）。将此策略，绑定到分组\u003e cop.xiaomi_owt.inf_pdl.falcon即可。 注意事项 配置名称name，要全局唯一。这是为了方便Nodata配置的管理。 监控实例endpoint, 可以是机器分组、机器名或者其他 这三种类型，只能选择其中的一种。同一类型，支持多个记录，但建议不超过5个，多条记录换行分割、每行一条\u003e 记录。选择机器分组时，系统会帮忙展开成具体机器名，支持动态生效。监控实体不是机器名时，只能选择“其他”类型。 监控指标metric。 数据标签tags，多个tag要用逗号隔开。必须填写完整的tags串，因为nodata会按照此tags串，去完全匹配、筛选监控数指标项。 数据类型type，只支持原始值类型GAUGE。因为，nodata只应该监控 “特征指标”(如agent.alive)，“特征指标\"都是GAUGE类型的 采集周期step，单位是秒。必须填写 完整\u0026真实step。该字段不完整 或者 不真实，将会导致nodata监控的误报、漏报。 补发值default，必须有别于上报的真实数据。比如，cpu.idle的取值范围是[0,100]，那么它的nodata默认取值 只能取小于0或者大于100\u003e 的值。否则，会发生误报、漏报 报警函数说明 说明：#后面的数字的最大值，即在judge内存中保留最近几个点，是支持自定义的 all(#3): 最新的3个点都满足阈值条件则报警 max(#3): 对于最新的3个点，其最大值满足阈值条件则报警 min(#3): 对于最新的3个点，其最小值满足阈值条件则报警 sum(#3): 对于最新的3个点，其和满足阈值条件则报警 avg(#3): 对于最新的3个点，其平均值满足阈值条件则报警 diff(#3): 拿最新push上来的点（被减数），与历史最新的3个点（3个减数）相减，得到3个差，只要有一个差满足阈值条件则报警 pdiff(#3): 拿最新push上来的点，与历史最新的3个点相减，得到3个差，再将3个差值分别除以减数，得到3个商值，只要有一个商值满足阈值则报警 lookup(#2,3): 最新的3个点中有2个满足条件则报警； stddev(#7) = 3：离群点检测函数，取最新7个点的数据分别计算得到他们的标准差和均值，分别计为σ和μ，其中当前值计为X，那么当X落在区间 [μ-3σ, μ+3σ] 之外时，则认为当前值波动过大，触发报警；更多请参考3-sigma算法：https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule。 最常用的就是all函数了，比如cpu.idle all(#3) \u003c 5，表示cpu.idle的值连续3次小于5%则报警。 lookup为非连续性报警函数，适用于在一定范围内容忍监控指标抖动的场景，比如某个主机的cpu.busy忽高忽低，使用all(#1)\u003e80明显过于严格，会产生大量报警干扰视线，使用all(#3)\u003e80则连续三次偏高的概率很小，可能永远不会触发报警，不能帮助我们发现系统的不稳定，那么如果使用lookup(#3,5)，我们就可以知道cpu.busy最近抖动频繁，超过了我们容忍的界线。 新增 stddev 函数，基于高斯分布的离群点检测方式，比如cpu.idle stddev(#5) = 3 ，表示获取cpu.idle的历史5个点数据，计算得到他们的标准差和均值，分别计为σ和μ，看其是否分布在(μ-3σ,μ+3σ)范围之内，如果不在范围之内则报警。 screen的使用 我们可以使用screen提前将图像定制好，而不用每次都去搜索出图，这样就实现了类似的cacti图像展示功能。 注：graph可以加多个",
    "description": "Open-falcon配置 查看监控数据 Linux下smokeping网络监控环境部署记录\nagent只要部署到机器上，并且配置好了heartbeat和transfer就自动采集数据了，我们就可以去dashboard上面搜索监控数据查看了。dashboard是个web\u003e 项目，浏览器访问之。左侧输入endpoint搜索，endpoint是什么？应该用什么搜索？对于agent采集的数据endpoint都是机器名，去目标机器上执行hostname\u003e ，看到的输出就是endpoint，拿着hostname去搜索。\n选中前面的复选框，点击“查看counter列表”，可以列出隶属于这个endpoint的counter假如我们要查看cpu.busy，在counter搜索框中输入cpu\u003e 并回车。看到cpu.busy了吧，点击，会看到一个新页面，图表中就是这个机器的cpu.busy\u003e 的近一小时数据了，想看更长时间的？右上角有个小三角，展开菜单，可以选择更长的时间跨度\n配置报警策略 配置报警接收人",
    "tags": [],
    "title": "Configure_Open_Falcon",
    "uri": "/systems/linux/monitor/configure_open_falcon/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "ActiveMQ部署 通过http://localhost:8161/admin/来访问ActiveMQ的控制台界面. 账号：admin 密码：admin 端口：8161：后台管理系统，61616：给JAVA程序连接的TCP端口 $ sudo wget https://archive.apache.org/dist/activemq/5.15.16/apache-activemq-5.15.16-bin.tar.gz $ tar zxvf apache-activemq-5.15.16-bin.tar.gz $ bin\\activemq start $ bin\\activemq stop # 发送消息的示例 $ bin\\activemq producer --message \"My message\" --messageCount 1 # 收消息的示例 $ bin\\activemq consumer # 控制台输出 $ bin\\activemq consumer ",
    "description": "ActiveMQ部署 通过http://localhost:8161/admin/来访问ActiveMQ的控制台界面. 账号：admin 密码：admin 端口：8161：后台管理系统，61616：给JAVA程序连接的TCP端口 $ sudo wget https://archive.apache.org/dist/activemq/5.15.16/apache-activemq-5.15.16-bin.tar.gz $ tar zxvf apache-activemq-5.",
    "tags": [],
    "title": "Install_ActiveMQ",
    "uri": "/systems/linux/message_queue/install_activemq/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "Rocketmq部署 单机单实例 安装Rocketmq必要条件 64位JDK 1.8+ Maven 3.2.x Git 使用于Broker服务器4G+可用磁盘空间 安装JDK配置环境变量 打开链接找早期版本 $ tar -zxvf /usr/local/src/jdk-8u181-linux-x64.tar.gz -C /usr/local/src/ # 加压到指定位置 $ ln -s /usr/local/src/jdk1.8.0_181 /usr/local/jdk # 做个软链接，取消软链接rm -rf /usr/local/jdk 文件后不要加\"/\" # 添加环境变量 $ echo '################################ HISTSIZE=10 export TMOUT=600 export HISTTIMEFORMAT=\"%F %T \" #######JDK環境變數######################## export JAVA_HOME=/usr/local/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin '\u003e\u003e /etc/profile $ source /etc/profile 部署maven3.2.2版本 $ wget -P /usr/local/src/ https://downloads.apache.org/maven/maven-3/3.8.1/binaries/apache-maven-3.8.1-bin.tar.gz $ tar -zxvf /usr/local/src/apache-maven-3.8.1-bin.tar.gz -C /usr/local/src/ $ ln -s /usr/local/src/apache-maven-3.8.1/ /usr/local/maven echo '##### 添加maven环境变量 ######## export MAVEN_HOME=/usr/local/maven export PATH=${PATH}:${MAVEN_HOME}/bin' \u003e\u003e/etc/profile source /etc/profile # cp /usr/local/src/apache-maven-3.8.1/conf/settings.xml ~/.m2/ # 拷贝文件到此目录下 # vim ~/.m2/settings.xml # \u003cprofiles\u003e # 拷贝下面几行到\u003cprofiles\u003e下 # \u003crepositories\u003e # \u003crepository\u003e # \u003cid\u003eorg.codehaus\u003c/id\u003e # \u003curl\u003ehttps://repo1.maven.org/maven2/org/codehaus/\u003c/url\u003e # \u003c/repository\u003e # \u003c/repositories\u003e 下载并解压rocketmq安装包、使用mvn打包 $ yum -y install unzip $ wget -P /usr/local/src/ https://downloads.apache.org/rocketmq/4.8.0/rocketmq-all-4.8.0-source-release.zip # 二进制文件包 $ wget -P /usr/local/src/ https://downloads.apache.org/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip $ unzip /usr/local/src/rocketmq-all-4.8.0-source-release.zip -d /usr/local/src/ # 解压到指定位置 $ cd /usr/local/src/rocketmq-all-4.8.0-source-release $ mvn -Prelease-all -DskipTests clean install -U $ cd distribution/target/rocketmq-4.8.0/rocketmq-4.8.0 启动名称服务器 $ nohup sh bin/mqnamesrv \u0026 $ tail -f ~/logs/rocketmqlogs/namesrv.log 先修改经纪人服务器配置文件 $ vim /usr/local/src/rocketmq-all-4.8.0-source-release/distribution/target/rocketmq-4.8.0/rocketmq-4.8.0/bin/runbroker.sh JAVA_OPT=\"${JAVA_OPT} -server -Xms128m -Xmx256m -Xmn256m\" # 此处几个参数需要修改 $ vim /usr/local/src/rocketmq-all-4.8.0-source-release/distribution/target/rocketmq-4.8.0/rocketmq-4.8.0/bin/runserver.sh JAVA_OPT=\"${JAVA_OPT} -server -Xms128m -Xmx256m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" # 修改Xms128m -Xmx256m \u003e -Xmn256m 启动经纪人服务 $ tail -f ~/logs/rocketmqlogs/broker.log # 报错异常关闭selinux The broker[%s, 172.30.30.233:10911] boot success... 发送接收消息 $ export NAMESRV_ADDR=localhost:9876 $ sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer $ sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 关闭服务器 $ sh bin/mqshutdown broker The mqbroker(36695) is running... Send shutdown request to mqbroker(36695) OK $ sh bin/mqshutdown namesrv The mqnamesrv(36664) is running... Send shutdown request to mqnamesrv(36664) OK 集群模式部署 运维管理部署Rocketmq 启动NameServer $ nohup sh /usr/local/src/rocketmq-all-4.8.0-source-release/distribution/target/rocketmq-4.8.0/rocketmq-4.8.0/bin/mqnamesrv \u0026 验证Name Server是否启动成功 $ tail -f ~/logs/rocketmqlogs/namesrv.log 2021-04-24 16:51:14 INFO main - The Name Server boot success. serializeType=JSON 查看并修改Rocketmq集群配置文件 $ cd /usr/local/src/rocketmq-all-4.8.0-source-release/distribution/target/rocketmq-4.8.0/rocketmq-4.8.0/conf/2m-2s-sync [root@localhost 2m-2s-sync]# ll -rw-r--r--. 1 root root 928 Dec 8 18:16 broker-a.properties -rw-r--r--. 1 root root 922 Dec 8 18:16 broker-a-s.properties -rw-r--r--. 1 root root 928 Dec 8 18:16 broker-b.properties -rw-r--r--. 1 root root 922 Dec 8 18:16 broker-b-s.properties -rw-------. 1 root root 290 Apr 23 22:47 nohup.out $ vim broker-a-s.properties # 主机做主从必添加两处 storePathRootDir=/opt/slave/broker-a-s listenPort = 10915 修改broker-a.properties配置文件 $ cat \u003ebroker-a.properties\u003c\u003c-EOF # 所属集群名字 brokerClusterName=rocketmq-cluster # broker名字，注意此处不同的配置文件填写的不一样， brokerName=broker-a # 0:表示 Master，\u003e0:表示 Slave brokerId=0 # nameServer地址，分号分割 namesrvAddr=mq-nameserver1:9876;mq-nameserver2:9876 # 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 # 是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=false # 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=false # Broker 对外服务的监听端口 listenPort=10911 haListenPort=10912 # 删除文件时间点，默认凌晨 4点 deleteWhen=04 # 文件保留时间，默认 48 小时 fileReservedTime=120 # commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 # ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 # destroyMapedFileIntervalForcibly=120000 # redeleteHangedFileInterval=120000 # 检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 # 存储路径 storePathRootDir=/rocketmq/store # commitLog 存储路径 storePathCommitLog=/rocketmq/store/commitlog # 消费队列存储路径存储路径 storePathConsumeQueue=/rocketmq/store/consumequeue # 消息索引存储路径 storePathIndex=/rocketmq/store/index # checkpoint 文件存储路径 storeCheckpoint=/rocketmq/store/checkpoint # abort 文件存储路径 abortFile=/rocketmq/store/abort # 限制的消息大小 maxMessageSize=65536 # flushCommitLogLeastPages=4 # flushConsumeQueueLeastPages=2 # flushCommitLogThoroughInterval=10000 # flushConsumeQueueThoroughInterval=60000 # Broker 的角色 # - ASYNC_MASTER 异步复制Master # - SYNC_MASTER 同步双写Master # - SLAVE brokerRole=SYNC_MASTER # 刷盘方式 # - ASYNC_FLUSH 异步刷盘 # - SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH # checkTransactionMessageEnable=false # 发消息线程池数量 # sendMessageThreadPoolNums=128 # 拉消息线程池数量 # pullMessageThreadPoolNums=128 # 强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误 brokerIP1=10.125.15.124 EOF 修改broker-a-s.properties配置文件 $ cat \u003ebroker-a-s.properties\u003c\u003c-EOF # 所属集群名字 brokerClusterName=rocketmq-cluster # broker名字，注意此处不同的配置文件填写的不一样， brokerName=broker-a-s # 0 表示 Master，\u003e0 表示 Slave brokerId=1 # nameServer地址，分号分割 namesrvAddr=mq-nameserver1:9876;mq-nameserver2:9876 # 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 # 是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=false # 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=false # Broker 对外服务的监听端口 listenPort=10923 haListenPort=10924 # 删除文件时间点，默认凌晨 4点 deleteWhen=04 # 文件保留时间，默认 48 小时 fileReservedTime=120 # commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 # ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 # destroyMapedFileIntervalForcibly=120000 # redeleteHangedFileInterval=120000 # 检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 # 存储路径 storePathRootDir=/rocketmq/store-s # commitLog 存储路径 storePathCommitLog=/rocketmq/store-s/commitlog # 消费队列存储路径存储路径 storePathConsumeQueue=/rocketmq/store-s/consumequeue # 消息索引存储路径 storePathIndex=/rocketmq/store-s/index # checkpoint 文件存储路径 storeCheckpoint=/rocketmq/store-s/checkpoint # abort 文件存储路径 abortFile=/rocketmq/store-s/abort # 限制的消息大小 maxMessageSize=65536 # flushCommitLogLeastPages=4 # flushConsumeQueueLeastPages=2 # flushCommitLogThoroughInterval=10000 # flushConsumeQueueThoroughInterval=60000 # Broker 的角色 # - ASYNC_MASTER 异步复制Master # - SYNC_MASTER 同步双写Master # - SLAVE brokerRole=SLAVE # 刷盘方式 # - ASYNC_FLUSH 异步刷盘 # - SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH # checkTransactionMessageEnable=false # 发消息线程池数量 # sendMessageThreadPoolNums=128 # 拉消息线程池数量 # pullMessageThreadPoolNums=128 # 强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误 brokerIP1=10.125.15.125 EOF 修改broker-b.properties配置文件 $ cat \u003ebroker-b.properties\u003c\u003c-EOF # 所属集群名字 brokerClusterName=rocketmq-cluster # broker名字，注意此处不同的配置文件填写的不一样， brokerName=broker-b # 0 表示 Master，\u003e0 表示 Slave brokerId=0 # nameServer地址，分号分割 namesrvAddr=mq-nameserver1:9876;mq-nameserver2:9876 # 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 # 是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=false # 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=false # Broker 对外服务的监听端口 listenPort=10911 haListenPort=10912 # 删除文件时间点，默认凌晨 4点 deleteWhen=04 # 文件保留时间，默认 48 小时 fileReservedTime=120 # commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 # ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 # destroyMapedFileIntervalForcibly=120000 # redeleteHangedFileInterval=120000 # 检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 # 存储路径 storePathRootDir=/rocketmq/store # commitLog 存储路径 storePathCommitLog=/rocketmq/store/commitlog # 消费队列存储路径存储路径 storePathConsumeQueue=/rocketmq/store/consumequeue # 消息索引存储路径 storePathIndex=/rocketmq/store/index # checkpoint 文件存储路径 storeCheckpoint=/rocketmq/store/checkpoint # abort 文件存储路径 abortFile=/rocketmq/store/abort # 限制的消息大小 maxMessageSize=65536 # flushCommitLogLeastPages=4 # flushConsumeQueueLeastPages=2 # flushCommitLogThoroughInterval=10000 # flushConsumeQueueThoroughInterval=60000 # Broker 的角色 # - ASYNC_MASTER 异步复制Master # - SYNC_MASTER 同步双写Master # - SLAVE brokerRole=SYNC_MASTER # 刷盘方式 # - ASYNC_FLUSH 异步刷盘 # - SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH # checkTransactionMessageEnable=false # 发消息线程池数量 # sendMessageThreadPoolNums=128 # 拉消息线程池数量 # pullMessageThreadPoolNums=128 # 强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误 brokerIP1=10.125.15.125 EOF 修改broker-b-s.properties配置文件 $ cat \u003ebroker-b-s.properties\u003c\u003c-EOF # 所属集群名字 brokerClusterName=rocketmq-cluster # broker名字，注意此处不同的配置文件填写的不一样， brokerName=broker-b-s # 0：表示Master，\u003e0：表示 Slave brokerId=1 # nameServer地址，分号分割 namesrvAddr=mq-nameserver1:9876;mq-nameserver2:9876 # 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 # 是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=false # 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=false # Broker 对外服务的监听端口 listenPort=10923 haListenPort=10924 # 删除文件时间点，默认凌晨 4点 deleteWhen=04 # 文件保留时间，默认 48 小时 fileReservedTime=120 # commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 # ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 # destroyMapedFileIntervalForcibly=120000 # redeleteHangedFileInterval=120000 # 检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 # 存储路径 storePathRootDir=/rocketmq/store-s # commitLog 存储路径 storePathCommitLog=/rocketmq/store-s/commitlog # 消费队列存储路径存储路径 storePathConsumeQueue=/rocketmq/store-s/consumequeue # 消息索引存储路径 storePathIndex=/rocketmq/store-s/index # checkpoint 文件存储路径 storeCheckpoint=/rocketmq/store-s/checkpoint # abort 文件存储路径 abortFile=/rocketmq/store-s/abort # 限制的消息大小 maxMessageSize=65536 # flushCommitLogLeastPages=4 # flushConsumeQueueLeastPages=2 # flushCommitLogThoroughInterval=10000 # flushConsumeQueueThoroughInterval=60000 # Broker 的角色 # - ASYNC_MASTER 异步复制Master # - SYNC_MASTER 同步双写Master # - SLAVE brokerRole=SLAVE # 刷盘方式 # - ASYNC_FLUSH 异步刷盘 # - SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH # checkTransactionMessageEnable=false # 发消息线程池数量 # sendMessageThreadPoolNums=128 # 拉消息线程池数量 # pullMessageThreadPoolNums=128 # 强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误 brokerIP1=10.125.15.124 EOF 在其他几个节点服务器启动Master $ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-a.properties \u0026 # 在机器A机器启动Master $ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-b.properties \u0026 # 在机器B机器启动Master $ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-a-s.properties \u0026 # 在机器C机器启动Slave $ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-b-s.properties \u0026 # 在机器C机器启动Slave 安装rocketmq-console图形化管理控制台 下载图形化管理控制台 $ git clone https://github.com/apache/rocketmq-externals.git 修改配置文件 $ cat \u003e/usr/local/src/rocketmq-externals/rocketmq-console/src/main/resources/application.properties\u003c\u003c-EOF # 管理后台访问上下文路径，默认为空，如果填写，一定要前面加“/”，后面不要加，否则启动报错 server.contextPath=/rocketmq # 访问端口 server.port=8080 ### SSL setting 默认就行 # server.ssl.key-store=classpath:rmqcngkeystore.jks # server.ssl.key-store-password=rocketmq # server.ssl.keyStoreType=PKCS12 # server.ssl.keyAlias=rmqcngkey # spring.application.index=true spring.application.name=rocketmq-console spring.http.encoding.charset=UTF-8 spring.http.encoding.enabled=true spring.http.encoding.force=true # logback配置文件路径，先默认即可 logging.config=classpath:logback.xml # if this value is empty,use env value rocketmq.config.namesrvAddr NAMESRV_ADDR | now, you can set it in ops page.default \u003e localhost:9876 # Name Server地址，修改成你自己的服务地址。多个地址用英文分号“;”隔开 rocketmq.config.namesrvAddr=localhost:9876 # if you use rocketmq version \u003c 3.5.8, rocketmq.config.isVIPChannel should be false.default true rocketmq.config.isVIPChannel= # rocketmq-console's data path:dashboard/monitor rocketmq.config.dataPath=/tmp/rocketmq-console/data # set it false if you don't want use dashboard.default true rocketmq.config.enableDashBoardCollect=true # set the message track trace topic if you don't want use the default one rocketmq.config.msgTrackTopicName= rocketmq.config.ticketKey=ticket # Must create userInfo file: ${rocketmq.config.dataPath}/users.properties if the login is required rocketmq.config.loginRequired=false EOF 打包运行rocketmq-console服务 $ mvn clean package -Dmaven.test.skip=true $ cd /usr/local/src/rocketmq-externals/rocketmq-console/target/ $ java -jar rocketmq-console-ng-2.0.0.jar 打开浏览器访问 $ http://IP:8080/#/ 控制台→更换语言→Simplified Chinese(切换中文) ",
    "description": "Rocketmq部署 单机单实例 安装Rocketmq必要条件 64位JDK 1.8+ Maven 3.2.x Git 使用于Broker服务器4G+可用磁盘空间 安装JDK配置环境变量 打开链接找早期版本 $ tar -zxvf /usr/local/src/jdk-8u181-linux-x64.",
    "tags": [],
    "title": "Install_RocketMQ",
    "uri": "/systems/linux/message_queue/install_rocketmq/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "Redpanda部署 名称地址 描述 Redpanda Redpanda部署文档 ",
    "description": "Redpanda部署 名称地址 描述 Redpanda Redpanda部署文档 ",
    "tags": [],
    "title": "Install_Redpanda",
    "uri": "/systems/linux/message_queue/install_redpanda/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "Rabbitmq部署 安装RabbitMQ Celery分布式任务队列 RabbitMQ集群安装 集群服务器配置 IP 主机名 节点属性 192.168.150.21 rabbit-mq-01 内存节点+Haproxy节点 192.168.150.22 rabbit-mq-02 内存节点+Haproxy节点 192.168.150.23 rabbit-mq-03 磁盘节点 192.168.150.24 keepalived vip 提供对外VIP Erlang安装 RabbitMQ是用Erlang语言编写的，我们将安装最新版本的Erlang到服务器中。 Erlang在默认的YUM存储库中不可用，因此您将需要安装EPEL存储库。 运行以下命令相同。 做好hosts解析，防火墙开放端口port 25672 $ yum -y update $ yum -y install epel-release $ yum -y install erlang socat RabbitMQ安装 RabbitMQ为预编译并可以直接安装的企业Linux系统提供RPM软件包。 唯一需要的依赖是将Erlang安装到系统中。 我们已经安装了Erlang，我们可以进一步下载RabbitMQ。 通过运行下载Erlang RPM软件包 $ rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc $ wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.10/rabbitmq-server-3.6.10-1.el7.noarch.rpm $ rpm -Uvh rabbitmq-server-3.6.10-1.el7.noarch.rpm # https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.19/rabbitmq-server-3.7.19-1.el7.noarch.rpm # https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.19/rabbitmq-server-3.7.19-1.el7.noarch.rpm.asc 开启第一台MQ $ systemctl start rabbitmq-server 复制.erlang.cookie文件到其他两台MQ服务器集群节点 $ scp /var/lib/rabbitmq/.erlang.cookie rabbit-mq-02:/var/lib/rabbitmq/ $ scp /var/lib/rabbitmq/.erlang.cookie rabbit-mq-03:/var/lib/rabbitmq/ 启动其他两台集群节点服务器上的MQ服务 $ chown -R rabbitmq. /var/lib/rabbitmq $ systemctl start rabbitmq-server Rabbitmq集群连接、集群节点之间防火墙开启：4369端口 $ rabbitmqctl stop_app $ rabbitmqctl join_cluster rabbit@rabbit-mq-01 $ rabbitmqctl start_app 设置镜像模式 $ rabbitmqctl cluster_status $ rabbitmqctl set_policy ha-all \"^\" '{\"ha-mode\":\"all\"}' $ rabbitmqctl cluster_status 设置节点信息内存节点、磁盘节点 $ rabbitmqctl stop_app $ rabbitmqctl change_cluster_node_type ram # 类型(ram 内存)、(disc 硬盘)延迟插件必须硬盘 $ rabbitmqctl start_app 在所有节点机器上开启rabbit监控 $ rabbitmq-plugins enable rabbitmq_management Rabbitmq用户授权 添加用户、用户密码都是：admin $ rabbitmqctl add_user admin admin 设置permissions $ rabbitmqctl set_permissions -p \"/\" admin \".*\" \".*\" \".*\" 设置用户角色权限 $ rabbitmqctl set_user_tags admin administrator 防火墙开启：15672端口，使用浏览器访问 $ http://IP:15672/ RabbitMQ安装延时插件 切换安装Rabbitmq服务主目录plugins下 $ cd /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.10/plugins 下载延时插件安装包 $ wget https://dl.bintray.com/rabbitmq/community-plugins/3.6.x/rabbitmq_delayed_message_exchange/\u003e rabbitmq_delayed_message_exchange-20171215-3.6.x.zip 解压延时插件安装包 $ yum -y install unzip $ unzip rabbitmq_delayed_message_exchange-20171215-3.6.x.zip $ cd ../sbin $ ./rabbitmq-plugins enable rabbitmq_delayed_message_exchange 重启Rabitymq服务 $ systemctl restart rabbitmq-server HAProxy部署 使用HAProxy使Rabbitmq服务实现高可用 两台服务器都安装HAProxy服务 IP 主机名 节点属性 192.168.150.21 rabbit-mq-01 内存节点+Haproxy节点，端口：8888(haproxy监控端口)、8889(rabbitmq\u003e 服务端口) 192.168.150.22 rabbit-mq-02 内存节点+Haproxy节点，端口：8888(haproxy监控端口)、8889(rabbitmq\u003e 服务端口) $ yum install -y haproxy 修改配置文件 $ cat \u003e/etc/haproxy/haproxy.cfg\u003c\u003c-EOF global # log /yougo/haproxy/home/log local0 # log /yougo/haproxy/home/log local1 notice # chroot /yougo/haproxy # 改变当前工作目录 # stats socket /yougo/haproxy/home/admin.sock mode 660 level admin # 创建监控所用的套接字目录 pidfile /var/run/haproxy.pid # haproxy的pid存放路径,启动进程的用户必须有权限访问此文件 maxconn 4000 # 最大连接数，默认4000 # user haproxy # 默认用户 # group haproxy # 默认用户组 daemon # 创建1个进程进入deamon模式运行。此参数要求将运行模式设置为\"daemon # Default SSL material locations # ca-base /etc/ssl/certs # crt-base /etc/ssl/private # Default ciphers to use on SSL-enabled listening sockets. # For more information, see ciphers(1SSL). This list is from: # https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ # ssl-default-bind-ciphers \u003e ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS # ssl-default-bind-options no-sslv3 ###########默认配置######### defaults log global mode http # 默认的模式mode { tcp|http|health }，tcp是4层，http是7层，health只会返回OK option httplog # 采用http日志格式 option dontlognull # 启用该项，日志中将不会记录空连接。所谓空连接就是在上游的负载均衡器或者监控系统为了探测该服务是否存活可用时, # 需要定期的连接或者获取某一固定的组件或页面,或者探测扫描端口是否在监听或开放等动作被称为空连接; # 官方文档中标注，如果该服务上游没有其他的负载均衡器的话，建议不要使用 # 该参数，因为互联网上的恶意扫描或其他动作就不会被记录下来 timeout connect 5000 # 连接超时时间 timeout client 50000 # 客户端连接超时时间 timeout server 50000 # 服务器端连接超时时间 option httpclose # 每次请求完毕后主动关闭http通道 option httplog # 日志类别http日志格式 #option forwardfor # 如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip option redispatch # serverId对应的服务器挂掉后,强制定向到其他健康的服务器 timeout connect 10000 # default 10 second timeout if a backend is not found maxconn 60000 # 最大连接数 retries 3 # 3次连接失败就认为服务不可用，也可以通过后面设置 # errorfile 400 /yougo/haproxy/home/errors/400.http # errorfile 403 /yougo/haproxy/home/errors/403.http # errorfile 408 /yougo/haproxy/home/errors/408.http # errorfile 500 /yougo/haproxy/home/errors/500.http # errorfile 502 /yougo/haproxy/home/errors/502.http # errorfile 503 /yougo/haproxy/home/errors/503.http # errorfile 504 /yougo/haproxy/home/errors/504.http #################################################################### listen http_front bind 0.0.0.0:8888 # 监听端口 stats refresh 30s # 统计页面自动刷新时间 stats uri /haproxy?stats # 统计页面url stats realm Haproxy Manager # 统计页面密码框上提示文本 stats auth admin:admin # 统计页面用户名和密码设置 #stats hide-version # 隐藏统计页面上HAProxy的版本信息 #####################RabbitMQ的管理界面也放在HAProxy后面了############################### #listen rabbitmq_admin # bind 0.0.0.0:8004 # server node1 192.168.0.31:15672 # server node2 192.168.0.32:15672 # server node3 192.168.0.33:15672 #################################################################### listen rabbitmq_cluster bind 0.0.0.0:8889 # rabbitmq集群调用的端口 option tcplog mode tcp timeout client 3h timeout server 3h option clitcpka balance roundrobin # 负载均衡算法（#banlance roundrobin 轮询，balance source 保存session值，支持static-rr，leastconn，first，uri等参数） # balance url_param userid # balance url_param session_id check_post 64 # balance hdr(User-Agent) # balance hdr(host) # balance hdr(Host) use_domain_only # balance rdp-cookie # balance leastconn # balance source //ip server rabbitmq1 172.16.0.30:5672 check inter 5s rise 2 fall 3 # check inter 2000 是检测心跳频率，rise \u003e 2是2次正确认为服务器可用，fall 3是3次失败认为服务器不可用 server rabbitmq2 172.16.0.31:5672 check inter 5s rise 2 fall 3 server rabbitmq3 172.16.0.32:5672 check inter 5s rise 2 fall 3 EOF 两台HAProxy服务器启动服务 $ systemctl start haproxy Keepalived部署 安装Keepalived服务 $ yum install -y keepalived 配置Keepalived主节点Master配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF global_defs { # 全局配置 notification_email { # 指定keepalived在发生切换时需要需要发送Email的对象，一行一个 user@example.com # 指定的收件人 } notification_email_from mail@example.org # 指定的发件人 smtp_server 192.168.200.1 # 指定的SMTP服务器地址 smtp_connect_timeout 30 # 指定SMTP连接超时时间 router_id Rabbitmq_Dev # 此处注意router_id为负载均衡标识，在局域网内应该是唯一 } vrrp_instance VI_1 { # 监控多个网段的实例 state MASTER # 指定Keepalived的角色，MASTER表示此主机是主服务器,BACKUP表示此主机是备用服务器，所以设置priority时要注意MASTER比BACKUP高。如\u003e 果设置了nopreempt,那么state的这个值不起作用，主备靠priority决定，必须大写 nopreempt # 设置为不抢占 interface eth0 # 指定监测网络的接口，当LVS接管时，将会把IP地址添加到该网卡上。 virtual_router_id 58 # 虚拟路由标识，同一个vrrp实例使用唯一的标识，同一个vrrp_instance下，MASTER和BACKUP必须一致。 priority 101 # MASTER权重要高于 BACKUP advert_int 1 # 心跳报文发送间隔 unicast_src_ip 192.168.150.21 # 配置单播的源地址 unicast_peer { 192.168.150.22 # 配置单播的目标地址、对端IP } # keepalived在组播模式下所有的信息都会向224.0.0.18的组播地址发送，产生众多的无用信息，并且会产生干扰和冲突，可以将组播的模式改为单拨。这是一种安\u003e 全的方法，避免局域网内有大量的keepalived造成虚拟路由id的冲突。 authentication { # 认证配置 auth_type PASS # 主从服务器验证方式 auth_pass 1111 # 认证密码 } virtual_ipaddress { # 设置虚拟IP地址，可以设置多个虚拟IP地址，每行一个 192.168.150.24/24 dev eth1 } track_interface { # 设置额外的监控，里面那个网卡出现问题都会切换 eth0 } } EOF 配置Keepalived备用节点Backup配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF global_defs { # 全局配置 notification_email { # 指定在keepalived在发生切换时需要发送Email的对象，一行一个 user@example.com # 指定收件人 } notification_email_from mail@example.org # 指定发件人 smtp_server 192.168.200.1 # 指定SMTP服务器地址 smtp_connect_timeout 30 # 指定SMTP连接超时时间 router_id Rabbitmq_Dev # 此处注意router_id为负载均衡表示，在局域网应该是唯一 } vrrp_instance VI_1 { # 监控多个网段实例 state BACKUP # 指定Keepalived的角色，MASTER表示此主机是主服务器,BACKUP表示此主机是备用服务器，所以设置priority时要注意MASTER比BACKUP高。如\u003e 果设置了nopreempt,那么state的这个值不起作用，主备靠priority决定。 nopreempt # 设置为不抢占 interface eth0 # 设置实例绑定的网卡 virtual_router_id 58 # 虚拟路由标识，同一个vrrp实例使用唯一的标识，同一个vrrp_instance下，MASTER和BACKUP必须一致。 priority 100 # 权重要低于MASTER advert_int 1 # 心跳报文发送间隔、检查间隔默认1秒 unicast_src_ip 192.168.150.22 # 配置单播的源地址 unicast_peer { 192.168.150.21 # 配置单播的目标地址、对端IP } # keepalived在组播模式下所有的信息都会向224.0.0.18的组播地址发送，产生众多的无用信息，并且会产生干扰和冲突，可以将组播的模式改为单拨。这是一种安\u003e 全的方法，避免局域网内有大量的keepalived造成虚拟路由id的冲突。 authentication { # 设置认证 auth_type PASS # 认证方式有两种PASS、AH两种 auth_pass 1111 # 认证密码 } # VIP virtual_ipaddress { # 设置虚拟IP地址，可以设置多个虚拟IP地址，每行一个 192.168.150.24/24 dev eth1 } } EOF 启动Keepalived服务 $ systemctl start keepalived 允许组播网段和vrrp协议通信 centos7 firewalld开启情况下，会阻断组播和vrrp的协议通信，导致Keepalived脑裂情况，需要在keepalived的两台服务器执行以下命令，就可以正常通信 $ firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface 网卡名称(eth0) --destination 224.0.0.18 --protocol \u003e vrrp -j ACCEPT $ firewall-cmd --reload 监控网络协议，查看是否有脑裂情况 $ tcpdump -i 网卡名称(eth0) vrrp -n 使用python安装pika包进行测试 $ yum install -y python-pip $ pip install pika 生产端程序脚本 $ cat \u003eProduction.py\u003c\u003c-EOF # !/usr/bin/env python import pika credentials = pika.PlainCredentials('admin','admin') connection = pika.BlockingConnection(pika.ConnectionParameters( '192.168.150.21',8889,'/',credentials)) channel = connection.channel() channel.queue_declare(queue='balance') channel.basic_publish(exchange='', routing_key='balance', body='Hello World!') print(\" [x] Sent 'Hello World!'\") connection.close() EOF 消费端程序脚本 $ cat \u003eConsumption.py\u003c\u003c-EOF # !/usr/bin/env python import pika credentials = pika.PlainCredentials('admin','admin') connection = pika.BlockingConnection(pika.ConnectionParameters( '192.168.150.21',8889,'/',credentials)) channel = connection.channel() channel.queue_declare(queue='balance') channel.basic_publish(exchange='', routing_key='balance', body='Hello World!') print(\" [x] Sent 'Hello World!'\") connection.close() EOF ",
    "description": "Rabbitmq部署 安装RabbitMQ Celery分布式任务队列 RabbitMQ集群安装 集群服务器配置 IP 主机名 节点属性 192.168.150.21 rabbit-mq-01 内存节点+Haproxy节点 192.",
    "tags": [],
    "title": "Install_RabbitMQ",
    "uri": "/systems/linux/message_queue/install_rabbitmq/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "nsq部署 Nsq官网 下载nsq预编译二进制安装包 $ wget -P /usr/local/src/ https://s3.amazonaws.com/bitly-downloads/nsq/nsq-1.2.1.linux-amd64.go1.16.6.tar.gz 解压启动安装包 $ tar -zxvf nsq-1.2.1.linux-amd64.go1.16.6.tar.gz -C /usr/local/src/ $ cd nsq-1.2.1.linux-amd64.go1.16.6/bin/ $ nohup ./nsqlookupd \u0026 # 启动nsqlookup $ nohup ./nsqd --lookupd-tcp-address=127.0.0.1:4160 \u0026 # nsqd $ nohup ./nsqadmin --lookupd-http-address=0.0.0.0:4161 --http-address=IP:8761 \u0026 # nsqadmin管理，ip需要更换为服务所在的服务器IP 测试、访问 $ curl -d 'hello world 1' 'http://127.0.0.1:4151/pub?topic=test' # 写入消息 $ ./nsq_to_file --topic=test --output-dir=/tmp/log --lookupd-http-address=127.0.0.1:4161 # 把队列消息写入到文件 通过浏览器访问nsqadmin http://IP:8761/ ",
    "description": "nsq部署 Nsq官网 下载nsq预编译二进制安装包 $ wget -P /usr/local/src/ https://s3.amazonaws.com/bitly-downloads/nsq/nsq-1.2.1.linux-amd64.go1.16.6.tar.gz 解压启动安装包 $ tar -zxvf nsq-1.",
    "tags": [],
    "title": "Install_Nsq",
    "uri": "/systems/linux/message_queue/install_nsq/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "Kafka部署 Kafka简介 名称地址 描述 Kafka官网 安装及快速入门 php安装kafka扩展 Kafka集群搭建过程和简单使用 使用zookeeper保存所有集群主机消息内容 开发语言：Java/Scala，支持协议：仿AMQP Kafka是分布式发布-订阅消息系统,它最初由LinkedIn公司开发，之后成为Apache项目的一部分 Kafka是一个分布式的，可划分的，冗余备份的持久性的日志服务，它主要用于处理活跃的流式数据 事务处理不支持、支持集群、支持负载均衡、支持zookeeper动态扩容 所有消息自动保存两天时间 Kafka为了避免随机写入带来的时间消耗，采取顺序写的方式存储数据 Kafka采用零拷贝技术，让数据传输更加迅速 批量读书数据，减少磁盘IO操作，可以提升性能 为了保证历史消息继续可以被消费，提供一个offset指向，通过指向来负责消息读取顺序 网络传输采用数据压缩格式，所以传输更快，占用带宽越少 Kafka中数据可以设置副本，可以在出现问题之后依然保证该数据的有效性 Kafka整体采用显示分布式架构，producers、broker(Kafka)和consumers都可以有多个 producer、consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用，broker分发注册到系统中的consumer broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存，客户端和服务端的通信，是基于简单，高性能，且与编程语言无关的TCP协议 Topic：特指Kafka处理的消息源feeds of messages的不同分类 Partition：代表分区，单核CPU一个分区，多个CPU可以有多个分区。Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列，partition中的每条消息都会被分配一个有序的id(offset) Message：消息，是通信的基本单位，每个producer可以向一个topic(主题)发布一些消息 Producers：消息和数据产生着，向Kafka的一个topic发布消息的过程叫做producers Consumers：消息和数据消费者，订阅topics并处理其发布消息的过程叫做consumers Broker：缓存代理，Kafka集群中的一台或者多台服务器统称为broker offset与消息访问 消费者通过offset的方式来取得消息数据，利用offset偏移改变消息读取位置，可以实现历史消息读取 为了避免频繁的大量小数据磁盘IO操作，Kafka采用批量读取模式处理消息 在高负载状态下，为防止无效率的字节复制，Kafka采用由Producer，broker和consumer共享的标准化二进制消息格式，这样数据库就可以在它们之间自由传输，无需转换，降低了字节复制成本开销 Kafka图形化页面 名称地址 描述 Kafka图形化工具Eagle Apache Kafka的用户界面 Kafdrop – Kafka Web UI Eagle For Apache Kafka以前称为Kafka Eagle Kafka单节点部署 Kafka安装 单机部署单实例 下载、解压Kafka安装包 $ wget -P /usr/local/src/ https://archive.apache.org/dist/kafka/2.8.1/kafka_2.13-2.8.1.tgz $ tar -zxvf /usr/local/srckafka_2.13-2.8.1.tgz -C /opt/ $ cd /opt/ $ mv kafka_2.13-2.8.1/ kafka 单机单实例修改Kafka配置文件 $ sed -i '/^dataDir=/cdataDir=\\/opt\\/kafka\\/zookeeper' /opt/kafka/config/zookeeper.properties $ sed -i '/^broker.id=/cbroker.id=1' /opt/kafka/config/server.properties # 集群设置不同id $ sed -i '/^log.dirs=/clog.dirs=/opt/kafka/logs/logs-1' /opt/kafka/config/server.properties # Kafka默认端口号：9092，如果要修改默认端口执行下面两条命令 $ sed -i '/#advertised.listeners/a port=9095' /opt/kafka/config/server.properties $ sed -i '/#advertised.listeners/a advertised.listeners=PLAINTEXT://$IP:9095' /opt/kafka/config/server.properties $ mkdir -p /opt/kafka/{zookeeper,logs} # 创建持久化目录 单机启动单实例zookeeper和Kafka $ /opt/kafka/bin/zookeeper-server-start.sh -daemon /opt/kafka/config/zookeeper.properties # 后台启动zookeeper进程 $ /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties 执行检查命令 $ jps 14050 Kafka 10042 QuorumPeerMain 15724 Jps Kafka单节点多实例 单机部署多实例集群模式 修改Kafka配置文件 $ sed -i '/^dataDir=/cdataDir=\\/opt\\/kafka\\/zookeeper' /opt/kafka/config/zookeeper.properties # 拷贝修改kafka配置文件 $ cp /opt/kafka/config/server.properties /opt/kafka/config/server-2.properties $ cp /opt/kafka/config/server.properties /opt/kafka/config/server-3.properties # 修改第一个实例配置 $ sed -i '/^broker.id=/cbroker.id=1' /opt/kafka/config/server.properties # 集群设置不同id $ sed -i '/^log.dirs=/clog.dirs=/opt/kafka/logs/logs-1' /opt/kafka/config/server.properties $ sed -i '/#advertised.listeners/a advertised.listeners=PLAINTEXT://$IP:9092' /opt/kafka/config/server.properties # 修改第二个实例 $ sed -i '/^broker.id=/cbroker.id=2' /opt/kafka/config/server.properties # 集群设置不同id $ sed -i '/^log.dirs=/clog.dirs=/opt/kafka/logs/logs-2' /opt/kafka/config/server.properties $ sed -i '/#advertised.listeners/a advertised.listeners=PLAINTEXT://$IP:9093' /opt/kafka/config/server.properties # 修改第三个实例 $ sed -i '/^broker.id=/cbroker.id=3' /opt/kafka/config/server.properties # 集群设置不同id $ sed -i '/^log.dirs=/clog.dirs=/opt/kafka/logs/logs-3' /opt/kafka/config/server.properties $ sed -i '/#advertised.listeners/a advertised.listeners=PLAINTEXT://$IP:9094' /opt/kafka/config/server.properties 单机启动多实例zookeeper和Kafka $ /opt/kafka/bin/zookeeper-server-start.sh -daemon /opt/kafka/config/zookeeper.properties # 后台启动zookeeper进程 # 启动Kafka多个实例 $ /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties $ /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server-2.properties $ /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server-3.properties Kafka集群模式 多zookeeper多Kafka实例 下载、解压Kafka安装包 $ wget -P /usr/local/src/ https://archive.apache.org/dist/kafka/2.8.1/kafka_2.13-2.8.1.tgz $ tar -zxvf /usr/local/srckafka_2.13-2.8.1.tgz -C /opt/ $ cd /opt/ $ mv kafka_2.13-2.8.1/ kafka 修改zookeeper和Kafka配置文件 $ mkdir -p /opt/kafka/{zookeeper,logs} # 创建持久化目录 $ sed -i '/^dataDir=/cdataDir=\\/opt\\/kafka\\/zookeeper' /opt/kafka/config/zookeeper.properties $ sed -i '/^broker.id=/cbroker.id=1' /opt/kafka/config/server.properties # 集群设置不同id $ sed -i '/^log.dirs=/clog.dirs=/opt/kafka/logs/logs-1' /opt/kafka/config/server.properties $ sed -i '/^zookeeper.connect=/czookeeper.connect=${IP-1}:2128,${IP-2}:2128,${IP-3}:2128' /opt/kafka/config/server.properties 多zookeeper和多Kafka实例启动 $ /opt/kafka/bin/zookeeper-server-start.sh -daemon /opt/kafka/config/zookeeper.properties # 后台启动zookeeper进程 $ /opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties 创建Topic测试 --create：创建 --zookeeper： 使用zookeeper --replication-factor 1： 使用1个副本 --partitions 1：启用分区数量 --topic test： 主题名字：test $ /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test # 使用kafka-console-producer.sh 产生消息，发送消息 $ /opt/kafka/bin/kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092 # 使用kafka-console-consumer.sh消费消息 --from-beginning： 接受历史消息参数 $ /opt/kafka/bin/kafka-topics.sh --describe --topic test --bootstrap-server localhost:9092 # 查看topics描述信息 第一行给出了所有分区的摘要，每个附加行给出了关于一个分区的信息。 由于我们只有一个分区，所以只有一行 Leader：是负责给定分区的所有读取和写入的节点。 每个节点将成为分区随机选择部分的领导者 Replicas：是复制此分区日志的节点列表，无论它们是否是领导者，或者即使他们当前处于活动状态 Isr：是一组“同步”副本。这是复制品列表的子集，当前活着并被引导到领导者 ",
    "description": "Kafka部署 Kafka简介 名称地址 描述 Kafka官网 安装及快速入门 php安装kafka扩展 Kafka集群搭建过程和简单使用 使用zookeeper保存所有集群主机消息内容 开发语言：Java/Scala，支持协议：仿AMQP Kafka是分布式发布-订阅消息系统,它最初由LinkedIn公司开发，之后成为Apache项目的一部分 Kafka是一个分布式的，可划分的，冗余备份的持久性的日志服务，它主要用于处理活跃的流式数据 事务处理不支持、支持集群、支持负载均衡、支持zookeeper动态扩容 所有消息自动保存两天时间 Kafka为了避免随机写入带来的时间消耗，采取顺序写的方式存储数据 Kafka采用零拷贝技术，让数据传输更加迅速 批量读书数据，减少磁盘IO操作，可以提升性能 为了保证历史消息继续可以被消费，提供一个offset指向，通过指向来负责消息读取顺序 网络传输采用数据压缩格式，所以传输更快，占用带宽越少 Kafka中数据可以设置副本，可以在出现问题之后依然保证该数据的有效性 Kafka整体采用显示分布式架构，producers、broker(Kafka)和consumers都可以有多个 producer、consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用，broker分发注册到系统中的consumer broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存，客户端和服务端的通信，是基于简单，高性能，且与编程语言无关的TCP协议 Topic：特指Kafka处理的消息源feeds of messages的不同分类 Partition：代表分区，单核CPU一个分区，多个CPU可以有多个分区。Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列，partition中的每条消息都会被分配一个有序的id(offset) Message：消息，是通信的基本单位，每个producer可以向一个topic(主题)发布一些消息 Producers：消息和数据产生着，向Kafka的一个topic发布消息的过程叫做producers Consumers：消息和数据消费者，订阅topics并处理其发布消息的过程叫做consumers Broker：缓存代理，Kafka集群中的一台或者多台服务器统称为broker offset与消息访问 消费者通过offset的方式来取得消息数据，利用offset偏移改变消息读取位置，可以实现历史消息读取 为了避免频繁的大量小数据磁盘IO操作，Kafka采用批量读取模式处理消息 在高负载状态下，为防止无效率的字节复制，Kafka采用由Producer，broker和consumer共享的标准化二进制消息格式，这样数据库就可以在它们之间自由传输，无需转换，降低了字节复制成本开销 Kafka图形化页面 名称地址 描述 Kafka图形化工具Eagle Apache Kafka的用户界面 Kafdrop – Kafka Web UI Eagle For Apache Kafka以前称为Kafka Eagle Kafka单节点部署 Kafka安装 单机部署单实例 下载、解压Kafka安装包 $ wget -P /usr/local/src/ https://archive.",
    "tags": [],
    "title": "Install_Kafka",
    "uri": "/systems/linux/message_queue/install_kafka/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Message_Queue",
    "content": "使用Rabbitmq Rabbitmq添加登录账户 在/etc/rabbitmq/rabbitmq.config配置文件下添加，如果不存在就自行创建添加 admin就是用户名称 $ cat /etc/rabbitmq/rabbitmq.config [ {rabbit,[{tcp_listeners,[5672]},{loopback_users,[\"admin\"]}]} ] 使用命令添加用户并授权 添加用户 $ rabbitmqctl add_user admin admin 设置permissions $ rabbitmqctl set_permissions -p \"/\" admin \".*\" \".*\" \".*\" 设置用户角色 $ rabbitmqctl set_user_tags admin administrator 查看新添加的admin $ rabbitmqctl list_users 查看用于的权限 $ ./rabbitmqctl list_permissions -p / RabbitMQ问题 RabbitMQ无法新建连接问题处理过程记录 症状描述客户反馈无法云平台VNC控制台窗口一直处于loading状态，无法打开. 定位过程 首先查看nova-api服务是否正常nova list正常 查看nova service-list输出，所有服务在线 使用nova get-vnc-console获取云主机vnc链接，超时无法获取 初步找到控制台窗口无法打开的原因，继续分析问题 查看云主机所在节点的nova-compute服务，一切正常 查看nova-compute日志，没有收到创建vnc链接请求vnc控制台链接是在云主机所在计算节点生成的，因为要查询云主机qemu进程创建的vnc server端口号，创建完成后要把token和端口号对应关系保存到nova-consoleauth进程，nova-consoleauth进程会根据配置项决定把对应关系保存到进程内存还是memcache服务，之前处理过一次控制节点内存不足导致token保存失败的问题，这次也先查了下nova-consoleauth日志，没有发现类似情况 查看nova-api节点日志，发现收到了请求但没有返回 打开nova-api和nova-compute的debug日志继续分析 发现nova-api一直在尝试连接到RabbitMQ，一直卡在connecting，没有connected日志 找到更进一步的问题原因，继续分析问题 首先重启nova-api服务，试验下能否恢复，发现启动进程时可以连接到MQ，但获取vnc链接时问题仍然存在 通过rabbitmqctl命令行查看queue和exchange情况，也没发现异常，云主机节点的compute队列也有 重启MQ服务，试验能否恢复，重启后发现vnc链接获取命令恢复正常，页面打开控制台窗口正常 问题解决但没找到原因，于是继续观察，等了大概2分钟，再次尝试打开vnc控制台窗口，发现老问题还在，一直loading，继续分析问题， 查看MQ服务器日志，发现异常 发现问题根本原因，文件句柄数量超出限制，google搜索这个错误，发现了解决方法原创RabbitMQ之file descriptor limit alarm分析 =WARNING REPORT==== 25-Oct-2017::10:35:48 === file descriptor limit alarm set. ******************************************************************** *** New connections will not be accepted until this alarm clears *** ******************************************************************** 首先修改MQ节点物理机文件句柄数量配置（增加如下两行） $ cat /etc/security/limits.conf | grep nofile * soft nofile 262144 * hard nofile 262144 $ ulimit -n 65536 # 也修改 重启RabbitMQ，rabbitmqctl status命令查看限制，发现不生效： 按照搜索结果中的提示执行：rabbitmqctl stop、rabbitmq-server -detached再次查看，发现句柄数限制已修改 尝试web打开vnc窗口，发现恢复正常，nova-api和nova-compute日志正常connected到MQ等待几分钟仍然正常，问题解决 {file_descriptors, [{total_limit,924}, {total_used,525}, 尝试修改安装部署脚本，发现先修改系统句柄数配置再安装MQ，仍然无法修改MQ句柄限制 继续google，查看到RabbitMQ官方文档 有如下描述： 控制 Linux 上的系统限制 运行生产工作负载的 RabbitMQ 安装可能需要系统限制和内核参数调整，以便处理相当数量的并发连接和队列。需要调整的主要设置是最大打开文件数，也称为ulimit -n。许多操作系统上的默认值对于消息传递代理来说太低了（例如，在几个 Linux 发行版上为 1024）。我们建议在生产环境中为用户 rabbitmq 允许至少 65536 个文件描述符。对于大多数开发工作负载，4096 应该足够了。 有两个限制：操作系统内核允许打开文件的最大数量（fs.file-max）和每个用户的限制（ulimit -n）。前者必须高于后者。 使用 systemd（最近的 Linux 发行版） 在使用 systemd 的发行版上，操作系统限制是通过 /etc/systemd/system/rabbitmq-server.service.d/limits.conf 中的配置文件控制的，例如： [Service] LimitNOFILE=300000 据此修改正常 $ mkdir /etc/systemd/system/rabbitmq-server.service.d -p $ cat \u003e/etc/systemd/system/rabbitmq-server.service.d/limits.conf\u003c\u003cEOF [Service] LimitNOFILE=300000 EOF $ setenforce 0 $ sed -i \"s#enforcing#disabled#g\" /etc/selinux/config $ cat \u003e/etc/security/limits.conf\u003c\u003cEOF * soft nofile 204800 * hard nofile 204800 EOF $ ulimit -n 204800 $ systemctl daemon-reload $ systemctl restart rabbitmq-server.service Zabbix监控 Rabbitmq Rabbitmq-python监控脚本 RabbitMQ自己已经有一个挺好的管理监控界面，可以看到非常详细的消息队列信息，但是对于运维人员来说，还缺少了很重要的告警功能。 自己写一个脚本也是很有必要的，在网上也有很多参考，主要思路是利用RabbitMQ自带管理模块的RESTful API取值，发送到zabbix，由zabbix负责告警阀值判断和发送告警 RabbitMQ RESTful API 首先认识RabbitMQ的API，看看能取到什么，推荐看官方help 查看MQ总体情况 官方解析：/api/overview Various random bits of information that describe the whole system 例子：curl -u guest:guest http://192.168.55.241:15672/api/overview 然后返回d的json格式响应是： { \"management_version\": \"3.0.0\", \"statistics_level\": \"fine\", \"exchange_types\": [ { \"name\": \"topic\", \"description\": \"AMQP topic exchange, as per the AMQP specification\", \"enabled\": true }, { \"name\": \"fanout\", \"description\": \"AMQP fanout exchange, as per the AMQP specification\", \"enabled\": true }, { \"name\": \"direct\", \"description\": \"AMQP direct exchange, as per the AMQP specification\", \"enabled\": true }, { \"name\": \"headers\", \"description\": \"AMQP headers exchange, as per the AMQP specification\", \"enabled\": true } ], \"rabbitmq_version\": \"3.0.0\", \"erlang_version\": \"R15B01\", \"message_stats\": { \"publish\": 1104833, \"publish_details\": { \"rate\": 12.262779782167032, \"interval\": 298146914019, \"last_event\": 1476068131606 }, \"ack\": 1177571, \"ack_details\": { \"rate\": 11.230039450092189, \"interval\": 57927468985, \"last_event\": 1476068130882 }, \"deliver\": 1177572, \"deliver_details\": { \"rate\": 11.027518607238914, \"interval\": 57927468985, \"last_event\": 1476068130882 }, \"deliver_get\": 1207878, \"deliver_get_details\": { \"rate\": 11.027518607238914, \"interval\": 57927468985, \"last_event\": 1476068130882 }, \"deliver_no_ack\": 30306, \"deliver_no_ack_details\": { \"rate\": 0, \"interval\": 1067361970, \"last_event\": 1476068115093 }, \"redeliver\": 8, \"redeliver_details\": { \"rate\": 0, \"interval\": 115179973, \"last_event\": 1476068099504 } }, \"queue_totals\": { \"messages\": 0, \"messages_ready\": 0, \"messages_unacknowledged\": 0, \"messages_details\": { \"rate\": 0, \"interval\": 255911999, \"last_event\": 1476068131232 }, \"messages_ready_details\": { \"rate\": 0, \"interval\": 255911999, \"last_event\": 1476068131232 }, \"messages_unacknowledged_details\": { \"rate\": 0, \"interval\": 255911999, \"last_event\": 1476068131232 } }, \"object_totals\": { \"consumers\": 70, \"queues\": 27, \"exchanges\": 13, \"connections\": 176, \"channels\": 236 }, \"node\": \"rabbit@rabbit01\", \"statistics_db_node\": \"rabbit@rabbit01\", \"listeners\": [ { \"node\": \"rabbit@rabbit01\", \"protocol\": \"amqp\", \"ip_address\": \"::\", \"port\": 5672 } ], \"contexts\": [ { \"node\": \"rabbit@rabbit01\", \"description\": \"RabbitMQ Management\", \"path\": \"/\", \"port\": 15672 }, { \"node\": \"rabbit@rabbit01\", \"description\": \"Redirect to port 15672\", \"path\": \"/\", \"port\": 55672, \"ignore_in_use\": true } ] } 查看单个队列 官方解析：/api/queues/vhost/name An individual queue. To PUT a queue, you will need a body looking something like this: {“auto_delete”:false,”durable”:true,”arguments”:[],”node”:”rabbit@smacmullen”} All keys are optional 例子：%2F代表vhost为/ curl -u guest:guest http://192.168.55.241:15672/api/queues/%2F/wxq.msgweb.push.wgw.0 然后返回d的json格式响应是： { \"policy\": \"\", \"exclusive_consumer_tag\": \"\", \"messages_ready\": 0, \"messages_unacknowledged\": 0, \"messages\": 0, \"consumers\": 1, \"active_consumers\": 1, \"memory\": 55680, \"backing_queue_status\": { \"q1\": 0, \"q2\": 0, \"delta\": [ \"delta\", \"undefined\", 0, \"undefined\" ], \"q3\": 0, \"q4\": 0, \"len\": 0, \"pending_acks\": 0, \"target_ram_count\": \"infinity\", \"ram_msg_count\": 0, \"ram_ack_count\": 0, \"next_seq_id\": 1, \"persistent_count\": 0, \"avg_ingress_rate\": 0, \"avg_egress_rate\": 0, \"avg_ack_ingress_rate\": 0, \"avg_ack_egress_rate\": 0 }, \"messages_details\": { \"rate\": 0, \"interval\": 10001981, \"last_event\": 1476068574166 }, \"messages_ready_details\": { \"rate\": 0, \"interval\": 10001981, \"last_event\": 1476068574166 }, \"messages_unacknowledged_details\": { \"rate\": 0, \"interval\": 10001981, \"last_event\": 1476068574166 }, \"incoming\": [ { \"stats\": { \"publish\": 763, \"publish_details\": { \"rate\": 0, \"interval\": 75305976, \"last_event\": 1476068545922 } }, \"exchange\": { \"name\": \"wxq_appmsg_exchange\", \"vhost\": \"/\" } } ], \"deliveries\": [ { \"stats\": { \"deliver_get\": 774, \"deliver_get_details\": { \"rate\": 0, \"interval\": 44411017, \"last_event\": 1476068470753 }, \"deliver_no_ack\": 774, \"deliver_no_ack_details\": { \"rate\": 0, \"interval\": 44411017, \"last_event\": 1476068470753 } }, \"channel_details\": { \"name\": \"192.168.65.158:64326 -\u003e 192.168.55.241:5672 (1)\", \"number\": 1, \"connection_name\": \"192.168.65.158:64326 -\u003e 192.168.55.241:5672\", \"peer_port\": 64326, \"peer_host\": \"192.168.65.158\" } } ], \"message_stats\": { \"deliver_get\": 774, \"deliver_get_details\": { \"rate\": 0, \"interval\": 44411017, \"last_event\": 1476068470753 }, \"deliver_no_ack\": 774, \"deliver_no_ack_details\": { \"rate\": 0, \"interval\": 44411017, \"last_event\": 1476068470753 }, \"publish\": 763, \"publish_details\": { \"rate\": 0, \"interval\": 75305976, \"last_event\": 1476068545922 } }, \"consumer_details\": [ { \"channel_details\": { \"name\": \"192.168.65.158:64326 -\u003e 192.168.55.241:5672 (1)\", \"number\": 1, \"connection_name\": \"192.168.65.158:64326 -\u003e 192.168.55.241:5672\", \"peer_port\": 64326, \"peer_host\": \"192.168.65.158\" }, \"queue_details\": { \"name\": \"wxq.msgweb.push.wgw.0\", \"vhost\": \"/\" }, \"consumer_tag\": \"amq.ctag-jKVWrQSs7dbX9VaFfOZiYA\", \"exclusive\": false, \"ack_required\": false } ], \"name\": \"wxq.msgweb.push.wgw.0\", \"vhost\": \"/\", \"durable\": true, \"auto_delete\": false, \"arguments\": {}, \"node\": \"rabbit@rabbit01\" } zabbix sender zabbix sender区别于在zabbix agent添加item，sender可以主动发送item值到zabbix server 可以先规划好在zabbix server中使用的host和item名字 例如：这样就可以通过python取值，保存在临时文件中，再send到zabbix server rabbitmq.[rabbit@wx-pro-server01,messages_ready]待处理消息总数 rabbitmq.[rabbit@wx-pro-server01,messages_unacknowledged]未收到ack响应消息总数 rabbitmq.queues[/,queue_messages_ready,wxq_msg_send] wxq_msg_send队列的待处理消息数 rabbitmq.queues[/,queue_active_consumers,wxq_msg_send] wxq_msg_send队列的活动连接数 zabbix_sender使用方法 -c：agent配置文件 -i ：临时文件，用于保存多个item和对应值，每行一个item -s：在zabbix server上配置的host名字 /usr/bin/zabbix_sender -c /etc/zabbix/zabbix_agentd.conf -i /tmp/tmp5ai4uI -s ser01-rabbitmq python代码 使用Zabbix监控RabbitMQ #!/usr/bin/python # coding=utf-8 ''' RabbitMq监控脚本 v1.0 v1.1 监控channel的unacknowledged v1.0 监控overview、queue ''' import json import urllib2 import os import socket import tempfile import logging import subprocess import optparse import time logging.basicConfig(filename='/var/log/zabbix/rabbitmq_zabbix.log', level=logging.WARNNING, format='%(asctime)s %(levelname)s: %(message)s') class RabbitMqApi(object): ''' 调用RabbitMQ的API类 ''' ######## json.loads() transfer json data to python data ######## json.dump() transfer python data to json data def __init__(self, user_name='guest', password='guest', host_name='192.168.55.241', protocol='http', port=15672, senderhostname='ser01-rabbitmq', zbconf='/etc/zabbix/zabbix_agentd.conf'): self.user_name = user_name self.password = password self.host_name = host_name or socket.gethostname() self.protocol = protocol self.port = port self.senderhostname = senderhostname if senderhostname else host_name self.conf = zbconf # 调用RabbitMQ的API类取原始数据，json格式 def call_api(self, path): ''' All URIs will server only resource of type application/json,and will require HTTP basic authentication. The default username and password is guest/guest. /%sf is encoded for the default virtual host '/' ''' url = '{0}://{1}:{2}/api/{3}'.format(self.protocol, self.host_name, self.port, path) password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm() password_mgr.add_password(None, url, self.user_name, self.password) handler = urllib2.HTTPBasicAuthHandler(password_mgr) logging.debug('Issue a rabbit API call to get data on ' + url) return json.loads(urllib2.build_opener(handler).open(url).read()) # 调用RabbitMQ的API类取原始数据，json格式 def call_api_queue(self, queue_name): ''' get queue detail ''' url = '{0}://{1}:{2}/api/queues/%2F/{3}'.format(self.protocol, self.host_name, self.port, queue_name) password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm() password_mgr.add_password(None, url, self.user_name, self.password) handler = urllib2.HTTPBasicAuthHandler(password_mgr) logging.debug('Issue a rabbit API call to get data on ' + url) return json.loads(urllib2.build_opener(handler).open(url).read()) def call_api_channel(self, channel_name): ''' get channel detail ''' url = '{0}://{1}:{2}/api/channels/{3}'.format(self.protocol, self.host_name, self.port, urllib2.quote(channel_name)) password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm() password_mgr.add_password(None, url, self.user_name, self.password) handler = urllib2.HTTPBasicAuthHandler(password_mgr) logging.debug('Issue a rabbit API call to get data on ' + url) return json.loads(urllib2.build_opener(handler).open(url).read()) # 把数据与item对应写进临时文件 def _get_queue_data(self, queue, tmpfile): for item in [ 'memory','messages','messages_ready','messages_unacknowledged','consumers','active_consumers' ]: #key = rabbitmq.queues[/,queue_memory,queue.helloWorld] key = '\"rabbitmq.queues[{0},queue_{1},{2}]\"'.format(queue['vhost'], item, queue['name']) ### if item is in queue,value=queue[item],else value=0 value = queue.get(item, 0) logging.debug(\"SENDER_DATA: - %s %s\" % (key,value)) tmpfile.write(\"- %s %s\\n\" % (key, value)) ## This is a non standard bit of information added after the standard items for item in ['deliver_get', 'publish']: key = '\"rabbitmq.queues[{0},queue_message_stats_{1},{2}]\"'.format(queue['vhost'], item, queue['name']) value = queue.get('message_stats', {}).get(item, 0) logging.debug(\"SENDER_DATA: - %s %s\" % (key,value)) tmpfile.write(\"- %s %s\\n\" % (key, value)) # 使用zabbix_sender把item发送到zabbix server def _send_queue_data(self, tmpfile): '''Send the queue data to Zabbix.''' '''Get key value from temp file. ''' args = '/usr/bin/zabbix_sender -c {0} -i {1}' if self.senderhostname: args = args + \" -s \" + self.senderhostname return_code = 0 process = subprocess.Popen(args.format(self.conf, tmpfile.name), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) out, err = process.communicate() logging.debug(\"Finished sending data\") return_code = process.wait() logging.info(\"Found return code of \" + str(return_code)) if return_code != 0: logging.warning(out) logging.warning(err) else: logging.debug(err) logging.debug(out) return return_code def check_queue(self, queueName): rdatafile = tempfile.NamedTemporaryFile(delete=False) return_code = 0 queue = self.call_api_queue(queueName) self._get_queue_data(queue, rdatafile) self._get_channel_data(queue, rdatafile) rdatafile.close() return_code = self._send_queue_data(rdatafile) os.unlink(rdatafile.name) return return_code def check_overview(self): return_code = 0 rdatafile = tempfile.NamedTemporaryFile(delete=False) queue = self.call_api('overview') self._get_overview_data(queue, rdatafile) rdatafile.close() return_code = self._send_queue_data(rdatafile) os.unlink(rdatafile.name) return return_code def _get_overview_data(self, queue, tmpfile): for item in ['publish_details', 'ack_details', 'deliver_get_details']: key = \"rabbitmq.[{0},{1}_rate]\".format(queue['node'], item) value = queue.get('message_stats').get(item).get('rate', 0) logging.debug(\"SENDER_DATA: - {0} {1:.2f}\\n\".format(key, value)) tmpfile.write(\"- {0} {1:.2f}\\n\".format(key, value)) for item in ['messages','messages_ready','messages_unacknowledged']: key = \"rabbitmq.[{0},{1}]\".format(queue['node'], item) value = queue.get('queue_totals').get(item,0) logging.debug(\"SENDER_DATA: - %s %s\" % (key,value)) tmpfile.write(\"- %s %s\\n\" % (key, value)) def _get_channel_data(self, queue, tmpfile): ''' 从queue获取queue name和channel name，组装zabbix的k-v并写进临时文件 ''' for ch_detail in queue['consumer_details']: key = \"rabbitmq.[{},{}]\".format(queue['name'], ch_detail.get('channel_details').get('name','no_name')) value = self._get_channel_ack(ch_detail.get('channel_details').get('name','no_name')) logging.debug(\"SENDER_DATA: - %s %s\" % (key,value)) tmpfile.write(\"- %s %s\\n\" % (key, value)) def _get_channel_ack(self, channel_name): ''' 使用api获取messages_unacknowledged值 ''' d = self.call_api_channel(channel_name) return d['messages_unacknowledged'] def main(): '''Command-line parameters and decoding for Zabbix use/consumption.''' #testapi = RabbitMqApi() #testapi.check_queue('wxq_msg_send') parser = optparse.OptionParser() parser.add_option('-u', '--username', help='RabbitMQ API username,default=guest',default='guest') parser.add_option('-p', '--password', help='RabbitMQ API password,default=guest',default='guest') parser.add_option('--mqhost', help='RabbitMQ API hostname,default=hostname',default=socket.gethostname()) parser.add_option('--protocol', help='RabbitMQ API protocol,default=http',default='http') parser.add_option('--port', help='RabbitMQ API port,default=15672',default=15672) parser.add_option('--host', help='Zabbix Host name which the item belongs to,no default') parser.add_option('--conf', help='Zabbix agent configure file,default=/etc/zabbix/zabbix_agentd.conf',default='/etc/zabbix/zabbix_agentd.conf') parser.add_option('--queue', help='RabbitMQ queue which you want to check,no default') parser.add_option('-o','--overview', help='check RabbitMQ overview',action=\"store_true\") parser.add_option('-c','--count', help='How many times to execute command', type='int', default=1) parser.add_option('-i','--interval', help='Command execute interval', type='int', default=0) (options, args) = parser.parse_args() if not options.host: parser.error(\"请输入zabbix里定义的hostname\") elif (not options.queue and not options.overview): parser.error(\"请指定-o或者--queue，选择检查mq总体指标或者某个队列指标\") logging.debug(\"Started trying to process data\") api = RabbitMqApi(user_name=options.username, password=options.password, host_name=options.mqhost, protocol=options.protocol, port=options.port, senderhostname=options.host, zbconf=options.conf) cnt = 0 while cnt \u003c options.count: if options.overview: api.check_overview() time.sleep(options.interval) elif options.queue: api.check_queue(options.queue) time.sleep(options.interval) cnt += 1 if __name__ == '__main__': main() 脚本使用方式 --mqhost：RabbitMQ服务器ip --host：zabbix server上配置的host名字 --queue：队列名字 -o：获取overview数据 -c：执行5次 -i：间隔12秒 --help：查看帮助，有其他参数可选 $ mqMon.py -o –mqhost 192.168.55.241 –host ser01-rabbitmq -c 5 -i 12 # 监控`mq`总体情况 $ mqMon.py –queue wxq_msg_send –mqhost 192.168.55.241 –host ser01-rabbitmq -c 5 -i 12 # 监控队列情况 ",
    "description": "使用Rabbitmq Rabbitmq添加登录账户 在/etc/rabbitmq/rabbitmq.config配置文件下添加，如果不存在就自行创建添加 admin就是用户名称 $ cat /etc/rabbitmq/rabbitmq.config [ {rabbit,[{tcp_listeners,[5672]},{loopback_users,[\"admin\"]}]} ] 使用命令添加用户并授权 添加用户 $ rabbitmqctl add_user admin admin 设置permissions $ rabbitmqctl set_permissions -p \"/\" admin \".",
    "tags": [],
    "title": "Configure_Rabbitmq",
    "uri": "/systems/linux/message_queue/configure_rabbitmq/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "logrotate日志切割 man logrotate查看logrodate使用详情 如果日志切割在：/usr, boot, /etc, efi等目录下时，会提示：error: error opening /usr/local/nginx/logs/nginx.log: Read-only file system这是因为启动文件配置：ProtectSystem=full 修改/lib/systemd/system/logrotate.service配置文件 $ systemctl status logrotate.service $ cat \u003e/lib/systemd/system/logrotate.service\u003c\u003c-EOF ReadWritePaths=/usr/local/nginx/logs # 文件末尾添加此行 EOF $ systemctl daemon-reload $ systemctl restart logrotate.service 配置Nginx日志切割 名称地址 描述 centos7 logrotate日志切割 CentOS下使用Logrotate日志切割 Logs日志分析排查GitBook Logs日志分析排查Github 日志切割方法小结Logrotate、python、shell脚本实现 $ man logrotate # 新增nginx log 每日切割 $ grep \"nginx\" /etc/logrotate.d/nginx \u0026\u003e/dev/null $ cat \u003e/etc/logrotate.d/nginx\u003c\u003c-EOF \"/opt/apps/nginx/logs/*.jsonl\" /opt/apps/nginx/logs/*.log{ daily # 安日期轮转日志：hourly(小时)、daily(天)、weekly(月)、monthly(月)、yearly(年)，如果设置(size)则不用该参数 dateext # 文件后缀是日期格式,也就是切割后文件是:xxx.log-20150828，该设置可能和大小切割冲突，该设置按日期生成 size 100k\t# 在日志大小大于 logsize（例如 100K，100M，100G）时轮换、minsize、maxsize，该选项与日期设置是互斥的 rotate 15 # 指定日志文件删除之前转储的次数，0指没有备份，15指保留15个备份 compress # 通过gzip压缩转储以后的日志（gzip -d xxx.gz解压） missingok # 如果日志不存在则忽略该警告信息 notifempty # 如果是空文件的话，不转储 copytruncate # 用于还在打开中的日志文件，把当前日志备份并截断 delaycompress # 和compress一起使用时，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行 sharedscripts # 运行postrotate脚本，在所有日志都轮转后统一执行一次脚本。如果没配该选项，每个日志轮转后都会执行一次脚本 postrotate # 运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本，如重启（kill -HUP）服务 [ -f /var/run/nginx.pid ] \u0026\u0026 kill -USR1 `cat /var/run/nginx.pid` endscript # 最通常的作用是让应用重启，以便切换到新的日志文件, 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，nginx 进程将立即再次读取其配置并继续运行 create 640 www root # 以指定的权限用户和组创建全新的日志文件，同时logrotate也会重命名原始日志文件 su root root } EOF # 手动调试验证不执行：-d $ /usr/sbin/logrotate -d /etc/logrotate.d/nginx # 手动强制执行：-f $ /usr/sbin/logrotate -f /etc/logrotate.d/nginx # 新增刪除7天以前log定時腳本 $ echo \"###nginx超過七天log刪除 1 0 * * * /bin/bash /opt/scripts/DEL_NGINX.sh \u003e\u003e ~/del_tom.log 2\u003e\u00261\" \u003e\u003e /var/spool/cron/admin ",
    "description": "logrotate日志切割 man logrotate查看logrodate使用详情 如果日志切割在：/usr, boot, /etc, efi等目录下时，会提示：error: error opening /usr/local/nginx/logs/nginx.log: Read-only file system这是因为启动文件配置：ProtectSystem=full 修改/lib/systemd/system/logrotate.",
    "tags": [],
    "title": "Use_Logrotate",
    "uri": "/systems/linux/logs/use_logrotate/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "Quickwit Quickwit日志管理、分析 OpenTelemetry ",
    "description": "Quickwit Quickwit日志管理、分析 OpenTelemetry ",
    "tags": [],
    "title": "Install_Quickwit",
    "uri": "/systems/linux/logs/install_quickwit/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "LogKit LogKit 非常强大的服务器代理，用于通过易于使用的Web控制台收集和发送日志和指标 ",
    "description": "LogKit LogKit 非常强大的服务器代理，用于通过易于使用的Web控制台收集和发送日志和指标 ",
    "tags": [],
    "title": "Install_Logkit",
    "uri": "/systems/linux/logs/install_logkit/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "GrayLog日志服务 GrayLog日志服务 Graylog—日志聚合工具中的后起之秀 推荐！国外程序员整理的系统管理员资源大全 Java ( \u003e= 8 ) MongoDB (4.0, 4.2 or 4.4) Elasticsearch (6.x or 7.x) GrayLog-Server GrayLog-Web 安装GrayLog所需服务 Mongodb数据库 配置Mongodb的yum存储库 $ cat \u003e/etc/yum.repos.d/mongodb-org.repo\u003c\u003c-EOF [mongodb-org-4.2] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.2/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-4.2.asc EOF 安装并启动MongoDB $ yum -y install mongodb-org $ systemctl daemon-reload $ systemctl enable mongod.service \u0026\u0026 systemctl start mongod.service $ systemctl --type=service --state=active | grep mongod Elasticsearch数据存储服务 GrayLog所需服务Elasticsearch弹性搜索、数据存储服务 配置Elasticsearch的yum存储库 GrayLog不支持Elasticsearch 7.11及更高版本。它会破坏你的Graylog实例！ $ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch # 添加密钥 $ cat \u003e/etc/yum.repos.d/elasticsearch.repo\u003c\u003c-EOF [elasticsearch-7.x] name=Elasticsearch repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/oss-7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md EOF 安装elasticsearch-oss $ yum -y install elasticsearch-oss 修改Elasticsearch配置文件，并将集群名称设置为Graylog并取消注释 $ tee -a /etc/elasticsearch/elasticsearch.yml \u003e/dev/null \u003c\u003c-EOT cluster.name: graylog action.auto_create_index: false # 并取消注释，启用该操作 EOT 启动Elasticsearch $ systemctl daemon-reload $ systemctl enable elasticsearch.service \u0026\u0026 systemctl restart elasticsearch.service $ systemctl --type=service --state=active | grep elasticsearch 安装GrayLog服务 GrayLog各插件功能 graylog-enterprise-integrations-plugins企业集成插件 graylog-enterprise-plugins企业插件 graylog-integrations-plugins集成插件 graylog-server服务端 $ rpm -Uvh https://packages.graylog2.org/repo/packages/graylog-4.2-repository_latest.rpm $ yum install graylog-server graylog-enterprise-plugins graylog-integrations-plugins graylog-enterprise-integrations-plugins 修改GrayLog配置文件 阅读配置文件中的说明并根据需要进行编辑，位于/etc/graylog/server/server.conf另外添加password_secret和root_password_sha2因为这些是强制性的，没有它们Graylog将无法启动 $ ln -s /usr/local/src/jdk1.8.0_221/bin/java /usr/bin/java # 给Java做个软连接 $ echo -n \"Enter Password: \" \u0026\u0026 head -1 \u003c/dev/stdin | tr -d '\\n' | sha256sum | cut -d\" \" -f1 # 为：password_secret，生成64位密码字符 $ echo -n yourpassword | sha256sum # 为：root_password_sha2，生成哈希值 修改配置文件 $ cat //etc/graylog/server/server.conf password_secret = # 57行左右， 添加用户集群数据库中所用 root_password_sha2 = # 68行左右，添加生成的哈希值， 用于登录web界面 http_bind_address = 127.0.0.1:9000 # 105行左右修改为：http_bind_address = 0.0.0.0:9000 启动GrayLog服务 $ systemctl daemon-reload $ systemctl enable graylog-server.service \u0026\u0026 systemctl start graylog-server.service $ systemctl --type=service --state=active | grep graylog 配置Selinux开放端口 允许Web服务器访问网络 $ setsebool -P httpd_can_network_connect 1 针对端口配置Selinux开放 $ semanage port -a -t http_port_t -p tcp 9000 # Graylog REST API 和 Web 界面 $ semanage port -a -t http_port_t -p tcp 9200 # Elasticsearch（仅当使用 HTTP API 时） $ semanage port -a -t mongod_port_t -p tcp 27017 # 允许使用 MongoDB 的默认端口 (27017/tcp) 防火墙开放端口 $ firewall-cmd --add-port=9000/tcp --permanent $ firewall-cmd --reload 打开浏览器访问GrayLog $ http://IP:9000 # 默认用户名：admin，所定义的root_password_sha2密码 Google浏览器访问报错更换浏览器 While rendering this widget, the following error occurred: NotFoundError: Failed to execute 'removeChild' on 'Node': The node to be removed is not a child of this node. ",
    "description": "GrayLog日志服务 GrayLog日志服务 Graylog—日志聚合工具中的后起之秀 推荐！国外程序员整理的系统管理员资源大全 Java ( \u003e= 8 ) MongoDB (4.",
    "tags": [],
    "title": "Install_Graylog",
    "uri": "/systems/linux/logs/install_graylog/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "Fluentd Fluentd\nFluentd是一个开源的数据收集器，用作统一化数据收集和使用",
    "description": "Fluentd Fluentd\nFluentd是一个开源的数据收集器，用作统一化数据收集和使用",
    "tags": [],
    "title": "Install_Fluentd",
    "uri": "/systems/linux/logs/install_fluentd/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "Finder日志系统 JDK1.8 Tomcat8 # 使用root登录 # 1. 创建用户: tomcat # 如果已有可忽略 $ useradd tomcat # 2. 设置临时变量: TOMCAT_HOME TOMCAT_HOME=Tomcat根目录 # 3. 删除并重建ROOT目录, 如有重要资料请注意备份 $ rm -rf $TOMCAT_HOME/webapps/ROOT $ mkdir -p $TOMCAT_HOME/webapps/ROOT # 4. 下载并解压到ROOT目录 $ wget -O /tmp/finder-web-2.5.8.zip http://www.finderweb.net/download/finder-web-2.5.8.war $ unzip -o -d $TOMCAT_HOME/webapps/ROOT /tmp/finder-web-2.5.8.zip # rm -f /tmp/finder-web-2.5.8.zip # 5. 为应用目录赋权限 $ chown -R tomcat:tomcat $TOMCAT_HOME $ chmod -R 755 $TOMCAT_HOME # 6. 启动Tomcat $ sudo -u tomcat $TOMCAT_HOME/bin/startup.sh # 7. 访问地址：http://ip:8080/finder tomcat默认的端口号为8080，如需修改，请手动编辑TOMCAT_HOME/conf/server.xml，需重启Tomcat。 默认的用户名密码： admin 1234 # 8. 修改挂载文件 $ cat \u003efinder/webapps/ROOT/WEB-INF/finderweb/workspaces.xml\u003c\u003c-EOF \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cfinderweb\u003e \u003cworkspace name=\"nginx\" displayName=\"nginx\" work=\"/opt/logs/nginx\" charset=\"utf8\" readonly=\"true\" orderNum=\"1\"/\u003e \u003cworkspace name=\"mysql\" displayName=\"mysql\" work=\"/opt/logs/mysql\" charset=\"utf8\" readonly=\"true\" orderNum=\"2\"/\u003e \u003c/finderweb\u003e EOF Docker方式安装Finder version: '1.0' services: tomcat: restart: always image: tomcat:8.5.15-jre8 container_name: tomcat_finder ports: - 8090:8080 environment: TZ: Asiz/Shanghai volumes: - /opt/finder/webapps:/usr/local/tomcat/webapps - /opt/finder/conf:/usr/local/tomcat/conf - /opt/finder/logs:/usr/local/tomcat/logs - /opt/finder/project/logs/nginx:/opt/hwc-logs/nginx ",
    "description": "Finder日志系统 JDK1.8 Tomcat8 # 使用root登录 # 1. 创建用户: tomcat # 如果已有可忽略 $ useradd tomcat # 2.",
    "tags": [],
    "title": "Install_Finder",
    "uri": "/systems/linux/logs/install_finder/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "elasticsearch-head elasticsearch-head Github地址 安装nodejs、npm 安装nodejs前先安装epel-release源 $ yum -y install epel-release 安装nodejs、npm $ yum -y install nodejs npm # 更新npm $ npm install -g npm # 安装 n 模块 $ npm install -g n 国内安装cnpm 更换国内阿里云源 # 查看npm 使用地址 $ npm config get registry # 更换源 $ npm config set registry https://registry.npm.taobao.org # 使用cnpm $ npm install -g cnpm --registry=https://registry.npm.taobao.org 安装elasticsearch-head $ wget https://github.com/mobz/elasticsearch-head/archive/refs/tags/v5.0.0.tar.gz $ tar zxvf v5.0.0.tar.gz $ cd elasticsearch-head $ npm install $ npm run start ",
    "description": "elasticsearch-head elasticsearch-head Github地址 安装nodejs、npm 安装nodejs前先安装epel-release源 $ yum -y install epel-release 安装nodejs、npm $ yum -y install nodejs npm # 更新npm $ npm install -g npm # 安装 n 模块 $ npm install -g n 国内安装cnpm 更换国内阿里云源 # 查看npm 使用地址 $ npm config get registry # 更换源 $ npm config set registry https://registry.",
    "tags": [],
    "title": "Install_Es_Head",
    "uri": "/systems/linux/logs/install_es_head/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "Elasticsearch部署 Elasticsearch简介官方文档 Elasticsearch常用插件集合 ELK基于ElastAlert实现日志的微信报警 Elasticsearch是一个基于Lucene的弹性数据存储、搜索、开源分布式搜索服务，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口，在elasticsearch中，所有节点的数据是均等的。 特点：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源， 自动搜索负载等。 Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 下载elasticsearch-8.1 $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.3-linux-x86_64.tar.gz $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.3-linux-x86_64.tar.gz.sha512 $ sha512sum -c elasticsearch-8.1.3-linux-x86_64.tar.gz.sha512 $ tar -xzf elasticsearch-8.1.3-linux-x86_64.tar.gz $ cd elasticsearch-8.1.3/ 修改Elasticsearch配置文件 修改Elasticsearch主配置文件 $ cd /opt/elasticsearch/config $ cp elasticsearch.yml{,.bak} # 提前给配置文件做个备份 # 17行、组名(同一个组，组名必须一致) $ sed -i \"/cluster.name:/a\\\\cluster.name: cluster-1\" elasticsearch.yml # 23行、节点名称，建议和主机名一致 $ sed -i \"/node.name:/a\\\\node.name: server-1\" elasticsearch.yml # 33行、数据存放的路径 $ sed -i \"/path.data:/a\\\\path.data: /opt/elasticsearch/data\" elasticsearch.yml # 37行、日志存放的路径 $ sed -i \"/path.logs:/a\\\\path.logs: /opt/elasticsearch/logs\" elasticsearch.yml # 43行、 锁住内存，不被使用到交换分区去(通常在内部不足时，休眠的程序内存信息会交换到交换分区) $ sed -i \"/bootstrap.memory_lock:/a\\\\bootstrap.memory_lock: false\" elasticsearch.yml # 56行、网络设置，建议填写本机IP或者0.0.0.0 $ sed -i \"/network.host:/a\\\\network.host: 0.0.0.0\" elasticsearch.yml # 61行、开启端口 $ sed -i \"/http.port:/a\\\\http.port: 9200\" elasticsearch.yml # 74行、和节点名称一致 $ sed -i \"/cluster.initial_master_nodes:/a\\\\cluster.initial_master_nodes: [\"server_1\"]\" elasticsearch.yml $ echo \"http.cors.enabled: true # 支持跨域 xpack.security.enabled: true # 启用安全性检查 xpack.security.transport.ssl.enabled: true # discovery.zen.ping.multicast.enabled: false # 集群模式，从节点关闭多播 # discovery.zen.ping.unicast.hosts: [\"10.18.41.31\",\"10.18.41.137\" # 集群模式，从节点配置主服务器和自己的地址 http.cors.allow-origin: \"*\" # 范围 http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type # 手动创建系统索引 action.auto_create_index: .monitoring*,.watches,.triggered_watches,.watcher-history*,.ml* \" \u003e\u003eelasticsearch.yml 修改Elasticsearch资源限制配置文件 # 调整jvm.options文件的32、和33行 $ cd /opt/elasticsearch/config $ sed -i \"/## -Xms4g/a\\\\-Xms512m\" jvm.options $ sed -i \"/## -Xmx4g/a\\\\-Xmx512m\" jvm.options 启动服务并开启防火墙：9200端口 配置Ulimit调整进程的最大文件描述符 $ ulimit -n 65535 $ echo \"* soft nofile 65536 * hard nofile 65536 * soft nproc 32000 * hard nproc 32000 * hard memlock unlimited * soft memlock unlimited \"\u003e\u003e/etc/security/limits.conf 配置vm.max_map_count最大虚拟内存区域 $ echo \"vm.max_map_count=655360\" \u003e\u003e/etc/sysctl.conf 修改权限启动服务开放防火墙 9200端口：用于所有通过HTTP协议进行的API调用。包括搜索、聚合、监控、以及其他任何使用HTTP协议的请求。所有的客户端库都会使用该端口与ElasticSearch进行交互。\n9300端口：是一个自定义的二进制协议，用于集群中各节点之间的通信。用于诸如集群变更、主节点选举、节点加入/离开、分片分配等事项。\n$ chown -R user:user /opt/elasticsearch # 普通用户启动 $ cd /opt/elasticsearch/ $ ./bin/elasticsearch-setup-passwords interactive # 设置密码，修改密码也是一样。 $ ./bin/elasticsearch # 此命令来判断是init启动还是systemctl启动 $ ps -p 1 # 当systemd启用了日志记录，日志信息使用可用journalctl的命令 $ journalctl - f # 列出elasticsearch服务的日记帐分录 $ journalctl - unit elasticsearch # 要从给定时间开始列出elasticsearch服务的日记帐分录： $ journalctl --unit elasticsearch --since \"2016-10-30 18:17:16\" # 检查Elasticsearch $ curl -i -XGET http://127.0.0.1:9200 elasticsearch-head插件安装 下载启动elasticsearch-head防火墙开放：9100端口 $ cd /opt/ $ git clone git://github.com/mobz/elasticsearch-head.git $ cd elasticsearch-head $ npm install $ npm run start # grunt server # 或者使用 grunt 启动 $ curl http://localhost:9100/ # 登录浏览器输入地址访问 Logstash部署 Logstash简介、官方文档 Logstash是一个完全开源工具，可以对你的日志进行收集、过滤、分析，并将其存储供以后使用（如，搜索），logstash带有一个web界面，搜索和展示所有日志。 下载、解压Logstash $ wget https://artifacts.elastic.co/downloads/logstash/logstash-8.3.3-linux-x86_64.tar.gz $ tar zxvf logstash-8.3.3-linux-x86_64.tar.gz 配置Logstash的conf文件收集Nginx日志 名称地址 描述 参考官网标准输入输出 参考官网函数输入输出 参考官网收集系统日志 参考官网收集Java日志 参考官网使用multiline多行模式 input{}：logstash从日志文件中调用函数输入 output{}：logstash从日志文件中调用函数输出 stdin{}：logstash从标准输入中收集日志 stdout{} ：logstash从标准输出日志 syslog：logstash从系统日志程序中收集日志 tcp：logstash从TCP程序端口中收集日志 udp：logstash从UDP程序端口中收集日志 rubuydebug：通过rubuy库进行收集 multiline：多行模块 $ echo \"Settings: Default filter workers: 4 Logstash startup completed input { file { type =\u003e \"nginx-error-log\" path =\u003e \"/usr/local/nginx/logs/*error*.log\" start_position =\u003e \"beginning\" }file { type =\u003e \"nginx-access-log\" path =\u003e \"/usr/local/nginx/logs/*access*.log\" start_position =\u003e \"beginning\" codec =\u003e json } } output { if [type] =~ \"nginx-error-log\" { elasticsearch { hosts =\u003e [\"elasticsearch服务所在IP:9200\"] index =\u003e \"mayi-nginx-error--%{+YYYY.MM.dd}\" } }else if [type] =~ \"nginx-access-log\" { elasticsearch { hosts =\u003e [\"elasticsearch服务所在IP:9200\"] index =\u003e \"mayi-nginx-access-%{+YYYY.MM.dd}\" } } } \" \u003e\u003e/opt/elk/logstash/data/nginx-log.conf ####### $ cat \u003elogstash.yml\u003c\u003c-EOF input { redis { host =\u003e \"Redis 服务所在IP\" port =\u003e \"6379\" password =\u003e \"password\" data_type =\u003e \"list\" key =\u003e \"filebeat\" #从redis中导入的key，与filebeat输出对应 type =\u003e \"redis-input\" db =\u003e 0 #导入key的数据库，默认为0 } } filter { # 判断redis字符串在不在自己定义的新字段中，用于区分日志类型，做对应的处理 if 'redis' in [app] { # 聚合redis日志 grok { # 自定义匹配日志内容，默认一条日志从上到下只会匹配一次对的。且只会匹配一个字段，如需要匹配多个字段，需进行严格匹配 patterns_dir =\u003e [\"/opt/elk/patterns_time\"] # grok提供很多自带的正则，可供使用 match =\u003e { \"message\" =\u003e \"%{LOGTIME:log_time}\" } # （?\u003c自定义的\u003e要匹配的内容） match =\u003e { \"message\" =\u003e \"(?\u003clog_time\u003e%{TIMESTAMP_ISO8601}).*session (?\u003csession\u003e.*\\S$)\"} } date { # 修改采集时间为日志里的时间 match =\u003e [\"log_time\", \"yyyy-MM-dd HH:mm\",\"dd MMM yyyy HH:mm:ss.SSS\" ] locale =\u003e \"en\"} ruby { code =\u003e \"event.set('timestamp', event.get('@timestamp').time.localtime - 8*60*60)\" } ruby { code =\u003e \"event.set('@timestamp',event.get('timestamp'))\" } mutate { # 转换字段类型，用于聚合操作 convert =\u003e { \"session\" =\u003e \"string\" } # 删除无用字段 remove_field =\u003e [\"log_time\"] } } # 将logstash时间转化中国时间,logstash默认为utc时间，比中国时间慢8个小时（修改的是采集时间，对日志时间没有影响） ruby { code =\u003e \"event.set('timestamp', event.get('@timestamp').time.localtime + 8*60*60)\" } ruby { code =\u003e \"event.set('@timestamp',event.get('timestamp'))\" } mutate { remove_field =\u003e [\"timestamp\"] } } output { # 用于调试 # stdout{ codec =\u003e rubydebug } ##### 创建线上环境索引 ###### if 'online_82' in [app] { elasticsearch { action =\u003e \"index\" #The operation on ES hosts =\u003e \"127.0.0.1:9200\" # ElasticSearch host, can be array. # 输出到es中的索引 index =\u003e \"online_82_%{+YYYY.MM.dd}\" #The index to write data to. user =\u003e \"elastic\" password =\u003e \"dtyn!@$\" } # 对应filebeat中[tags],用对应索引进行判断 if [tags][0] == 'count' { elasticsearch { action =\u003e \"index\" #The operation on ES hosts =\u003e \"127.0.0.1:9200\" #ElasticSearch host, can be array. index =\u003e \"online_82_redis_count\" #The index to write data to. user =\u003e \"elastic\" password =\u003e \"dtyn!@$\" } } } } 检查配置、启动服务 # 添加\"--configtest\"或者\"-t\"参数检查配置语法是否有误 $ /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx.conf --config.test_and_exit # 启动程序后台运行\"\u0026\" $ nohup /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx.conf \u0026 # \"screen\" 启动另一个终端 $ /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx.conf $ screen -ls $ screen -r 16582 Beats部署 Beats是由Elastic公司开发和维护的一组开源数据采集器。它们设计用于从各种数据源收集数据，然后将数据发送到Elasticsearch或者Logstash等后端存储和分析系统中 名称地址 描述 官方文档 选择一个Beat任何Beat皆可 - Filebeat部署 Filebeat用于轻量级日志和文件数据收集。Filebeat可以监控指定的日志文件或位置，收集日志数据，并将其发送到Elasticsearch或Logstash进行存储和分析 下载安装Filebeat Filebeat安装配置编辑 $ curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.3.3-linux-x86_64.tar.gz $ tar xzvf filebeat-8.3.3-linux-x86_64.tar.gz 配置Filebeat # elasticsearch output.elasticsearch: hosts: [\"https://myEShost:9200\"] username: \"filebeat_internal\" password: \"YOUR_PASSWORD\" ssl: enabled: true ca_trusted_fingerprint: \"b9a10bbe64ee9826abeda6546fc988c8bf798b41957c33d05db736716513dc9c\" # kibana setup.kibana: host: \"mykibanahost:5601\" username: \"my_kibana_user\" password: \"{pwd}\" $ cat \u003efilebeat.yml\u003c\u003c-EOF filebeat.inputs: - type: log enabled: True # True表示收集 # pasths配置收集日志的路径，支持配置多条路径，及多目录 paths: - /opt/app/nacos-1.3.2/nacos/bin/logs/*.log # tags 标记;可以用来区分日志,这是一个列表可以写多个标记 tags: [\"nacos\"] # fileds创建新的字段，默认是二级字段，可以自定义多个key: value fields: app: test_71_nacos-1.3.2 # 让新建的字段变成顶级字段，减少不必要的资源开销 fields_under_root: true # 让filebeat采集最新的日志变化，忽略掉之前旧日志 tail_files: true # 下边这几项可以不用 # filebeat依靠文件描述符识别文件，当发生重命名或移动，filebeat依然采集的原文件。 close_renamed: false # 等待再次检查文件的时间，默认是10s max_backoff: 1s # 此选项指定等待时间的增加速度,1表示禁用回算算法 backoff_factor: 1 # ====== Outputs ====== # --------- reids output ------------ output.redis: hosts: [\"Redis服务所在IP:6379\"] # 输出到redis的ip端口号 password: \"password\" key: \"filebeat\" # 输出到redis中的key，这个key是一个列表，llen key查看长度 lrange key 0 -1 查看列表所有的值 timeout: 30 # 连接redis超时时间，默认为5s output.elasticsearch: hosts: [\"\u003c节点01的IP\u003e:9200\"] template.name: \"filebeat\" template.path: \"filebeat.template.json\" template.overwrite: false username: \"elastic\" password: \"changeme\" # 拓展 filbeat也可以采集jar堆栈日志 # 堆栈日志的格式：多行日志内容为一条日志 - type: log enabled: True paths: - /opt/app/nacos-1.3.2/nacos/bin/logs/*.log multiline: # 自定义每条日志的开头 pattern: '\\# Time: \\d{4}-\\d{2}-\\d{2}' # 定义模式是否被否定,默认值为false negate: true # 与模式不匹配的连续行将追加到匹配的上一行 match: after EOF $ cat \u003efilebeat.yml\u003c\u003c-EOF filebeat.config.inputs: enabled: true path: /etc/filebeat/input.d/*.yml reload.enabled: true reload.period: 10s filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true setup.template.settings: index.number_of_shards: 3 processors: - drop_fields: fields: [\"agent.ephemeral_id\", \"agent.hostname\", \"agent.id\", \"agent.name\", \"agent.type\", \"agent.version\", \"headers\"] - rename: fields: - from: \"url\" to: \"url_host\" ignore_missing: false fail_on_error: true output.elasticsearch: hosts: [\"\"\u003c节点01的IP\u003e:9200\"\"] api_key: \"\" index: \"nginx-%{[fields.application]}-%{+yyyy.MM.dd}\" # fields.application参数修改 indices: when.equals: fields.application: ['app-docker-nginx_access'] setup.ilm.enabled: false # 自定义模板格式 setup.template.name: \"nginx\" # 模板名称 setup.template.pattern: \"nginx-*\" # 匹配模板类型 setup.template.enabled: false # false：不使用默认模板，true：使用默认模板 setup.template.overwrite: true # 是否覆盖原来模板 EOF $ cat \u003e/etc/filebeat/input.d/app-docker-nginx_access.yml\u003c\u003c-EOF filebeat.inputs: - type: log enabled: true paths: - /usr/local/nginx/logs/gitlab.log fields: application: app-docker-nginx_access # 开启 json日志格式 json.keys_under_root: true json.overwrite_keys: true json.message_key: message json.add_error_key: true # 输出位置 output.elasticsearch: hosts: [\"192.168.1.1:9200\"] EOF 列出以及使用模块 $ ./filebeat modules list $ ./filebeat modules enable nginx - module: nginx access: enabled: true var.paths: [\"/var/log/nginx/access.log*\"] 检测启动 $ ./filebeat setup -e $ chown root filebeat.yml $ chown root modules.d/nginx.yml $ ./filebeat -e Metricbeat部署 Metricbeat用于定时收集系统和服务的指标数据。Metricbeat支持收集各种服务（如Redis、Apache、MySQL等）的性能指标，并将这些数据发送到Elasticsearch或者其他数据存储和可视化工具中 Packetbeat部署 Packetbeat用于实时网络数据分析。Packetbeat可以监控网络流量，捕获和分析应用层协议（如HTTP、MySQL、DNS`等）的数据，帮助识别问题和优化网络性能 Heartbeat部署 Heartbeat用于监控服务的可用性。Heartbeat可以定期检查服务、网站或者主机的可访问性，并记录响应时间和状态，以帮助运维人员快速发现和解决故障。 Auditbeat部署 Auditbeat用于收集系统审计日志。Auditbeat监控操作系统和文件系统的活动，包括文件访问、用户登录等安全相关事件，并将这些事件发送到中心化的日志管理系统 Kibana部署 部署Kibana图形化展示官方文档\nKibana是由Elastic公司开发的开源数据可视化工具，用于对Elasticsearch索引中的数据进行搜索、分析和可视化。它是Elastic Stack（也称为ELK Stack）中的一个重要组件，与Elasticsearch、Logstash和Beats一起构成了一个强大的数据分析平台\n是一个基于浏览器页面的Elasticsearch前端展示工具，也是一个开源和免费的工具，Kibana可以为Logstash和ElasticSearch提供的日志分析友好的Web界面，可以帮你汇总、分析和搜索重要数据日志\n主要功能和特点：\n数据查询和搜索：\nKibana提供了一个直观的搜索和查询界面，允许用户在Elasticsearch索引中执行复杂的搜索操作。用户可以使用Lucene\u003e 查询语法或者结构化的查询构建器来筛选和查找数据。\n数据可视化：\nKibana允许用户将Elasticsearch\u003e 中的数据通过各种图表（如折线图、柱状图、饼图等）和图形化展示方式进行可视化。这些图表可以帮助用户直观地理解数据的趋势、关系和模式\n仪表盘和视图：\n用户可以通过创建仪表盘Dashboard\u003e 来集成多个数据可视化组件，形成一个全面的数据展示和监控面板。仪表盘可以包含多个图表、指标和数据表格，为用户提供全面的数据洞察力\n实时数据分析：\nKibana支持实时数据分析和实时查询，用户可以即时查看和分析数据的变化和趋势。这对于监控和操作实时系统特别有用\n用户权限和安全性：\nKibana提供了灵活的用户权限管理和安全功能，允许管理员定义和控制用户对不同数据和功能的访问权限。这对于多用户和多团队协作使用的环境非常重要。\n插件和扩展性：\nKibana提供了丰富的插件和可扩展的API，使得用户可以根据自己的需求和场景定制和扩展Kibana的功能。社区和第三方开发者可以通过插件扩展Kibana的功能，增加新的数据处理和可视化能力。\n使用场景： 日志分析和监控：\n通过结合Elasticsearch和Beats，Kibana可以实时分析和监控日志数据，帮助用户快速发现和解决系统问题。\n应用性能监控：\n通过集成Metricbeat和Elasticsearch，Kibana可以实时展示和分析应用程序的性能指标，帮助开发团队优化应用性能。\n安全事件分析：\n结合Auditbeat和Elasticsearch，Kibana可以监控和分析系统和应用的安全事件，帮助安全团队及时响应和调查安全事件。\n下载、解压Kibana图形化展示工具 $ curl -O https://artifacts.elastic.co/downloads/kibana/kibana-8.3.3-linux-x86_64.tar.gz $ curl https://artifacts.elastic.co/downloads/kibana/kibana-8.3.3-linux-x86_64.tar.gz.sha512 | sha512sum -c - $ tar -zxvf kibana-8.3.3-linux-x86_64.tar.gz $ cd kibana-8.3.3/ 修改配置文件 $ cd /usr/local/src/kibana-8.3.3/config $ cp kibana.yml{,.bak} # 6行左右、去掉注释 $ sed -i \"/server.port:/a\\\\server.port: 5601\" kibana.yml # 11行左右、去掉注释，修改为本机IP $ sed -i '/server.host:/a\\\\server.host: \"Kibana服务所在IP\"' kibana.yml # 43行左右、去掉注释，修改为elssticsearch的IP地址和端口 $ sed -i '/elasticsearch.host:/a\\\\elasticsearch.host: [\"http://elssticsearch服务所在IP:9200\"]' kibana.yml # 49行左右、设置访问用户名密码 $ sed -i '/#elasticsearch.username:/a\\\\elasticsearch.username: \"username\"' kibana.yml $ sed -i '/#elasticsearch.password:/a\\\\elasticsearch.password: \"password\"' kibana.yml # sed -i '/kibana.index:/a\\\\kibana.index: \".kibana\"' kibana.yml # 新版不存在此参数 启动服务、处理不能删除索引问题 防火墙开放：5601端口 # 检测启动方式 $ ps -p 1 $ ./bin/kibana # 命令行执行 $ curl -XPUT -H \"Content-Type: application/json\" http://localhost:9200/_all/_settings -d '{\"index.blocks.read_only_allow_delete\":null}' # 浏览器 PUT _settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": \"false\" } } } $ cat \u003edelete-es-index.sh\u003c\u003c-EOF #!/bin/bash date=`date -d \"7 days ago\" +%Y.%m.%d` curl -XDELETE -u 'elastic:dtyn!@$' http://localhost:9200/*{$date} EOF ",
    "description": "Elasticsearch部署 Elasticsearch简介官方文档 Elasticsearch常用插件集合 ELK基于ElastAlert实现日志的微信报警 Elasticsearch是一个基于Lucene的弹性数据存储、搜索、开源分布式搜索服务，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口，在elasticsearch中，所有节点的数据是均等的。 特点：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源， 自动搜索负载等。 Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 下载elasticsearch-8.1 $ wget https://artifacts.",
    "tags": [],
    "title": "Install_ELK",
    "uri": "/systems/linux/logs/install_elk/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Logs",
    "content": "配置elasticsearch+redis elasticsearch出现问题怎么处理 接下来描述会遇见到的一个问题：一旦我们的elasticsearch出现问题，就不能进行日志采集处理了！这种情况下该怎么办呢？ 解决方案：可以在client和elasticsearch之间添加一个中间件作为缓存，先将采集到的日志内容写到中间件上，然后再从中间件输入到elasticsearch中。 这就完美的解决了上述的问题了。ELK中使用redis作为中间件，缓存日志采集内容 $ curl 'localhost:9200/_cat/health?v' # 检测集群是否健康 $ curl 'localhost:9200/_cat/nodes?v' # 获取集群节点列表 $ curl 'localhost:9200/_cat/indices?v' # 列出所有索引 $ curl -XPUT 'localhost:9200/customer?pretty' # 创建一个名为\"customer\"的索引 $ curl -XDELETE 'localhost:9200/customer?pretty' # 删除一个名为\"customer\"的索引 $ curl localhost:9200/_cat/segments/{indexName}|wc -l # 查看某个索引的段数量：GET /nginx-2022-*/_segments $ curl -XPOST 192.168.60.7:9200/indexName/_forcemerge?max_num_segments=1 # 合并某个索引的段 POST /nginx-2022-*/_forcemerge?max_num_segments=1 # 支持通配符 $ cat \u003edelete_es_index.sh\u003c\u003c-EOF ##!/bin/bash ## 定期删除两个月之前elasticsearch索引 date=`date -d \"-2 months\" \"+%Y.%m\"` /usr/bin/curl -v --user elastic:elastic用户密码 -XDELETE \"http://es机器IP:9200/*-$date\" EOF 配置Redis $ cat /etc/redis.conf # 修改下面两行内容 daemonize yes bind 192.168.1.160 $ systemctl start redis $ lsof -i:6379 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME redis-ser 19474 redis 4u IPv4 1344465 0t0 TCP elk-node1:6379 (LISTEN) $ redis-cli -h 192.168.1.160 192.168.1.160:6379\u003e info # Server redis_version:2.8.19 ....... 编写从Client端收集数据的文件 $ cat /opt/logstash/data/redis-out.conf input { stdin {} } output { redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"demo\" } } 执行收集数据的文件，并输入数据hello redis $ /opt/logstash/bin/logstash -f redis-out.conf Settings: Default filter workers: 1 Logstash startup completed # 下面输入数据hello redis hello redis 在redis中查看数据 $ redis-cli -h 192.168.1.160 192.168.1.160:6379\u003e info # Server ....... ....... # Keyspace db6:keys=1,expires=0,avg_ttl=0 # 在最下面一行，显示是db6 192.168.1.160:6379\u003e select 6 OK 192.168.1.160:6379[6]\u003e keys * 1) \"demo\" 192.168.1.160:6379[6]\u003e LINDEX demo -1 \"{\\\"message\\\":\\\"hello redis\\\",\\\"@version\\\":\\\"1\\\",\\\"@timestamp\\\":\\\"2016-11-14T08:04:25.981Z\\\",\\\"host\\\":\\\"elk-node1\\\"}\" 继续随便写点数据测试 $ /opt/logstash/bin/logstash -f redis-out.conf Settings: Default filter workers: 1 Logstash startup completed hello redis 123456 asdf ert wang shi bo guohuihui as we r g asdfjkdfsak 5423wer 34rt3 6y 7uj u io9 sdjfhsdk890 huanqiu huanqiuchain hqsb asda 在redis中查看长度 $ redis-cli -h 192.168.1.160 192.168.1.160:6379\u003e info # Server redis_version:2.8.19 ....... ....... # Keyspace db6:keys=1,expires=0,avg_ttl=0 # 显示是db6 192.168.1.160:6379\u003e select 6 OK 192.168.1.160:6379[6]\u003e keys * 1) \"demo\" 192.168.1.160:6379[6]\u003e LLEN demo (integer) 24 将redis中的内容写到elasticsearch中 $ vim redis-in.conf input { redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"demo\" } } output { elasticsearch { hosts =\u003e [\"192.168.1.160:9200\"] index =\u003e \"redis-in-%{+YYYY.MM.dd}\" } } 执行 $ /opt/logstash/bin/logstash -f redis-in.conf --configtest Configuration OK $ /opt/logstash/bin/logstash -f redis-in.conf \u0026 # 在redis中查看，发现数据已被读出： 192.168.1.160:6379[6]\u003e LLEN demo (integer) 0 # 登陆elasticsearch界面查看 将收集到的所有日志写入到redis中。这了重新定义一个添加redis缓存后的总文件shipper.conf。（可以将之前执行的总文件file.conf停掉） $ vim shipper.conf input { file { path =\u003e \"/var/log/messages\" type =\u003e \"system\" start_position =\u003e \"beginning\" } file { path =\u003e \"/var/log/elasticsearch/huanqiu.log\" type =\u003e \"es-error\" start_position =\u003e \"beginning\" codec =\u003e multiline { pattern =\u003e \"^\\[\" negate =\u003e true what =\u003e \"previous\" } } file { path =\u003e \"/var/log/nginx/access_json.log\" codec =\u003e json start_position =\u003e \"beginning\" type =\u003e \"nginx-log\" } syslog { type =\u003e \"system-syslog\" host =\u003e \"192.168.1.160\" port =\u003e \"514\" } } output { if [type] == \"system\"{ redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"system\" } } if [type] == \"es-error\"{ redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"demo\" } } if [type] == \"nginx-log\"{ redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"nginx-log\" } } if [type] == \"system-syslog\"{ redis { host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"system-syslog\" } } } 执行上面的文件（提前将上面之前启动的file.conf文件的执行给结束掉！） $ /opt/logstash/bin/logstash -f shipper.conf --configtest Configuration OK $ /opt/logstash/bin/logstash -f shipper.conf Settings: Default filter workers: 1 Logstash startup completed # 在redis中查看： $ redis-cli -h 192.168.1.160 192.168.1.160:6379\u003e info # Server redis_version:2.8.19 ....... ....... # Keyspace db6:keys=1,expires=0,avg_ttl=0 # 显示是db6 192.168.1.160:6379\u003e select 6 OK 192.168.1.160:6379[6]\u003e keys * 1) \"demo\" 2) \"system\" 192.168.1.160:6379[6]\u003e keys * 1) \"nginx-log\" 2) \"demo\" 3) \"system\" # 另开一个窗口，添加点日志: $ logger \"12325423\" $ logger \"12325423\" $ logger \"12325423\" $ logger \"12325423\" $ logger \"12325423\" $ logger \"12325423\" # 又会增加日志： 192.168.1.160:6379[6]\u003e keys * 1) \"system-syslog\" 2) \"nginx-log\" 3) \"demo\" 4) \"system\" 可以在任意的一台ES中将数据从redis读取到ES中。 下面咱们在elk-node2节点，将数据从redis读取到ES中： 编写文件： $ cat file.conf input { redis { type =\u003e \"system\" host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"system\" } redis { type =\u003e \"es-error\" host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"es-error\" } redis { type =\u003e \"nginx-log\" host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"nginx-log\" } redis { type =\u003e \"system-syslog\" host =\u003e \"192.168.1.160\" port =\u003e \"6379\" db =\u003e \"6\" data_type =\u003e \"list\" key =\u003e \"system-syslog\" } } output { if [type] == \"system\"{ elasticsearch { hosts =\u003e [\"192.168.1.160:9200\"] index =\u003e \"system-%{+YYYY.MM.dd}\" } } if [type] == \"es-error\"{ elasticsearch { hosts =\u003e [\"192.168.1.160:9200\"] index =\u003e \"es-error-%{+YYYY.MM.dd}\" } } if [type] == \"nginx-log\"{ elasticsearch { hosts =\u003e [\"192.168.1.160:9200\"] index =\u003e \"nignx-log-%{+YYYY.MM.dd}\" } } if [type] == \"system-syslog\"{ elasticsearch { hosts =\u003e [\"192.168.1.160:9200\"] index =\u003e \"system-syslog-%{+YYYY.MM.dd}\" } } } # 执行 $ /opt/logstash/bin/logstash -f file.conf --configtest Configuration OK $ /opt/logstash/bin/logstash -f file.conf \u0026 # 去redis中检查，发现数据已经被读出到elasticsearch中了、同时登陆logstash和kibana看，发现可以正常收集到日志了。 192.168.1.160:6379[6]\u003e keys * (empty list or set) # 可以执行这个 去查看nginx日志、也可以启动多个redis写到ES中，具体根据自己的实际情况而定。 $ ab -n10000 -c1 http://192.168.1.160/ ",
    "description": "配置elasticsearch+redis elasticsearch出现问题怎么处理 接下来描述会遇见到的一个问题：一旦我们的elasticsearch出现问题，就不能进行日志采集处理了！这种情况下该怎么办呢？ 解决方案：可以在client和elasticsearch之间添加一个中间件作为缓存，先将采集到的日志内容写到中间件上，然后再从中间件输入到elasticsearch中。 这就完美的解决了上述的问题了。ELK中使用redis作为中间件，缓存日志采集内容 $ curl 'localhost:9200/_cat/health?v' # 检测集群是否健康 $ curl 'localhost:9200/_cat/nodes?",
    "tags": [],
    "title": "Configure_ELK",
    "uri": "/systems/linux/logs/configure_elk/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e LDAP",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Config_OpenLDAP",
    "uri": "/systems/linux/ldap/config_openldap/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e LDAP",
    "content": "Kerberos 如何在CentOS/RHEL 7中安装和配置Kerberos 安装Kerberos ",
    "description": "Kerberos 如何在CentOS/RHEL 7中安装和配置Kerberos 安装Kerberos ",
    "tags": [],
    "title": "Install_Kerberos",
    "uri": "/systems/linux/ldap/install_kerberos/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e LDAP",
    "content": "OpenLDAP 名称地址 描述 OpenLDAP的安装与配置 LDAP Admin for Linux Apache Directory Studio LDAP Admin for PortableApps.com LDAP Account Manager openldap介绍和使用 LDAP基础学习笔记 OpenLDAP安装使用及与各系统的集成 在LDAP中创建用户 OpenLDAP安装 安装Openldap $ yum install openldap-servers openldap-clients -y 修改配置文件 把/etc/openldap/目录下slapd.d默认文件夹备份 $ cd /etc/openldap/ $ cp -r slapd.d{,.bak} 生成加密密钥 $ slappasswd New password: Re-enter new password: {SSHA}2OhbHFHD0Lx1JUS7IsQZnHlS65tKlAvf 拷贝、修改配置文件 $ cp /usr/share/openldap-servers/slapd.ldif /etc/openldap/ # 修改配置文件，把中文注释行都删除 $ cat \u003e/etc/openldap/slapd.ldif\u003c\u003c-EOF dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/run/openldap/slapd.args olcPidFile: /var/run/openldap/slapd.pid olcTLSCACertificatePath: /etc/openldap/certs olcTLSCertificateFile: \"OpenLDAP Server\" olcTLSCertificateKeyFile: /etc/openldap/certs/password dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema # 添加/etc/openldap/schema/ 目录下属性类 include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/collective.ldif include: file:///etc/openldap/schema/corba.ldif include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/duaconf.ldif include: file:///etc/openldap/schema/dyngroup.ldif include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/java.ldif include: file:///etc/openldap/schema/misc.ldif include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/openldap.ldif include: file:///etc/openldap/schema/pmi.ldif include: file:///etc/openldap/schema/ppolicy.ldif dn: olcDatabase=frontend,cn=config objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: frontend dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth\" manage by * none dn: olcDatabase=monitor,cn=config objectClass: olcDatabaseConfig olcDatabase: monitor # dc=my-domain 修改为定义域名 olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth\" read by dn.base=\"cn=Manager,dc=ladp.erge,dc=com\" read by * none dn: olcDatabase=hdb,cn=config objectClass: olcDatabaseConfig objectClass: olcHdbConfig olcDatabase: hdb # my-domain 修改为定义域名 olcSuffix: dc=ladp.erge,dc=com olcRootDN: cn=Manager,dc=ladp.erge,dc=com # olcRootPW 为新增字段 olcRootPW: {SSHA}2OhbHFHD0Lx1JUS7IsQZnHlS65tKlAvf olcDbDirectory:\t/var/lib/ldap olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub EOF 生成主配置文件 -n 0指定0号数据库\n-F slapd.d指定生成的目录\n-l slapd.ldif指定使用那个文件生成\n$ slapadd -n 0 -F slapd.d -l slapd.ldif # 返回以下：100.00% 代表成功，如果报错是：slapd.ldif 配置文件问题 _#################### 100.00% eta none elapsed none fast! Closing DB... 修改权限\n$ chown -R ldap:ldap /etc/openldap/slapd.d $ chown -R ldap:ldap /var/lib/ldap/ 拷贝数据库默认配置文件\n$ cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG 启动并设置为开机自启 $ systemctl start slapd \u0026\u0026 systemctl enable slapd 配置基本域 $ cat \u003e/etc/openldap/config_init.ldif\u003c\u003c-EOF # dn 条目 dn: dc=ladp.erge,dc=com # 对象类 objectclass: dcObject objectclass: organization # 组织名称 o: aishangwei # dc dc: ladp.erge EOF 添加基本域 系统会提示您输入LDAP密码。 输入您为LDAP root用户定义的纯文本密码 $ ldapadd -x -D \"cn=Manager,dc=ldap.erge,dc=com\" -W -f /etc/openldap/config_init.ldif 查询域 $ ldapsearch -x -b 'dc=ldap.erge,dc=com' '(objectClass=*)' $ ldapsearch -H ldapi:/// -Y EXTERNAL -b \"cn=config\" -LLL –Q $ ldapsearch -h 192.168.88.110 -b \"dc=ladp.erge,dc=com\" -D \"cn=Manager,dc=erge,dc=com\" -W |grep dn 取消匿名登录 openldap在匿名情况下是可以被访问的。而且openldap的相关信息，除了用户的密码信息之外，其他openldap的信息完全被呈现出来。\n从安全的角度考虑，这种情况是不被允许的，所以要取消openldap的匿名访问功能。\n要取消openldap的匿名访问功能，操作方法也比较简单。我们只需要把以下openldap信息导入openldap中即可，而且是无需重启openldap服务即时生效的。\n$ cat \u003e/etc/openldap/disable_anon.ldif\u003c\u003c-EOF dn: cn=config changetype: modify add: olcDisallows olcDisallows: bind_anon dn: cn=config changetype: modify add: olcRequires olcRequires: authc dn: olcDatabase={-1}frontend,cn=config changetype: modify add: olcRequires olcRequires: authc EOF $ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/disable_anon.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 modifying entry \"cn=config\" modifying entry \"cn=config\" modifying entry \"olcDatabase={-1}frontend,cn=config\" # 查看配置文件 $ cat /etc/openldap/slapd.d/cn\\=config.ldif # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 af9dbdcd dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/run/openldap/slapd.args olcPidFile: /var/run/openldap/slapd.pid olcTLSCACertificatePath: /etc/openldap/certs olcTLSCertificateFile: \"OpenLDAP Server\" olcTLSCertificateKeyFile: /etc/openldap/certs/password structuralObjectClass: olcGlobal entryUUID: 7b515fd2-ab06-103b-8cdb-d13498ff4586 creatorsName: cn=config createTimestamp: 20210916065302Z olcDisallows: bind_anon olcRequires: authc //取消匿名用户登录 entryCSN: 20210916072755.667534Z#000000#000#000000 modifiersName: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth modifyTimestamp: 20210916072755Z 开启Openldap日志 $ cat \u003e/etc/openldap/loglevel.ldif\u003c\u003c-EOF dn: cn=config changetype: modify replace: olcLogLevel olcLogLevel: stats EOF $ ldapmodify -Y EXTERNAL -H ldapi:/// -f /etc/openldap/loglevel.ldif $ cat \u003e\u003e/etc/rsyslog.conf\u003c\u003c-EOF local4.* /var/log/slapd.log EOF $ systemctl restart rsyslog $ systemctl restart slapd 允许普通用户修改自己的密码 $ cat \u003e/etc/openldap/updatepass.ldif\u003c\u003c-EOF dn: olcDatabase={2}hdb,cn=config changetype: modify add: olcAccess olcAccess: to attrs=userPassword by self =xw by anonymous auth by * none olcAccess: to * by self write by users read by * none EOF $ ldapmodify -Y EXTERNAL -H ldapi:/// -f /etc/openldap/updatepass.ldif 修改Openldap管理员密码 # 1. 查看openldap管理员密码字段放在哪个配置文件中 $ ldapsearch -H ldapi:// -LLL -Q -Y EXTERNAL -b \"cn=config\" \"(olcRootDN=*)\" dn olcRootDN olcRootPW dn: olcDatabase={2}hdb,cn=config olcRootDN: cn=admin,dc=hebye,dc=com olcRootPW: {SSHA}Z9XXRjQYHbjYXuOvXPgR/g+HRBoNmj/u # 2. 设置openldap管理员最新的密码 $ slappasswd -s password # 3. 生成修改openldap管理员密码的ldif文件 $ cat \u003e/root/newpasswd.ldif\u003c\u003c-EOF dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcRootPW olcRootPW: {SSHA}YB8N9nZg9qKisiW/Xp6NVPeqhE66mQOB EOF # 4. 导入文件 $ ldapmodify -H ldapi:// -Y EXTERNAL -f /root/newpasswd.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 modifying entry \"olcDatabase={2}hdb,cn=config\" # 5. 上述命令执行完毕后，openldap的管理员密码就已经被修改掉了 ",
    "description": "OpenLDAP 名称地址 描述 OpenLDAP的安装与配置 LDAP Admin for Linux Apache Directory Studio LDAP Admin for PortableApps.",
    "tags": [],
    "title": "Install_OpenLDAP",
    "uri": "/systems/linux/ldap/install_openldap/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Keepalived",
    "content": "Keepalived简介 标签： 高可用vrrp Keepalived啥软件起初是准尉LVS负载软件设计的，用来管理并监控LVS集群系统中各个服务节点的装阿提，后来加入了高可用的VRRP功能。 VRRP是Virtual Router Redundancy Protocol(虚拟路由器冗余协议)的缩写，为解决静态路由器单点故障问题，确保个别节点宕机时，真哥哥网络可以不间断地运行。 Keepalived另一方面具有配置配置管理LVS的功能，同时还具有对LVS下面节进行健康检查的功能。 VRRP原理介绍 VRRP，全称Virtual Router Redundancy Protocol中文名为虚拟路由冗余协议，VRRP的出现是为了解决静态路由的单 keepalived通过vrrp通信，通过竞选确定主备协议机制来将路由任务交给某台VRRP路由器的，主优先级高于备。因此，工作时主会获得所有资源，备节点处于等待状态，当主节点宕机，那么备节点启用接管程序接管主节点资源，顶替主节点提供服务。 VRRP报文封装在IP报文中，只有一种VRRP通告报文， 只有处于master状态下的路由器会发送，VRRP用IP多播的方式（默认多播地址（224.0.0.18））实现高可用对之间通信。 在Keepalived服务对之间，只有作为主的服务器会一直发送VRRP广播包，告诉备它还活着，此时备不会抢占主，当主不可用时，即监听不到主发送的广播包时，就会启动相关服务接管资源，保证业务的连续性。接管速度最快可以小于1秒，备节点可以有多个，通过优先级竞选，但一般Keepalived系统运维工作中都是一对。 VRRP使用了加密协议加密数据，但Keepalived官方目前还是推荐用明文的方式配置认证类型和密码。 VRID虚拟路由器表示，拥有相同VRID的一组路由器构成一个虚拟路由器，一个虚拟路由器可以拥有一个或多个虚拟IP地址 虚拟MAC地址00-00-5E-00-01（VRID） 分为抢占和不抢占 优先级高的成为master路由器，范围是0-255，0表示路由器放弃master状态，255表示虚拟IP地址实际拥有者。默认为100 backup路由器切换到master路由器的时间为skew time=256-backup路由器优先级/256 master失效，backup转换成master需要的时间为3*V隔RRP报文间Skew tim Keepalived服务的三个重要功能 管理LVS负载均衡软件\nKeepalived软件起初是为了解决LVS的问题而诞生的。因此，Keepalived和LVS的感情很深，向夫妻一样可以紧密结合，愉快地工作。 Keepalived通过读取配置文件，实现通过更底层的接口直接管理LVS及控制服务器的启动、停止等功能，使得LVS应用更加简单方便。\n实现对LVS集群健康检查的功能\nKeepalived可以通过在自身的keepalived.conf文件里配置LVS的节点IP和相关参数实现对LVS的直接管理；当故障的节点服务器被修复以后，Keepalived服务又会自动地把它们加入到正常转发队列中，对客户提供服务。\n作为系统网络服务的高可用\nKeepalived可以实现任意两台主机之间，例如Master和Backup主机之间的故障转移和自动切换，这个主机可以是普通的不能停机的业务服务器，也可以是LVS负载均衡、Nginx反向代理这样的服务器。\nVIP漂移实战 服务器规划 服务器 ip 说明 keepalived-01 10.0.0.7 keepalived主服务器 keepalived-02 10.0.0.8 keepalived备服务器 10.0.0.3 VIP 安装、配置Keepalived 两台服务器都安装Keepalived $ yum install keepalived -y 修改主服务器Keepalived配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { # 设置的邮件报警，这部分一般由nagios、zabbix监控软件来负责，这里的内容很鸡肋。 notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_lb01 # 主节点id 不能和备节点重名 vrrp_skip_check_adv_addr # 使用 unicast_src_ip 需要注释 vrrp_strict，也可以使用 ping 进行测试 # vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 script_user root enable_script_security } # 定义vrrp检测脚本，檢查nginx狀況 vrrp_script chk_nginx { # 执行脚本，当nginx服务有问题的時候就停掉keepalived服务 script \"/opt/script/chk_nginx.sh\" # 间隔1秒 interval 1 weight 1 } # VRRP实例 vrrp_instance VI_1 { # 指定keepalived的角色，MASTER表示此主機是主服務器，BACKUP表示主機為備用服務器 state MASTER # 设置的通信网卡名称 备节点设置一样 interface eth0 # 虚拟路由标志，支持一个数字，同一个vrrp实例使用唯一的标志 # 同一個vrrp_instance底下，MASTER跟BACKUP必须一致 virtual_router_id 51 # 定义优先级，数字越大，优先级越高(0-255) priority 150 # 设定MASTER跟BACKUP之间同步检查的时间间隔，单位是秒。 advert_int 1 # 如果节点之间禁用了群发的話，则采用vrrp单发通告的方式 unicast_src_ip 10.0.0.11 unicast_peer { 10.0.0.12 } # 设置验证类型与密码 authentication { # 设置验证类型，主要有PASS跟HA两种 auth_type PASS # 设置验证密码，在同一個vrrp_instance底下，MASTER跟BACKUP必须使用相同得密码才能正常沟通 auth_pass 1111 } # 设置虚拟IP地址，可以设置多個虚拟IP地址，每行设定一个 virtual_ipaddress { # 虚拟VIP的地址 与网卡标签 10.0.0.3/24 dev eth0 label eth0:1 } track_script { # 触发检查 chk_nginx } } EOF 修改备用服务器Keepalived配置文件 $ cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { # 设置的邮件报警，这部分一般由nagios、zabbix监控软件来负责，这里的内容很鸡肋。 notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 192.168.200.1 smtp_connect_timeout 30 # 备节点id 不能和备节点重名 router_id LVS_lb02 } # VRRP实例 vrrp_instance VI_1 { # 设置主服务器 state MASTER # 设置通信网卡 备节点设置一样 interface eth0 # 同组路由器属性 virtual_router_id 51 # 优先级 这里必须比备节点高 priority 100 # 每隔一秒发一次心跳 advert_int 1 # 授权密码 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { # 虚拟VIP的地址 与网卡标签 10.0.0.3/24 dev eth0 label eth0:1 } } EOF 启动主节点keepalived服务并检查 $ /etc/init.d/keepalived start 正在启动 keepalived： [确定] [root@kepalived-01 ~]# ps -ef|grep keep|grep -v grep root 7428 1 0 10:54 ? 00:00:00 /usr/sbin/keepalived -D root 7430 7428 0 10:54 ? 00:00:00 /usr/sbin/keepalived -D root 7431 7428 0 10:54 ? 00:00:00 /usr/sbin/keepalived -D 检查配置后的虚拟IP 出现带有vip：10.0.0.3行的结果表示kepalived-01的keepalived服务单实例配置成功 $ ip add|grep 10.0.0.3 inet 10.0.0.3/24 scope global secondary eth0:1 启动备节点keepalived服务 查看备用服务器是否有IP没有返回任何结果就对 [root@keepalived-02 ~]# /etc/init.d/keepalived start 正在启动 keepalived： [root@keepalived-02 ~]# ip add|grep 10.0.0.3 [root@keepalived-02 ~]# 单实例主备模式keepalived配置文件对比 主备单实例keepalived.conf配置差别项 Keepalived配置参数 Master节点特殊参数 Backup节点特殊参数 Router_id (唯一标识) router_id lb01 router_id lb02 State（角色状态） Stat master Stat backup Priority （竞选优先级） Priority 150 Priority 100 Keepalived主备切换 停掉主服务上的keepalived服务或关闭主服务器，操作及检查步骤 [root@keepalived-01 ~]# ip add|grep 10.0.0.3 inet 10.0.0.3/24 scope global secondary eth0:1 [root@keepalived-01 ~]# /etc/init.d/keepalived stop 停止 keepalived： [确定] [root@keepalived-01 ~]# ip add|grep 10.0.0.3 # 查看vip消失 [root@keepalived-01 ~]# 可以看到主服务器vip10.00.3消失了，此时查看backup备份服务器，看是否会有vip10.0.0.3出现 可以看到备节点keepalived-02已经接管绑定了10.0.0.3这个vip，这期间备节点还会发送ARP广播，让所有的客户端更新本地的ARP表，以便客户端访问新接管vip服务节点。 [root@keepalived-02 ~]# ip add|grep 10.0.0.3 inet 10.0.0.3/24 scope global secondary eth0:1 此时如果在启动主服务器的keepalived服务，主服务器就会接管回vip 10.0.0.3 [root@keepalived-01 ~]# ip add|grep 10.0.0.3 [root@keepalived-01 ~]# /etc/init.d/keepalived start 正在启动 keepalived： [确定] [root@keepalived-01 ~]# ip add|grep 10.0.0.3 inet 10.0.0.3/24 scope global secondary eth0:1 此时备节点上的vip 10.0.0.3则被释放了，如下 [root@keepalived-02 ~]# ip add|grep 10.0.0.3 这样就实现了单实例keepalived服务IP自动漂移接管了，vip漂移到了新机器新服务上，用户的访问请求自然就会找到新机器新服务了 注意：这里仅实现了VIP自动漂移切换，因此仅适合两台服务器提供的服务均保持开启的应用场景，这也是工作中常用的高可用解决方案 keepalived双主模式 keepalived双实例双主模式配置实战 Keepalived还支持多实例多业务双向主备模式，即A业务在keepalived-01上主模式是主模式，在keepalived-02上是备模式，而B业务在keepalived-02上是备模式，在keepalived-02上是主模式. Keepalived双实例双主模式的ip及VIP规划 Hostname IP 说明 keepalived-01 10.0.0.5 VIP：10.0.0.3（用于绑定A服务www.etiantian.org） keepalived-02 10.0.0.4 VIP：10.0.0.4（用于绑定B服务blog.etiantian.org） 首先配置keepalived-01 10.0.0.5的keepalived.conf，在单实例的基础上增加一个VIP_instance VI_2步骤及内容如下 [root@keepalived-01 ~]# cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lb01 } # vrrp_script chk_nginx { # script \"/root/chk_nginx.sh\" # interval 1 # weight 1 # } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 51 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.3/24 dev eth0 label eth0:1 } } vrrp_instance VI_2 { state BACKUP interface eth0 virtual_router_id 52 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1112 } virtual_ipaddress { 10.0.0.4/24 dev eth0 label eth0:2 } } EOF 提示：以vrrp_instance VI_1在keepalived-01 10.0.0.5服务器上的角色为主，vrrp_instance VI_2在keepalived-01 10.0.0.5服务器上的角色为备 然后布置keepalived-02 10.0.0.6的keepalived.conf，在单实例的基础上增加vrrp_instance VI_2实例，步骤如下 [root@keepalived-02 ~]# cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lb02 } vrrp_instance VI_1 { state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.3/24 dev eth0 label eth0:1 } } vrrp_instance VI_2 { state MASTER interface eth0 virtual_router_id 52 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1112 } virtual_ipaddress { 10.0.0.4/24 dev eth0 label eth0:2 } } EOF 提示：以vrrp_instance VI_1在keepalived-02 10.0.0.6服务器上的角色为备，vrrp_instance VI_2在keepalived-02 10.0.0.6服务器上的角色为主 接着在keepalived-01、keepalived-02上分别重启keepalived服务，观察初始VIP设置情况 Lb01操作情况如下 [root@keepalived-01 ~]# /etc/init.d/keepalived restart 停止 keepalived： [确定] 正在启动 keepalived： [确定] [root@keepalived-01 ~]# ip add|grep -E \"10.0.0.3|0.4\" inet 10.0.0.3/24 scope global secondary eth0:1 inet 10.0.0.4/24 scope global secondary eth0:2 提示：启动keepalived-02后，初始状态已经启动了10.0.0.4VIP，即keepalived-02由VI_2实例配置的VIP对外提供服务，列入可以把blog.etiantian.org解析到10.0.0.4上 下面停掉任意一端服务器或者keepalived服务，然后查看vip是不是会漂移到另一端。停掉keepalived-01的keepalived [root@keepalived-01 ~]# /etc/init.d/keepalived stop 停止 keepalived： [确定] [root@keepalived-01 ~]# ip add|grep -E \"10.0.0.3|0.4\" [root@keepalived-01 ~]# # 此处无任何信息 停掉keepalived-01后，vip 10.0.0.3即被释放,检查keepalived-02服务器上vip的接管情况 keepalived-02已将接管了keepalived-01的vip 10.0.0.3 [root@keepalived-02 ~]# ip add|grep -E \"10.0.0.3|0.4\" inet 10.0.0.4/24 scope global secondary eth0:2 inet 10.0.0.3/24 scope global secondary eth0:1 问题排查 裂脑问题 什么是裂脑 由于某些原因，导致两台高可用服务器对在指定时间内无法检测到对方的心跳消息。各自取得资源及服务的所有权，而此时的两台高可用服务器对都还活着并在正常运行着，这样就会导致同一个ip或服务在两端同时存在而发生冲突，最严重的是两台主机占用一个VIP地址，当用户写入数据时可能会分别写入到两端，这可能会导致服务器两端数据不一致或造成数据丢失，这种情况称为脑裂 导致脑裂发生的原因 一般来说脑裂的发生，有以下几种原因： 高可用服务器之间心跳线路发生故障，导致无法正常通信 心跳线坏了(包括断了，老化) 网卡及相关驱动坏了，IP配置及冲突 心跳线连接的设备故障（网卡及交换机） 仲裁的机器出问题 高可用服务器上开启了iptableable防火墙阻挡了心跳消息传输 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败 其他服务器配置不当等原因，心跳广播冲突。软件BUG等 提示：keepalived配置里同一VRRP实例如果virtual_router_id两端参数配置不一致，也会导致脑裂问题发生 脑裂排查 出现上述无任何结果的现象，表示keepalived-02的keepalived服务单实例配置成功。如果keepalived-02配置过滤后出现10.0.0.3的ip。则表示keepalived工作不正常，同一个IP地址同一时刻应该只能出现一台服务器。 如果查看backup备节点vip有如下信息，说明高可用脑裂了，裂脑是两台服务器争抢同一资源导致的，例如:两边都配置了同一个ip，一般要先考虑排查两个地方 主备两台服务器之间是否通信正常，如果不正常是否有iptables防火墙阻挡 主备两台服务器对应的keepalived.conf配置文件是否有错误？例如：是否同一实例的virtual_router_id配置不一致 [root@keepalived-02 ~]# ip add|grep 10.0.0.3 inet 10.0.0.3/24 scope global secondary eth0:1 脑裂解决常见方案 同时使用串行电缆和以太网电缆连接，同时用两条心跳线路，这样一条线路坏了，另一条线路还是好的，依然能够传送心跳信息 当检测到脑裂时强行关闭一个心跳节点（这个功能需要特殊设备支持，如Stonith、fence）。相当于节点信息接收不到心跳信息，通过单独的线路发送机关命令关闭主节点电源 做好裂脑的监控警报 编写监控Keepalived脑裂脚本 检测思路： 在备节点上执行脚本，如果可以ping通主节点并且备节点有VIP就报警 让人员介入检查是否裂脑。 在keepalived-02备节点开发脚本并执行 [root@keepalived-02 ~]# cat \u003echeck_split_brain.sh\u003c\u003c-EOF #!/bin/sh keepalived-01_vip=10.0.0.12 keepalived-01_ip=10.0.0.7 while true do ping -c 2 -W 3 ${\"keepalived-01_ip\"} \u0026\u003e/dev/null if [ $ -eq 0 -a `ip add|grep ${\"keepalived-01_vip\"}|wc -l` -eq 1 ] then echo \"ha is split brain.warning.\" else echo \"ha is ok\" fi sleep 5 done EOF [root@keepalived-02 ~]# sh check_split_brain.sh ha is okha is ok 正常情况下主节点活着，VIP 10.0.0.12在主节点，因此不会报警提示ha is ok。 keepalived-01 停止Keepalived服务看keepalived-02脚本执行情况 [root@keepalived-01 ~]# /etc/init.d/keepalived stop 停止 keepalived： [确定] [root@keepalived-01 ~]# ip add|grep 10.0.0.12 在keepalived-02上观察即可，此前脚本已经执行 [root@keepalived-02 ~]# sh check_split_brain.sh ha is okha is ok ha is split brain.warning. ha is split brain.warning. ha is split brain.warning. 关掉keepalived-01服务器，然后再观察keepalived-02脚本的输出 [root@@keepalived-02 ~]# sh check_split_brain.sh ha is okha is ok ha is split brain.warning. ha is split brain.warning. ha is split brain.warning. ha is ok ha is ok ha is ok nginx配置负载 结合nginx负载均衡的环境，两边keepalived-01和keepalived-02的配置环境一样 这里使用nginx负载均衡的配置如下： [root@@keepalived-01 ~]# cat \u003e/usr/local/nginx/conf/nginx.conf\u003c\u003c-EOF worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; upstream server_pools { server 10.0.0.7:80 weight=1; server 10.0.0.8:80 weight=1; } server { listen 10.0.0.3:80; server_name www.etiantian.org; location / { proxy_pass http://server_pools; include proxy.conf; } } server { listen 10.0.0.3:80; server_name bbs.etiantian.org; location / { proxy_pass http://server_pools; include proxy.conf; } } server { listen 10.0.0.4:80; server_name blog.etiantian.org; location / { proxy_pass http://server_pools; include proxy.conf; } } } EOF keepalived-01上配置keepalived.conf配置文件 [root@keepalived-01 ~]# cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lb01 } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 51 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.3/24 dev eth0 label eth0:1 } } vrrp_instance VI_2 { state BACKUP interface eth0 virtual_router_id 52 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1112 } virtual_ipaddress { 10.0.0.4/24 dev eth0 label eth0:2 } } EOF keepalived-02上配置keepalived.conf配置文件 [root@keepalived-02 ~]# cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lb02 } vrrp_instance VI_1 { state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.3/24 dev eth0 label eth0:1 } } vrrp_instance VI_2 { state MASTER interface eth0 virtual_router_id 52 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1112 } virtual_ipaddress { 10.0.0.4/24 dev eth0 label eth0:2 } } EOF 解决监听的服务网卡上不存在IP地址问题 如果配置使用listen 10.0.0.3:80 的方式指定IP监听服务，而本地的网卡上没有10.0.0.3这个IP，nginx就会报错，如：出现上述的原因是在物理网卡上没有配置与文件里监听的IP相对应的IP，解决办法是在/etc/sysctl.conf中加入如下参数： 此项表示启动nginx而忽视配置中监听的VIP是否存在，它同样适合Haproxy [root@keepalived-02 ~]# echo \"net.ipv4.ip_nonlocal_bind = 1\" \u003e\u003e/etc/sysctl.conf [root@keepalived-02 ~]# sysctl -p 解决高可用服务只针对物理服务器的问题 默认情况下keepalived软件仅仅在对方机器宕机或keepalived停掉的时候才会接管业务，但在实际过程中，有业务服务停止而keepalived服务还在工作的情况，这就会导致用户访问VIP无法找到对应的服务 方法一：可以写守护进程脚本来处理。当nginx业务有问题时，就停掉本地的keepalived服务，实现IP漂移到对端继续提供服务。实际工作中部署及开发的示例脚本 此脚本的思路是如没有80端口存在，就停掉keepalived服务实现释放本地的VIP在后台执行上述脚本 [root@keepalived-01 ~]# cat \u003e/server/scripts/check_nginx.sh\u003c\u003c-EOF #!/bin/sh while true do if [ `netstat -lntup|grep nginx|wc -l` -eq 0 ];then /etc/init.d/keepalived stop fi sleep 5 done EOF $ sh server/scripts/check_nginx.sh \u0026 $ ps -ef|grep check|grep -v grep root 8580 8394 0 16:19 pts/0 00:00:00 sh check_nginx.s 确定nginx以及keepalived服务是否正常 [root@keepalived-01 ~]# netstat -lntup|grep nginx tcp 0 0 10.0.0.4:80 0.0.0.0:* LISTEN 8541/nginx tcp 0 0 10.0.0.3:80 0.0.0.0:* LISTEN 8541/nginx [root@keepalived-01 ~]# /etc/init.d/keepalived status keepalived (pid 8438) 正在运行... 然后模拟nginx服务挂掉，看IP是否会发生切换 [root@keepalived-01 ~]# /usr/local/nginx/sbin/nginx -s stop 停止 keepalived： [确定] [root@@keepalived-01 ~]# /etc/init.d/keepalived status keepalived 已停 [root@keepalived-01 ~]# netstat -lntup|grep nginx [root@keepalived-01 ~]# 此时备节点接管 [root@keepalived-02 ~]# ip add|grep -E \"10.0.0.3|0.4\" inet 10.0.0.3/24 scope global secondary eth0:1 inet 10.0.0.4/24 scope global secondary eth0:2 方法二：可以使用keepalived的配置脚本参数触发写好的监测服务脚本 首先要开发监测服务脚本，注意:这个脚本与上一个的不同 [root@keepalived-01 ~]# cat \u003e/server/scripts/chk_nginx_proxy.sh\u003c\u003c-EOF #!/bin/sh if [ `netstat -lntup|grep nginx|wc -l` -eq 0 ];then /etc/init.d/keepalived stop fi EOF [root@keepalived-01 ~]# chmod +x /server/scripts/chk_nginx_proxy.sh [root@keepalived-01 ~]# ll /server/scripts/chk_nginx_proxy.sh -rwxr-xr-x 1 root root 99 6月 10 16:30 chk_nginx_proxy.sh [root@keepalived-01 ~]# 此时keepalived服务的完整配置为 [root@keepalived-01 ~]# cat \u003e/etc/keepalived/keepalived.conf\u003c\u003c-EOF ! Configuration File for keepalived global_defs { notification_email { 31333741@qq.com } notification_email_from 31333741@qq.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lb01 } vrrp_script chk_nginx_proxy { # 定义vrrp脚本，检测HTTP端口。 script \"/server/scripts/chk_nginx_proxy.sh\" # 执行脚本，当nginx服务有问题，就停掉keepalived服务。 interval 2 # 间隔2秒 weight 2 } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 51 priority 150 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.0.3/24 dev eth0 label eth0:1 } track_script { chk_nginx_proxy #触发检查 } } vrrp_instance VI_2 { state BACKUP interface eth0 virtual_router_id 52 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1112 } virtual_ipaddress { 10.0.0.4/24 dev eth0 label eth0:2 } } EOF 注意： vrrp_script chk_nginx_proxy { # \u003c==定义vrrp脚本，检测HTTP端口。 script \"/server/scripts/chk_nginx_proxy.sh\" # \u003c==执行脚本，当nginx服务有问题，就停掉keepalived服务。 interval 2 # \u003c==间隔2秒 weight 2 } 解决多组keepalived服务器在一个局域网的冲突问题 可以在同组的keepalived服务器所有配置文件里指定独一无二的多播地址 不同实例的认证密码最好不同 global_defs { router_id LVS_19 vrrp_mcast_group4 224.0.0.19 # \u003c==这个就是指定多播地址的配置 } 配置指定文件接收keepalived服务日记 默认情况下keepalived服务日记会输出到系统日记/var/log/messages和其他日记信息会混合在一起，很不方便，可以将其调整为由独立的文件记录keepalived服务日记;操作步骤如下 编辑配置文件/etc/sysconfig/keepalived，将第14行的KEEPALIVED_OPTIONS=\"-D\"修改为KEEPALIVED_OPTIONS=\"-D -d -S 0\"快速修改方法： [root@keepalived-01 ~]# sed -i '14 s#KEEPALIVED_OPTIONS=\"-D\"#KEEPALIVED_OPTIONS=\"-D -d -S 0\"#g' /etc/sysconfig/keepalived [root@keepalived-01 ~]# sed -n '14p' /etc/sysconfig/keepalived KEEPALIVED_OPTIONS=\"-D -d -S 0\" 说明：可以查看/etc/sysconfig/keepalived里注释获得上述参数的说明 # --dump-conf -d 导出备份配置数据 # --log-detail -D 详细日志 # --log-facility -S 设置本地的syslog设备，编号0-7（default=LOG_DAEMON） * -S 0 表示指定为local0设备 修改rsyslog的配置文件vim /etc/rsyslog.conf，在结尾处加入如下2行内容： 配置表示来自local0设备的所有日志信息都记录到/var/log/keepalived.log文件。 然后在约第42行如下信息的第一列结尾加入“；local0.none”： # keepalived local0.* /var/log/keepalived.log # 配置表示来自local0设备的所有日志信息不再记录于/var/log/messages里。 3 配置完成后，重启rsyslog服务。 [root@keepalived-01 ~]# sed -i '42 s#*.info;mail.none;authpriv.none;cron.none#*.info;mail.none;authpriv.none;cron.none;local0.none#g' /etc/rsyslog.conf [root@keepalived-01 ~]# sed -n '42p' /etc/rsyslog.conf *.info;mail.none;authpriv.none;cron.none;local0.none /var/log/messages [root@keepalived-01 ~]# /etc/init.d/rsyslog restart 关闭系统日志记录器： [确定] 启动系统日志记录器： [确定] 测试Keepalived日志记录结果。在重启Keepalived服务后，就会把日志信息输出到rsyslog定义的/var/log/ keepalived.log文件 如果要求更高，还可以在/var/log/messages上设置对/var/log/keepalived.log进行轮询，以防单个日志文件变得太大 Jun 10 22:38:03 lb01 Keepalived[10852]: Stopping Keepalived v1.2.13 (03/19,2015) Jun 10 22:38:03 lb01 Keepalived_vrrp[10855]: VRRP_Instance(VI_1) sending 0 priority Jun 10 22:38:03 lb01 Keepalived_vrrp[10855]: VRRP_Instance(VI_1) removing protocol VIPs. Jun 10 22:38:03 lb01 Keepalived_vrrp[10855]: VRRP_Instance(VI_2) sending 0 priority Jun 10 22:38:03 lb01 Keepalived_vrrp[10855]: VRRP_Instance(VI_2) removing protocol VIPs. Jun 10 22:38:03 lb01 Keepalived_healthcheckers[10854]: Netlink reflector reports IP 10.0.0.3 removed Jun 10 22:38:03 lb01 Keepalived_healthcheckers[10854]: Netlink reflector reports IP 10.0.0.4 removed Jun 10 22:38:03 lb01 Keepalived[10884]: Starting Keepalived v1.2.13 (03/19,2015) ",
    "description": "Keepalived简介 标签： 高可用vrrp Keepalived啥软件起初是准尉LVS负载软件设计的，用来管理并监控LVS集群系统中各个服务节点的装阿提，后来加入了高可用的VRRP功能。 VRRP是Virtual Router Redundancy Protocol(虚拟路由器冗余协议)的缩写，为解决静态路由器单点故障问题，确保个别节点宕机时，真哥哥网络可以不间断地运行。 Keepalived另一方面具有配置配置管理LVS的功能，同时还具有对LVS下面节进行健康检查的功能。 VRRP原理介绍 VRRP，全称Virtual Router Redundancy Protocol中文名为虚拟路由冗余协议，VRRP的出现是为了解决静态路由的单 keepalived通过vrrp通信，通过竞选确定主备协议机制来将路由任务交给某台VRRP路由器的，主优先级高于备。因此，工作时主会获得所有资源，备节点处于等待状态，当主节点宕机，那么备节点启用接管程序接管主节点资源，顶替主节点提供服务。 VRRP报文封装在IP报文中，只有一种VRRP通告报文， 只有处于master状态下的路由器会发送，VRRP用IP多播的方式（默认多播地址（224.",
    "tags": [],
    "title": "Install_Keepalived",
    "uri": "/systems/linux/keepalived/install_keepalived/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e JumpServer",
    "content": "配置Jumpserver 配置Nginx代理Jumpserver Nginx配置文件代理Jumpserver默认用户名密码都是：admin $ cat \u003e/usr/local/nginx/conf/vhosts/jumpserver.conf\u003c\u003c-EOF server{ listen 80; server_name jumpserver.com; location / { client_max_body_size 50m; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8888; index index.html index.htm; } error_page 404 http://jumpserver.com; access_log /usr/local/nginx/logs/jumpserver-access.log main; error_log /usr/local/nginx/logs/jumpserver-error.log info; } EOF 配置Jumpserver配置文件 修改上传默认目录为：/tmp $ cat \u003e/opt/koko-2.24.2/config_example.yml\u003c\u003c-EOF # 项目名称, 会用来向Jumpserver注册, 识别而已, 不能重复 # NAME: {{ Hostname }} # Jumpserver项目的url, api请求注册会使用 CORE_HOST: http://127.0.0.1:8080 # Bootstrap Token, 预共享秘钥, 用来注册coco使用的service account和terminal # 请和jumpserver 配置文件中保持一致，注册完成后可以删除 BOOTSTRAP_TOKEN: \u003cPleasgeChangeSameWithJumpserver\u003e # 启动时绑定的ip, 默认 0.0.0.0 # BIND_HOST: 0.0.0.0 # 监听的SSH端口号, 默认2222 # SSHD_PORT: 2222 # 监听的HTTP/WS端口号，默认5000 # HTTPD_PORT: 5000 # 设置日志级别 [DEBUG, INFO, WARN, ERROR, FATAL, CRITICAL] # LOG_LEVEL: INFO # SSH连接超时时间 (default 15 seconds) # SSH_TIMEOUT: 15 # 语言 [en,zh] # LANGUAGE_CODE: zh # SFTP的根目录, 可选 /tmp, Home其他自定义目录 # SFTP_ROOT: /tmp # SFTP是否显示隐藏文件 # SFTP_SHOW_HIDDEN_FILE: false # 是否复用和用户后端资产已建立的连接(用户不会复用其他用户的连接) # REUSE_CONNECTION: true # 资产加载策略, 可根据资产规模自行调整. 默认异步加载资产, 异步搜索分页; 如果为all, 则资产全部加载, 本地搜索分页. # ASSET_LOAD_POLICY: # zip压缩的最大额度 (单位: M) # ZIP_MAX_SIZE: 1024M # zip压缩存放的临时目录 /tmp # ZIP_TMP_PATH: /tmp # 向 SSH Client 连接发送心跳的时间间隔 (单位: 秒)，默认为30, 0则表示不发送 # CLIENT_ALIVE_INTERVAL: 30 # 向资产发送心跳包的重试次数，默认为3 # RETRY_ALIVE_COUNT_MAX: 3 # 会话共享使用的类型 [local, redis], 默认local # SHARE_ROOM_TYPE: local # Redis配置 # REDIS_HOST: 127.0.0.1 # REDIS_PORT: 6379 # REDIS_PASSWORD: # REDIS_CLUSTERS: # REDIS_DB_ROOM: # 是否开启本地转发 (目前仅对 vscode remote ssh 有效果) # ENABLE_LOCAL_PORT_FORWARD: false # 是否开启 针对 vscode 的 remote-ssh 远程开发支持 (前置条件: 必须开启 ENABLE_LOCAL_PORT_FORWARD ) # ENABLE_VSCODE_SUPPORT: false EOF Jumpserver界面配置 系统用户配置 权限管理配置 其它系统设置 ",
    "description": "配置Jumpserver 配置Nginx代理Jumpserver Nginx配置文件代理Jumpserver默认用户名密码都是：admin $ cat \u003e/usr/local/nginx/conf/vhosts/jumpserver.conf\u003c\u003c-EOF server{ listen 80; server_name jumpserver.",
    "tags": [],
    "title": "Use_JumpServer",
    "uri": "/systems/linux/jumpserver/use_jumpserver/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e JumpServer",
    "content": "安装Jumpserver堡垒机 jump server简介、安装JumpServer 完全开源，使用GNU GPL v2.0开源协议，符合4A专业运维审计 使用Python/Django进行开发，遵循Web2.0规范 实现了跳板机基本功能，认证、授权、审计 集成了Ansible批量命令，支持web Terminal 采纳分布式架构，支持多机房跨区域部署 现支持SSH、Telnet、RDP、VNC协议资产 自动收集硬件信息、录像回放、命令搜索、实时监控、批量上传下载 多租户：一套系统，多个子公司和部门同时使用 多应用支持：数据库，Windows远程应用Kubernetes 官方视频 基础配置环境要求 安装环境要求，默认账号密码都是：admin 系统/服务 版本 工具/数据库字符集 linux/amd64 \u003e= 4.0 wget curl tar gettext iptables python MySQL \u003e= 5.7 utf8、utf8_general_ci MariaDB \u003e= 10.2 utf8mb3、utf8mb3_general_ci Redis \u003e= 5.0 Sentinel模式，使用Redis做cache和celery broke 生成随机加密密钥 Linux系统，生成随机加密密钥 $ if [ \"$SECRET_KEY\" = \"\" ]; then SECRET_KEY=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 50`; echo \"SECRET_KEY=$SECRET_KEY\" \u003e\u003e ~/.bashrc; echo $SECRET_KEY; else echo $SECRET_KEY; fi $ if [ \"$BOOTSTRAP_TOKEN\" = \"\" ]; then BOOTSTRAP_TOKEN=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 16`; echo \"BOOTSTRAP_TOKEN=$BOOTSTRAP_TOKEN\" \u003e\u003e ~/.bashrc; echo $BOOTSTRAP_TOKEN; else echo $BOOTSTRAP_TOKEN; fi macOS系统，生成随机key $ if [ \"$SECRET_KEY\" = \"\" ]; then SECRET_KEY=`LC_CTYPE=C tr -dc A-Za-z0-9 \u003c /dev/urandom | head -c 50`; echo \"SECRET_KEY=$SECRET_KEY\" \u003e\u003e ~/.bash_profile; echo $SECRET_KEY; else echo $SECRET_KEY; fi $ if [ \"$BOOTSTRAP_TOKEN\" = \"\" ]; then BOOTSTRAP_TOKEN=`LC_CTYPE=C tr -dc A-Za-z0-9 \u003c /dev/urandom | head -c 16`; echo \"BOOTSTRAP_TOKEN=$BOOTSTRAP_TOKEN\" \u003e\u003e ~/.bash_profile; echo $BOOTSTRAP_TOKEN; else echo $BOOTSTRAP_TOKEN; fi 创建数据库 $ DB_PASSWORD=$(cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 24) # 生成随机数据库密码 $ echo -e \"\\033[31m 你的数据库密码是 $DB_PASSWORD \\033[0m\" $ mysql -uroot -e \"create database jumpserver default charset 'utf8'; grant all on jumpserver.* to 'jumpserver'@'127.0.0.1' identified by '$DB_PASSWORD'; flush privileges;\" # 创建数据库以及编码类型 mysql \u003e create database jumpserver default charset 'utf8'; # 创建用户以及授权 mysql \u003e grant all on jumpserver.* to 'jumpserver'@'%' identified by 'password'; Docker安装JumpServer 执行docker部署命令 使用docker-compose标准部署 $ git clone --depth=1 https://github.com/jumpserver/Dockerfile.git /opt/docker-compose/jumpserver 修改配置文件 $ cd /opt/docker-compose/jumpserver/ $ cp config_example.conf .env $ cat \u003e/opt/docker-compose/jumpserver/.env\u003c\u003c-EOF ## 版本号可以自己根据项目的版本修改 Version=v2.28.7 ## 构建参数, 支持 amd64/arm64 TARGETARCH=amd64 ## Compose COMPOSE_PROJECT_NAME=jms ## COMPOSE_HTTP_TIMEOUT=3600 ## DOCKER_CLIENT_TIMEOUT=3600 DOCKER_SUBNET=172.16.238.0/24 ## 持久化存储 VOLUME_DIR=/opt/jumpserver ## MySQL DB_HOST=mysql DB_PORT=3306 DB_USER=root DB_PASSWORD=nu4x599Wq7u0Bn8EABh3J91G DB_NAME=jumpserver ## Redis REDIS_HOST=redis REDIS_PORT=6379 REDIS_PASSWORD=8URXPL2x3HZMi7xoGTdk3Upj ## Core SECRET_KEY=B3f2w8P2PfxIAS7s4URrD9YmSbtqX4vXdPUL217kL9XPUOWrmy BOOTSTRAP_TOKEN=7Q11Vz6R2J6BLAdO DEBUG=FALSE LOG_LEVEL=ERROR ## Web HTTP_PORT=80 SSH_PORT=2222 MAGNUS_PORT=30000-30020 ## ## SECRET_KEY 保护签名数据的密匙, 首次安装请一定要修改并牢记, 后续升级和迁移不可更改, 否则将导致加密的数据不可解密。 ## BOOTSTRAP_TOKEN 为组件认证使用的密钥, 仅组件注册时使用。组件指 koko、guacamole EOF 初始化数据库、启动jms_core容器 $ docker-compose -f docker-compose-network.yml -f docker-compose-init-db.yml up -d 处理数据库合并 $ docker exec -i jms_core bash -c './jms upgrade_db' 构建启动Jumpserver $ docker-compose -f docker-compose-network.yml -f docker-compose.yml up -d Hlem部署Jump Server 使用Hlem部署Jumpserver到Kubernetes 使用Hlem安装Jumpserver库 $ helm repo add jumpserver https://jumpserver.github.io/helm-charts $ helm repo list 修改Jumserver的yaml文件JumpServer模板链接 $ cat \u003evalues.yaml\u003c\u003c-EOF # Default values for jumpserver. # This is a YAML-formatted file. # Declare variables to be passed into your templates. nameOverride: \"\" fullnameOverride: \"\" ## @param global.imageRegistry Global Docker image registry ## @param global.imagePullSecrets Global Docker registry secret names as an array ## @param global.storageClass Global StorageClass for Persistent Volume(s) ## @param global.redis.password Global Redis\u0026trade; password (overrides `auth.password`) ## global: imageRegistry: \"docker.io\" # 国内可以使用华为云加速 imageTag: v2.26.0 # 版本号 ## E.g. # imagePullSecrets: # - name: harborsecret # # storageClass: \"jumpserver-data\" ## imagePullSecrets: [] # - name: yourSecretKey storageClass: \"\" # (*必填) NFS SC ## Please configure your MySQL server first ## Jumpserver will not start the external MySQL server. ## externalDatabase: # (*必填) 数据库相关设置 engine: mysql host: localhost port: 3306 user: root password: \"\" database: jumpserver ## Please configure your Redis server first ## Jumpserver will not start the external Redis server. ## externalRedis: # (*必填) Redis 设置 host: localhost port: 6379 password: \"\" serviceAccount: # Specifies whether a service account should be created create: false # The name of the service account to use. # If not set and create is true, a name is generated using the fullname template name: ingress: enabled: true # 不使用 ingress 可以关闭 annotations: # kubernetes.io/tls-acme: \"true\" compute-full-forwarded-for: \"true\" use-forwarded-headers: \"true\" kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/configuration-snippet: | proxy_set_header Upgrade \"websocket\"; proxy_set_header Connection \"Upgrade\"; hosts: - \"test.jumpserver.org\" # 对外域名 tls: [] # - secretName: chart-example-tls # hosts: # - chart-example.local core: enabled: true labels: app.jumpserver.org/name: jms-core config: # Generate a new random secret key by execute `cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 50` # secretKey: \"B3f2w8P2PfxIAS7s4URrD9YmSbtqX4vXdPUL217kL9XPUOWrmy\" secretKey: \"\" # (*必填) 加密敏感信息的 secret_key, 长度推荐大于 50 位 # Generate a new random bootstrap token by execute `cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 16` # bootstrapToken: \"7Q11Vz6R2J6BLAdO\" bootstrapToken: \"\" # (*必填) 组件认证使用的 token, 长度推荐大于 24 位 # Enabled it for debug debug: false log: level: ERROR replicaCount: 1 image: registry: docker.io repository: jumpserver/core tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: # See: https://docs.jumpserver.org/zh/master/admin-guide/env/#core SESSION_EXPIRE_AT_BROWSER_CLOSE: true # SESSION_COOKIE_AGE: 86400 # SECURITY_VIEW_AUTH_NEED_MFA: true livenessProbe: failureThreshold: 30 httpGet: path: /api/health/ port: web readinessProbe: failureThreshold: 30 httpGet: path: /api/health/ port: web podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP web: port: 8080 ws: port: 8070 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 1000m # memory: 2048Mi # requests: # cpu: 500m # memory: 1024Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 100Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection # subPath: \"\" # existingClaim: volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} koko: enabled: true labels: app.jumpserver.org/name: jms-koko config: log: level: ERROR replicaCount: 1 image: registry: docker.io repository: jumpserver/koko tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: [] # See: https://docs.jumpserver.org/zh/master/admin-guide/env/#koko # LANGUAGE_CODE: zh # REUSE_CONNECTION: true # ENABLE_LOCAL_PORT_FORWARD: true # ENABLE_VSCODE_SUPPORT: true livenessProbe: failureThreshold: 30 httpGet: path: /koko/health/ port: web readinessProbe: failureThreshold: 30 httpGet: path: /koko/health/ port: web podSecurityContext: {} # fsGroup: 2000 securityContext: privileged: true # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP web: port: 5000 ssh: port: 2222 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 10Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} lion: enabled: true labels: app.jumpserver.org/name: jms-lion config: log: level: ERROR replicaCount: 1 image: registry: docker.io repository: jumpserver/lion tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: # See: https://docs.jumpserver.org/zh/master/admin-guide/env/#lion JUMPSERVER_ENABLE_FONT_SMOOTHING: true # JUMPSERVER_COLOR_DEPTH: 32 # JUMPSERVER_ENABLE_WALLPAPER: true # JUMPSERVER_ENABLE_THEMING: true # JUMPSERVER_ENABLE_FULL_WINDOW_DRAG: true # JUMPSERVER_ENABLE_DESKTOP_COMPOSITION: true # JUMPSERVER_ENABLE_MENU_ANIMATIONS: true livenessProbe: failureThreshold: 30 httpGet: path: /lion/health/ port: web readinessProbe: failureThreshold: 30 httpGet: path: /lion/health/ port: web podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP web: port: 8081 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 512Mi # requests: # cpu: 100m # memory: 512Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 50Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} magnus: enabled: true labels: app.jumpserver.org/name: jms-magnus config: log: level: ERROR replicaCount: 1 image: registry: docker.io repository: jumpserver/magnus tag: v2.21.0 pullPolicy: IfNotPresent command: [] env: [] livenessProbe: failureThreshold: 30 tcpSocket: port: mysql readinessProbe: failureThreshold: 30 tcpSocket: port: mysql podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP mysql: port: 33060 mariadb: port: 33061 postgre: port: 54320 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 512Mi # requests: # cpu: 100m # memory: 512Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 10Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} xpack: enabled: false # 企业版本打开此选项 omnidb: labels: app.jumpserver.org/name: jms-omnidb config: log: level: ERROR replicaCount: 1 image: registry: registry.fit2cloud.com repository: jumpserver/omnidb tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: [] livenessProbe: failureThreshold: 30 tcpSocket: port: web readinessProbe: failureThreshold: 30 tcpSocket: port: web podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP web: port: 8082 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 10Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} razor: labels: app.jumpserver.org/name: jms-razor config: log: level: ERROR replicaCount: 1 image: registry: registry.fit2cloud.com repository: jumpserver/razor tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: [] livenessProbe: failureThreshold: 30 tcpSocket: port: rdp readinessProbe: failureThreshold: 30 tcpSocket: port: rdp podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP rdp: port: 3389 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 50Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} web: enabled: true labels: app.jumpserver.org/name: jms-web replicaCount: 1 image: registry: docker.io repository: jumpserver/web tag: v2.26.0 pullPolicy: IfNotPresent command: [] env: [] # nginx client_max_body_size, default 4G # CLIENT_MAX_BODY_SIZE: 4096m livenessProbe: failureThreshold: 30 httpGet: path: /api/health/ port: web readinessProbe: failureThreshold: 30 httpGet: path: /api/health/ port: web podSecurityContext: {} # fsGroup: 2000 securityContext: {} # capabilities: # drop: # - ALL # readOnlyRootFilesystem: true # runAsNonRoot: true # runAsUser: 1000 service: type: ClusterIP web: port: 80 resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi persistence: storageClassName: jumpserver-data accessModes: - ReadWriteMany size: 1Gi # annotations: {} finalizers: - kubernetes.io/pvc-protection volumeMounts: [] volumes: [] nodeSelector: {} tolerations: [] affinity: {} EOF 安装、卸载命令 # 安装 $ helm install jms-k8s jumpserver/jumpserver -n jumpserver -f values.yaml # 卸载 $ helm uninstall jms-k8s -n default 脚本安装Jumpserver 安装完成后配置文件/opt/jumpserver/config/config.txt Jumpserver $ curl -sSL https://github.com/jumpserver/jumpserver/releases/download/v2.24.2/quick_start.sh | bash $ cd /opt/jumpserver-installer-v2.24.2 # 启动 $ ./jmsctl.sh start -d # 后台运行使用 -d 参数./jms start -d # 停止 $ ./jmsctl.sh down # 卸载 $ ./jmsctl.sh uninstall # 帮助 $ ./jmsctl.sh -h ",
    "description": "安装Jumpserver堡垒机 jump server简介、安装JumpServer 完全开源，使用GNU GPL v2.0开源协议，符合4A专业运维审计 使用Python/Django进行开发，遵循Web2.0规范 实现了跳板机基本功能，认证、授权、审计 集成了Ansible批量命令，支持web Terminal 采纳分布式架构，支持多机房跨区域部署 现支持SSH、Telnet、RDP、VNC协议资产 自动收集硬件信息、录像回放、命令搜索、实时监控、批量上传下载 多租户：一套系统，多个子公司和部门同时使用 多应用支持：数据库，Windows远程应用Kubernetes 官方视频 基础配置环境要求 安装环境要求，默认账号密码都是：admin 系统/服务 版本 工具/数据库字符集 linux/amd64 \u003e= 4.",
    "tags": [],
    "title": "Install_JumpServer",
    "uri": "/systems/linux/jumpserver/install_jumpserver/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Jenkins",
    "content": "配置Jenkins 升级Jenkins 定位jenkins.war包所在目录 Jenkins实践文档 $ ps -ef|grep jenkins # 定位jenkins.war包所在目录 root 1773 1 1 09:06 ? 00:03:00 /usr/local/jdk1.8.0_221/bin/java -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20 $ cd /usr/lib/jenkins/ $ systemctl stop jenkins # 停止Jenkins $ mv jenkins.war jenkins.war.bak # 备份 $ wget -P /usr/lib/jenkins/ http://mirrors.jenkins.io/war-stable/latest/jenkins.war $ systemctl start jenkins 汉化Jenkins 登录Jenkins页面选择：Manage Jenkins→Manage Plugins 在搜索框搜索：Locale选择安装并重启Jenkins页面 设置Local：Configure System(系统设置)→ Locale(语言设置)→en_US(英文)、zh_CN(中文) 配置域名 配置Nginx配置文件方便使用域名访问Jenkins $ cat \u003e/usr/local/nginx/conf/vhosts/jenkins.conf\u003c\u003c-EOF server { listen 80; server_name jenkins.ken.io; #监听的域名 access_log /var/log/nginx/jenkins.access.log main; error_log /var/log/nginx/jenkins.error.log error; location / { # 转发或处理 proxy_pass http://127.0.0.1:8080; } error_page 500 502 503 504 /50x.html; # 错误页 location = /50x.html { root /usr/share/nginx/html; } } EOF 权限管理 持续集成之Jenkins配置基于角色的项目权限管理(五) 配置Jenkins权限管理 Jenkins全局安装配置 系统管理→插件管理→安装插件:Role-based Authorization Strategy Role-based Authorization Strategy Matrix Authorization Strategy Authorize Project 系统管理→全局安全配置勾选:Role-Based Strategy Jenkisn角色分配权限 系统管理→管理和分配角色：Manage and Assign Roles 先配置： 管理角色 添加Jenkins全局项目角色 添加Jenkins项目角色 Role代表视图\nPattern代表视图下test*的任务名称\n给Jenkins角色分配执行权限 Jenkins全局角色 Jenkins项目角色 Jenkins配置邮箱 Jenkins服务器配置 配置ssh管理服务器 Jenkins使用ssh管理服务器 搜索ssh插件：系统管理→插件管理→搜索：Publish Over SSH 配置ssh插件：系统管理→系统配置→Publish over SSH→SSH Servers 配置ansible管理服务器 配置ansible实现免密登录以便Jenkins批量处理 生成密钥对，拷贝公钥到目部主机 $ /usr/bin/sed -i \"/host_key_checking/a\\\\host_key_checking = false\" /etc/ansible/ansible.cfg # 关闭主机密钥检查 $ sudo su -s /bin/bash jenkins # 如果Jenkins用户不是root需要切换用户 $ ssh-keygen # 生成密钥对 $ ssh-copy-id root@\"目标IP\" # 拷贝公钥到目标主机 配置Ansible的hosts文件 $ cat \u003e/etc/ansible/hosts\u003c\u003c-EOF console # 自定义名称， ansible_ssh_user=root # 用户， ansible_ssh_pass=\"a\" # 密码，ansible_ssh_port=22 # 端口， ansible_ssh_host=192.168.1.1 # 目部主机IP EOF 登录Jenkins页面，到插件管理界面搜索安装Ansible插件 安装好Ansible插件后重启Jenkins页面 使用Gitlab+Ansible构建项目验证Ansible是否可用 选择：新建任务→输入任务名称：→选择：构建一个自由风格的软件项目→点击：确认 添加Ansible构建 配置Ansible构建 测试Ansible构建 Jenkins部署插件 部署插件 General→Gogs 允许用户使用Gogs Webhook General→This project is parameterized(参数化构建过程)→Git Parameter 该插件允许您在构建中分配Git分支、标签、拉取请求或修订号作为参数 Build Triggers(构建触发器)→安装GitLab Plugin或Generic Webhook Trigger自动部署插件 此插件允许GitLab在提交代码或打开/更新合并请求时触发Jenkins中的构建。它还可以将构建状态发送回GitLab Build Environment(构建环境)→AnsiColor 这个插件增加了对标准ANSI转义序列的支持，包括颜色，到控制台输出。 该插件可在此处获得，并且在Jenkins Wiki上有一个页面 Build Environment(构建环境)→Set jenkins user build variables 描述启动构建的用户的一组环境变量 Post-build Actions(构建后操作)→Post build task 此功能允许用户关联shell或批处理脚本，这些脚本根据构建日志输出在Jenkins上执行某些任务。如果日志文本在构建日志文件中的某个位置匹配，则脚本将执行并且构建后日志将附加到项目构建日志中。允许使用Java正则表达式 Jenkins回滚插件 General→This project is parameterized(参数化构建过程)→Active Choices Active Choices插件用于参数化的自由式Jenkins作业，以创建脚本化、动态和交互式作业参数。Active Choices参数可以动态更新，并且可以呈现为组合框、复选框、单选按钮或丰富的HTML UI小部件。Active Choices参数使用Groovy或（可选）Scriptler Groovy脚本编写脚本。这些自定义脚本支持使用Jenkins Java API、系统环境变量、全局节点属性以及潜在的外部Java和Javascript库 ",
    "description": "配置Jenkins 升级Jenkins 定位jenkins.war包所在目录 Jenkins实践文档 $ ps -ef|grep jenkins # 定位jenkins.war包所在目录 root 1773 1 1 09:06 ?",
    "tags": [],
    "title": "Use_Jenkins",
    "uri": "/systems/linux/jenkins/use_jenkins/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Jenkins",
    "content": "Jenkins安装 名称地址 描述 Jenkins安装与升级 官方文档 事先最好安装：jdk-8u221以上版本，最新版本需要Java 11并且配置好环境变量 Huawei Java $ echo \"######### JDK环境变量 ####### export JAVA_HOME=/usr/local/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin \"\u003e\u003e/etc/profile $ source /etc/profile $ ln -s /usr/local/jdk/bin/java /usr/bin/java # 需要添加软连接 $ yum -y install avahi-libs copy-jdk-configs cups-libs fontconfig giflib \\ javapackages-tools libICE libSM libX11 libX11-common \\ libXau libXext libXi libXrender libXtst libfontenc \\ libjpeg-turbo libxcb libxslt lksctp-tools pcsc-lite-libs \\ python-javapackages python-lxml ttmkfdir tzdata-java \\ xorg-x11-font-utils xorg-x11-fonts-Type1 yum方式部署Jenkins Jenkins历史版本 $ wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo $ rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key $ yum -y install jenkins rpm方式部署Jenkins Jenkins稳定版rpm安装包 $ yum install -y ca-certificates $ wget https://pkg.jenkins.io/redhat/jenkins-2.219-1.1.noarch.rpm $ rpm -ivh jenkins-2.156-1.1.noarch.rpm war方式部署启动Jenkins Jenkins历史war包 $ wget https://get.jenkins.io/war-stable/2.319.3/jenkins.war $ java -jar jenkins.war --httpPort=8080 通过Docker部署Jenkins docker部署Jenkins $ docker run -d --name jenkins \\ -p 18090:8080 \\ -p 50000:50000 \\ -v /opt/jenkins/data:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --user root \\ jenkins/jenkins:jdk11 使用docker-compose构建启动Jenkins $ cat \u003e/opt/docker-compose/jenkins/docker-compose.yaml\u003c\u003c-EOF version: \"3\" services: jenkins: hostname: 'jenkins' container_name: jenkins # 启动后名称 image: 'jenkins/jenkins:jdk11' restart: always environment: TZ: Asia/Shanghai ports: - '18090:8080' - '50000:50000' # enkins-slave-agent服务端口 volumes: - '/opt/apps/jenkins:/var/jenkins_home' - '/var/run/docker.sock:/var/run/docker.sock' EOF 修改Jenkins配置 修改启动脚本：在candidates=\" 下添加jdk文件安装路径 $ vim /etc/init.d/jenkins candidates=\" # 大概在 99 行左右 /usr/local/jdk1.8.0_221/bin/java 修改Jenkins主配置文件 $ vim /etc/sysconfig/jenkins JENKINS_USER=\"root\" # 修改为root用户 JENKINS_PORT=\"8080\" # 修改监听端口 修改/usr/lib/systemd/system/jenkins.service文件下用户权限 $ vim /usr/lib/systemd/system/jenkins.service User=jenkins # 修改为root Group=jenkins # 修改为root Environment=\"JENKINS_PORT=8080\" # 端口修改 修改Jenkins目录权限 $ chown -R root:root /var/lib/jenkins $ chown -R root:root /var/cache/jenkins $ chown -R root:root /var/log/jenkins 启动Jenkins $ systemctl enable jenkins \u0026\u0026 systemctl start jenkins 修改防火墙规则放行Jenkins服务端口 $ firewall-cmd --add-port=8080/tcp --permanent $ firewall-cmd --reload 浏览器登录Jenkins http://IP:8080 docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword获取登录密码 登录后选择安装插件，默认即可 跳过创建用户界面 URL配置界面选择：保存并完成 选择：开始使用Jenkins安装完成 ",
    "description": "Jenkins安装 名称地址 描述 Jenkins安装与升级 官方文档 事先最好安装：jdk-8u221以上版本，最新版本需要Java 11并且配置好环境变量 Huawei Java $ echo \"######### JDK环境变量 ####### export JAVA_HOME=/usr/local/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.",
    "tags": [],
    "title": "Install_Jenkins",
    "uri": "/systems/linux/jenkins/install_jenkins/"
  },
  {
    "breadcrumb": "Systems \u003e Linux",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Use_Linux",
    "uri": "/systems/linux/use_linux/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e JDK",
    "content": "安装JDK 安装JDK 名称地址 描述 Oracle Java存档 华为JDK源 Java应用诊断利器 运维：你们JAVA服务怎么又又又又出问题了！内存降不下来 $ yum -y install wget $ wget -P /usr/local/src/ http://83.103.170.157/apps/java/jdk_1.8/jdk/jdk-8u202-linux-x64.tar.gz $ tar -zxvf /usr/local/src/jdk-8u202-linux-x64.tar.gz -C /usr/local/src/ $ ln -s /usr/local/src/jdk1.8.0_202 /usr/local/jdk $ echo \"####### JDK環境變數 ############ export JAVA_HOME=/usr/local/jdk export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=${JAVA_HOME}/lib:${JAVA_HOME}/lib/tools.jar export PATH=${PATH}:${JAVA_HOME}/bin:${JAVA_HOME}/jre/bin \"\u003e\u003e /etc/profile $ source /etc/profile jar包启动 命令启动Jar包 # 将Spring boot安装为Linux服务启动 使jar包可以直接运行,后面做软连接 $ ln -s /opt/lucky/jdk/bin/java /sbin/java # 授权指定用户可以运行jar包 $ echo \" alias kg-business-anchor-backstage='sudo /etc/init.d/kg-business-anchor-backstage' alias kg-business-anchor-player='sudo /etc/init.d/kg-business-anchor-player' \"\u003e\u003e/home/myadmin/.bashrc $ ll /etc/init.d/ # 软连接 lrwxrwxrwx 1 root root 64 Mar 12 14:49 kg-business-anchor-backstage -\u003e /opt/webapps/hsperfdata_ksadmin/kg-business-anchor-backstage.jar lrwxrwxrwx 1 root root 61 Mar 12 14:49 kg-business-anchor-player -\u003e /opt/webapps/hsperfdata_ksadmin/kg-business-anchor-player.jar 脚本启动Jar包 $ cat \u003ejava.sh\u003c\u003c-EOF #!/bin/bash cd `dirname $0` CUR_SHELL_DIR=`pwd` CUR_SHELL_NAME=`basename ${BASH_SOURCE}` # 修改这里jar包名即可 JAR_NAME=\"red_admin-1.0.0-SNAPSHOT.jar\" # 修改为对应运行jar包 JAR_PATH=$CUR_SHELL_DIR/$JAR_NAME # JAVA_MEM_OPTS=\" -server -Xms1024m -Xmx1024m -XX:PermSize=128m\" JAVA_MEM_OPTS=\"\" # SPRING_PROFILES_ACTIV=\"-Dspring.profiles.active=eureka2\" SPRING_PROFILES_ACTIV=\"\" LOG_DIR=$CUR_SHELL_DIR/log LOG_PATH=$LOG_DIR/${JAR_NAME}.log echo_help() { echo -e \"syntax: sh $CUR_SHELL_NAME start|stop\" } if [ -z $1 ];then echo_help exit 1 fi if [ ! -d \"$LOG_DIR\" ];then mkdir \"$LOG_DIR\" fi if [ ! -f \"$LOG_PATH\" ];then touch \"$LOG_DIR\" fi if [ \"$1\" == \"start\" ];then # check server PIDS=`ps --no-heading -C java -f --width 1000 | grep $JAR_NAME | awk '{print $2}'` if [ -n \"$PIDS\" ]; then echo -e \"ERROR: The $JAR_NAME already started and the PID is ${PIDS}.\" exit 1 fi echo \"Starting the $JAR_NAME...\" # start nohup java $JAVA_MEM_OPTS -jar $SPRING_PROFILES_ACTIV $JAR_PATH \u003e\u003e $LOG_PATH 2\u003e\u00261 \u0026 COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=`ps --no-heading -C java -f --width 1000 | grep \"$JAR_NAME\" | awk '{print $2}' | wc -l` if [ $COUNT -gt 0 ]; then break fi done PIDS=`ps --no-heading -C java -f --width 1000 | grep \"$JAR_NAME\" | awk '{print $2}'` echo \"${JAR_NAME} Started and the PID is ${PIDS}.\" echo \"You can check the log file in ${LOG_PATH} for details.\" elif [ \"$1\" == \"stop\" ];then PIDS=`ps --no-heading -C java -f --width 1000 | grep $JAR_NAME | awk '{print $2}'` if [ -z \"$PIDS\" ]; then echo \"ERROR:The $JAR_NAME does not started!\" exit 1 fi echo -e \"Stopping the $JAR_NAME...\" for PID in $PIDS; do kill $PID \u003e /dev/null 2\u003e\u00261 done COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=1 for PID in $PIDS ; do PID_EXIST=`ps --no-heading -p $PID` if [ -n \"$PID_EXIST\" ]; then COUNT=0 break fi done done echo -e \"${JAR_NAME} Stopped and the PID is ${PIDS}.\" else echo_help exit 1 fi EOF Tomcat配置调整 为Tomcat指定JDK $ vim bin/setclasspath.sh # 在脚本开头的地方指定JAVA_HOME和JRE_HOME export JAVA_HOME=/usr/local/jdk1.8.0_40 export JRE_HOME=/usr/local/jdk1.8.0_40/jre 为Tomcat设置内存大小 $ vim bin/catalina.sh # Tomcat设置内存为8G JAVA_OPTS=\"-server -Xms8192M -Xmx8192M -XX:PermSize=256M -XX:MaxPermSize=256M\" # Tomcat设置内存为4G JAVA_OPTS=\"-server -Xms4096M -Xmx4096M -XX:PermSize=256M -XX:MaxPermSize=256M\" 使用maven打成war包 $ mvn clean install $ mvn clean package -Dmaven.test.skip=true ",
    "description": "安装JDK 安装JDK 名称地址 描述 Oracle Java存档 华为JDK源 Java应用诊断利器 运维：你们JAVA服务怎么又又又又出问题了！内存降不下来 $ yum -y install wget $ wget -P /usr/local/src/ http://83.",
    "tags": [],
    "title": "Install_Jdk_And_Jar_Run",
    "uri": "/systems/linux/jdk/install_jdk_and_jar_run/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e HAProxy",
    "content": "部署代理服务 HTTP代理privoxy 部署依赖 $ yum install epel-release 部署privoxy $ yum install privoxy 修改配置 $ cat \u003e/etc/privoxy/config\u003c\u003c-EOF listen-address 127.0.0.1:端口 # 服务端口 keep-alive-timeout 5 # 连接保持活动的时间为 5 秒，减少长时间空闲连接的占用。 max-client-connections 256 # 限制最大链接数，防止资源耗尽 timeout 300 # 超时时间可以防止超时请求占用太多时间 enable-edit-actions 0 # 禁用不必要的功能以减少消耗 log-messages 2 # 可减小到更小 # forward-socks5 / 127.0.0.1:8889 . # 将 DNS查询转发到本地 SOCKS5代理，可以减少DNS查询的数量 permit-access 0.0.0.0/0 EOF 启动privoxy $ systemctl start privoxy $ systemctl enable privoxy socket代理dante 安装dante $ yum install dante-server 调整配置 $ cat \u003e/etc/sockd.conf\u003c\u003c-EOF internal: 0.0.0.0 port=端口 # 服务端口 external: eth0 socksmethod: none clientmethod: none client pass { from: 0.0.0.0/0 to: 0.0.0.0/0 } socks pass { from: 0.0.0.0/0 to: 0.0.0.0/0 } EOF 启动sockd $ service sockd restart 测试代理服务 防火墙开放端口 $ curl -v -x http://ip:端口 https://www.baidu.com $ curl -v -x socks://ip:端口 https://www.baidu.com ",
    "description": "部署代理服务 HTTP代理privoxy 部署依赖 $ yum install epel-release 部署privoxy $ yum install privoxy 修改配置 $ cat \u003e/etc/privoxy/config\u003c\u003c-EOF listen-address 127.",
    "tags": [],
    "title": "Install_Proxy",
    "uri": "/systems/linux/haproxy/install_proxy/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Install_System",
    "content": "Cobbler简介 Cobbler是一个快速网络安装linux的服务，而且在经过调整也可以支持网络安装windows。该工具使用python开发，小巧轻便（才15k行python代码），使用简单的命令即可完成PXE网络安装环境的配置，同时还可以管理DHCP、DNS、TFTP、RSYNC以及yum仓库、构造系统ISO镜像 Cobbler支持命令行管理，web界面管理，还提供了API接口，可以方便二次开发使用 Cobbler客户端Koan支持虚拟机安装和操作系统重新安装，使重装系统更便捷 运维自动化在生产环境中占据着举足轻重的地位，尤其是面对几百台，几千台甚至几万台的服务器时，仅仅是安装操作系统，如果不通过自动化来完成，根本是不可想象的。 面对生产环境中不同服务器的需求，该如何实现批量部署多版本的操作系统呢？Cobbler便可以的满足这一实际需求，实现多版本操作系统批量部署 Cobbler各个组件之间关系 distro-\u003eprofile-system(可选) distro发行版 面对不同的操作系统 面对同一个操作系统不同的版本 profile 核心特性是通过kickstart来部署 system 主要目的配置网络接口 Cobbler功能 使用Cobbler，您无需进行人工干预即可安装机器。Cobbler设置一个PXE引导环境（它还可使用yaboot支持PowerPC），并控制与安装相关的所有方面，比如网络引导服务（DHCP和TFTP）与存储库镜像。当希望安装一台新机器时，Cobbler可以：使用一个以前定义的模板来配置DHCP服务（如果启用了管理DHCP）将一个存储库（yum或rsync）建立镜像或解压缩一个媒介，以注册一个新操作系统，在DHCP配置文件中为需要安装的机器创建一个条目，并使用您指定的参数（IP和MAC地址），在TFTFP服务目录下创建适当的PXE文件，重新启动DHCP服务以反映更改，重新启动机器以开始安装（如果电源管理已启用） Cobbler支持众多的发行版：Red Hat、Fedora、CentOS、Debian、Ubuntu和SuSE。当添加一个操作系统（通常通过使用ISO文件）时，Cobbler知道如何解压缩合适的文件并调整网络服务，以正确引导机器。 Cobbler可使用kickstart模板。基于Red Hat或Fedora的系统使用kickstart文件来自动化安装流程。通过使用模板，您就会拥有基本的kickstart模板，然后定义如何针对一种配置文件或机器配置而替换其中的变量。例如，一个模板可能包含两个变量$domain和$machine_name。在 Cobbler配置中，一个配置文件指定domain=mydomain.com，并且每台使用该配置文件的机器在machine_name变量中指定其名称。该配置文件中的所有机器都使用相同的kickstart安装且针对 domain=mydomain.com进行配置，但每台机器拥有其自己的机器名称。您仍然可以使用kickstart模板在不同的域中安装其他机器并使用不同的机器名称。 为了协助管理系统，Cobbler 可通过 fence scripts 连接到各种电源管理环境。 Cobbler支持apc_snmp、bladecenter、bullpap、drac、ether_wake、ilo、integrity、ipmilan、ipmitool、lpar、rsa、virsh和wti。要重新安装一台机器，可运行reboot system foo命令，而且Cobbler会使用必要的凭据和信息来为您运行恰当的fence scripts（比如机器插槽数） 除了这些特性，还可使用一个配置管理系统 (CMS)。您有两种选择：该工具内的一个内部系统，或者集成一个现有的外部CMS，比如Chef或Puppet。借助内部系统，您可以指定文件模板，这些模板会依据配置参数进行处理（与kickstart模板的处理方式一样），然后复制到您指定的位置。如果必须自动将配置文件部署到特定机器，那么此功能很有用 使用koan客户端，Cobbler可从客户端配置虚拟机并重新安装系统。我不会讨论配置管理和koan特性，因为它们不属于本文的介绍范畴。但是，它们是值得研究的有用特性 Cobbler自动部署 基础环境准备 提示：虚拟机网卡采用NAT模式，因为我们会搭建DHCP服务器，在同一局域网多个DHCP服务会有冲突，并且导致实践失败 $ cat /etc/redhat-release # 系统版本 $ uname –r # 内核版本 $ getenforce # 检测selinux是否关闭(必须关闭) $ systemctl stop firewalld # 关闭防火墙 $ ifconfig eth0|awk -F '[ :]+' 'NR==2 {print $3}' # 查看IP地址 $ hostname # 查看主机名 $ wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # cobbler安装必须使用到epel源 安装Cobbler $ yum install cobbler cobbler-web pykickstart httpd tftp dhcp xinetd cobbler # cobbler程序包 cobbler-web # cobbler的web服务包 pykickstart # cobbler检查kickstart语法错误 httpd # Apache web服务 tftp # tftp服务 dhcp # dhcp服务 /etc/cobbler # 配置文件目录 /etc/cobbler/settings # cobbler主配置文件 /etc/cobbler/dhcp.template # DHCP服务的配置模板 /etc/cobbler/tftpd.template # tftp服务的配置模板 /etc/cobbler/rsync.template # rsync服务的配置模板 /etc/cobbler/iso # iso模板配置文件目录 /etc/cobbler/pxe # pxe模板文件目录 /etc/cobbler/power # 电源的配置文件目录 /etc/cobbler/users.conf # Web服务授权配置文件 /etc/cobbler/users.digest # web访问的用户名密码配置文件 /etc/cobbler/dnsmasq.template # DNS服务的配置模板 /etc/cobbler/modules.conf # Cobbler模块配置文件 /var/lib/cobbler # Cobbler数据目录 /var/lib/cobbler/config # 配置文件 /var/lib/cobbler/kickstarts # 默认存放kickstart文件 /var/lib/cobbler/loaders # 存放的各种引导程序 /var/www/cobbler # 系统安装镜像目录 /var/www/cobbler/ks_mirror # 导入的系统镜像列表 /var/www/cobbler/images # 导入的系统镜像启动文件 /var/www/cobbler/repo_mirror # yum源存储目录 /var/log/cobbler # 日志目录 /var/log/cobbler/install.log # 客户端系统安装日志 /var/log/cobbler/cobbler.log # cobbler日志 检测Cobbler cobbler的运行依赖于dhcp、tftp、rsync及dns服务，其中dhcp可由dhcpd（isc）提供，也可由dnsmasq提供；tftp可由tftp-server程序包提供，也可由cobbler功能提供，rsync有rsync程序包提供，dns可由bind提供，也可由dnsmasq提供\ncobbler可自行管理这些服务中的部分甚至是全部，但需要配置/etc/cobbler/settings文件中的manange_dhcp、manager_tftpd、manager_rsync、manager_dns分别来进行定义，另外，由于各种服务都有着不同的实现方式，如若需要进行自定义，需要通过修改/etc/cobbler/modules.conf配置文件中各服务的模块参数的值来实现\n$ systemctl start httpd # 启动apache服务 $ systemctl start cobblerd # 启动cobbler程序 检查配置文件，需要在cobblerd和httpd启动的情况下检查 $ systemctl start httpd # 启动apache服务 $ systemctl start cobblerd # 启动cobbler程序 # 检查配置文件，需要在cobblerd和httpd启动的情况下检查 $ cobbler check # 检查存在的问题,逐一解决 The following are potential configuration items that you may want to fix: 1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : change 'disable' to 'no' in /etc/xinetd.d/tftp 4 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements. 5 : enable and start rsyncd.service with systemctl 6 : debmirror package is not installed, it will be required to manage debian deployments and repositories 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Restart cobblerd and then run 'cobbler sync' to apply changes. # 如上各问题的解决方法如下所示： # 1. 修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相应的IP地址或主机名，如server: 10.0.0.101； $ sed -i 's/server: 127.0.0.1/server: 10.0.0.101/' /etc/cobbler/settings # 2. 修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机相应的IP地址，如next_server: 10.0.0.101； $ sed -i 's/next_server: 127.0.0.1/next_server: 10.0.0.101/' /etc/cobbler/settings # 3. 修改/etc/xinetd.d/tftp文件中的disable参数修改为 disable = no # 4. 执行 cobbler get-loaders 命令即可；否则，需要安装syslinux程序包，而后复制/usr/share/syslinux/{pxelinux.0,memu.c32}等文件至/var/lib/cobbler/loaders/目录中； # 5. 执行 systemctl enable rsyncd命令即可； # 6. 如果有强迫症可以选择 yum –y install debmirror 然后根据错误进行解决,一般错误如下。 # 注释/etc/dedmirror.conf文件中的 @dists=”sid”; @arches=”i386”; $ openssl passwd -1 -salt '$(openssl rand -hex 4)' 'xuliangwei' # $1$$(openss$.wbDUBV/STL0YaNuAcusK/ # 返回参数 $ grep \"default_password_crypted\" /etc/cobbler/settings # 替换/etc/cobbler/setting内的default_password_crypted default_password_crypted: \"$1$$(openss$.wbDUBV/STL0YaNuAcusK/\" # 7. yum –y install cman fence-agents # 最后重启Cobbler：systemctl restart cobblerd 配置DHCP $ sed -i 's#manage_dhcp: 0#manage_dhcp: 1#g' /etc/cobbler/settings # 使用cobbler管理dhcp $ vim /etc/cobbler/dhcp.template # 修改cobbler的dhcp模版，因为cobbler会替换。 subnet 10.0.0.0 netmask 255.255.255.0 { option routers 10.0.0.2; option domain-name-servers 10.0.0.2; option subnet-mask 255.255.255.0; range dynamic-bootp 10.0.0.200 10.0.0.250; default-lease-time 21600; max-lease-time 43200; next-server $next_server; 同步Cobbler $ systemctl restart xinetd # 重启xinetd $ systemctl restart cobblerd # 重启cobbler $ cobbler sync # 同步最新cobbler配置，可以看具体做了哪些操作 task started: 2016-04-29_234117_sync task started (id=Sync, time=Fri Apr 29 23:41:17 2016) running pre-sync triggers cleaning trees removing: /var/lib/tftpboot/pxelinux.cfg/default removing: /var/lib/tftpboot/grub/images removing: /var/lib/tftpboot/grub/grub-x86.efi removing: /var/lib/tftpboot/grub/grub-x86_64.efi removing: /var/lib/tftpboot/grub/efidefault removing: /var/lib/tftpboot/s390x/profile_list copying bootloaders trying hardlink /var/lib/cobbler/loaders/grub-x86.efi -\u003e /var/lib/tftpboot/grub/grub-x86.efi trying hardlink /var/lib/cobbler/loaders/grub-x86_64.efi -\u003e /var/lib/tftpboot/grub/grub-x86_64.efi copying distros to tftpboot copying images generating PXE configuration files generating PXE menu structure rendering DHCP files generating /etc/dhcp/dhcpd.conf rendering TFTPD files generating /etc/xinetd.d/tftp cleaning link caches running post-sync triggers running python triggers from /var/lib/cobbler/triggers/sync/post/* running python trigger cobbler.modules.sync_post_restart_services running: dhcpd -t -q received on stdout: received on stderr: running: service dhcpd restart received on stdout: received on stderr: Redirecting to /bin/systemctl restart dhcpd.service running shell triggers from /var/lib/cobbler/triggers/sync/post/* running python triggers from /var/lib/cobbler/triggers/change/* running python trigger cobbler.modules.scm_track running shell triggers from /var/lib/cobbler/triggers/change/* *** TASK COMPLETE *** 管理Cobbler 管理distro cobbler变得可用的第一步为定义distro，其可以通过为其指定外部的安装引导内核及ramdisk文件的方式实现。如果已经有完成的安装树（如os的安装镜像）则推荐使用improt之间导入的方式进行 如果有kickstart文件，也可以使用--kickstart=/path/to/kickstart_file进行导入，因此import会自动为导入的distro生成一个profile $ mount /dev/cdrom /mnt/ # 挂在ISO光盘至服务器 mount: /dev/sr0 is write-protected, mounting read-only $ cobbler import --path=/mnt/ --name=CentOS-7.1-x86_64-distro --arch=x86_64 # --path 镜像路径 # --name 为安装源定义一个名字 # --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64 # 安装源的唯一标示就是根据name参数来定义，本例导入成功后，安装源的唯一标示就是：CentOS-7.1-distro-x86_64。 # 镜像存放目录，cobbler会将镜像中的所有安装文件拷贝到本地一份，放在/var/www/cobbler/ks_mirror下的CentOS-7.1-x86_64-distro-x86_64目录下。因此/var/www/cobbler目录必须具有足够容纳安装文件的空间。 task started: 2016-04-30_010122_import task started (id=Media import, time=Sat Apr 30 01:01:22 2016) Found a candidate signature: breed=redhat, version=rhel6 Found a candidate signature: breed=redhat, version=rhel7 Found a matching signature: breed=redhat, version=rhel7 Adding distros from path /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64: creating new distro: CentOS-7.1-distro-x86_64 trying symlink: /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64 -\u003e /var/www/cobbler/links/CentOS-7.1-distro-x86_64 creating new profile: CentOS-7.1-distro-x86_64 associating repos checking for rsync repo(s) checking for rhn repo(s) checking for yum repo(s) starting descent into /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64 for CentOS-7.1-distro-x86_64 processing repo at : /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64 need to process repo/comps: /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64 looking for /var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64/repodata/*comps*.xml Keeping repodata as-is :/var/www/cobbler/ks_mirror/CentOS-7.1-x86_64-distro-x86_64/repodata *** TASK COMPLETE *** $ cobbler distro list # 列出所有的distro CentOS-7.1-distro-x86_64 $ cobbler profile list # 导入distro会自动生成profile CentOS-7.1-distro-x86_64 管理profile cobbler使用profile来为特定的需求类别提供锁需要安装的配置，即在distro的基础上通过提供kiskstart文件来生成一个特定的系统安装配置。distro的profile可以出现在pxe的引导菜单中作为安装的选择之一 Cobbler-CentOS-7.1-x86_64.cfg配置文件我会上传至至附件，默认是有kickstart文件的，所以edit，如果没有kickstart文件可以add $ cobbler profile edit --name=Centos7.1-distro-x86_64 --kickstart=/var/lib/cobbler/kickstarts/Cobbler-CentOS-7.1-x86_64.cfg # 指定ks路径 CentOS7系统网卡名变成eno...这种，为了运维标准化，我们需要修改为我们常用的eth0，使用下面的参数。但要注意是CentOS7才需要下面的步骤，CentOS6不需要 $ cobbler profile edit --name=Centos7.1-distro-x86_64 --kopts='net.ifnames=0 biosdevname=0' # 修改centos7内核 新部署机器安装yum源，并同步。建议使用内网yum源，在这里使用阿里云yum源 $ cobbler repo add --name=base --mirror=http://mirrors.aliyun.com/centos/7/os/x86_64/Packages/ --arch=x86_64 --breed=yum # 添加yum源 $ cobbler reposync # 同步yum源 $ cobbler sync # 每次修改profile都需要同步 署操作系统 新建一台虚拟机，通过网络启动即可。（我这里虚拟机使用的是NAT模式,并且关闭DHCP功能） 用户：root 密码：xuliangwei openssl生成时指定 定制化安装 由于kickstart指定某台服务器使用某个ks文件比较复杂，所以引用Cobbler就很简单。通过物理MAC地址来区分 自定义安装：system主要目的配置网络接口，通过system来固定机器的IP、掩码、网关、DNS、主机名、等等实现基础环境标准化 根据机器的MAC地址，自动绑定IP，网关，dns等 $ cobbler system add --name=xuliangwei-pc --mac=00:0C:29:6E:41:CB --profile=Centos7.1-profile-x86_64 \\ --ip-address=10.0.0.110 --subnet=255.255.255.0 --gateway=10.0.0.2 --interface=eth0 \\ --static=1 --hostname=xuliangwei.com --name-servers=\"114.114.114.114 8.8.8.8\" $ cobbler sync $ cobbler system list xuliangwei-pc 自定义登陆界面 $ grep \"xuliangwei\" /etc/cobbler/pxe/pxedefault.template # 自定义装机页面 MENU TITLE Xuliangwei | http://xuliangwei.com $ cobbler sync # 同步 web管理Cobbler 新版cobbler的web界面使用的是https，登录https://10.0.0.7/cobbler_web\ncobbler_web支持多种认证方式，如authn_configfil、authn_ldap或authn_pam等，默认为authn_denyall即拒绝所有用户登陆，下面说明三种能认证用户登录cobbler_web的方式\n使用authn_pam模块认证cobbler_web用户\n首先修改modules中的authentication段中的module参数的值为authn_pam 接着创建系统用户，并为用户设定密码而后将设定的系统用户添加至cobbler_web的admin组中，修改/etc/cobbler/users.conf文件，将设定的用户添加为admin参数的值即可 使用authn_configfile模块认证cobbler_web用户 首先修改modules中的authentication段中的module参数的值为authn_configfile 添加第一用户时，需要为htdigest命令使用\"-c\" etc/cobbler/users.digest，后续添加其他用户则不能再使用，同步cobbler重启httpd以及cobbler 使用cobbler默认的web账号密码认证 user：cobbler pass：cobbler ",
    "description": "Cobbler简介 Cobbler是一个快速网络安装linux的服务，而且在经过调整也可以支持网络安装windows。该工具使用python开发，小巧轻便（才15k行python代码），使用简单的命令即可完成PXE网络安装环境的配置，同时还可以管理DHCP、DNS、TFTP、RSYNC以及yum仓库、构造系统ISO镜像 Cobbler支持命令行管理，web界面管理，还提供了API接口，可以方便二次开发使用 Cobbler客户端Koan支持虚拟机安装和操作系统重新安装，使重装系统更便捷 运维自动化在生产环境中占据着举足轻重的地位，尤其是面对几百台，几千台甚至几万台的服务器时，仅仅是安装操作系统，如果不通过自动化来完成，根本是不可想象的。 面对生产环境中不同服务器的需求，该如何实现批量部署多版本的操作系统呢？Cobbler便可以的满足这一实际需求，实现多版本操作系统批量部署 Cobbler各个组件之间关系 distro-\u003eprofile-system(可选) distro发行版 面对不同的操作系统 面对同一个操作系统不同的版本 profile 核心特性是通过kickstart来部署 system 主要目的配置网络接口 Cobbler功能 使用Cobbler，您无需进行人工干预即可安装机器。Cobbler设置一个PXE引导环境（它还可使用yaboot支持PowerPC），并控制与安装相关的所有方面，比如网络引导服务（DHCP和TFTP）与存储库镜像。当希望安装一台新机器时，Cobbler可以：使用一个以前定义的模板来配置DHCP服务（如果启用了管理DHCP）将一个存储库（yum或rsync）建立镜像或解压缩一个媒介，以注册一个新操作系统，在DHCP配置文件中为需要安装的机器创建一个条目，并使用您指定的参数（IP和MAC地址），在TFTFP服务目录下创建适当的PXE文件，重新启动DHCP服务以反映更改，重新启动机器以开始安装（如果电源管理已启用） Cobbler支持众多的发行版：Red Hat、Fedora、CentOS、Debian、Ubuntu和SuSE。当添加一个操作系统（通常通过使用ISO文件）时，Cobbler知道如何解压缩合适的文件并调整网络服务，以正确引导机器。 Cobbler可使用kickstart模板。基于Red Hat或Fedora的系统使用kickstart文件来自动化安装流程。通过使用模板，您就会拥有基本的kickstart模板，然后定义如何针对一种配置文件或机器配置而替换其中的变量。例如，一个模板可能包含两个变量$domain和$machine_name。在 Cobbler配置中，一个配置文件指定domain=mydomain.",
    "tags": [],
    "title": "Install_Cobbler",
    "uri": "/systems/linux/install_system/install_cobbler/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Install_System",
    "content": "KICKSTART无人值守 指令作用介绍 pxe\nPXE使用DHCP（动态主机配置协议）和TFTP（普通文件传送协议）从网络上查找并装载引导程序。PXE环境从NIC（Network Interface Card）上的BIOS装载。预引导服务使用PXE来发现设备是否存在为其指定的预引导服务工作，并向设备提供执行指派工作所需的文件。通过使用预引导服务，可以自动将映像放置到设备上，即使设备的硬盘为空\npxelinux.0\n主要作用是装载执行指派的预引导工作所需的操作系统。pxelinux.0文件是syslinux这一开放源代码项目的一部分的改进版本。虽然pxelinux.0主要是Linux加载器，但它也可以装载其他操作系统。它的工作方式是使用位于TFTP服务器上的配置文件来提供引导指令\nvmlinuz\nvmlinuz是Linux内核的镜像文件,可以被引导程序加载,从而启动Linux系统\ninitrd\ninitrd—-boot loader initialized RAM disk(全称)，是一种启动Linux系统的方式，当前流行的Linux版本一般都采用模块化的内核,这种方式可以在不重新编译构建内核的情形下增加功能模块，但是如果你的Linux的root文件系统所在设备的驱动是一个模块(没有编译进内核映象),就不能被引导程序(例如loadlin)直接加载，这时会用到initrd方式来启动你的Linux系统\n这种方式包括两个阶段: 在一个RAM disk上建立一个临时的root文件系统,在这个RAM disk上包含着你需要的驱动模块 载入所需驱动模块,挂载实际的root文件系统 ,启动Linux initrd.img\n就是RAM disk的映象\nPXE+Kickstart工作流程 Kickstart是一种无人值守的安装方式。它的工作原理是在安装过程中记录典型的需要人工干预填写的各种参数，并生成一个名为ks.cfg的文件。如果在安装过程中（不只局限于生成Kickstart安装文件的机器）出现要填写参数的情况，安装程序首先会去查找Kickstart生成的文件，如果找到合适的参数，就采用所找到的参数；如果没有找到合适的参数，便需要安装者手工干预了。所以，如果Kickstart文件涵盖了安装过程中可能出现的所有需要填写的参数，那么安装者完全可以只告诉安装程序从何处取ks.cfg文件，然后就去忙自己的事情。等安装完毕，安装程序会根据ks.cfg中的设置重启系统，并结束安装 PXE+Kickstart无人值守安装操作系统完整过程如下 **PXE Client向DHCP发送请求 **\nPXE Client从自己的PXE网卡启动，通过PXE BootROM(自启动芯片)会以UDP(简单用户数据报协议)发送一个广播请求，向本网络中的DHCP服务器索取IP\nDHCP服务器提供信息\nDHCP服务器收到客户端的请求，验证是否来至合法的PXE Client的请求，验证通过它将给客户端一个提供响应，这个提供响应中包含了为客户端分配的IP地址、pxelinux启动程序(TFTP)位置，以及配置文件所在位置\nPXE客户端请求下载启动文件\n客户端收到服务器的回应后，会回应一个帧，以请求传送启动所需文件。这些启动文件包括：pxelinux.0、pxelinux.cfg/default、vmlinuz、initrd.img等文件\nBoot Server响应客户端请求并传送文件\n当服务器收到客户端的请求后，他们之间之后将有更多的信息在客户端与服务器之间作应答, 用以决定启动参数。BootROM由TFTP通讯协议从Boot Server下载启动安装程序所必须的文件(pxelinux.0、pxelinux.cfg/default)。default文件下载完成后，会根据该文件中定义的引导顺序，启动Linux安装程序的引导内核\n请求下载自动应答文件\n客户端通过pxelinux.cfg/default文件成功的引导Linux安装内核后，安装程序首先必须确定你通过什么安装介质来安装linux，如果是通过网络安装(NFS, FTP, HTTP)，则会在这个时候初始化网络，并定位安装源位置。接着会读取default文件中指定的自动应答文件ks.cfg所在位置，根据该位置请求下载该文件\n客户端安装操作系统\n将ks.cfg文件下载回来后，通过该文件找到OS Server，并按照该文件的配置请求下载安装过程需要的软件包。\nOS Server和客户端建立连接后，将开始传输软件包，客户端将开始安装操作系统。安装完成后，将提示重新引导计算机\n安装 Kickstart的安装方式有多种组合，Kickstart+DHCP+TFTP+HTTP/NFS/FTP等，不管是HTTP、NFS或者FTP，都是为了寻找到系统引导后需要安装的包组等文件。下面的安装方式是Kickstart+DHCP+TFTP+HTTP DHCP安装配置 /etc/dhcp/dhcpd.conf range 10.0.0.100 10.0.0.200; # 可分配的起始IP-结束IP\noption subnet-mask 255.255.255.0; # 设定netmask\ndefault-lease-time 21600; # 设置默认的IP租用期限\nmax-lease-time 43200; # 设置最大的IP租用期限\nnext-server 10.0.0.7; # 告知客户端TFTP服务器的ip\nfilename \"/pxelinux.0\"; # 告知客户端从TFTP根目录下载pxelinux.0文件\n注意：\n如果机器数量过多的话，注意dhcp服务器的地址池，不要因为耗尽IP而导致dhcpd服务器没有IP地址release的情况\n本来软件装完后都要加入开机自启动，但这个Kickstart系统就不能开机自启动，而且用完后服务都要关闭，防止未来重启服务器自动重装系统了\n$ yum -y install dhcp $ vim /etc/dhcp/dhcpd.conf # # DHCP Server Configuration file. # see /usr/share/doc/dhcp*/dhcpd.conf.sample # see 'man 5 dhcpd.conf' # subnet 10.0.0.0 netmask 255.255.255.0 { range 10.0.0.201 10.0.0.210; option subnet-mask 255.255.255.0; default-lease-time 21600; max-lease-time 43200; next-server 10.0.0.61; filename \"/pxelinux.0\"; } \"/etc/dhcp/dhcpd.conf\" 13L, 360C 已写入 $ /etc/init.d/dhcpd start 正在启动 dhcpd： [确定] $ netstat -lntup|grep dhcp udp 0 0 0.0.0.0:67 0.0.0.0:* 2040/dhcpd TFTP安装配置 TFTP服务器提供文件使用简单文件传输协议。TFTP协议通常用于启动无盘工作站，下载配置文件到客户端，并开始对部分操作系统的安装过程 server_args = -s /var/lib/tftpboot # 指定boot启动目录，保持默认 disable = yes # no改为yes $ yum -y install tftp.server $ vim /etc/xinetd.d/tftp # default: off # description: The tftp server serves files using the trivial file transfer \\ # protocol. The tftp protocol is often used to boot diskless \\ # workstations, download configuration files to network-aware printers, \\ # and to start the installation process for some operating systems. service tftp { socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no per_source = 11 cps = 100 2 flags = IPv4 } \"/etc/xinetd.d/tftp\" 18L, 517C 已写入 $ /etc/init.d/xinetd restart 停止 xinetd： [确定] 正在启动 xinetd： [确定] $ netstat -lntup|grep xinetd udp 0 0 0.0.0.0:69 0.0.0.0:* 2066/xinetd HTTP安装配置 ServerName指定Nginx用于识别自身的名字和端口号。通常这个值是自动指定的，但是我们推荐你显式的指定它以防止启动时出错。如果你为你的主机指定了一个无效的DNS名，server-generated重定向将不能工作 $ sed -i \"277i ServerName 127.0.0.1:80\" /etc/httpd/conf/httpd.conf 将CentOS-6.7挂载到http服务下 $ mount /dev/cdrom /var/www/html/CentOS-6.7/ $ cat extra/www.conf server { listen 80; server_name www.ky.com; # 域名设置 autoindex on; # 不找首页文件，展示目录结构 location / { root /var/www/html/; # 显示网页内容的文件目录路径 } } 访问浏览器10.0.0.61/CentOS-6.7/查看配置是否正确\n$ yum -y install httpd $ sed -i \"277i ServerName 127.0.0.1:80\" /etc/httpd/conf/httpd.conf $ /etc/init.d/httpd start 正在启动 httpd： [确定] $ netstat -lntup|grep \"httpd\" tcp 0 0 :::80 :::* LISTEN 2085/httpd $ mkdir /var/www/html/CentOS-6.7 $ mount /dev/cdrom /var/www/html/CentOS-6.7/ mount: block device /dev/sr0 is write-protected, mounting read-only $ df -h Filesystem Size Used Avail Use% Mounted on /dev/sda3 8.8G 1.5G 6.9G 18% / tmpfs 495M 0 495M 0% /dev/shm /dev/sda1 190M 36M 145M 20% /boot /dev/sr0 3.7G 3.7G 0 100% /var/www/html/CentOS-6.7 $ cat nginx.conf worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; \\#include set include extra/www.conf; } $ cat extra/www.conf server { listen 80; server_name www.ky.com; autoindex on; location / { root /var/www/html/; } } $ fuser -k 80/tcp # 杀死因前面开启httpd服务占用80的端口进程，然后就可以开启nginx服务 syslinux配置 syslinux是一个功能强大的引导加载程序，而且兼容各种介质。SYSLINUX是一个小型的Linux操作系统，它的目的是简化首次安装Linux的时间，并建立修护或其它特殊用途的启动盘。如果没有找到pxelinux.0这个文件,可以安装一下 将sysliunx的pxelinux.0文件拷贝到tftp启动目录下 $ cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ 将/var/www/html/CentOS-6.7/isolinux/*下的所有系统引导安装的文件拷贝到tftp启动目录下 $ cp -a /var/www/html/CentOS-6.7/isolinux/* /var/lib/tftpboot/ 将isolinux.cfg文件拷贝到tftp启动目录下的pxelinux.cfg目录下并改名为default $ mkdir -p /var/lib/tftpboot/pxelinux.cfg $ cp /var/www/html/CentOS-6.7/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default $ yum -y install syslinux $ cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ $ cp -a /var/www/html/CentOS-6.7/isolinux/* /var/lib/tftpboot/ $ mkdir -p /var/lib/tftpboot/pxelinux.cfg $ cp /var/www/html/CentOS-6.7/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default /var/www/html/CentOS-6.7/isolinux/isolinux.cfg文件详解 $ cat /var/www/html/CentOS-6.7/isolinux/isolinux.cfg default vesamenu.c32 # 默认加载一个菜单 # prompt 1 # 开启会显示命令行'boot: '提示符。prompt值为0时则不提示，将会直接启动'default'参数中指定的内容 timeout 600 # timeout时间是引导时等待用户手动选择的时间，设为1可直接引导，单位为1/10秒 display boot.msg # 菜单背景图片、标题、颜色 menu background splash.jpg menu title Welcome to CentOS 6.7! menu color border 0 #ffffffff #00000000 menu color sel 7 #ffffffff #ff000000 menu color title 0 #ffffffff #00000000 menu color tabmsg 0 #ffffffff #00000000 menu color unsel 0 #ffffffff #00000000 menu color hotsel 0 #ff000000 #ffffffff menu color hotkey 7 #ffffffff #ff000000 menu color scrollbar 0 #ffffffff #00000000 label linux # label指定在boot:提示符下输入的关键字，比如boot:linux[ENTER]，这个会启动label linux下标记的kernel和initrd.img文件 menu label ^Install or upgrade an existing system menu default # 一个标签就是前面图片的一行选项 kernel vmlinuz # 指定要启动的内核。同样要注意路径，默认是/tftpboot目录 append initrd=initrd.img # 指定追加给内核的参数，initrd.img是一个最小的linux系统 label vesa menu label Install system with ^basic video driver kernel vmlinuz append initrd=initrd.img nomodeset label rescue menu label ^Rescue installed system kernel vmlinuz append initrd=initrd.img rescue label local menu label Boot from ^local drive localboot 0xffff label memtest86 menu label ^Memory test kernel memtest append - 编辑default $ cat \u003e/var/lib/tftpboot/pxelinux.cfg/default\u003c\u003c-EOF default ks prompt 0 label ks kernel vmlinuz append initrd=initrd.img ks=http://10.0.0.61/ks_config/CentOS-6.7-ks.cfg ksdevice=eth0 EOF 这个文件就是实现下图这个界面的功能 $ cat \u003e/var/lib/tftpboot/pxelinux.cfg/default\u003c\u003c-EOF default ks prompt 0 label linux kernel vmlinuz append initrd=initrd.img ks=http://10.0.0.61/ks_config/CentOS-6.7-ks.cfg ksdevice=eth0 # 告诉安装程序ks.cfg文件在哪里，ksdevice=eth0代表当客户端有多块网卡的时候，设置从eth0安装 EOF ks.cfg文件 通常，我们在安装操作系统的过程中，需要大量的和服务器交互操作，为了减少这个交互过程，kickstart就诞生了。使用这种kickstart，只需事先定义好一个Kickstart自动应答配置文件ks.cfg（通常存放在安装服务器上），并让安装程序知道该配置文件的位置，在安装过程中安装程序就可以自己从该文件中读取安装配置，这样就避免了在安装过程中多次的人机交互，从而实现无人值守的自动化安装 生成kickstart配置文件的三种方法： 方法1、 每安装好一台Centos机器，Centos安装程序都会创建一个kickstart配置文件，记录你的真实安装配置。如果你希望实现和某系统类似的安装，可以基于该系统的kickstart配置文件来生成你自己的kickstart配置文件。（生成的文件名字叫anaconda-ks.cfg位于/root/anaconda-ks.cfg） 方法2、Centos提供了一个图形化的kickstart配置工具。在任何一个安装好的Linux系统上运行该工具，就可以很容易地创建你自己的kickstart配置文件。kickstart配置工具命令为redhat-config-kickstart（RHEL3）或system-config-kickstart（RHEL4，RHEL5）.网上有很多用CentOS桌面版生成ks文件的文章，如果有现成的系统就没什么可说。但没有现成的，也没有必要去用桌面版，命令行也很简单 方法3、阅读kickstart配置文件的手册。用任何一个文本编辑器都可以创建你自己的kickstart配置文件 编写ks.cfg文件 $ grub-crypt # 生成一个密码 Password: Retype password: $6$PqVOBDIH4wHJ.JyH$6/xoqOGnm3DnEJyyXgWxCdmscsWrGKbTmMYYE/lgVgzIep999j8z9s7Ci5V5TG16TALy/Grtk6Vh/jj2WLnEn1 $ cat /var/www/html/ks_config/CentOS-6.7-ks.cfg # Kickstart Configurator for CentOS 6.7 by ky install # 告知安装程序，这是一次全新安装，而不是升级upgrade url --url=\"http://10.0.0.61/CentOS-6.7/\" # 指定系统安装的包组等的路径 text # 文本模式安装 lang en_US.UTF-8 # 安装使用的语言 keyboard us # 设置系统键盘类型 zerombr # 清楚mbr引导信息 bootloader --location=mbr --driveorder=sda --append=\"crashkernel=auto rhgb quiet\" # --location=,指定引导记录被写入的位置.有效的值如下:mbr(缺省),partition(在包含内核的分区的第一个扇区安装引导装载程序)或none(不安装引导装载程序；--driveorder,指定在BIOS引导顺序中居首的驱动器；--append=,指定内核参数.要指定多个参数,使用空格分隔它们 network --bootproto=dhcp --device=eth0 --onboot=yes --noipv6 --hostname=CentOS6 # 指定ip地址为dhcp分发，网卡eth0启动，是否在引导时启用该设备，禁用此设备的IPv6安装的系统的主机名 timezone --utc Asia/Shanghai # 设置系统时区 authconfig --enableshadow --passalgo=sha512 # 系统认证信息，设置密码加密方式为sha512 启用shadow文件 rootpw --iscrypted $6$X20eRtuZhkHznTb4$dK0BJByOSAWSDD8jccLVFz0CscijS9ldMWwpoCw/ZE jYw2BTQYGWlgKsn945fFTjRC658UXjuocwJbAjVI5D6/ # root密码 clearpart --all –initlabel # 清空分区 part /boot --fstype=ext4 --asprimary --size=200 part swap --size=800 part / --fstype=ext4 --grow --asprimary --size=200 # --fstype=,为分区设置文件系统类型.有效的类型，--asprimary,强迫把分区分配为主分区,否则提示分区失败，--size=,以MB为单位的分区最小值.在此处指定一个整数值,如500.不要在数字后面加MB firstboot –disable # 负责协助配置redhat一些重要的信息 selinux --disabled firewall –disabled # 关闭selinux、防火墙 logging --level=info # 设置日志级别 reboot # 设定安装完成后重启,此选项必须存在，不然kickstart显示一条消息，并等待用户按任意键后才重新引导，也可以选择halt关机 %packages @base @compat-libraries @debugging @development # 要安装的包组 tree nmap sysstat lrzsz telnet # 要安装的软件 %end 无人值守安装系统 新建一个虚拟机加电，即可开始无人值守安装linux系统 Rpm打包 Yum仓库 ",
    "description": "KICKSTART无人值守 指令作用介绍 pxe\nPXE使用DHCP（动态主机配置协议）和TFTP（普通文件传送协议）从网络上查找并装载引导程序。PXE环境从NIC（Network Interface Card）上的BIOS装载。预引导服务使用PXE来发现设备是否存在为其指定的预引导服务工作，并向设备提供执行指派工作所需的文件。通过使用预引导服务，可以自动将映像放置到设备上，即使设备的硬盘为空\npxelinux.0\n主要作用是装载执行指派的预引导工作所需的操作系统。pxelinux.0文件是syslinux这一开放源代码项目的一部分的改进版本。虽然pxelinux.0主要是Linux加载器，但它也可以装载其他操作系统。它的工作方式是使用位于TFTP服务器上的配置文件来提供引导指令\nvmlinuz\nvmlinuz是Linux内核的镜像文件,可以被引导程序加载,从而启动Linux系统",
    "tags": [],
    "title": "Install_Kickstart",
    "uri": "/systems/linux/install_system/install_kickstart/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e HAProxy",
    "content": "安装HAProxy 名称地址 描述 HAProxy官网 haproxy、nginx、proxy protocol获得客户真实IP方法 负载均衡\nHAProxy可以将入站请求分发到多个后端服务器，实现负载均衡。它支持多种负载均衡算法，如轮询round-robin、最小连接数leastconn、源IP哈希source、权重等\n高可用性\nHAProxy支持健康检查health checks，可以定期检查后端服务器的状态，并根据检查结果动态调整负载均衡策略。当后端服务器出现故障或不可用时，HAProxy可以自动将流量转移到健康的服务器上，从而提高系统的可用性\nSSL/TLS 终端\nHAProxy可以作为SSL/TLS的终端Termination，负责处理和管理传入和传出的加密流量。它支持SSL握手和证书管理，可以提供安全的HTTPS服务\n反向代理\nHAProxy作为反向代理reverse proxy，可以隐藏后端服务器的实际IP地址和细节，提供更安全的服务访问接口。客户端请求首先到达HAProxy，再由HAProxy转发到后端服务器\nTCP和HTTP支持\nHAProxy不仅支持HTTP和HTTPS流量的负载均衡，还可以负责TCP流量的负载均衡。这使得它非常适合于支持Web应用程序、API和其他网络服务的高性能和高可用性部署\n灵活配置和动态更新\nHAProxy的配置文件支持灵活的配置选项，可以根据需要调整负载均衡策略和参数。此外，HAProxy支持动态更新配置，可以在运行时重新加载配置文件，无需重启服务即可生效\n安装配置HAProxy $ yum install -y haproxy 举例：监控Rabbit消息队列服务配置 $ cat \u003e/etc/haproxy/haproxy.cfg\u003c\u003c-EOF global # log /yougo/haproxy/home/log local0 # log /yougo/haproxy/home/log local1 notice # chroot /yougo/haproxy # 改变当前工作目录 # stats socket /yougo/haproxy/home/admin.sock mode 660 level admin # 创建监控所用的套接字目录 pidfile /var/run/haproxy.pid # haproxy的pid存放路径,启动进程的用户必须有权限访问此文件 maxconn 4000 # 最大连接数，默认4000 # user haproxy # 默认用户 # group haproxy # 默认用户组 daemon # 创建1个进程进入deamon模式运行。此参数要求将运行模式设置为\"daemon # Default SSL material locations # ca-base /etc/ssl/certs # crt-base /etc/ssl/private # Default ciphers to use on SSL-enabled listening sockets. # For more information, see ciphers(1SSL). This list is from: # https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ # ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS # ssl-default-bind-options no-sslv3 ###########默认配置######### defaults log global mode http # 默认的模式mode { tcp|http|health }，tcp是4层，http是7层，health只会返回OK option httplog # 采用http日志格式 option dontlognull # 启用该项，日志中将不会记录空连接。所谓空连接就是在上游的负载均衡器或者监控系统为了探测该服务是否存活可用时,需要定期的连接或者获取某一固定的组件或页面,或者探测扫描端口是否在监听或开放等动作被称为空连接;官方文档中标注，如果该服务上游没有其他的负载均衡器的话，建议不要使用该参数，因为互联网上的恶意扫描或其他动作就不会被记录下来 timeout connect 5000 # 连接超时时间 timeout client 50000 # 客户端连接超时时间 timeout server 50000 # 服务器端连接超时时间 option httpclose # 每次请求完毕后主动关闭http通道 option httplog # 日志类别http日志格式 #option forwardfor # 如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip option redispatch # serverId对应的服务器挂掉后,强制定向到其他健康的服务器 timeout connect 10000 # default 10 second timeout if a backend is not found maxconn 60000 # 最大连接数 retries 3 # 3次连接失败就认为服务不可用，也可以通过后面设置 # errorfile 400 /yougo/haproxy/home/errors/400.http # errorfile 403 /yougo/haproxy/home/errors/403.http # errorfile 408 /yougo/haproxy/home/errors/408.http # errorfile 500 /yougo/haproxy/home/errors/500.http # errorfile 502 /yougo/haproxy/home/errors/502.http # errorfile 503 /yougo/haproxy/home/errors/503.http # errorfile 504 /yougo/haproxy/home/errors/504.http ################################################ listen http_front bind 0.0.0.0:8888 # HAProxy 服务端口 stats refresh 30s # 统计页面自动刷新时间 stats uri /haproxy?stats # 统计页面url stats realm Haproxy Manager # 统计页面密码框上提示文本 stats auth admin:admin # 统计页面用户名和密码设置 #stats hide-version # 隐藏统计页面上HAProxy的版本信息 ########## RabbitMQ的管理界面也放在HAProxy后面了 ################ #listen rabbitmq_admin # bind 0.0.0.0:8004 # server node1 192.168.0.31:15672 # server node2 192.168.0.32:15672 # server node3 192.168.0.33:15672 ################################################# listen rabbitmq_cluster bind 0.0.0.0:8889 # rabbitmq集群调用的端口 option tcplog mode tcp timeout client 3h timeout server 3h option clitcpka balance roundrobin # 负载均衡算法（#banlance roundrobin 轮询，balance source 保存session值，支持static-rr，leastconn，first，uri等参数） # balance url_param userid # balance url_param session_id check_post 64 # balance hdr(User-Agent) # balance hdr(host) # balance hdr(Host) use_domain_only # balance rdp-cookie # balance leastconn # balance source //ip server rabbitmq1 172.16.0.30:5672 check inter 5s rise 2 fall 3 # check inter 2000 是检测心跳频率，rise 2是2次正确认为服务器可用，fall 3是3次失败认为服务器不可用 server rabbitmq2 172.16.0.31:5672 check inter 5s rise 2 fall 3 server rabbitmq3 172.16.0.32:5672 check inter 5s rise 2 fall 3 EOF 启动HAProxy $ systemctl enable haproxy \u0026\u0026 systemctl start haproxy ",
    "description": "安装HAProxy 名称地址 描述 HAProxy官网 haproxy、nginx、proxy protocol获得客户真实IP方法 负载均衡\nHAProxy可以将入站请求分发到多个后端服务器，实现负载均衡。它支持多种负载均衡算法，如轮询round-robin、最小连接数leastconn、源IP哈希source、权重等\n高可用性\nHAProxy支持健康检查health checks，可以定期检查后端服务器的状态，并根据检查结果动态调整负载均衡策略。当后端服务器出现故障或不可用时，HAProxy可以自动将流量转移到健康的服务器上，从而提高系统的可用性",
    "tags": [],
    "title": "Install_HAProxy",
    "uri": "/systems/linux/haproxy/install_haproxy/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "登录安装好的gitlab配置git-runner 获取注册使用的token 注册git-runner到安装好的gitlab仓库 2.1 命令行执行命令 url：私有gitlab的路径 token：项目的token，用于关联runner和项目 name：runner的名字，用于区分runner tags：用于匹配任务jobs和执行任务的设备runners executor：执行环境 $ gitlab-ci-multi-runner register # 执行注册命令， 然后输入gitlab浏览器地址、token Enter the GitLab instance URL (for example, https://gitlab.com/): http://192.168.35.130 # gitlab地址 Enter the registration token: LBsW7DfZdJN87yUAMVVh # gitlab查看到的token Enter a description for the runner: [node-2-35.130]: node-2-35.130 # 最好是本机的hostname、也可以为空 Enter tags for the runner (comma-separated): # 在什么情况下触发，可以直接回车，后面在注册好的git-runner的Tags中添加，.gitlab-ci.yml文件中引用此tags Enter optional maintenance note for the runner: # 没明白什么意思直接回车 Registering runner... succeeded runner=LBsW7DfZ Enter an executor: docker+machine, docker, shell, parallels, ssh, virtualbox, docker-ssh+machine, kubernetes, custom, docker-ssh: shell # 选择使用执行器yum，rpm安装一般选择shell环境 Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 配置gitlab-runner用户环境变量 执行完成后gitlab-runner会自动修改/etc/gitlab-runner/config.toml文件，并重载daemon程序 $ su - gitlab-runner $ cp /etc/skel/.bashrc . # 拷贝环境变量到当前用户家目录 $ cp /etc/skel/.bash_profile . # 拷贝环境变量到当前用户家目录 $ cat /etc/gitlab-runner/config.toml # 存放gitlab-runner配置的文件，可以有多个runner concurrent = 1 check_interval = 0 [session_server] session_timeout = 1800 [[runners]] name = \"node-2-runner-1\" url = \"http://192.168.35.130\" token = \"7Ganz-WjwqVwbiwuyPMu\" executor = \"shell\" shell = \"bash\" [runners.custom_build_dir] [runners.cache] [runners.cache.s3] [runners.cache.gcs] [runners.cache.azure] runner配置模板 listen_address = \"[::]:8090\" concurrent = 16 check_interval = 1 [session_server] listen_address = \"[::]:8093\" advertise_address = \"\u003cip_or_domain\u003e:8093\" session_timeout = 1800 [[runners]] name = \"runner0\" limit = 8 url = \"https://gitlab.example.com/\" token = \"sKj-SjZAxxxxxxxxxxxx\" executor = \"shell\" shell = \"bash\" [[runners]] name = \"runner1\" url = \"https://gitlab.example.com/\" token = \"z9y9YKkYxxxxxxxxxxxx\" executor = \"shell\" shell = \"bash\" [[runners]] name = \"runner2\" url = \"https://gitlab.example.com/\" token = \"wPKY9ovsxxxxxxxxxxxx\" executor = \"shell\" shell = \"bash\" 新建一个测试代码库New Project ",
    "description": "登录安装好的gitlab配置git-runner 获取注册使用的token 注册git-runner到安装好的gitlab仓库 2.1 命令行执行命令 url：私有gitlab的路径 token：项目的token，用于关联runner和项目 name：runner的名字，用于区分runner tags：用于匹配任务jobs和执行任务的设备runners executor：执行环境 $ gitlab-ci-multi-runner register # 执行注册命令， 然后输入gitlab浏览器地址、token Enter the GitLab instance URL (for example, https://gitlab.",
    "tags": [],
    "title": "Use_Gitrunner",
    "uri": "/systems/linux/gitlab/use_gitrunner/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "修改gitlab配置文件 GitLab → 搭建中常遇的问题与日常维护 $ cat \u003e/etc/gitlab/gitlab.rb\u003c\u003c-EOF # 修改gitlab默认端口 external_url 'http://185.167.13.45:12580' # 修改链接地址，在32行左右 unicorn['port'] = '9092' # 修改默认端口，在 995行左右，新版本改为：puma['port'] EOF 处理gitlab报错 gitlab runner 500错误解决 $ docker exec -it gitlab cat /var/log/gitlab/gitlab-rails/production.log $ gitlab-rails console -------------------------------------------------------------------------------- Ruby: ruby 2.7.5p203 (2021-11-24 revision f69aeb8314) [x86_64-linux] GitLab: 14.4.4 (838dea1cf23) FOSS GitLab Shell: 13.21.1 PostgreSQL: 12.7 -------------------------------------------------------------------------------- Loading production environment (Rails 6.1.4.1) irb(main):001:0\u003e ApplicationSetting.current.reset_runners_registration_token! =\u003e true irb(main):002:0\u003e exit $ gitlab-rails dbconsole -- Clear project tokens(清除项目令牌) UPDATE projects SET runners_token = null, runners_token_encrypted = null; -- Clear group tokens(清除组令牌) UPDATE namespaces SET runners_token = null, runners_token_encrypted = null; -- Clear instance tokens(清除实例令牌) UPDATE application_settings SET runners_registration_token_encrypted = null; -- Clear key used for JWT authentication(用于 JWT 身份验证的清除密钥) -- This may break the $CI_JWT_TOKEN job variable: -- https://gitlab.com/gitlab-org/gitlab/-/issues/325965 UPDATE application_settings SET encrypted_ci_jwt_signing_key = null; -- Clear runner tokens(清除跑步者令牌) UPDATE ci_runners SET token = null, token_encrypted = null; 处理502报错 修改配置文件 $ vim /etc/gitlab/gitlab.rb # 修改gitlab默认端口 # 报错502,下列取消注释 # unicorn['port'] = 8088 # postgresql['shared_buffers'] = \"256MB\" # postgresql['max_connections'] = 200 然后重启gitlab以及做初始化 $ gitlab-ctl reconfigure # 初始化gitlab $ gitlab-ctl restart gitlab 403 forbidden报错解决 gitlab稳定运行有一年多了，今天研发部小伙伴跑来说，他的gitlab访问不了，不一会，还有几位小伙伴也一样的反馈查看他们的报错，为403 forbidden奇怪的是，我访问是正常的 排查过程 首先上服务器，查看各服务均正常gitlab-ctl logs查看日志，发现有一个IP 172.17.2.254访问被拒绝，而这个IP，是无线网段的网关。瞬间明白了，不能用的全是用无线上网的同学，只要是经过2.254的都不能用继续查看日志，有个xiaoxiao用户，有过几次登陆失败，之后就全都是forbidden看来gitlab是有防爆破机制，查看配置文档gitlab.yml，果然有rack_attack的配置，如图： 解决方法，进入redis，删除被墙的IP地址即可以，命令如下： $ /opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket keys '*' | grep 'rack::attack' | xargs /opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket DEL (integer) 1 # 执行这命令 使用无线连接gitlab的电脑恢复正常。 postfix启动报错 修改/etc/postfix/main.cf中：#myhostname = host.domain.tld 其中：host.domain.tld必须是：xxx.xxxx.xxx gitlab8.0版本汉化 安装扩展插件以及下载汉化版本库 $ yum -y install patch git # git clone https://gitlab.com/xhang/gitlab.git # 汉化版本库 # git diff v10.0.2 v10.0.2-zh \u003e ../10.0.2-zh.diff # 版本对比 $ git clone https://gitlab.com/larryli/gitlab.git 配置汉化文件 $ cd gitlab $ git diff origin/8-0-stable..origin/8-0-zh \u003e patch.diff # 生成:patch.diff文件 $ patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 \u003c /tmp/patch.diff # 把:patch.diff文件安装到gitlab安装目录下 重启gitlab以及做初始化 $ gitlab-ctl reconfigure $ gitlab-ctl restart # 重启gitlab 在打包补丁patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 \u003c …/v10.8.4-zh.diff 后可能会出来该情况，一路回车跳过即可\n修改gitlab管理员密码的三种方式 方法一，使用id irb(main):001:0\u003e user = User.where(id:[user's register index]).first 方法二，使用邮箱 irb(main):001:0\u003e user = User.where(email:[user's register email]).first 方法三，使用用户名 irb(main):001:0\u003e user = User.where(name:[user's register name]).first 执行命令进入控制台：gitlab-rails console production，如果报错执行：gitlab-rails console -e production $ gitlab-rails console -e production -------------------------------------------------------------------------------- GitLab: 12.8.6 (5fc76a64537) FOSS GitLab Shell: 11.0.0 PostgreSQL: 10.12 -------------------------------------------------------------------------------- Loading production environment (Rails 6.0.2) irb(main):001:0\u003e user = User.where(id: 1).first =\u003e #\u003cUser id:1 @root\u003e irb(main):002:0\u003e user.password = '12345678' =\u003e \"12345678\" irb(main):003:0\u003e user.password_confirmation = '12345678' =\u003e \"12345678\" irb(main):004:0\u003e user.save! Enqueued ActionMailer::DeliveryJob (Job ID: b6aca58a-cfde-4890-aa22-a8f491290c96) to Sidekiq(mailers) with arguments: \"DeviseMailer\", \"password_change\", \"deliver_now\", #\u003cGlobalID:0x00007f79cb5f5298 @uri=#\u003cURI::GID gid://gitlab/User/1\u003e\u003e =\u003e true irb(main):005:0\u003e exit Gitlab配置邮箱 $ vim /etc/gitlab/gitlab.ra # gitlab_rails['smtp_enable'] = true # gitlab_rails['smtp_address'] = \"smtp.server\" # gitlab_rails['smtp_port'] = 465 # gitlab_rails['smtp_user_name'] = \"smtp user\" # gitlab_rails['smtp_password'] = \"smtp password\" # gitlab_rails['smtp_domain'] = \"example.com\" # gitlab_rails['smtp_authentication'] = \"login\" # gitlab_rails['smtp_enable_starttls_auto'] = true # gitlab_rails['smtp_tls'] = false Gitlab版本升级 地址 描述 Gitlab升级 升级博客 Gitlab版本升级 升级博客 $ curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash $ yum install -y gitlab-ce-9.5.10 $ yum install -y gitlab-ce-10.8.7 $ yum install -y gitlab-ce-11.11.8 $ yum install -y gitlab-ce-12.0.12 $ yum install -y gitlab-ce-12.1.17 $ yum install -y gitlab-ce-12.10.14 $ yum install -y gitlab-ce-13.0.14 $ yum install -y gitlab-ce-13.1.11 $ yum install -y gitlab-ce-13.8.8 $ yum install -y gitlab-ce-13.12.15 $ yum install -y gitlab-ce-14.0.12 $ yum install -y gitlab-ce-14.1.1 # 14.1.1为过度必须版本 $ yum install -y gitlab-ce-14.2.1 # 14.2.1为过度必须版本 $ yum install -y gitlab-ce-14.3.6 $ yum install -y gitlab-ce-14.9.5 $ yum install -y gitlab-ce-14.10.Z $ yum install -y gitlab-ce-15.0.Z $ yum install -y gitlab-ce-15.1.Z $ yum install -y gitlab-ce-15.4.0 Gitlab备份还原 地址 描述 Gitlab备份还原 备份还原博客 创建备份，创建后会在：/var/opt/gitlab/backups/目录下生成备份文件 $ gitlab-rake gitlab:backup:create 备份还原前先停止相关服务 $ gitlab-ctl stop unicorn # docker exec -it gitlab gitlab-ctl stop unicorn $ gitlab-ctl stop sidekiq # docker exec -it gitlab gitlab-ctl stop sidekiq 从默认备份恢复，以及backups目录下有多个备份文件时，指定时间戳恢复 $ gitlab-rake gitlab:backup:restore BACKUP=1500809139 # 从默认备份恢复（backups目录下只有一个备份文件时） $ gitlab-rake gitlab:backup:restore # docker exec -it gitlab gitlab-rake gitlab:backup:restore 确认：gitlab-secrets.json文件是否有做备份，如果忘记做备份需要做清空处理 $ gitlab-rails dbconsole $ gitlab-psql -d gitlabhq_production # 等待几分钟，会进入交互界面，进入后输入如下命令 $ SELECT * FROM public.\"ci_group_variables\"; $ SELECT * FROM public.\"ci_variables\"; $ DELETE FROM ci_group_variables; $ DELETE FROM ci_variables; $ UPDATE projects SET runners_token = null, runners_token_encrypted = null; $ UPDATE namespaces SET runners_token = null, runners_token_encrypted = null; $ UPDATE application_settings SET runners_registration_token_encrypted = null; $ UPDATE application_settings SET encrypted_ci_jwt_signing_key = null; $ UPDATE ci_runners SET token = null, token_encrypted = null; $ UPDATE ci_builds SET token = null, token_encrypted = null; $ TRUNCATE web_hooks CASCADE; 还原后启动Gitlab $ gitlab-ctl start # docker exec -it gitlab gitlab-ctl start $ gitlab-ctl reconfigure # docker exec -it gitlab gitlab-ctl reconfigure Gitlab恢复数据报错解决方法 地址 描述 Gitlab恢复数据报错解决方法 博客地址 修改postgresql配置 $ vim /var/opt/gitlab/postgresql/data/postgresql.conf listen_addresses = '*' # 中添加*符号 # 最下面新增两行 $ vim /var/opt/gitlab/postgresql/data/pg_hba.conf local all all trust host all all 127.0.0.1/32 trust $ gitlab-ctl restart 修改gitlab账号为超级用户 $ su - gitlab-psql Last login: Fri Dec 24 17:35:01 CST 2021 on pts/0 -sh-4.2$ /opt/gitlab/embedded/bin/psql -h 127.0.0.1 gitlabhq_production psql (12.7) SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off) Type \"help\" for help. gitlabhq_production=# ALTER USER gitlab WITH SUPERUSER; ALTER ROLE gitlabhq_production=# \\q 配置Gitlab的Nginx映射以及白名单 Gitlab白名单 $ cat \u003e/opt/gitlab/gitlab.rb\u003c\u003c-EOF gitlab_rails['rack_attack_git_basic_auth'] = { # 670 行左右 #'enabled' =\u003e true, 'enabled' =\u003e false, 'ip_whitelist' =\u003e [\"IP\",\"127.0.0.1\"], 'maxretry' =\u003e 10, 'findtime' =\u003e 60, 'bantime' =\u003e 86400 EOF 修改展示Gitlab UI端的SSH端口 $ cat \u003e/opt/gitlab/gitlab.rb\u003c\u003c-EOF gitlab_rails['gitlab_shell_ssh_port'] = 18082 # 651 行左右， EOF ",
    "description": "修改gitlab配置文件 GitLab → 搭建中常遇的问题与日常维护 $ cat \u003e/etc/gitlab/gitlab.rb\u003c\u003c-EOF # 修改gitlab默认端口 external_url 'http://185.",
    "tags": [],
    "title": "Use_Gitlab",
    "uri": "/systems/linux/gitlab/use_gitlab/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "git命令 地址 描述 Git官网 Git命令工具下载地址 Git: submodule子模块简明教程 初始配置、获取仓库 配置环境提交所用账户以及邮箱\n$ git config --global user.name \"name\" $ git config --global user.emamil \"name@gmail.com\" $ git config --global core.sshCommand \"ssh -i ~/.ssh/id_rsa\" # 配置密钥 克隆现有远程代码到本地开发\n$ git clone https://github.com/zabbix/zabbix.git $ git clone --recursive git@github.com:username/service.git # 克隆带有子模块仓库 # 删除子模块 $ vim .gitmodules # 删除文件内子模块配置 $ vim .git/config # 删除文件内子模块配置 $ rm -rf .git/module/* # 删除子模块下目录文件 本地创建仓库\n$ git init # 初始化git本地仓库，初始化后在本地生成一个.git目录 $ git add . # 把修改或者添加文件到索引中：-A：参数代表所有 $ git commit -m \"清除缓存\" # 声明本次修改或添加内容并且交到本地仓库 拉取推送仓库\n$ git pull -u origin master # 拉取master分支到本地-f:强制拉取， $ git push -u origin master # 推送master分支到远程 提交时转换为LF检出时不转换\n$ git config --global core.autocrlf input 切换、查看、合并分支\n$ git fetch # 查看线上分支,--all:查看线上所有分支 $ git branch -a # -a：查看本地当前分支、dev：创建dev分支、-d：删除分支、-D：强制删除 $ git checkout dev # 切换分支，dev：切换到dev分支 $ git checkout . # 放弃本地所有修改 $ git merge -m '合并dev分支到master' dev # 先切换到master分支 # 查看当前版分支 $ git rev-parse --abbrev-ref HEAD $ git name-rev --name-only HEAD $ git branch --show-current # 此方式需要git 2.22版本或者以上 回退版本\n$ git reset --hard # 回退版本、可选择版本分支号回退 $ git reset --hard HEAD~3 # 解决代码冲突 $ git rm -r --cached . # 清楚本地缓存 1.8 查看git仓库状态以及日志\n$ git status # 命令查看当前git仓库的状态 $ git log -5 # 查看最近五次日志，v2.5.. Makefile fs/:找出所有从\"v2.5\"开始在fs目录下的所有Makefile的修改 $ git log --stat # 显示在每个提交(commit)中哪些文件被修改, 这些文件分别添加或删除多少行内容 $ git diff --cached # diff比较选项再加上 --cached参数，看看缓存区中哪些文件被修改 $ git diff --name-only --diff-filter=ACMRT old_commit new_commit $ git diff ${current_id} ${commit_id} --name-only | grep dist_prod $ git rev-parse HEAD # 获取当前版本commit id，参数： --short $ git rev-list HEAD -2 # 查看历史commit id，-2：代表查看最近几次 $ git log --pretty=oneline # 格式化日志输出。--pretty参数可以使用若干表现格式， # 如oneline，--pretty=short， # 也可用medium,full,fuller,email 或 raw， # 也可以用--pretty=format参数定义格式， $ git log --graph --pretty=oneline # --graph 选项， # 可以可视化你的提交图(commit graph)， # 会用ASCII字符来画出一个很漂亮的提交历史(commit history)线： $ git log --pretty=%s 3ff4f298f7a13ab0150e369f4bbcf43a553c05a5 -1 # 获取变更文件注释信息 # 测试网络 git ssh $ ssh -T git.gitlab.com 缓存保存命令git-stash用法小结\n$ git stash save \"test-cmd-stash\" $ git stash pop 处理git文件过大 解决git提交次数过多导致文件过大 运行 gc ，生成 pack 文件（后面的 --prune=now 表示对之前的所有提交做修剪，有的时候仅仅 gc 一下.git 文件就会小很多） $ git gc --prune=now 找出最大的三个文件 $ git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -3 # 示例输出： # 1debc758cf31a649c2fc5b0c59ea1b7f01416636 blob 4925660 3655422 14351 # c43a8da9476f97e84b52e0b34034f8c2d93b4d90 blob 154188651 152549294 12546842 # 2272096493d061489349e0a312df00dcd0ec19a2 blob 155414465 153754005 165096136 查看那些大文件究竟是谁（c43a8da 是上面大文件的hash码） $ git rev-list --objects --all | grep c43a8da # c43a8da9476f97e84b52e0b34034f8c2d93b4d90 data/bigfile 移除对该文件的引用（也就是 data/bigfile） $ git filter-branch --force --index-filter \"git rm --cached --ignore-unmatch 'data/bigfile'\" --prune-empty --tag-name-filter cat -- --all 进行 repack $ git for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin $ git reflog expire --expire=now --all $ git gc --prune=now 查看 pack 的空间使用情况 $ git count-objects -v LFS功能压缩大文件 开启LFS功能 $ git lfs install 设置LFS要管理的文件类型pth、mmdb、pack、idx $ git lfs track \"*.pth\" 报LFS错，在执行上面的最后一步上传命令的时候可能会报两个错误 第一个错误：WARNING: Authentication error: Authentication required: LFS only supported repository in paid enterprise.。可以执行以下命令, 命令中的{your_gitee}/{your_repo}是你的远程仓库地址,根据自己情况替换 $ git config lfs.https://gitee.com/{ your_gitee}/{ your_repo}.git/info/lfs.locksverify false 第二个错误：batch response: LFS only supported repository in paid enterprise. 。可以尝试删除./git/hooks/pre-push文件,最后重新push一下即可 git获取仓库指定目录或文件 此功能只在1.7.0以上版本提供 $ mkdir test \u0026\u0026 cd test $ git init $ git remote add origin https://xxxx.com/xxx.git $ git config core.sparsecheckout true # 使用Sparse checkout模式 $ echo \"redis-conf/*\" \u003e\u003e .git/info/sparse-checkout # 将检出的目录或文件使用文件追加的形式写入到git的配置.git/info/sparse-checkout文件中，允许添加多行 $ git pull origin master # 获取到需要的文件或目录 $ git checkout # 在对配置文件.git/info/sparse-checkout的内容进行增、删、改操作之后，使用下面的命令重新修正目录和文件 $ git push origin master ",
    "description": "git命令 地址 描述 Git官网 Git命令工具下载地址 Git: submodule子模块简明教程 初始配置、获取仓库 配置环境提交所用账户以及邮箱\n$ git config --global user.",
    "tags": [],
    "title": "Use_Git_Command",
    "uri": "/systems/linux/gitlab/use_git_command/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "Gogs Gogs官网 ",
    "description": "Gogs Gogs官网 ",
    "tags": [],
    "title": "Install_Gogs",
    "uri": "/systems/linux/gitlab/install_gogs/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "gitlab简介以及安装 gitlab安装包库 Gitea GitLab是管理Git存储库的平台。 GitLab提供免费的公共和私人存储库，问题跟踪和维基。 GitLab是Git之上的一个用户友好的Web界面层，它提高了使用Git的速度。 GitLab提供了自己的持续集成CI系统来管理项目，并提供用户界面以及GitLab的其他功能。 cat /etc/gitlab/initial_root_password | grep Password 获取初始密码 安装前准备 安装扩展插件 $ yum install -y make telnet inotify-tools tree rdate ntp gcc gcc-c++ psmisc net-tools screen expect sysstat hdparm traceroute zip unzip pcre pcre-devel zlib zlib-devel openssl openssl-devel tcping libaio dig epel-release wget git $ yum -y install lsof zeromq-devel policycoreutils openssh-server openssh-clients policycoreutils-python postfix perl patch cronie 启动postfix并设置开机自启，gitlab需要postfix $ systemctl enable postfix \u0026\u0026 systemctl start postfix yum按照Gitlab 安装Gitlab 配置gitlab yum仓库，安装Gitlabyum安装Gitlab $ curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash $ yum list gitlab-ce* # 列出要安装的版本 $ yum install gitlab-ce-14.9.3-ce.0.el7.x86_64 # 安装指定版本 rpm包安装gitlab $ wget --content-disposition https://packages.gitlab.com/gitlab/gitlab-ce/packages/el/7/gitlab-ce-14.9.3-ce.0.el7.x86_64.rpm/download.rpm $ rpm gitlab-ce-14.9.3-ce.0.el7.x86_64.rpm 初始化启动Gitlab $ gitlab-ctl reconfigure # 初始化gitlab $ gitlab-ctl restart # 重启完成 防火墙放行端口 $ firewall-cmd --permanent --add-service={http,https} $ firewall-cmd --reload docker安装gitlab Docker命令启动Gitlab $ mkdir -p /opt/gitlab/{config,logs,data} $ docker run --detach \\ --publish 18081:80 --publish 18083:443 --publish 18082:22 \\ --name gitlab \\ --restart always \\ --volume /opt/gitlab/config:/etc/gitlab \\ --volume /opt/gitlab/logs:/var/log/gitlab \\ --volume /opt/gitlab/data:/var/opt/gitlab \\ --env GITLAB_OMNIBUS_CONFIG=\"external_url 'https://gitlab.example.com/';\" \\ gitlab/gitlab-ce:10.0.0-ce.0 docker-compose启动Gitlab $ mkdir -p /opt/gitlab/{config,logs,data} $ cat \u003e/opt/docker-compose/gitlab/docker-compose.yaml\u003c\u003c-EOF version: \"3\" services: gitlab: container_name: gitlab # 启动后名称 image: 'gitlab/gitlab-ce:10.0.0-ce.0' # image: 'gitlab/gitlab-ce:10.8.7-ce.0' # image: 'gitlab/gitlab-ce:11.11.8-ce.0' # image: 'gitlab/gitlab-ce:12.0.12-ce.0' # image: 'gitlab/gitlab-ce:12.1.17-ce.0' # image: 'gitlab/gitlab-ce:12.10.14-ce.0' # image: 'gitlab/gitlab-ce:13.0.14-ce.0' # image: 'gitlab/gitlab-ce:13.1.11-ce.0' # image: 'gitlab/gitlab-ce:13.8.8-ce.0' # image: 'gitlab/gitlab-ce:13.12.15-ce.0' # image: 'gitlab/gitlab-ce:14.0.12-ce.0' # image: 'gitlab/gitlab-ce:14.1.1-ce.0' # 14.1.1为过度必须版本 # image: 'gitlab/gitlab-ce:14.2.1-ce.0' # 14.2.1为过度必须版本 # image: 'gitlab/gitlab-ce:14.3.6-ce.0' # image: 'gitlab/gitlab-ce:14.9.5-ce.0' # image: 'gitlab/gitlab-ce:14.10.5-ce.0' # image: 'gitlab/gitlab-ce:15.0.2-ce.0' # image: 'gitlab/gitlab-ce:15.1.0-ce.0' restart: always hostname: 'gitlab' environment: TZ: Asia/Shanghai GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.erge.com' gitlab_rails['gitlab_shell_ssh_port'] = 18082 ports: - '18081:80' - '18082:22' - '18083:443' volumes: - '/opt/gitlab/config:/etc/gitlab' - '/opt/gitlab/logs:/var/log/gitlab' - '/opt/gitlab/data:/var/opt/gitlab' EOF $ docker-compose up -d ",
    "description": "gitlab简介以及安装 gitlab安装包库 Gitea GitLab是管理Git存储库的平台。 GitLab提供免费的公共和私人存储库，问题跟踪和维基。 GitLab是Git之上的一个用户友好的Web界面层，它提高了使用Git的速度。 GitLab提供了自己的持续集成CI系统来管理项目，并提供用户界面以及GitLab的其他功能。 cat /etc/gitlab/initial_root_password | grep Password 获取初始密码 安装前准备 安装扩展插件 $ yum install -y make telnet inotify-tools tree rdate ntp gcc gcc-c++ psmisc net-tools screen expect sysstat hdparm traceroute zip unzip pcre pcre-devel zlib zlib-devel openssl openssl-devel tcping libaio dig epel-release wget git $ yum -y install lsof zeromq-devel policycoreutils openssh-server openssh-clients policycoreutils-python postfix perl patch cronie 启动postfix并设置开机自启，gitlab需要postfix $ systemctl enable postfix \u0026\u0026 systemctl start postfix yum按照Gitlab 安装Gitlab 配置gitlab yum仓库，安装Gitlabyum安装Gitlab $ curl -s https://packages.",
    "tags": [],
    "title": "Install_Gitlab",
    "uri": "/systems/linux/gitlab/install_gitlab/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": "Git Runner git-runner库\ngitlab-runner\nGitlab配置runner\nyum安装git-runner $ curl -s https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash $ yum install gitlab-runner-14.9.1-1.x86_64 rpm安装git-runner $ wget --content-disposition https://packages.gitlab.com/runner/gitlab-runner/packages/el/7/gitlab-runner-14.9.1-1.x86_64.rpm/download.rpm # curl -O https://gitlab-runner-downloads.s3.amazonaws.com/latest/rpm/gitlab-runner_amd64.rpm # rpm -ivh gitlab-runner_amd64.rpm $ rpm -ivh gitlab-runner-14.9.1-1.x86_64.rpm docker安装git-runner $ docker run -d --name gitlab-runner --restart always \\ -v /opt/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest ",
    "description": "Git Runner git-runner库\ngitlab-runner\nGitlab配置runner\nyum安装git-runner $ curl -s https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash $ yum install gitlab-runner-14.",
    "tags": [],
    "title": "Install_Gitlab_Runner",
    "uri": "/systems/linux/gitlab/install_gitlab_runner/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Gitlab",
    "content": " Gitea官网 ",
    "description": " Gitea官网 ",
    "tags": [],
    "title": "Install_Gitea",
    "uri": "/systems/linux/gitlab/install_gitea/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Firewalld",
    "content": "配置防火墙 配置Firewalld防火墙 Linux配置Firewalld防火墙的路由转发 CentOS7下firewall的ipset配置使用详解 CentOS7开启路由转发 常见失败原因：电脑本身没有开启虚拟化支持，需要在重启时进入BIOS里设置 # 临时开启路由转发 $ echo \"1\" \u003e /proc/sys/net/ipv4/ip_forward # 永久开启路由转发 $ echo \"net.ipv4.ip_forward = 1\" \u003e\u003e/etc/sysctl.conf $ sysctl -p # 加载一下 $ sysctl -a |grep \"ip_forward\" # 查看一下 net.ipv4.ip_forward = 1 net.ipv4.ip_forward_use_pmtu = 0 配置Linux的Firewalld 配置Firewalld转发 # 外网卡 $ firewall-cmd --permanent --zone=external --change-interface=eth0 # 内网网卡 $ firewall-cmd --permanent --zone=internal --change-interface=eth1 # IP地址伪装 $ firewall-cmd --zone=external --add-masquerade --permanent $ firewall-cmd --permanent --direct --passthrough ipv4 -t nat POSTROUTING -o eth0# 外网卡 -j MASQUERADE -s 192.168.100.0/24# 内网网段 $ firewall-cmd --reload 配置Firewalld访问规则 $ firewall-cmd --add-service={http,https} --permanent $ firewall-cmd --permanent --new-ipset=ssh_whitelist --type=hash:ip $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='ssh_whitelist port port='22' protocol='tcp' accept\" $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='redis_whitelist' port port='17693-17695' protocol='tcp' accept\" $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='redis_whitelist' port port='27693-27695' protocol='tcp' accept\" # 重新载入配置 $ firewall-cmd --reload \u003e/dev/null $ systemctl status firewalld \u003e/dev/null # 查看已经开放端口 $ firewallport=`firewall-cmd --zone=public --list-ports` 配置Iptables防火墙 Linux的Iptables配置规则 Iptables规则4表 filter(过滤规则表)：控制数据包是否允许进出及转发，可以控制的链路有INPUT、OUTPUT和FORWARD nat(地址转换规则表)：控制数据包中地址转换，可以控制的链路有INPUT、OUTPUT、PREROUTING和POSTROUTING mangle(修改数据标记位规则表)：修改数据包中的原数据，可以控制的链路有INPUT、OUTPUT、FORWARD、PREROUTING和POSTROUTING raw(跟踪数据表规则表)：控制nat表中连接追踪机制的启用状况，可以控制的链路有OUTPUT、PREROUTING Iptables规则5链 INPUT(入站数据过滤链) OUTPUT(出站数据过滤链) FORWARD(转发数据过滤链) PREROUTING(路由前过滤链) POSTROUTING(路由后过滤链) 选项参数 选项/参数 具体作用 -A 在规则链的末尾加入新规则 -D 删除某一条规则 -I 在规则链的头部加入新规则 -F 清空规则链 -L 查看规则链 -R 替换防火墙规则 -Z 清空防火墙数据表统计信息 -P 设置默认策略:iptables -P INPUT (DROP -p 匹配协议，! 表示取反 -s 匹配源地址 --sport 匹配源端口 --sports 匹配源端口 --src-range 匹配目标地址范围 -d 匹配目标地址 --dport 匹配目标端口 --dports 匹配目标端口 --dst-range 匹配目标地址范围 -i 匹配入站网卡接口 -o 匹配出站网卡接口 --limit 四配数据表速率 --mac-cource 匹配源MAC地址 --stste 匹配状态（INVALID、ESTABLISHED、NEW、RELATED) --string 匹配应用层字串 -m comment --comment \"我是注释\" 添加注释 触发规则 触发动作 更能 ACCEPT 允许数据包通过 DROP 丢弃数据包 REJECT 拒绝数据包通过 LOG 将数据包信息记录syslog曰志 DNAT 目标地址转换 SNAT 源地址转换 MASQUERADE 地址欺骗 REDIRECT 重定向 命令选项输入顺序 -t：后面跟4表中的表名 -A/I/D/R：后面跟5链中的链名 -i/o：跟网卡名 -p：协议名：tcp/udp -s：源IP/源子网 $ iptables -t：表名(filter/nat/mangle/raw) -A/I/D/R：规则链名[规则号] -i/o：网卡名 -p：协议名(tcp/udp) -s：源IP/源子网 --sport：源端口 -d：目标IP/目标子网 --dport：目标端口 -j 动作(ACCEPT/DROP/DNAT/SNAT/...) $ service iptables save $ systemctl reload iptables 配置Iptables的INPUT规则 放行端口，如果需要针对IP限制加：-s $ iptables -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT # 开放21端口 $ cat \u003e/etc/sysconfig/iptables\u003c\u003c-EOF -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT EOF 放行多端口，如果需要针对IP限制加：-s $ iptables -A INPUT -p tcp -m multiport --dports 3306,6379 -j ACCEPT $ cat \u003e/etc/sysconfig/iptables\u003c\u003c-EOF -A INPUT -p tcp -m multiport --dports 3306,6379 -j ACCEPT EOF 放行IP网段 $ iptables -A INPUT -s 192.168.0.0/32 -j ACCEPT $ cat \u003e/etc/sysconfig/iptables\u003c\u003c-EOF -A INPUT -s 192.168.0.0/32 -j ACCEPT EOF 配置Iptables转发规则 $ iptables -P FORWARDACCEPT # 缺省允许IP转发 # 利用iptables 实现nat MASQUERADE 共享上网 $ iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE $ iptables -t nat -A PREROUTING -p tcp --dport 6379 -j DNAT --to-destination 目标IP:目标端口 $ iptables -t nat -A POSTROUTING -p tcp -d 目标IP --dport 目标端口 -j SNAT --to-source 源IP # 源IP需和目标IP同一网段 $ cat \u003e\u003c\u003c-EOF -A PREROUTING -p tcp -m tcp --dport 6379 -j DNAT --to-destination 目标IP:目标端口 -A POSTROUTING -p tcp -d 目标IP -m tcp --dport 目标端口 -j SNAT --to-source 源IP EOF # 查看现有转发规则 $ iptables -t nat -L 清除、修改规则 修改规则 # 修改规则,1代表第一行 $ iptables -R INPUT 1 -s IP -p tcp --dport 端口 -j DROP 删除规则 $ iptables -L -n --line-number # 查看规则行号 $ iptables -D INPUT 9 # 按行号删除规则 清除规则 $ iptables -F # 清除所有 $ iptables-t nat -F # 清除nat表所有 Iptables防御规则 阻止Windows蠕虫的攻击 $ iptables -I INPUT -j DROP -p tcp -s 0.0.0.0/0 -m string --algo kmp --string \"cmd.exe\" 防止SYN洪水攻击 $ iptables -A INPUT -p tcp --syn -m limit --limit 5/second -j ACCEPT 添加SECMARK记录 $ iptables -t mangle -A INPUT -p tcp --src 192.168.1.2 --dport 443 -j SECMARK --selctx system_u:object_r:myauth_packet_t # 向从 192.168.1.2:443 以TCP方式发出到本机的包添加MAC安全上下文 system_u:object_r:myauth_packet_t 防CC攻击 $ iptables -L -F -A -D # list flush append delete # 场景一 $ iptables -I INPUT -p tcp --dport 80 -j ACCEPT # 允许 tcp 80 端口 $ iptables -I INPUT -p tcp --dport 10:22 -j ACCEPT # 允许 tcp 10-22 端口 $ iptables -I INPUT -p icmp -j ACCEPT # 允许 icmp $ iptables -A INPUT -j REJECT # 添加一条规则, 不允许所有 # 优化场景一 $ iptables -I INPUT -i lo -j ACCEPT # 允许本机访问 $ iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # 允许访问外网 $ iptables -I INPUT -p tcp --dport 80 -s 10.10.188.233 -j ACCEPT # 只允许固定ip访问80 # 场景二 $ vi /etc/vsftpd/vsftpd.conf # 使用 vsftpd 开启 ftp 主动模式 port_enable=yes connect_from_port_20=YES $ iptables -I INPUT -p tcp --dport 21 -j ACCEPT $ vi /etc/vsftpd/vsftpd.conf # 建议使用 ftp 被动模式 pasv_min_port=50000 pasv_max_port=60000 $ iptables -I INPUT -p tcp --dport 21 -j ACCEPT $ iptables -I INPUT -p tcp --dport 50000:60000 -j ACCEPT # 还可以使用 iptables 模块追踪来自动开发对应的端口 # 场景三 $ iptables -I INPUT -i lo -j ACCEPT # 允许本机访问 $ iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # 允许访问外网 $ iptables -I INPUT -s 10.10.155.0/24 -j ACCEPT # 允许内网访问 $ iptables -I INPUT -p tcp -m multiport --dports 80,1723 -j ACCEPT # 允许端口, 80 -\u003e http, 1723 -\u003e vpn $ iptables -A INPUT -j REJECT # 添加一条规则, 不允许所有 $ iptables-save # 保存设置到配置文件 # 场景四 $ iptables -t nat -L # 查看 nat 配置 $ iptables -t nat -A POST_ROUTING -s 10.10.177.0/24 -j SNAT --to 10.10.188.232 # SNAT $ vi /etc/sysconfig/network # 配置网关 $ iptables -t nat -A POST_ROUTING -d 10.10.188.232 -p tcp --dport 80 -j DNAT --to 10.10.177.232:80 # DNAT #场景五 $ iptables -I INPUT -p tcp --syn --dport 80 -m connlimit --connlimit-above 100 -j REJECT # 限制并发连接访问数 $ iptables -I INPUT -m limit --limit 3/hour --limit-burst 10 -j ACCEPT # limit模块; --limit-burst 默认为5 配置Ipset 使用ipset提高iptables的控制效率 使用ipset提高iptables的控制效率 ipset使用method(方法)\nbitmap：使用固定大小的存储\nhash：使用hash表来存储元素\nlist：使用固定大小的存储\nipset使用datatype(数据类型) ip：使用哈希存储ip主机地址(默认)或网络地址。零值IP地址不能存储在散列中 net：使用集合存储不同大小的IP网络段。前缀大小为零的网络地址不能存储在这种类型的集合中 mac port：使用hash存储IP地址和端口号对。端口号与协议(默认TCP)一起，不能使用零协议号 iface create创建ipset集合、add添加条目 timeout：超时时间，如果设置为0，表示永久生效，超时时间可以通过-exist来进行修改 counters：支持packets包和bytes字节创建集合 comment：备注，注释不能包含任何引号，通常的转义字符()没有任何意义 $ ipset create SetName TypeName # SetName：为自定义名称，TypeName：为method:datatype # 举例说明 $ ipset create mysql hash:ip timeout 3600 $ ipset create php hash:ip,port $ ipset create Nginx hash:net # 添加条目 $ ipset -exist add mysql 127.0.0.1 timeout 7200 $ ipset add php 127.0.0.1,9000 $ ipset add Nginx 127.0.0.0/8 list列出集合、test检查条目 $ ipset list # 列出所有集合 $ ipset list mysql # 列出指定集合 $ ipset test mysql 127.0.0.1 del某条，flush清空集合条目 $ ipset del mysql 127.0.0.1 $ ipset flush Nginx destroy删除集合 $ ipset destroy # 删除所有集合 $ ipset destroy mysql # 删除指定集合 在iptables中使用ipse，只要加上-m set --match-set即可 目的ip使用ipset $ iptables -I INPUT -s 192.168.88.110 -m set --match-set Nginx dst -j DROP 源ip使用ipset $ iptables -I INPUT -m set --match-set Nginx src -d 192.168.88.110 -j DROP 源和目的都使用ipset $ iptables -I INPUT -m set --match-set Nginx src -m set --match-set mysql dst -j DROP 配置hosts.allow和hosts.deny /etc/hosts.allow：文件配置 使用hosts.allow和hosts.deny实现简单的防火墙\nSSH之hosts.allow和hosts.deny文件\n$ cat \u003e/etc/hosts.allow\u003c\u003cEOF # Jenkins sshd:IP:allow # jumpserver sshd:IP:allow # local 网段 sshd:192.168.0.:allow # 内连数据库 sshd:IP:allow nfsd:ALL sshd:all:deny EOF ",
    "description": "配置防火墙 配置Firewalld防火墙 Linux配置Firewalld防火墙的路由转发 CentOS7下firewall的ipset配置使用详解 CentOS7开启路由转发 常见失败原因：电脑本身没有开启虚拟化支持，需要在重启时进入BIOS里设置 # 临时开启路由转发 $ echo \"1\" \u003e /proc/sys/net/ipv4/ip_forward # 永久开启路由转发 $ echo \"net.",
    "tags": [],
    "title": "Use_Firewalld",
    "uri": "/systems/linux/firewalld/use_firewalld/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Email",
    "content": "iReadMail 服务器必须开通端口25 硬件要求内存最少4G 确保服务器中UID/GID没有使用2000、2001、2002 安装dig $ sudo apt-get install dnsutils $ yum install bind-utils 确认服务器是否支持PTR Pointer Records $ dig -x ip地址 $ sudo nslookup set type=PTR ip地址 安装前准备、安装文档 设置主机名 $ sudo hostnamectl set-hostname email_name 添加到hosts $ cat \u003e/etc/hosts\u003c\u003c-EOF 127.0.1.1\temail.domain.com email EOF $ hostname \u0026\u0026 hostname -f # 确认是否修改 下载安装包安装iRedMail服务 $ sudo apt-get install -y gzip dialog # 安装所需安装包 $ wget https://github.com/iredmail/iRedMail/archive/refs/tags/1.6.8.tar.gz $ tar zxvf 1.6.8.tar.gz $ cd /opt/email/iRedMail-1.6.8/ $ sudo bash iRedMail.sh 图形安装提示 欢迎并感谢您的使用 指定存储所有邮箱的位置。默认为/var/vmail/\n是否使用Web服务\n选择安装数据库 设置数据库密码 添加您的第一个邮件域名 创建管理员密码 选择组件 确认选项是否无误， web访问地址以及用户名密码 **Roundcube**网络邮件登录地址 **SOGo**组件 网络后台管理面板**iRedAdmin** **netdata**数据状态监控 用户名：postmaster@domain.com 密码：password 优化配置项 建议您获取SSL证书，以避免在通过HTTPS/IMAPS/POP3/SMTPS访问邮箱时在Web浏览器或邮件客户端中出现烦人的警告消息 禁用iRedMail灰名单 $ cat \u003e/opt/iredapd/settings.py\u003c\u003c-EOF # 必须root 用户 plugins = [\"reject_null_sender\", \"wblist_rdns\", \"reject_sender_login_mismatch\", \"greylisting\", \"throttle\", \"amavisd_wblist\", \"sql_alias_access_policy\", \"sql_ml_access_policy\"] # 删除：greylisting 选项 EOF $ sudo systemctl restart iredapd 解析A记录，解析名为：email， 解析值为：iRedMail服务所在的服务器IP 检测A记录：nslookup email.domain.com # 更换：domain.com为对应域名 添加MX记录，解析名为：@，优先级值为：10，解析值为：email.domain.com 检测MX记录：nslookup -type=mx domain.com 设置SPF记录，选择：TXT，解析名为：@，解析值为：v=spf1 mx ~all 检测SPF记录：nslookup -type=txt domain.com\n设置DKIM记录 查看安装包文件，复制过滤字段下方记录，去掉括号：()，和双引号：\"\"，使其变为一行 $ cat /opt/email/iRedMail-1.6.8/iRedMail.tips | grep -C 8 dkim._domainkey选择：TXT，解析值为：dkim._domainkey，解析值为：v=DKIM1; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5gFOvR/IiKwqxWeVQXSpWppiW/Gezd3Kgt3JlvhZTL2KI+Za4pSKcaQqkNH9aM5dyAZHYHLKkeVoD5tgaHvBZRaoKN8erL2X2xOfRbkLFpiqpHfgPZB0ADssuCHSK+pGgSz3tVUus9sGaXR7WZoWL50McJnfEKM74dYqhwJ+/EcLsabprKaV+C60TaQS8gqnDfOh4B5dE7B5sPEE/kG23qHGYQhYbIU2LDV1BFgjanJkMbZSNhah2OmQPnXPq4MshaQx1Xld8iLSyKna6KV9Tsi+MIiXSdCM2zoRx5wN4X4i//gNX4jHgaQ56RhSkEybGDCS+g+0oQvDE7XOj6vbHQIDAQAB\n检测DKIM记录：nslookup -type=txt dkim._domainkey.domain.com 设置DMARC记录，选择：TXT，解析名为：_dmarc，解析值为：v=DMARC1; p=none; pct=100; rua=mailto:dmarc@domain.com，domain.com换成对应域名 检测DMARC记录：nslookup -type=txt _dmarc.domain.com 添加iRedMail用户 测试iRedMail邮件服务 测试邮件垃圾匹配度 ",
    "description": "iReadMail 服务器必须开通端口25 硬件要求内存最少4G 确保服务器中UID/GID没有使用2000、2001、2002 安装dig $ sudo apt-get install dnsutils $ yum install bind-utils 确认服务器是否支持PTR Pointer Records $ dig -x ip地址 $ sudo nslookup set type=PTR ip地址 安装前准备、安装文档 设置主机名 $ sudo hostnamectl set-hostname email_name 添加到hosts $ cat \u003e/etc/hosts\u003c\u003c-EOF 127.",
    "tags": [],
    "title": "Install_iRedMail",
    "uri": "/systems/linux/email/install_iredmail/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "Mysql 5.7 升级到Mysql 8 下载解压Mysql 8安装包 $ wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -P /usr/local/src/ $ tar -xvf /usr/local/src/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -C /usr/local/src/ $ mv /usr/local/src/mysql-8.0.21-linux-glibc2.12-x86_64 /usr/local/mysql8 修改Mysql的cnf文件 只更改工作目录，不更改 data 数据目录\n$ sed -i \"s#/usr/local/mysql#/usr/local/mysql8#g\" /etc/my.cnf $ sed -i 's/sql_mode/#sql_mode/g' /etc/my.cnf $ sed -i '20i sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION' /etc/my.cnf $ sed -i '20i default_authentication_plugin=mysql_native_password' /etc/my.cnf $ sed -i 's/query_cache_size/#query_cache_size/g' /etc/my.cnf $ sed -i 's/query_cache_limit/#query_cache_limit/g' /etc/my.cnf 备份Mysql数据、目录，停止现有Mysql $ /usr/local/mysql/bin/mysql -uroot -p'password' -S /opt/data/data_16303/mysql.sock -e \"set global innodb_fast_shutdown=0;\" $ mysql -uroot -p'password' -S /opt/data/data_16303/mysql.sock -e \"shutdown;\" $ cp -r /usr/local/mysql/data{,.bak} 启动Mysql 8 $ /usr/local/mysql8/bin/mysqld --defaults-file=/etc/my.cnf --user=mysql \u0026 $ mv /usr/local/mysql /usr/local/src/mysql-5.7-`date +%F`.bak 检查数据库是否升级成功 $ /usr/local/mysql8/bin/mysql -uroo -p'password' -S /tmp/mysql.sock -e \"select version();\" | tail -1` ",
    "description": "Mysql 5.7 升级到Mysql 8 下载解压Mysql 8安装包 $ wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -P /usr/local/src/ $ tar -xvf /usr/local/src/mysql-8.",
    "tags": [],
    "title": "Update_Mysql5 7_To_Mysql8",
    "uri": "/systems/linux/databases/update_mysql5-7_to_mysql8/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "部署Ydb单节点数据库 Ydb使用端口 端口 协议 描述 2135~2136 TCP 用于客户端-集群交互的GRPC 19001~19002 TCP 集群内节点交互互连 8765~8766 TCP 集群监控的HTTP接口 Ydb数据库、Github-Ydb 系统要求Ubuntu 20.04、Debian 11、Fedora34等以上版本系统 $ mkdir -p /opt/{ydb,ydb-cli} $ cd /opt/ydb/ $ curl https://binaries.ydb.tech/local_scripts/install.sh | bash 启动、停止 # 磁盘启动使用，磁盘最少不能低于 80G $ ./start.sh disk # 内存启动，内存启动服务器重启数据丢失 $ ./start.sh ram # 停止 $ ./stop.sh 部署Ydb-cli $ curl -sSL https://storage.yandexcloud.net/yandexcloud-ydb/install.sh | bash $ source /root/.bashrc 使用Ydb-cli查询 $ ydb -e grpc://localhost:2136 -d /Root/test scheme ls $ ydb -e grpc://nodeip:2136 -d /Root/testdb workload stock init # 启动YDB Web页面 $ ydb -e grpc://nodeip:2136 -d /Root/testdb workload stock run add-rand-order -s 600 $ ydb -e grpc://192.168.88.112:2136 -d /Root/testdb topic read orders/updates -c ilnaz --wait --format=newline-delimited 部署集群模式 安装前准备 在虚拟或裸机服务器上部署YDB集群 虚拟机系统安装好后，重新添加NVMe(v)类型磁盘 准备环境、用户 $ sudo groupadd ydb $ sudo useradd ydb -g ydb $ sudo usermod -aG disk ydb # 为了确保YDB可以访问块磁盘来运行，您需要将进程所有者添加到disk组中 $ apt install sudo # 使用root用户安装sudo $ echo \"name ALL=(ALL:ALL) ALL\" \u003e\u003e/etc/sudoers $ sudo apt install curl parted 在所选磁盘上创建分区 $ sudo parted /dev/nvme0n1 mklabel gpt -s $ sudo parted -a optimal /dev/nvme0n1 mkpart primary 0% 100% $ sudo parted /dev/nvme0n1 name 1 ydb_disk_ssd_01 $ sudo partx --u /dev/nvme0n1 $ sudo parted /dev/nvme0n2 mklabel gpt -s $ sudo parted -a optimal /dev/nvme0n2 mkpart primary 0% 100% $ sudo parted /dev/nvme0n2 name 1 ydb_disk_ssd_02 $ sudo partx --u /dev/nvme0n2 $ sudo parted /dev/nvme0n3 mklabel gpt -s $ sudo parted -a optimal /dev/nvme0n3 mkpart primary 0% 100% $ sudo parted /dev/nvme0n3 name 1 ydb_disk_ssd_03 $ sudo partx --u /dev/nvme0n3 # 系统上将出现一个标有磁盘的磁盘 $ ll /dev/disk/by-partlabel/ 下载并解压包含ydbd可执行文件和YDB运行所需库的存档 $ sudo chown -R ydb:ydb /opt $ mkdir -p /opt/{ydb/{cfg,secure,certs,log},ydbd-stable-linux-amd64} $ curl -L https://binaries.ydb.tech/ydbd-stable-linux-amd64.tar.gz | tar -xz --strip-component=1 -C /opt/ydbd-stable-linux-amd64 将可执行文件和库复制到适当的目录 $ sudo cp -iR /opt/ydbd-stable-linux-amd64/bin /opt/ydb/ $ sudo cp -iR /opt/ydbd-stable-linux-amd64/lib /opt/ydb/ 使用以下内置命令格式化磁盘 $ sudo LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd admin bs disk obliterate /dev/disk/by-partlabel/ydb_disk_ssd_01 $ sudo LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd admin bs disk obliterate /dev/disk/by-partlabel/ydb_disk_ssd_02 $ sudo LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd admin bs disk obliterate /dev/disk/by-partlabel/ydb_disk_ssd_03 准备证书使用保护模式 准备CA文件 $ cat \u003e/opt/ydb/cfg/ca.cnf\u003c\u003c-EOF [ ca ] default_ca = CA_default [ CA_default ] default_days = 365 database = /opt/ydb/secure/index.txt serial = /opt/ydb/secure/serial.txt default_md = sha256 copy_extensions = copy unique_subject = no [ req ] prompt=no distinguished_name = distinguished_name x509_extensions = extensions [ distinguished_name ] organizationName = YDB commonName = YDB CA [ extensions ] keyUsage = critical,digitalSignature,nonRepudiation,keyEncipherment,keyCertSign basicConstraints = critical,CA:true,pathlen:1 [ signing_policy ] organizationName = supplied commonName = optional [ signing_node_req ] keyUsage = critical,digitalSignature,keyEncipherment extendedKeyUsage = serverAuth,clientAuth # Used to sign client certificates. 用于签署客户端证书 [ signing_client_req ] keyUsage = critical,digitalSignature,keyEncipherment extendedKeyUsage = clientAuth EOF 创建CA密钥 $ openssl genrsa -out /opt/ydb/certs/ca.key 2048 2.1 创建私有证书颁发机构CA证书 $ openssl req -new -x509 -config /opt/ydb/cfg/ca.cnf -key /opt/ydb/certs/ca.key -out /opt/ydb/certs/ca.crt -days 1830 -batch 创建文本数据库和OpenSSL证书索引文件 $ touch /opt/ydb/secure/index.txt $ echo 01 \u003e/opt/ydb/secure/serial.txt 创建node.cnf具有以下内容的配置文件 $ cat \u003e/opt/ydb/cfg/node.cnf\u003c\u003c-EOF # OpenSSL node configuration file [ req ] prompt = no distinguished_name = distinguished_name req_extensions = extensions [ distinguished_name ] organizationName = YDB [ extensions ] subjectAltName = DNS:\u003cnode\u003e.\u003cdomain\u003e # 节点IP或者域名 EOF 创建证书密钥 $ openssl genrsa -out /opt/ydb/certs/node.key 2048 创建证书签名请求CSR $ openssl req -new -sha256 -config /opt/ydb/cfg/node.cnf -key /opt/ydb/certs/node.key -out /opt/ydb/secure/node.csr -batch 创建节点证书 $ openssl ca -config /opt/ydb/cfg/ca.cnf \\ -keyfile /opt/ydb/certs/ca.key \\ -cert /opt/ydb/certs/ca.crt \\ -policy signing_policy \\ -extensions signing_node_req \\ -out /opt/ydb/certs/node.crt \\ -outdir /opt/ydb/certs/ \\ -in /opt/ydb/secure/node.csr -batch 将证书和节点密钥复制到安装文件夹 $ sudo -u ydb cp certs/ca.crt certs/node.crt certs/node.key /opt/ydb/certs/ 为YDB准备集群配置文件 集群配置 集群类型、在集群每个节点中添加/opt/ydb/cfg/config.yaml保存YDB 配置文件 block-4-2用于单数据中心集群 mirror-3dc用于由 9 个节点组成的跨数据中心集群 mirror-3dc-3nodes用于由 3 个节点组成的跨数据中心集群 在host_configs部分中，指定每个群集节点上所有磁盘类型 可用磁盘种类：固态硬盘：SSD、NVME、HDD host_configs: - drive: - path: /dev/disk/by-partlabel/ydb_disk_ssd_01 type: SSD # 可用磁盘种类：SSD、NVME、HDD host_config_id: 1 在该hosts部分中，指定每个节点的FQDN、它们的配置和在data_center或中的位置rack 在/etc/hosts文件下做映射：IP:hostname避免不必要麻烦所有主机名必须都是小写字母 hosts: - host: node1.ydb.tech host_config_id: 1 walle_location: body: 1 data_center: 'zone-a' # 填写 hostname rack: '1' - host: node2.ydb.tech host_config_id: 1 walle_location: body: 2 data_center: 'zone-b' # 填写 hostname rack: '1' - host: node3.ydb.tech host_config_id: 1 walle_location: body: 3 data_center: 'zone-c' # 填写 hostname rack: '1' 启用用户身份验证 在YDB集群中启用认证和用户访问差异化特性，在domains_config部分添加以下参数 domains_config: security_config: enforce_user_token_requirement: true monitoring_allowed_sids: - \"root\" - \"ADMINS\" - \"DATABASE-ADMINS\" administration_allowed_sids: - \"root\" - \"ADMINS\" - \"DATABASE-ADMINS\" viewer_allowed_sids: - \"root\" - \"ADMINS\" - \"DATABASE-ADMINS\" 在YDB配置文件中启用流量加密模式 在interconnect_config和grpc_config部分中，指定证书、密钥和CA证书的路径 interconnect_config: start_tcp: true encryption_mode: OPTIONAL path_to_certificate_file: \"/opt/ydb/certs/node.crt\" path_to_private_key_file: \"/opt/ydb/certs/node.key\" path_to_ca_file: \"/opt/ydb/certs/ca.crt\" grpc_config: cert: \"/opt/ydb/certs/node.crt\" key: \"/opt/ydb/certs/node.key\" ca: \"/opt/ydb/certs/ca.crt\" 完整block-4-2配置避免不必要麻烦所有主机名必须都是小写字母 $ cat \u003e/opt/ydb/cfg/config.yaml\u003c\u003c-EOF # YDB configuration options and their values # are described in documentaion https://ydb.tech/en/docs/deploy/configuration/config # static erasure is the parameter that # describes the fault tolerance mode of the # cluster. See docs for more details https://ydb.tech/en/docs/deploy/configuration/config#domains-blob static_erasure: mirror-3-dc host_configs: # the list of available host configurations in the cluster. - drive: - path: /dev/disk/by-partlabel/ydb_disk_ssd_01 # path of the first disk in the host configration. type: NVME # kind of the disk: available kinds are SSD, NVME, HDD - path: /dev/disk/by-partlabel/ydb_disk_ssd_02 type: NVME - path: /dev/disk/by-partlabel/ydb_disk_ssd_03 type: NVME host_config_id: 1 hosts: - host: debian-1-88-110 # storage node DNS name host_config_id: 1 # numeric host configuration template identifier walle_location: # this parameter describes where host is located. body: 1 # string representing a host serial number. data_center: 'debian-1-88-110' # string representing the datacenter / availability zone where the host is located. # if cluster is deployed using mirror-3-dc fault tolerance mode, all hosts must be distributed # across 3 datacenters. rack: '1' # string representing a rack identifier where the host is located. # if cluster is deployed using block-4-2 erasure, all hosts should be distrubited # accross at least 8 racks. - host: ubuntu-1-88-111 host_config_id: 1 walle_location: body: 2 data_center: 'ubuntu-1-88-111' rack: '2' - host: ubuntu-2-88-112 host_config_id: 1 walle_location: body: 3 data_center: 'ubuntu-2-88-112' rack: '3' domains_config: # There can be only one root domain in a cluster. Domain name prefixes all scheme objects names, e.g. full name of a table table1 in database db1. # in a cluster with domains_config.domain.name parameter set to Root would be equal to /Root/db1/table1 domain: - name: Root storage_pool_types: - kind: nvme pool_config: box_id: 1 # fault tolerance mode name - none, block-4-2, or mirror-3-dc.. # See docs for more details https://ydb.tech/en/docs/deploy/configuration/config#domains-blob erasure_species: mirror-3-dc kind: nvme geometry: realm_level_begin: 10 realm_level_end: 20 domain_level_begin: 10 domain_level_end: 256 pdisk_filter: - property: - type: NVME # device type to match host_configs.drive.type vdisk_kind: Default state_storage: - ring: node: [1, 2, 3] nto_select: 3 ssid: 1 table_service_config: sql_version: 1 actor_system_config: # the configuration of the actor system which descibes how cores of the instance are distributed executor: # accross different types of workloads in the instance. - name: System # system executor of the actor system. in this executor YDB launches system type of workloads, like system tablets # and reads from storage. threads: 2 # the number of threads allocated to system executor. type: BASIC - name: User # user executor of the actor system. In this executor YDB launches user workloads, like datashard activities, # queries and rpc calls. threads: 3 # the number of threads allocated to user executor. type: BASIC - name: Batch # user executor of the actor system. In this executor YDB launches batch operations, like scan queries, table # compactions, background compactions. threads: 2 # the number of threads allocated to the batch executor. type: BASIC - name: IO # the io executor. In this executor launches sync operations and writes logs. threads: 1 time_per_mailbox_micro_secs: 100 type: IO - name: IC # the interconnect executor which YDB uses for network communications accross different nodes of the cluster. spin_threshold: 10 threads: 1 # the number of threads allocated to the interconnect executor. time_per_mailbox_micro_secs: 100 type: BASIC scheduler: progress_threshold: 10000 resolution: 256 spin_threshold: 0 blob_storage_config: # configuration of static blobstorage group. # YDB uses this group to store system tablets' data, like SchemeShard service_set: groups: - erasure_species: mirror-3-dc # fault tolerance mode name for the static group rings: # in mirror-3-dc must have exactly 3 rings or availability zones - fail_domains: # first record: fail domains of the static group describe where each vdisk of the static group should be located. - vdisk_locations: - node_id: debian-1-88-110 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_01 - vdisk_locations: - node_id: debian-1-88-110 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_02 - vdisk_locations: - node_id: debian-1-88-110 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_03 - fail_domains: # second ring: fail domains of the static group describe where each vdisk of the static group should be located. - vdisk_locations: - node_id: ubuntu-1-88-111 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_01 - vdisk_locations: - node_id: ubuntu-1-88-111 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_02 - vdisk_locations: - node_id: ubuntu-1-88-111 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_03 - fail_domains: # third ring: fail domains of the static group describe where each vdisk of the static group should be located. - vdisk_locations: - node_id: ubuntu-2-88-112 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_01 - vdisk_locations: - node_id: ubuntu-2-88-112 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_02 - vdisk_locations: - node_id: ubuntu-2-88-112 pdisk_category: NVME path: /dev/disk/by-partlabel/ydb_disk_ssd_03 channel_profile_config: profile: - channel: - erasure_species: mirror-3-dc pdisk_category: 0 storage_pool_kind: nvme - erasure_species: mirror-3-dc pdisk_category: 0 storage_pool_kind: nvme - erasure_species: mirror-3-dc pdisk_category: 0 storage_pool_kind: nvme profile_id: 0 interconnect_config: start_tcp: true encryption_mode: OPTIONAL path_to_certificate_file: \"/opt/ydb/certs/node.crt\" path_to_private_key_file: \"/opt/ydb/certs/node.key\" path_to_ca_file: \"/opt/ydb/certs/ca.crt\" grpc_config: cert: \"/opt/ydb/certs/node.crt\" key: \"/opt/ydb/certs/node.key\" ca: \"/opt/ydb/certs/ca.crt\" EOF 启动数据库静态节点 手动方式启动 启动/Root/testdb数据库的YDB动态节点 \u003cnodeN.ydb.tech\u003e运行静态节点的服务器的FQDN在哪里 在其他服务器上运行额外的动态节点以确保数据库可用性 $ sudo su - ydb $ cd /opt/ydb $ export LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd server --log-level 3 --tcp --yaml-config /opt/ydb/cfg/config.yaml --grpc-port 2135 --ic-port 19001 --mon-port 8765 --node static \u003e/opt/ydb/log/static-node.out 2\u003e/opt/ydb/log/static-node.err \u0026\u003e 使用systemd方式启动 编写启动文件 /etc/systemd/system/ydbd-storage.service $ cat \u003e/etc/systemd/system/ydbd-storage.service\u003c\u003c-EOF [Unit] Description=YDB storage node After=network-online.target rc-local.service Wants=network-online.target StartLimitInterval=10 StartLimitBurst=15 [Service] Restart=always RestartSec=1 User=ydb # 根据用户修改 PermissionsStartOnly=true StandardOutput=/var/log/ydb.log StandardError=/var/log/ydb.log SyslogIdentifier=ydbd SyslogFacility=daemon SyslogLevel=err Environment=LD_LIBRARY_PATH=/opt/ydb/lib ExecStart=/opt/ydb/bin/ydbd server --log-level 3 --syslog --tcp --yaml-config /opt/ydb/cfg/config.yaml --grpc-port 2135 --ic-port 19001 --mon-port 8765 --node static LimitNOFILE=65536 LimitCORE=0 LimitMEMLOCK=3221225472 [Install] WantedBy=multi-user.target EOF 启动服务器、查看状态 $ sudo systemctl start ydbd-storage $ sudo systemctl status ydbd-storage 初始化集群 不使用身份验证方式初始化集群 在其中一个集群节点上，运行命令 $ export LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd admin blobstorage config init --yaml-file /opt/ydb/cfg/config.yaml $ echo $? 使用身份验证方式初始化集群 要在启用用户认证模式的集群中执行管理命令（包括集群初始化、数据库创建、磁盘管理等），您必须首先使用YDB CLI客户端2.0.0或更高版本获取认证令牌。您必须按照安装说明将YDB CLI客户端安装在任何可以通过网络访问集群节点的计算机上（例如，在其中一个集群节点上）。\n第一次安装集群时，它只有一个root密码为空的帐户，因此获取令牌的命令 任何集群服务器都可以指定为连接服务器（-e或--endpoint参数） $ ydb -e grpc://\u003cnode1.ydb.tech\u003e:2135 -d /Root --user root --no-password auth get-token --force \u003etoken-file 如果启用了TLS流量保护，请使用受保护的grpcs协议而不是grpc上面命令中的协议，并在参数中额外指定CA证书的路径--ca-file $ ydb -e grpcs://\u003cnode1.ydb.tech\u003e:2135 -d /Root --ca-file /opt/ydb/certs/ca.crt --user root --no-password auth get-token --force \u003etoken-file 如果命令执行成功，身份验证令牌将被写入token-file. 只需要将此文件复制到稍后要运行集群初始化和数据库创建命令的集群节点。接下来，在此集群节点上运行命令 $ export LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd -f token-file admin blobstorage config init --yaml-file /opt/ydb/cfg/config.yaml $ echo $? 创建数据库 要使用表，您需要至少创建一个数据库并运行一个进程来为该数据库提供服务（动态节点）不使用令牌 /Root: 根域的名称，必须与domains_config. domain. name在集群配置文件中设置 testdb: 创建的数据库名称 ssd:1：存储池的名称和池中块的编号。池名称通常表示数据存储设备的类型，并且必须与storage_pool_types. kind里面的设置domains_config。domain配置文件的元素 $ LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd admin database /Root/testdb create ssd:1 使用令牌文件的数据库创建命令\n如果在集群中启用了用户认证模式，则必须将认证令牌传递给数据库创建命令。集群初始化部分描述了获取令牌的过程\n$ LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd -f token-file admin database /Root/testdb create ssd:1 启动数据库动态节点 手动方式启动 启动/Root/testdb数据库的YDB动态节点 \u003cnodeN.ydb.tech\u003e运行静态节点的服务器的FQDN在哪里 在其他服务器上运行额外的动态节点以确保数据库可用性 $ sudo su - ydb $ cd /opt/ydb $ export LD_LIBRARY_PATH=/opt/ydb/lib /opt/ydb/bin/ydbd server --grpc-port 2136 --ic-port 19002 --mon-port 8766 --yaml-config /opt/ydb/cfg/config.yaml --tenant /Root/testdb --node-broker \u003cnode1.ydb.tech\u003e:2135 --node-broker \u003cnode2.ydb.tech\u003e:2135 --node-broker \u003cnode3.ydb.tech\u003e:2135 使用Systemd方式启动 编写启动文件 创建一个名为/etc/systemd/system/ydbd-testdb.service以下内容的配置文件 $ cat \u003e/etc/systemd/system/ydbd-testdb.service\u003c\u003c-EOF [Unit] Description=YDB testdb dynamic node After=network-online.target rc-local.service Wants=network-online.target StartLimitInterval=10 StartLimitBurst=15 [Service] Restart=always RestartSec=1 User=ydb PermissionsStartOnly=true StandardOutput=syslog StandardError=syslog SyslogIdentifier=ydbd SyslogFacility=daemon SyslogLevel=err Environment=LD_LIBRARY_PATH=/opt/ydb/lib ExecStart=/opt/ydb/bin/ydbd server --grpc-port 2136 --ic-port 19002 --mon-port 8766 --yaml-config /opt/ydb/cfg/config.yaml --tenant /Root/testdb --node-broker \u003cnode1.ydb.tech\u003e:2135 --node-broker \u003cnode2.ydb.tech\u003e:2135 --node-broker \u003cnode3.ydb.tech\u003e:2135 LimitNOFILE=65536 LimitCORE=0 LimitMEMLOCK=32212254720 [Install] WantedBy=multi-user.target EOF 启动/Root/testdb数据库的YDB动态节点在其他服务器上运行额外的动态节点以确保数据库可用性 $ sudo systemctl start ydbd-testdb 初始帐户设置 在集群配置文件中启用了身份验证模式，则必须在使用YDB集群之前完成初始帐户设置 YDB集群的初始安装会自动创建一个root密码为空的帐户，以及访问管理部分中描述的一组标准用户组\n要在创建的YDB集群中执行初始帐户设置，按照文档中的描述安装YDB CLI\n\u003cnode.ydb.tech\u003e是运行支持/Root/testdb数据库的动态节点的服务器的FQDN\n在运行帐户创建和组分配命令时，YDB CLI客户端将请求root用户密码。您可以按照YDB CLI文档中的说明创建连接配置文件，从而避免输入多个密码\n如果集群中启用了TLS流量保护，请使用受保护的grpcs协议而不是grpc上面命令中的协议，并在参数中指定CA证书的路径--ca-file（或将其保存在连接配置文件中）\nroot为账户设置密码\n$ ydb -e grpc://\u003cnode.ydb.tech\u003e:2136 -d /Root/testdb --user root --no-password yql -s 'ALTER USER root PASSWORD \"passw0rd\"' # 将passw0rd值替换为自己定义密码 创建其他帐户 $ ydb -e grpc://\u003cnode.ydb.tech\u003e:2136 -d /Root/testdb --user root yql -s 'CREATE USER user1 PASSWORD \"passw0rd\"' 通过将它们包含在集成组中来设置帐户权限 $ ydb -e grpc://\u003cnode.ydb.tech\u003e:2136 -d /Root/testdb --user root yql -s 'ALTER GROUP `ADMINS` ADD USER user1' 测试创建的数据库 按照文档中的描述安装YDB CLI，创建一个test_table \u003cnode.ydb.tech\u003e运行支持/Root/testdb数据库的动态节点的服务器的FQDN在哪里 $ ydb -e grpc://\u003cnode.ydb.tech\u003e:2136 -d /Root/testdb scripting yql --script 'CREATE TABLE `testdir/test_table` (id Uint64, title Utf8, PRIMARY KEY (id));' 集群开启了TLS流量保护或用户认证方式 $ ydb -e grpcs://\u003cnode.ydb.tech\u003e:2136 -d /Root/testdb --ca-file ydb-ca.crt --user root scripting yql --script 'CREATE TABLE `testdir/test_table` (id Uint64, title Utf8, PRIMARY KEY (id));' ",
    "description": "部署Ydb单节点数据库 Ydb使用端口 端口 协议 描述 2135~2136 TCP 用于客户端-集群交互的GRPC 19001~19002 TCP 集群内节点交互互连 8765~8766 TCP 集群监控的HTTP接口 Ydb数据库、Github-Ydb 系统要求Ubuntu 20.",
    "tags": [],
    "title": "Install_Ydb",
    "uri": "/systems/linux/databases/install_ydb/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "安装PostgreSQL数据库 PostgreSQL、Download-PostgreSQL、FTP-PostgreSQL $ yum -y install c++ gcc-c++ readline-devel zlib-devel $ curl -o /usr/local/src/postgresql-15.0.tar.gz https://ftp.postgresql.org/pub/source/v15.0/postgresql-15.0.tar.gz $ tar -zxvf postgresql-15.0.tar.gz $ cd postgresql-15.0 $ view INSTALL 安装 $ ./configure --prefix=/usr/local/postgresql $ make world $ make install-world $ adduser postgres # 创建用户 $ mkdir -p /usr/local/postgresql/data $ chown -R postgres. /usr/local/postgresql/data $ su - postgres # 初始化数据库 $ /usr/local/postgresql/bin/initdb -D /usr/local/postgresql/data # 启动数据库 $ /usr/local/postgresql/bin/pg_ctl -D /usr/local/postgresql/data -l logfile start 配置Postgresql $ vim /usr/local/postgresql/data/postgresql.conf listen_addresses = '192.168.88.0/24' # 开启远程访问 $ vim /usr/local/postgresql/data/pg_hba.conf # IPv4 local connections: # 信任远程连接,修改如下内容，信任指定服务器连接,ident修改为MD5 host all all 127.0.0.1/32 md5 host all all 10.1.8.0/24 md5 使用PostgreSQL $ su - postgres # 切换进去 $ psql # 进入命令行模式 $ \\l # 列出数据库 $ \\du # 列出用户 $ \\c mydb # 进入数据库 # 假定数据库名为gerericdb $ /opt/pgsql/bin/createdb genericdb # 进入数据库内部 $ /opt/pgsql/bin/psql genericdb ",
    "description": "安装PostgreSQL数据库 PostgreSQL、Download-PostgreSQL、FTP-PostgreSQL $ yum -y install c++ gcc-c++ readline-devel zlib-devel $ curl -o /usr/local/src/postgresql-15.",
    "tags": [],
    "title": "Install_PostgreSQL",
    "uri": "/systems/linux/databases/install_postgresql/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "Otter数据搬运 Otter ",
    "description": "Otter数据搬运 Otter ",
    "tags": [],
    "title": "Install_Otter",
    "uri": "/systems/linux/databases/install_otter/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "安装Mysql-PXC 企业主流MySQL高可用集群架构三部曲之PXC 在Docker容器中运行Percona XtraDB集群 docker安装Mysql-PXC $ cat \u003einstall-mysql-pxc.sh\u003c\u003c-EOF #!/bin/bash sudo yum -y remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest docker-latest-logrotate docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io sleep 5 sudo systemctl start docker sudo systemctl enable docker mkdir -p /opt/data/{data-3306.data-3307,data-3308} docker network create pxc-network # 创建网络 docker run -i -d -p 3306:3306 -v /etc/localtime:/etc/localtime -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1 --name=node1 --privileged=true --net=pxc-network percona/percona-xtradb-cluster:5.7 sleep 15 docker run -i -d -p 3307:3306 -v /etc/localtime:/etc/localtime -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1 -e CLUSTER_JOIN=node1 --name=node2 --privileged=true --net=pxc-network percona/percona-xtradb-cluster:5.7 sleep 5 docker run -i -d -p 3308:3306 -v /etc/localtime:/etc/localtime -e MYSQL_ROOT_PASSWORD=root -e CLUSTER_NAME=cluster1 -e CLUSTER_JOIN=node1 --name=node3 --privileged=true --net=pxc-network percona/percona-xtradb-cluster:5.7 sleep 5 docker exec -it node1 /usr/bin/mysql -uroot -proot -e \"show status like 'wsrep%';\" # 登录数据库查看数据库状态, 修改密码 # show status like 'wsrep%'; EOF EOF Yum安装PXC 最少准备三台服务器，在三台服务器上同步执行命令\n先卸载系统自带数据库，防火墙开放同步端口：4567\n$ cat \u003epxc-install.sh\u003c\u003c-EOF yum -y remove mariadb* yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm # 安装 PXC 的 Yum 源 yum install Percona-XtraDB-Cluster-57 -y # 安装 PXC 数据库 systemctl enable mysql systemctl start mysql pass=`grep \"temporary password\" /var/log/mysqld.log |awk '{print $11}'` password=`openssl rand -base64 14` # 生成随即密码 mysql -uroot -p$pass -e \"alter user 'root'@'localhost' identified by '$password';\" mysql -uroot -p$password -e \" flush privileges;\" EOF 关闭所有节点数据库、并修改配置文件 $ systemctl stop mysql 修改my.cnf配置文件 $ cat \u003e/etc/my.cnf\u003c\u003c-EOF [mysqld] # 必须定义 !includedir /etc/my.cnf.d/ # 原有不动 !includedir /etc/percona-xtradb-cluster.conf.d/ # 原有不动 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so # 提供程序的路径 wsrep_cluster_name=pxc-cluster # 定义的集群名称 wsrep_cluster_address=gcomm://192.168.2.11,192.168.2.12,192.168.2.13 # 所有的集群节点IP wsrep_node_name=pxc1 # 定义本机的名字 wsrep_node_address=192.168.2.11 # 定义本机IP wsrep_sst_method=xtrabackup-v2 # 同步方式 wsrep_sst_auth=sstuser:password # 提供同步密码 pxc_strict_mode=ENFORCING # 严格模式(强制执行) binlog_format=ROW # 行格式 default_storage_engine=InnoDB # 默认存储引擎 innodb_autoinc_lock_mode=2 # 自增锁定模式 EOF 先启动主节点，确保主库数据同步到其他从节点 wsrep_cluster_size=1表示集群中只有一个节点 已经连接并且状态时primary随时写入数据到集群，再加入其他两个节点之前，需要创建一个SST（State Snapshot Transfer）账号用于集群间通信，必须和主机my.cnf配置的参数一致 $ systemctl restart mysql@bootstrap.service $ mysql -uroot -p$password -e \"show status like 'wsrep%';\" 添加用户并且赋予权限 $ mysql -uroot -p$password -e \"CREATE USER 'sstuser'@'localhost' IDENTIFIED BY 'password';\" $ mysql -uroot -p$password -e \"GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO 'sstuser'@'localhost';\" $ mysql -uroot -p$password -e \"FLUSH PRIVILEGES;\" 在从节点依次启动 $ systemctl start mysql PXC导出数据库 $ mysqldump -uroot -p --skip_add_locks --skip-lock-tables LY_report \u003e /root/LY_report`date +%F`.sql 强行关机之后，PERCONA XTRADB CLUSTER集群无法启动 查看grastate.dat文件 $ cat \u003e/var/lib/mysql/grastate.dat\u003c\u003c-EOF # GALERA saved state version: 2.1 uuid: 8050b2ae-5de7-11ea-b72e-1b7d1643b17c seqno: 975 safe_to_bootstrap: 0 # 此值大的先启动、如果都是 0，找个修改成 1 即可 EOF 4.1.2 修改配置文件 vim /etc/percona-xtradb-cluster.conf.d/my.cnf [client] socket=/var/lib/mysql/mysql.sock [mysql] prompt=\"\\u@db2 \\R:\\m:\\s [\\d]\u003e \" no-auto-rehash server-id=2 # server-id每个服务器唯一 # 这里定义数据目录和日志目录 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid log-bin = /var/lib/mysql/mybinlog log_slave_updates bind-address = 0.0.0.0 # 监听地址 port = 3306 # 监听端口 default_storage_engine=InnoDB # 默认数据库引擎 character-set-server = utf8mb4 # 字符集 collation-server = utf8mb4_general_ci # 排序规则 max_connections = 1000 # 最大连接数 open_files_limit = 65535 # 限制打开文件数 default-time-zone = '+8:00' # 默认时区 # 设置数据库事务隔离级别 transaction_isolation = REPEATABLE-READ # 配置超时时间 interactive_timeout = 600 wait_timeout = 600 connect_timeout = 20 lock_wait_timeout = 3600 max_allowed_packet = 64M # 限制数据库服务器接收数据包的大小 # 配置排序和join的buffer大小 sort_buffer_size = 4M join_buffer_size = 4M # 配置binlog binlog_format=ROW expire_logs_days=7 # 开启binlog校验功能 binlog_checksum = 1 binlog_cache_size = 4M sync_binlog = 1 # 每1次提交变更后立刻将binlog落盘 # 配置performance_schema performance_schema = on performance_schema_instrument = '%memory%=on' performance_schema_instrument = '%lock%=on' skip-external-locking = on skip-name-resolve = on # 禁用域名解析 # 禁用软链接 symbolic-links=0 back_log = 1024 # 慢日志查询配置 slow_query_log = 1 long_query_time = 1 slow_query_log_file = /var/log/mysqld/slow.log # 配置每个EVENT都要执行刷盘操作 sync_master_info = 1 sync_relay_log_info = 1 sync_relay_log = 1 log_slave_updates = on relay_log_recovery = 1 relay_log_purge = 1 master_info_repository = TABLE relay_log_info_repository = TABLE # InnoDB引擎配置 innodb_file_per_table = on innodb_checksums = 1 innodb_checksum_algorithm = crc32 innodb_status_file = 1 innodb_status_output = 0 innodb_status_output_locks = 0 innodb_stats_on_metadata = 0 innodb_open_files = 65535 innodb_flush_method = O_DIRECT innodb_flush_sync = 0 innodb_flush_neighbors = 0 # 每个事务提交后立即刷新binlog文件 innodb_flush_log_at_trx_commit = 1 innodb_monitor_enable=\"module_innodb\" innodb_monitor_enable=\"module_server\" innodb_monitor_enable=\"module_dml\" innodb_monitor_enable=\"module_ddl\" innodb_monitor_enable=\"module_trx\" innodb_monitor_enable=\"module_os\" innodb_monitor_enable=\"module_purge\" innodb_monitor_enable=\"module_log\" innodb_monitor_enable=\"module_lock\" innodb_monitor_enable=\"module_buffer\" innodb_monitor_enable=\"module_index\" innodb_monitor_enable=\"module_ibuf_system\" innodb_monitor_enable=\"module_buffer_page\" innodb_monitor_enable=\"module_adaptive_hash\" # SQL mode配置，这里是默认值 sql_mode = ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION # GTID配置 #gtid_mode = on #enforce_gtid_consistency = 1 # wsrep配置 # This changes how InnoDB autoincrement locks are managed and is a requirement for Galera innodb_autoinc_lock_mode=2 wsrep_cluster_name=pxc-cluster # Cluster name集群名称 wsrep_cluster_address=gcomm://10.14.23.78:4567,10.14.23.180:4567,10.14.23.181:4567 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so #If wsrep_node_name is not specified, then system hostname will be used wsrep_node_name = db2 # Slave thread to use wsrep_slave_threads= 8 # SST method wsrep_sst_method=xtrabackup-v2 # Node IP address wsrep_node_address = 10.14.23.180 wsrep_sst_receive_address = 10.14.23.180 # Authentication for SST method wsrep_sst_auth=\"sstuser:sstuser_password\" # pxc_strict_mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER pxc_strict_mode=ENFORCING [mysqld_safe] pid-file = /var/run/mysqld/mysqld.pid socket = /var/lib/mysql/mysql.sock nice = 0 EOF ",
    "description": "安装Mysql-PXC 企业主流MySQL高可用集群架构三部曲之PXC 在Docker容器中运行Percona XtraDB集群 docker安装Mysql-PXC $ cat \u003einstall-mysql-pxc.sh\u003c\u003c-EOF #!/bin/bash sudo yum -y remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest docker-latest-logrotate docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager --add-repo \\ https://download.",
    "tags": [],
    "title": "Install_Mysql_PXC",
    "uri": "/systems/linux/databases/install_mysql_pxc/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "MySQL Router MySQL Router是MySQL官方提供的路由器和负载均衡器 支持基于轮询或自动检测到的服务器状态的负载均衡，可以将读写请求路由到不同的MySQL服务器 MySQL Router提供了简单的配置和管理接口，适合MySQL官方产品的环境 MySQL Router ",
    "description": "MySQL Router MySQL Router是MySQL官方提供的路由器和负载均衡器 支持基于轮询或自动检测到的服务器状态的负载均衡，可以将读写请求路由到不同的MySQL服务器 MySQL Router提供了简单的配置和管理接口，适合MySQL官方产品的环境 MySQL Router ",
    "tags": [],
    "title": "Install_MySQL_Router",
    "uri": "/systems/linux/databases/install_mysql_router/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "MaxScale轻量级数据库代理 MaxScale是MariaDB开发的一个轻量级的数据库代理和路由器 支持高级的查询路由和负载均衡功能，包括读写分离、故障切换和高可用性 MaxScale提供了丰富的插件和模块化架构，可以轻松扩展其功能 MaxScale ",
    "description": "MaxScale轻量级数据库代理 MaxScale是MariaDB开发的一个轻量级的数据库代理和路由器 支持高级的查询路由和负载均衡功能，包括读写分离、故障切换和高可用性 MaxScale提供了丰富的插件和模块化架构，可以轻松扩展其功能 MaxScale ",
    "tags": [],
    "title": "Install_MaxScale",
    "uri": "/systems/linux/databases/install_maxscale/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "ProxySQL代理 ProxySQL是一个高性能的MySQL代理，支持数据库连接池、查询缓存、负载均衡和读写分离 它可以根据SQL查询类型（读或写）将请求路由到不同的MySQL服务器 ProxySQL提供了丰富的配置选项，可以根据需求调整负载均衡策略和连接池管理 ProxySQL ",
    "description": "ProxySQL代理 ProxySQL是一个高性能的MySQL代理，支持数据库连接池、查询缓存、负载均衡和读写分离 它可以根据SQL查询类型（读或写）将请求路由到不同的MySQL服务器 ProxySQL提供了丰富的配置选项，可以根据需求调整负载均衡策略和连接池管理 ProxySQL ",
    "tags": [],
    "title": "Install_ProxySQL",
    "uri": "/systems/linux/databases/install_proxysql/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "manticoresearch 易于使用的开源快速搜索数据库. Manticore Search ",
    "description": "manticoresearch 易于使用的开源快速搜索数据库. Manticore Search ",
    "tags": [],
    "title": "Install_Manticore_Search",
    "uri": "/systems/linux/databases/install_manticore_search/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "Canal数据库增量日志解析 Canal ",
    "description": "Canal数据库增量日志解析 Canal ",
    "tags": [],
    "title": "Install_Canal",
    "uri": "/systems/linux/databases/install_canal/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "数据库使用 数据结构可视化 数据结构可视化 数据库连接工具 名称地址 描述 WorkBenCh MySQL产品档案 下载MySQL-8.0的索引 Mysql深入学习笔记 SQLyog数据库客户端连接工具 DBeaver数据库客户端连接工具 Mysql WorkBenCh菜单中文汉化 Navicat Premium 15安装与激活 Navicat Premium 16下载与安装破解教程 使用通用二进制文件在Unix/Linux 安装MySQL Navicat Premium 15永久破解激活工具及安装教程 数据库常用命令 数据库命令 说明 举例 select 从数据库中提取数据 查看用户数据：select user,host from mysql.user \\G; update 更新数据库中的数据 delete 从数据库中删除数据 insert into 向数据库中插入数据 插入数据：insert into tiantian.tt1 values(1,'lisi'); create database 创建新数据库 创建数据库：create database tiantian; alter database 更改数据库 create table 创建表 创建数据表：create table tiantian.tt1(id int, name varchar(50)); alter table 更改表 drop table 删除表 create index 创建索引(搜索键) drop index 删除索引 Where语句中的运算符 说明 举例 = 等于 \u003c\u003e 不等于：在SQL的一些版本中，改操作符被写成!= \u003e 大于 \u003c 小于 \u003e= 大于等于 \u003c= 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 IN 指定针对某个列的多个可能值 查询数据库连接数 查看当前活动线程状态 Threads_cached缓存的线程数量，这些线程处于睡眠状态以备复用 Threads_connected当前打开的连接数 Threads_created为处理连接而创建的线程数 mysql\u003e show status like 'Threads%'; 如果Threads_created很大，您可能需要增加thread_cache_size的值。缓存失误率可以通过Threads_created/Connections计算 显示用户正在运行的线程 mysql\u003e show full processlist; 查看最大链接数 mysql\u003e show variables like '%max_connections%'; # 临时增加连接数，配置文件增加参数：max_connections=4000 mysql\u003e set GLOBAL max_connections=4000; 查看连接的用户和IP以及超时时间 # 查看连接的用户和IP以及超时时间，或者使用：count(*) 统计总统连接数 mysql\u003e select * from information_schema.processlist; 看连接的用户和每个IP的连接总数地址 mysql\u003e SELECT substring_index(host, ':',1) AS host_ip,`user`,db,state,count(*) FROM information_schema.processlist GROUP BY state,host_ip,`user`,db; 查询数据库慢语句 # 查询占用超时慢语句 mysql\u003e select * from information_schema.processlist where Command != 'Sleep' order by Time desc \\G; 三种修改数据库密码 第一种修改方式，8.0用此方法 mysql\u003e alter user 'root'@'localhost' identified by '123'; mysql\u003e alter user 'root'@'localhost' identified with mysql_native_password by 'newpassword'; 第二种修改方式 mysql\u003e set password for 'root'@'localhost'=password('newpassword'); 第三种修改方式 mysql\u003e update mysql.user set authentication_string=password('123qwe') where user='root' and Host = 'localhost'; 更改密码为123456 mysql\u003e update destoon_member set password=’14e1b600b1fd579f47433b88e8d85291′ where username=’admin’; 忘记数据库密码 $ cat \u003e/etc/my.cnf\u003c\u003c-EOF [mysqld] # 在配置文件中最上面添加 skip-grant-tables EOF # 重启mysql服务 直接使用 mysql -uroot -p 不输入密码直接回车进入 修改密码 mysql\u003e update user set authentication_string=password('root'); 数据库备份、还原 数据库备份 使用mysqldump备份数据库 手动备份 --all-databases备份所有数据库 -B, --databases备份时指定数据库 --tables备份时指定数据表 --triggers在备份时包括触发器 --routines在备份时包括存储过程 --events在备份时包括事件 -S, --socket服务器通信时要使用的套接字文件 --flush-logs参数用于在备份之前刷新MySQL的二进制日志，确保备份包含最新的数据更新 --skip-lock-tables参数允许在导出MySQL数据库表时跳过对表的锁定操作，适用于需要最小化数据库停机时间或对导出过程影响较小的情况 --lock-tables=false：默认情况下，mysqldump 会锁定表，以确保备份的一致性。如果你不需要锁定表，可以使用--lock-tables=false参数 --column-statistics=0：禁用统计信息，在MySQL8默认情况下，尝试收集每个列的统计信息，这些统计信息包括每个列的最大值、最小值、平均值和标准差等，以便优化查询计划和执行 --no-autocommit 参数禁用自动提交模式，在备份过程中使用事务来确保备份的一致性，并减少对数据库的锁定时间。 --master-data 参数在备份输出中包含二进制日志文件名和位置信息，对于主从复制环境中的数据库恢复尤其有用 --single-transaction 参数用于使用单个事务进行备份，适用于 InnoDB 存储引擎，避免了备份期间的锁表操作。 --set-gtid-purged=OFF：如果源库开启了GTID特性，使用mysqldump导出数据时，存在需要super权限执行的语句：SET @@SESSION.SQL_LOG_BIN= 0;，SET @@GLOBAL.GTID_PURGED=´18f9a804-343b-11e5-a21d-b083fed01601:1-2; 备份用户权限 mysql\u003e GRANT SELECT,RELOAD,LOCK TABLES,REPLICATION CLIENT,SHOW VIEW,EVENT,TRIGGER,PROCESS ON *.* TO 'backup'@'localhost' identified BY 'passwoord'; 备份多个数据库 $ /bin/mysql -u root -p'password' \\ -S /tmp/mysqld.sock -e 'show databases;'| \\ grep -E -v \"sys|mysql|information_schema|performance_schema|Database\" \\ |grep -E \".*datebases1$|.*datebases2$\" | \\ xargs /bin/mysqldump -u root -p'password' \\ -S /tmp/mysqld.sock \\ --single-transaction --no-autocommit \\ --master-data=2 --skip-lock-tables --databases \u003e`date +%F`-datebases_name.sql 导出全部库 $ mysqldump -uroot -p'passowrd' --all-databases \u003e /tmp/all_databases.sql $ /usr/local/mysql/bin/mysqldump -u root -p'passowrd' \\ -S /tmp/mysqld.sock \\ --all-databases --lock-tables=false \\ --routines --single_transaction --flush-logs \\ --skip-lock-tables --master-data=1 \\ | gzip \u003e/tmp/mysql-all-`date +%F_%H%M%S`.sql.gz 导出单个库 $ mysqldump -uroot -p --databases databases_name \u003e /tmp/databases_name.sql $ /bin/mysqldump -uroot -p'passowrd' \\ --set-gtid-purged=OFF --single-transaction \\ --master-data=1 --flush-logs \\ -S /tmp/mysqld.sock \\ --databases database_name | gzip \u003e/tmp/database`date +%F_%H%M%S`.sql.gz 导出指定表 $ mysqldump -uroot -p --databases databases_name --tables tables_name \u003e /tmp/databases_name_tables_name.sql $ bin/mysql -u root -p'password' \\ -S /tmp/mysqld.sock \\ -e 'select table_name from information_schema.tables where table_schema like \"game\\-center\\_ali\";'|egrep \".*record\" | xargs /bin/mysqldump -u root -p'password' -S /tmp/mysqld.sock --databases databases_name --tables tables_name \u003e/tmp/tables_name.sql 导出表结构加-d参数 $ /bin/mysqldump -d -uroot -p'passowrd' \\ -S /opt/data/data_3306/mysql.sock --databases database_name \u003e database_name.sql 使用Mysql脚本备份并通知Telegram $ cat \u003e/opt/script/Backup_Mysql.sh\u003c\u003c-EOF #!/bin/bash DATA=$(date +%F_%H%M%S) ## set ff=unix # 修改换行符 ## 定义备份目录 MYSQL_BACKUP_PATH=/opt/backup/ ## 定义Telegram 机器人ID和报警组 TELEGRAM_BOT_ID='Telegram BOT_ID:BOT_Key' TELEGRAM_GROUP_ID='GROUP_ID' ## 定义连接数据库 账户密码IP USER_NAME='backup' USER_PASSWORD='pass' DATABASES='databases name' # 备份表用 USER_HOST_1='IP_1' USER_HOST_2='IP_2' ## 过滤数据库, xargs和sed '1d'效果一样 DATABASES_1=`/bin/mysql -u${USER_NAME} -p\"${USER_PASSWORD}\" -h\"${USER_HOST_1}\" -e 'show databases;' | grep -E -v \"sys|mysql|information_schema|performance_schema|Database\" | /bin/xargs` ## DATABASES_2=`/bin/mysql -u${USER_NAME} -p\"${USER_PASSWORD}\" -h\"${USER_HOST_2}\" -e 'show databases;' | grep -E -v \"sys|mysql|information_schema|performance_schema|Database\" | sed '1d'` ## 检测备份目录是否存在，不存在就创建 ## /bin/test -d /opt/backup function TEST_BACKUP_DIR() { if [ ! -d ${MYSQL_BACKUP_PATH} ];then /bin/mkdir -p ${MYSQL_BACKUP_PATH} fi } ## 开始准备备份数据库 cd ${MYSQL_BACKUP_PATH} /bin/curl -X POST \"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=开始备份：${DATABASES_1} ${DATABASES_2} 数据库\" for i in ${DATABASES_1};do /usr/local/mysql/bin/mysqldump -u${USER_NAME} -p\"${USER_PASSWORD}\" -h${USER_HOST_1} --single-transaction --no-autocommit --master-data=1 --skip-lock-tables ${i} \u003e ${MYSQL_BACKUP_PATH}${i}-`date +%F`.sql done if [ $? -eq 0 ];then /bin/tar -zcvf ${MYSQL_BACKUP_PATH}${i}-`date +%F`.tar.gz ${i}-`date +%F`.sql /bin/curl -X POST \"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=${DATABASES_1} ${DATABASES_2} 数据库备份完成\" else /bin/curl -X POST \"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=${DATABASES_1} ${DATABASES_2} 数据库备份失败\" fi /bin/rm -rf ${MYSQL_BACKUP_PATH}*.sql ## 备份数据表 function BACKUP_MYSQL_TABLES() { cd ${MYSQL_BACKUP_PATH} for DATABASES in ${DATABASES_1};do TABLES_1=$(/bin/mysql -u${USER_NAME} -p\"${USER_PASSWORD}\" -h\"${USER_HOST_1}\" ${DATABASES} -e \"show tables;\"|sed '1d') for I in ${TABLES_1};do /usr/local/mysql/bin/mysqldump -u${USER_NAME} -p\"${USER_PASSWORD}\" -h${USER_HOST_1} --single-transaction --no-autocommit --master-data=1 --skip-lock-tables ${I} \u003e ${MYSQL_BACKUP_PATH}${i}-`date +%F`.sql done /bin/tar -zcvf ${MYSQL_BACKUP_PATH}${DATABASES}-`date +%F`.tar.gz *.sql /bin/rm -rf ${MYSQL_BACKUP_PATH}*.sql done\tif [ $? -eq 0 ];then /bin/curl -X POST \"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=${DATABASES_1} ${DATABASES_2} 数据库备份完成\" else /bin/curl -X POST \"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage\" -d \"chat_id=${TELEGRAM_GROUP_ID}\u0026text=${DATABASES_1} ${DATABASES_2} 数据库备份失败\" fi } /bin/find ${MYSQL_BACKUP_PATH} -name \"databases-*\" -mtime +15 -exec rm {} \\; EOF 数据库还原 数据库还原、导入 # 第一种方式 $ /bin/mysql -u root -p'passowrd' -S /opt/data/data_16303/mysql.sock \u003c /root/all.sql # 第二种方式 mysql\u003e use mysql; mysql\u003e source /root/databases.sql # 当前目录绝对路径 .qp文件数据库恢复 $ xbstream -x -p 4 \u003c ./databases.qp -C /opt/mysql/backup 使用percona备份工具 Linux运维 mysql数据库的备份与恢复 innobackupex备份恢复+增量备份与恢复 innobackupex：更多高级管理功能和自动化备份脚本 xtrabackup：需要基本的物理备份和恢复功能，并且愿意手动管理备份流程 安装XtraBackup # 添加yum源 $ wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo # 安装依赖包 $ yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL # 下载rpm包 $ wget https://downloads.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.27/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.27-1.el7.x86_64.rpm # 安装 $ yum -y install percona-xtrabackup-24-2.4.27-1.el7.x86_64.rpm 手动备份 完整以及增量备份 # 完整备份 $ innobackupex --host=IP --user=name --password=123456 --prot=3306 --no-timestamp /opt/backup/ # 增量备份 基于全量备份实现增量备份，增量备份只支持Innodb $ innobackupex --host=IP --user=root --password=123456 --prot=3306 --no-timestamp --incremental /opt/backup/ --incremental-basedir=/opt/backup/$(date +%F_%T) 数据库恢复流程 --decompress该选项表示解压--compress选项压缩文件 --parallel该选项表示允许多个文件同时解压。为了解压，qpress工具必须有安装并且访问这个文件的权限。这个进程将在同一个位置移除原来的压缩/加密文件 --apply-log该选项表示同xtrabackup的--prepare参数,一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据 文件仍处理不一致状态 --apply-log的作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态 # 1.拷贝备份到data3306(只拷贝日期文件夹下面的文件) # 2.cd /opt/data3306 $ innobackupex --defaults-file=/opt/conf/my_3306.cnf --decompress --parallel=8 ./ # 3.删除所有.qp文件 # 4.恢复数据库(全量) $ cd /opt/data3306 $ innobackupex --defaults-file=/opt/conf/my_3306.cnf --apply-log --use-memory=4G ./ 手动恢复 $ service mysql stop # 初始化全量备份 $ innobackupex --apply-log --redo-only /opt/backup/ --incremental-dir=/opt/backup/$(date +%F_%T) # 初始化整合增量备份 $ innobackupex --apply-log --redo-only /data/backup/2017-08-24_22-57-43 --incremental-dir=/data/backup/2017-08-24_23-10-21 # 把整合好的增量再次初始化 $ innobackupex --apply-log /data/backup/2017-08-24_22-57-43 # 备份MySQL下data数据目录要恢复的数据库 $ mv /usr/local/mysql/data/ceshi/ /opt/backup/$(date +%F_%T)/ # 把整合后的全量备份目录下要恢复的数据库复制到MySQL下data目录 $ cp -a /opt/backup/quanliang/ceshi /usr/local/mysql/data/ # 重新赋予属组mysql权限 $ chown -R mysql.mysql /usr/local/mysql/data/ # 启动数据库 $ service mysql start 使用--copy参数实现备份恢复 $ service mysql stop # 把data数据目录下数据进行备份 $ cp -a /usr/local/mysql/data/* /opt/backup/$(date +%F_%T)/ # 把要恢复的数据备份生成 $ innobackupex --apply-log --redo-only /opt/backup/quanliang/ceshi_danku/ # 这个是单库备份目录 # data目录必须为空 $ innobackupex --copy-back /opt/backup/quanliang/ceshi_danku/ # 重新赋予属组权限 $ chown -R mysql.mysql /usr/local/mysql/data/ $ service mysql start 使用Mysql脚本备份并通知钉钉接口 $ cat \u003e/opt/script/Backup_Mysql_innobackupex.sh\u003c\u003c-EOF #!/bin/bash ## ***************************************************************# ## Create: DBA ## ***************************************************************# ## echo `hostname -I` |sed 's/ /#/g' - \u003e/tmp/ipaddr.txt # 定义Telegram 机器人ID和报警组 TELEGRAM_BOT_ID='Telegram bot_id:bot_key' TELEGRAM_GROUP_ID='GROUP_ID' IP_ADDRE=$(hostname -I |awk '{print $1}') USER_NAME='backup' USER_PASSWORD='IvV8BhpvHb/7EA==' DATABASES='databases name' backup_time=`date +'%Y%m%d%m'` backup_base=\"/opt/backup/dbback\" backup_dir=\"$backup_base/full\" backup_log=\"$backup_base/log/xtra_${backup_time}.log\" slave_days=0 ## 钉钉接口 function SendToDingding_error(){ #Dingding_Url=\"https://oapi.dingtalk.com/robot/send?access_token=d5201a579163dc6045b6da6d8dbc1cdc1d935698050971ceddb5a8956e9507ee\" Dingding_Url=\"https://api.telegram.org/bot${TELEGRAM_BOT_ID}/sendMessage?chat_id=${TELEGRAM_GROUP_ID}\u0026text=%22${IP_ADDRE}mysqlbak%20failure!Please check %22\" # 发送钉钉消息 curl \"${Dingding_Url}\" -H 'Content-Type: application/json' -d \" { \\\"actionCard\\\": { \\\"title\\\": \\\"$1\\\", \\\"text\\\": \\\"$2\\\", \\\"hideAvatar\\\": \\\"0\\\", \\\"btnOrientation\\\": \\\"0\\\", \\\"btns\\\": [ { \\\"title\\\": \\\"$1\\\", \\\"actionURL\\\": \\\"\\\" } ] }, \\\"msgtype\\\": \\\"actionCard\\\" }\" } ## 安装备份工具 innobackupex 或 xtrabackup if [ ! -x /usr/bin/innobackupex ];then yum -y install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm yum -y install percona-xtrabackup-24 qpress fi ## 开始创建目录 if [ ! -d ${backup_dir} ];then mkdir -p ${backup_dir} fi if [ ! -d ${backup_base}/log ];then mkdir -p ${backup_base}/log fi start_time=`date +'%Y%m%d_%H:%M:%S'` start_file=`date +'%Y-%m-%d_%H-%M-%S'` ## 开始备份数据库 echo -e \"`date +'%Y-%m-%d %H:%M:%S'` 开始物理备份数据库 ${ipaddr} ...\" \u003e\u003e ${backup_log} /usr/bin/innobackupex --defaults-file=/opt/conf/my_16303.cnf --user=${backup_user} --password=${backup_password} --host='localhost' --socket=/opt/data/data_16303/mysql.sock --use-memory=1G --compress --compress-threads=32 --parallel=3 --slave-info ${backup_dir} 2\u003e\u003e${backup_log} if [ $? -ne 0 ];then echo -e \"`date +'%Y%m%d_%H:%M:%S'` 备份数据库发生错误,具体看日志\" \u003e\u003e ${backup_log} Subject=\"物理备份xtra备份失败\" Body=\"'${ipaddr}'_物理备份失败,请参考日志:${backup_log}\" SendToDingding_error $Subject $Body exit 1 fi cd ${backup_dir} file_time=`date +'%Y-%m-%d'` flie_name=`ls -l | grep \"$file_time\"|tail -n 1|awk '{print $9}'` tar -zcf ${file_time}.tar.gz ${flie_name} rm -rf ${flie_name} ## rsync -avz if [ ! -z \"`tail -1 ${backup_log} | grep 'completed OK'`\" ]; then finish_time=`date +'%Y%m%d_%H:%M:%S'` file_size=`du -sm ${backup_dir} |awk '{print $1}'` echo -e \"${ipaddr}数据库xtrabackup物理备份工作完成!\\n 开始时间：${start_time} 结束时间：${finish_time}\\n 备份目录${backup_dir}\\n 备份文件大小${file_size} MB\" \u003e\u003e ${backup_log} # 删除以前的备份 echo -e \"`date +'%Y%m%d_%H:%M:%S'` 开始删除${slave_days}天以前的备份\" \u003e\u003e ${backup_log} cd ${backup_base} for tfile in $(/usr/bin/find ${backup_dir} -mindepth 1 -maxdepth 1 -mtime +${slave_days}) do cd ${backup_dir} \u0026\u0026 rm -rf ${tfile} 2\u003e\u003e${backup_log} echo -e \"---- delete file :${file} -----\" \u003e\u003e ${backup_log} done echo -e \"`date +'%Y%m%d_%H%M%S'` 删除${slave_days}天以前的备份-完成\" \u003e\u003e ${backup_log} find $backup_base/log -mindepth 1 -maxdepth 1 -mtime +${slave_days} -type f |xargs rm -f else echo -e \"`date +'%Y%m%d_%H:%M:%S'` 备份数据库发生错误,具体看日志\" \u003e\u003e ${backup_log} Subject=\"物理备份xtra备份失败\" Body=\"${ipaddr}_物理备份失败,请参考日志:${backup_log}\" SendToDingding_error $Subject $Body fi exit EOF 查看、导出、清理binlog日志 查看binlog # 指定查询 mysql-bin.000002这个文件，从pos点:624开始查起，偏移2行（即中间跳过2个），查询10条 mysql\u003e show binlog events in 'mysql-bin.000002' from 624 limit 2,10\\G; 导出数据库binlog日志 --base64-output=：decode-rows将行事件解码为注释伪SQL语句 --no-defaults --database=\"数据库名\"：仅列出此数据库的条目(仅限本地日志) --start-datetime=''：开始时间参数必须是本地时区的日期和时间，格式不限MySQL服务器接受DATETIME和TIMESTAMP类型，例如：2004-12-25 11:25:56 --stop-datetime=''：结束时间参数必须是本地时区的日期和时间，格式不限MySQL服务器接受DATETIME和TIMESTAMP类型，例如：2004-12-25 11:25:56 --start-position=875：偏移量开始读取位置 --stop-position=954：偏移量停止读取位置 -v：从行事件中重建伪SQL语句，-vv添加对列数据类型的注释 -r：直接输出到给定的文件 $ /bin/mysqlbinlog \\ --base64-output=decode-rows \\ --no-defaults --database=\"数据库名\" \\ --start-datetime='2019-04-11 00:00:00' \\ # 开始时间 --stop-datetime='2019-04-11 15:00:00' \\ # 结束时间 -v /opt/data/mysql/mysql-bin.000007 \\ -r /opt/binlog`date '+%F'`.sql # 方法二 $ /bin/mysqlbinlog \\ --no-defaults --database=db \\ --start-datetime='2019-04-11 00:00:00' \\ --stop-datetime='2019-04-11 15:00:00' mysql-bin.000007 | more mysqlbinlog \\ --base64-output=decode-rows \\ --start-position=2966 \\ --stop-position=2966 \\ -v mysql-bin.000125 2.1 从binlog日志中得DELETE删除换成INSERT INTO插入语句 mysql binlg delete语句解析为insert语句\n# 过滤非删除语句 $ sed -n '/^###/'p /opt/binlog`date '+%F'`.sql \u003e/opt/binlog`date '+%F'`.sql # 去掉#号 $ sed 's/### //g' /opt/binlog`date '+%F'`.sql \u003e/opt/binlog`date '+%F'`.sql $ sed 's#/\\*.*\\*/#,#g' c.txt \u003ed.txt # 如果有富文本里面含注释语句容易出错可以更精细匹配 $ sed 's#/\\*.*\\*/### @#,#g' c.txt \u003ed.txt $ cat /opt/binlog`date '+%F'`.sql $ find /path/to/binlog/directory -name \"binlog.*\" -printf \"%T@ %p\\n\" | sort -n | cut -d' ' -f2- | xargs mysqlbinlog \u003e combined_binlog.sql $ find ./ -name \"mysql-bin.266*\" -printf \"%T@ %p\\n\" | sort -n | cut -d' ' -f2- | xargs /usr/local/mysql/bin/mysqlbinlog -vv --base64-output=DECODE-ROWS --set-charset=UTF8 mysql-bin.266770 --database=databases_name -r new_binlog.sql ##### 解析binlog并还原成插入语句 ##### $ /usr/local/mysql/bin/mysqlbinlog -vv --base64-output=DECODE-ROWS --set-charset=UTF8 mysql-bin.merged.9 --database=databases_name \u003e\u003e/mnt/new_binlog.sql # 只过滤某个数据库中的某个表中的删除语句 $ cat new_binlog.sql | awk '/DELETE FROM/ \u0026\u0026 (/databases_name.tables_name/ || /`databases_name`.`tables_name`/) { while(1) { print $0; getline; if($0 !~ /^###/) { break; }; }}' \u003e new_binlog-1.sql # 去掉：### $ cp new_binlog-1.sql new_binlog-2.sql $ sed -i 's/^### //g' new_binlog-2.sql # 删除语句替换为插入语句 $ cp new_binlog-2.sql new_binlog-3.sql $ sed -i \"s/^DELETE FROM/INSERT INTO/g\" new_binlog-3.sql # 条件替换为值 $ cp new_binlog-3.sql new_binlog-4.sql $ sed -i \"s/^WHERE/VALUES(/g\" new_binlog-4.sql # @21 这里要看解析后的具体行数， $ cp new_binlog-4.sql new_binlog-5.sql $ sed -i '/@21=.*/a );' new_binlog-5.sql $ cat new_binlog-5.sql | awk -F\"=|/*\" '{ if($0 ~ /^INSERT|^VALUES|^);/) { print $0; } else { printf $2\",\"; };}' \u003enew_binlog-6.sql $ cp new_binlog-6.sql new_binlog-7.sql $ sed -i \"s/,);$/);/g\" new_binlog-7.sql $ cp new_binlog-7.sql new_binlog-8.sql $ sed -i 's/,INSERT/);INSERT/g' new_binlog-8.sql 清理binlog 3.1 mysql binlog日志自动清理及手动删除、Mysql清理binlog # 清除MySQL-bin.010日志 mysql\u003e PURGE MASTER LOGS TO 'MySQL-bin.010'; # 清除2008-06-22 13:00:00前binlog日志 mysql\u003e PURGE MASTER LOGS BEFORE '2008-06-22 13:00:00'; # 清除3天前binlog日志BEFORE，变量的date自变量可以为'YYYY-MM-DD hh:mm:ss'格式。 mysql\u003e PURGE MASTER LOGS BEFORE DATE_SUB( NOW( ), INTERVAL 3 DAY); 创建、授权、删除用户 创建、授权 5.7.*一下创建以及授权 mysql\u003e grant all on *.* to root@'10.14.23.%' identified by '123456'; # 192.168.%.% 表示网段 mysql\u003e grant all privileges on database.tables to 'user'@'localhost' identified by \"password\"; Myslq 8.0语句执行，8.0版本之后创建用户和授权分开了 # 创建用户 mysql\u003e CREATE USER 'username'@'127.0.0.1' IDENTIFIED BY 'passowrd'; # 授予权限 mysql\u003e GRANT ALL ON *.* TO 'username'@'127.0.0.1' WITH GRANT OPTION; # 删除权限 mysql\u003e REVOKE all privileges ON databasename.tablename FROM 'username'@'host'; 创建从库用户并授复制权限 MySQL\u003e grant replication slave, replication client on *.* to 'lisi'@'10.14.23.%' identified by '123456'; 撤销用户权限 mysql\u003e REVOKE privilege ON databasename.tablename FROM 'username'@'host'; 删除用户、数据 mysql\u003e drop user 'username'@'host'; # 如果是当前登陆用户用SET PASSWORD = PASSWORD(\"newpassword\"); mysql\u003e delete from 表名 where 列名=‘xx’ and 列名='xx'; # 授权查看数据库用户（clint） mysql\u003e delete from mysql.user where user=\"slave\" and host=\"10.14.23.%\"; 创建库、表 创建库 mysql\u003e create database db2 character set utf8 collate utf8_general_ci; 创建表 NOT NULL：每一行都必须含有值（不能为空），null值是不允许的 DEFAULT value：设置默认值 UNSIGNED：使用无符号数值类型，0及正数 AUTO INCREMENT：设置MySQL字段的值在新增记录时每次自动增长1 mysql\u003e create table databases_name.tables_name(id int not null, name varchar(50)not null); Query OK, 1 row affected (0.00 sec) # not null 不为空 # 设置数据表中每条记录的唯一标识。 通常列的 PRIMARY KEY 设置为 ID 数值，与AUTO_INCREMENT 一起使用。 mysql\u003e insert into `databases_name`.`tables_name`(name) values('lisi'); Query OK, 1 row affected (0.00 sec) # 不写id mysql\u003e insert into `databases_name`.`tables_name`(id,content,add_time) values(4,'Text','2023-01-11 02:52:54'); 按日期删除表 mysql\u003e USE example_db; mysql\u003e SELECT table_name FROM information_schema.tables WHERE table_schema = 'example_db'; mysql\u003e SELECT CONCAT('DROP TABLE IF EXISTS ', table_name, ';') AS sql_statement FROM information_schema.tables WHERE table_schema = 'example_db'; mysql\u003e SELECT table_name FROM information_schema.tables WHERE table_name LIKE 'prefix_%' AND table_name BETWEEN 'prefix_2022-02-01' AND 'prefix_2022-03-01'; mysql\u003e SELECT CONCAT('DROP TABLE IF EXISTS ', table_name, ';') AS sql_statement FROM information_schema.tables WHERE table_name LIKE 'prefix_%' AND table_name BETWEEN 'prefix_2022-02-01' AND 'prefix_2022-03-01'; 查询库、表容量大小 查询所有库容量大小 mysql\u003e SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables group by table_schema order by sum(data_length) desc, sum(index_length) desc; 查看指定库的容量大小 查看MySQL「指定库」的容量大小：database_name更改为要查询的库 mysql\u003e SELECT table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(DATA_FREE/1024/1024, 2)) as '碎片占用(MB)' from information_schema.tables where table_schema='database_name' order by data_length desc, index_length desc; 查看指定库中所有表的容量大小 查看MySQL「指定库」中「所有表」的容量大小 mysql\u003e SELECT table_schema as '数据库', table_name as '表名', table_rows as '记录数', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', truncate(DATA_FREE/1024/1024, 2) as '碎片占用(MB)' from information_schema.tables where table_schema='database_name' order by data_length desc, index_length desc; 查看指定库中指定表的容量大小 查看MySQL「指定库」中「指定表」的容量大小：将代码中database_name数据库名改为你要查询的数据库名，tables_name改为你要查询的表名 mysql\u003e SELECT table_schema as '数据库', table_name as '表名', table_rows as '记录数', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', truncate(DATA_FREE/1024/1024, 2) as '碎片占用(MB)' from information_schema.tables where table_schema='database_name'and table_name='tables_name' order by data_length desc, index_length desc; # 查询并且进行AES解码 mysql\u003e select aes_decrypt(from_base64(mobile),'key','加密掩码') from yl_users where member = ''; 排查Mysql占用内存原因 # 查看MySQL的Pid $ ps -ef | grep -i mysqld # 查看MySQL实时操作系统线程Pid $ top -p \"Mysql Pid\" -H # 数据库中查看Pid 具体操作内容 Mysql\u003e SELECT THREAD_ID,name ,PROCESSLIST_ID FROM `performance_schema`.threads WHERE THREAD_OS_ID =\"Mysql Pid\"; # 根据获取到MySQL中的 Thread_id 获取SQL mysql\u003e SELECT SQL_TEXT FROM `performance_schema`.events_statements_current WHERE THREAD_ID = Thread_id; ########################### mysql\u003e SELECT VARIABLE_NAME,VARIABLE_VALUE, CONCAT(VARIABLE_VALUE/1024/1024,' MB') AS VARIABLE_VALUE_MB FROM information_schema.SESSION_VARIABLES WHERE VARIABLE_NAME IN ('innodb_buffer_pool_size','innodb_log_buffer_size','innodb_additional_mem_pool_size','key_buffer_size','query_cache_size'); mysql\u003e SHOW VARIABLES LIKE '%show_compatibility_56%'; mysql\u003e SET GLOBAL show_compatibility_56=on; 其他命令 # MySQL-master,查看数据库偏移量 mysql\u003e show master status; mysql\u003e reset master; # 清理reset日志 # 从库执行，测试连接主库 mysql\u003eshow grants; mysql\u003e mysql_secure_installation # mysql安全配置 Enter current password for root (enter for none): # 输入进入数据库密码，默认为空，按回车 Set root password? [Y/n] # 设置mysql数据库root用户的密码 Remove anonymous users? [Y/n] # 移除匿名用户Y Disallow root login remotely? [Y/n] # 不允许root用户远程登陆Y Remove test database and access to it? [Y/n] # 移除test数据库和访问Y Reload privilege tables now? [Y/n] # 筛选数据不同值 mysql\u003e select distinct 列名 from 表名; mysql\u003e select * from 表名 where 列名 \u003e 15 and (列名='选项' or 列名='选项'); mysql\u003e select * from 表名 order by 列名、列名 desc(降序)、asc(升序、默认升序); mysql\u003e select * from 表名 limit 2 # 查看前两条数据 mysql\u003e select * from 表名 where 列名 like '首个关键字%'; # %匹配所有 mysql\u003e select * from 表名 where 列名 not like '%xx%'; # 反向查找 mysql\u003e select * from 表名 where 列名 in ('关键字',‘关键字’)； mysql\u003e select * from 表名 where 列名 between 1 and 20; # 选取1到20之间 mysql\u003e select * from 表名 where 列名 not between 1 and 20; # 取反 mysql\u003e select * from 表名 where (列名 between 1 and 20) and 列名 not in ('关键字')； # 更新、更改数据数据以及用户权限 mysql\u003e update 表名 set 列名='333', 列名='cn' where 列名='xxx'; mysql\u003e update user set host = '%' where user = 'root'; # 修改数据库同步线程mysql mysql\u003e set global sync_binlog=20; mysql\u003e set global innodb_flush_log_at_trx_commit=2; # 修改sql线程数 mysql\u003e STOP SLAVE SQL_THREAD; mysql\u003e SET GLOBAL slave_parallel_type='LOGICAL_CLOCK'; mysql\u003e SET GLOBAL slave_parallel_workers=8; mysql\u003e START SLAVE SQL_THREAD;\tMySQL查询锁表语句 MySQL查询锁表语句 查询是否锁表 mysql\u003e show OPEN TABLES where In_use \u003e 0; 查看正在锁的事务 mysql\u003e SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 查看等待锁的事务 mysql\u003e SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 查看当前的事务 mysql\u003e SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX; 查看当前锁定的事务 mysql\u003e SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 查看当前等锁的事务 mysql\u003e SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 查询死锁详情 mysql\u003e SELECT r.trx_id waiting_trx_id,r.trx_mysql_thread_id waiting_thread, TIMESTAMPADD(SECOND,r.trx_wait_started,CURRENT_TIMESTAMP) wait_time, r.trx_query waiting_query, l.lock_table waiting_table_lock, b.trx_id blocking_trx_id,b.trx_mysql_thread_id blocking_thread, SUBSTRING(p.`HOST`,1,INSTR(p.`HOST`,':')-1) blocking_host, SUBSTRING(p.`HOST`,INSTR(p.`HOST`,':')+1) blocking_port, IF(p.COMMAND ='Sleep',p.TIME,0) idle_in_trx, b.trx_query blocking_query from information_schema.INNODB_LOCK_WAITS w INNER JOIN information_schema.INNODB_TRX b ON b.trx_id = w.blocking_lock_id INNER JOIN information_schema.INNODB_TRX r ON r.trx_id = w.requesting_trx_id INNER JOIN information_schema.INNODB_LOCKS l ON l.lock_id = w.requested_lock_id LEFT JOIN information_schema.`PROCESSLIST` p ON p.id = b.trx_mysql_thread_id ORDER BY wait_time desc; 配置数据库主从复制 主数据库配置以及授权 # 修改ID $ server_id=`hostname -I |awk \"{print $1}\"|awk -F\".\" \"{print $4}\"` $ sed -i \"s/server-id = 16303110/server-id = 16303$server_id/g\" /etc/my.cnf # 授权从库连接账户密码 mysql\u003e grant replication slave on *.* to myuser@'host IP' identified by 'password'; mysql\u003e flush privileges; mysql\u003e reset master; \" 配置从库连接主库 # 修改ID $ server_id=`hostname -I |awk '{print $1}'|awk -F'.' '{print $4}'` $ sed -i \"s/server-id = 16303110/server-id = 16303$server_id/g\" /etc/my.cnf # 配置连接主库 $ /usr/local/mysql/bin/mysql -uroot -p -S /tmp/mysql.sock \\ -e \"CHANGE MASTER TO MASTER_HOST='127.0.0.1', \\ MASTER_USER='myuser', \\ MASTER_PASSWORD='password', \\ MASTER_PORT=16303, \\ MASTER_LOG_FILE='mysql-bin.000001', \\ # 主机show master status;中的File MASTER_LOG_POS=154,MASTER_CONNECT_RETRY=15;\" # 主机show master status;中的Position. $ /usr/local/mysql/bin/mysql -uroot -p -S /tmp/mysql.sock -e \"start slave;\" $ /usr/local/mysql/bin/mysql -uroot -p -S /tmp/mysql.sock -e \"show slave status\\G\" 2.1 配置多源复制 $ /usr/local/mysql/bin/mysql -uroot -p -S /tmp/mysql.sock \\ -e \"CHANGE MASTER TO MASTER_HOST='127.0.0.1', \\ MASTER_USER='myuser', \\ MASTER_PASSWORD='password', \\ MASTER_PORT=16303, \\ master_auto_position=1 for channel 'rep_master_1';\" # 协商、定义频道几个主机定义几次。 数据库开启GTID流程 # 如果可以先暂停业务，查询是否还有业务连接 mysql\u003e show processlist; # 主从依次执行：主库执行好后，去从库执行 ，再执行下一个命令 mysql\u003e SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY=WARN; # 查询主从错误日志，看看是否有报错，在做下一步 # 主库执行好后，去从库执行 ，再执行下一个命令 mysql\u003e SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY=ON; # 主库执行好后，去从库执行 ，再执行下一个命令 mysql\u003e SET @@GLOBAL.GTID_MODE=OFF_PERMISSIVE; # 主库执行好后，去从库执行 ，再执行下一个命令 mysql\u003e SET @@GLOBAL.GTID_MODE=ON_PERMISSIVE; # 从库查询：等待从库这个状态变为0 mysql\u003e show status like 'ONGOING_ANONYMOUS_TRANSACTION_COUNT'; # 主从执行： mysql\u003e SET @@GLOBAL.gtid_mode=on; # 从库执行： mysql\u003e stop slave; mysql\u003e change master to master_auto_position=1; mysql\u003e start slave; Mysql开启日志审计 # 连接数据库执行语句： mysql\u003e CREATE TABLE `mysql`.`audit_login` ( `ID` bigint NOT NULL AUTO_INCREMENT COMMENT '自增ID', `USER` varchar(128) NOT NULL COMMENT '数据库中的用户', `HOST` varchar(64) DEFAULT NULL COMMENT '登录的IP', `DB` varchar(64) DEFAULT NULL COMMENT '访问的数据库', `PROCESSLIST_ID` bigint NOT NULL COMMENT '用户连接', `LOGIN_TIME` datetime(3) DEFAULT CURRENT_TIMESTAMP(3) COMMENT '登录时间', `UPDATE_TIME` datetime(3) DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT '记录这行数据上次被修改的时间,默认等于LOGIN_TIME', PRIMARY KEY (`ID`), KEY `IDX_USER` (`USER`), KEY `IDX_HOST` (`HOST`), KEY `IDX_LOGIN_TIME` (`LOGIN_TIME`) ) ENGINE=InnoDB COMMENT \"用户登录审计日志表\"; # 查询授权SQL，复制查询出来的SQL语句，执行授权 mysql\u003e select concat(\"grant select,insert on mysql.audit_login to '\",user,\"'@'\",host,\"';\") grants_sql from mysql.user where user not in ('mysql.session','mysql.sys') and Super_priv='N'; # 执行： mysql\u003e set global init_connect=\"insert into mysql.audit_login(USER,HOST,DB,PROCESSLIST_ID) values(current_user(),substring_index(user(),'@',-1),database(),connection_id());\"; # 配置参数文件： [mysqld] init_connect=\"insert into mysql.audit_login(USER,HOST,DB,PROCESSLIST_ID) values(current_user(),substring_index(user(),'@',-1),database(),connection_id());\"; #DBA add # 最后执行看看有没有数据： mysql\u003e select * from mysql.audit_login; 主从跳过复制错误 主从跳过复制错误 # 停止复制 mysql\u003e slave stop; # 设定跳过一个事务 mysql\u003e SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1 # 重新开启复制 mysql\u003eslave start # 这样就正常了，但是，当然还是要把数据修改上去 mysql\u003eupdate tables set 。。。。。。。 SQL优化、审核平台工具 安装YearningSQL审核工具 默认账号/密码：admin/Yearning_admin $ yum -y install wget unzip $ wget -P /opt/src/ https://github.com/cookieY/Yearning/releases/download/v3.1.0/Yearning-v3.1.0-linux-amd64.zip $ unzip -d /opt/yearning /opt/src/Yearning-v3.1.0-linux-amd64.zip $ sed -i \"s/Port = \"3306\"/Port = \"16303\"/g\" /opt/apps/yearning/conf.toml $ sed -i \"s/Password = 'xxxx'/Password = 'p@ssw0rd'/g\" /opt/apps/yearning/conf.toml $ /bin/mysql -uroot \\ -S /opt/data/data_16303/mysql.sock \\ -p -e \"create database Yearning DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\" $ bin/mysql -uroot \\ -S /opt/data/data_16303/mysql.sock \\ -p -e \"grant all on *.* to root@'127.0.0.1' identified by \"p@ssw0rd\";\" $ ./Yearning install # 先初始化 $ ./Yearning run $ ./Yearning run --push \"域名、或者IP地址\" --port \"8000\" # 指定域名端口方式启动 安装美团SQL优化工具SQL-Advisor MySQL-SQLAdvisor的简单安装使用 美团点评SQL优化工具SQLAdvisor开源 $ yum -y install git wget cmake libaio-devel libffi-devel glib2 glib2-devel $ yum -y install --enablerepo=Percona56 Percona-Server-shared-56 $ git clone https://github.com/Meituan-Dianping/SQLAdvisor.git /opt/src/sqladvisor $ cd /opt/src/sqladvisor $ cmake -DBUILD_CONFIG=mysql_release \\ -DCMAKE_BUILD_TYPE=debug \\ -DCMAKE_INSTALL_PREFIX=/usr/local/sqlparser ./ $ make \u0026\u0026 make install # 1. DCMAKE_INSTALL_PREFIX为sqlparser库文件和头文件的安装目录，其中lib目录包含库文件libsqlparser.so，include目录包含所需的所有头文件。 # 2. DCMAKE_INSTALL_PREFIX值尽量不要修改，后面安装依赖这个目录。 $ cd SQLAdvisor/sqladvisor/ $ cmake -DCMAKE_BUILD_TYPE=debug ./ $ make # 在本路径下生成一个sqladvisor可执行文件，这即是我们想要 $ cat \u003esql.cnf\u003c\u003c-EOF [sqladvisor] username=xx password=xx host=xx port=xx dbname=xx # sqls=sql1;sql2;sql3.... EOF # cmd: ./sqladvisor -f sql.cnf -v 1 监听MySQL binlog实现数据变化后的实时通知 Github Alibaba Canal explain的使用 Mysql优化高级篇 explain+sql语句 mysql\u003e explain select * from Tables_name; id：表的读取顺序 select_type：数据读取操作的操作类型 possible_keys：哪些索引可以使用 key：哪些索引被实际使用 ref：表之间的引用 rows：每张表有多少行被优化器查询 SQL审计 MySQL审计插件介绍 # 进入数据库安装审计插件 mysql\u003e INSTALL PLUGIN server_audit SONAME 'server_audit.so'; Query OK, 0 rows affected (0.07 sec) mysql\u003e show plugins; +----------------------------+--------+--------------------+-----------------+---------+ | Name | Status | Type | Library | License | +----------------------------+--------+--------------------+-----------------+---------+ ... | SERVER_AUDIT | ACTIVE | AUDIT | server_audit.so | GPL | +----------------------------+--------+--------------------+-----------------+---------+ # 查看 audit 初始参数配置 mysql\u003e show variables like '%audit%'; +-------------------------------+-----------------------+ | Variable_name | Value | +-------------------------------+-----------------------+ | server_audit_events | | | server_audit_excl_users | | | server_audit_file_path | server_audit.log | | server_audit_file_rotate_now | OFF | | server_audit_file_rotate_size | 1000000 | | server_audit_file_rotations | 9 | | server_audit_incl_users | | | server_audit_loc_info | | | server_audit_logging | OFF | | server_audit_mode | 1 | | server_audit_output_type | file | | server_audit_query_log_limit | 1024 | | server_audit_syslog_facility | LOG_USER | | server_audit_syslog_ident | mysql-server_auditing | | server_audit_syslog_info | | | server_audit_syslog_priority | LOG_INFO | +-------------------------------+-----------------------+ # 在线开启审计 mysql\u003e set global server_audit_logging=on; Query OK, 0 rows affected (0.00 sec) mysql\u003e set global server_audit_events='connect,table,query_ddl,query_dcl,query_dml_no_select'; Query OK, 0 rows affected (0.00 sec) mysql\u003e set global server_audit_file_path ='/data/mysql/logs/server_audit.log'; Query OK, 0 rows affected (0.00 sec) mysql\u003e set global server_audit_file_rotate_size=104857600; Query OK, 0 rows affected (0.01 sec) # [mysqld]下添加以下配置 使得永久生效 server_audit=FORCE_PLUS_PERMANENT server_audit_logging=ON server_audit_file_path=/data/mysql/logs/server_audit.log server_audit_events=connect,table,query_ddl,query_dcl,query_dml_no_select server_audit_file_rotate_size=104857600 ",
    "description": "数据库使用 数据结构可视化 数据结构可视化 数据库连接工具 名称地址 描述 WorkBenCh MySQL产品档案 下载MySQL-8.0的索引 Mysql深入学习笔记 SQLyog数据库客户端连接工具 DBeaver数据库客户端连接工具 Mysql WorkBenCh菜单中文汉化 Navicat Premium 15安装与激活 Navicat Premium 16下载与安装破解教程 使用通用二进制文件在Unix/Linux 安装MySQL Navicat Premium 15永久破解激活工具及安装教程 数据库常用命令 数据库命令 说明 举例 select 从数据库中提取数据 查看用户数据：select user,host from mysql.",
    "tags": [],
    "title": "Use_Mysql",
    "uri": "/systems/linux/databases/use_mysql/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Databases",
    "content": "部署Mysql 5.7 从0开始搭建SQL Server AlwaysOn第四篇-配置异地机房节点 Mysql产品档案 安装扩展下载Mysql并解压安装包 # Debian系统 $ sudo apt-get install build-essential cmake bison libncurses5-dev libssl-dev pkg-config g++ libaio1 libnuma1 libncurses5 # CentOS $ yum -y remove mariadb* mariadb $ yum -y install numactl libaio* wget git epel-release $ yum -y install https://mirrors.cloud.tencent.com/percona/release/7/RPMS/noarch/percona-release-0.1-4.noarch.rpm $ sed -i \"s/gpgcheck = 1/gpgcheck = 0/g\" /etc/yum.repos.d/percona-release.repo $ yum -y install percona-xtrabackup-24 qpress $ wget -P /usr/local/src/ https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz $ tar -zxvf /usr/local/src/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz -C /usr/local/src/ $ cp -r /usr/local/src/mysql-5.7.28-linux-glibc2.12-x86_64 /usr/local/mysql 设置权限 $ groupadd mysql $ useradd -r -g mysql mysql $ cd /usr/local/ $ chown -R mysql:mysql ./mysql 初始化数据库 $ cd /usr/local/mysql/ $ bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data $ bin/mysql_ssl_rsa_setup --datadir=/usr/local/mysql/data $ chown -R mysql:mysql /usr/local/mysql 修改配置文件 $ mysqld --verbose --help # 查看完整列表 $ echo '[mysqld] character_set_server=utf8 init_connect='SET NAMES utf8' basedir=/usr/local/mysql datadir=/usr/local/mysql/data # 数据目录最好外挂 socket=/tmp/mysql.sock ## 开启binlog log-bin = mysql-bin binlog_format = ROW expire_logs_days = 7 server-id=3306110 # 端口加本机IP最后几位 ## 不区分大小写 lower_case_table_names = 1 ## 不开启sql严格模式 sql_mode = \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\" log-error=/usr/local/mysql/data/mysqld.log pid-file=/usr/local/mysql/data/mysqld.pid' \u003e /etc/my.cnf 修改启动文件配置参数并启动数据库 $ mysqlconf=/etc/init.d/mysqld $ cp /usr/local/mysql/support-files/mysql.server $mysqlconf $ sed -i '46s,basedir=,basedir=/usr/local/mysql,' $mysqlconf $ sed -i '47s,datadir=,datadir=/usr/local/mysql/data,' $mysqlconf # 启动数据库 $ service mysqld start # 添加软连接 $ ln -s /usr/local/mysql/bin/mysql /usr/bin # 查看端口号 $ netstat -nuplt | grep :3306 # 防火墙开放端口 $ firewall-cmd --permanent --new-ipset=db_whitelist --type=hash:ip $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='db_whitelist' port port='16303' protocol='tcp' accept\" $ firewall-cmd --reload 安装Mysql 8 安装扩展下载Mysql并解压安装包 $ yum -y remove mariadb* mariadb $ yum -y install ncurses-compat-libs wget git epel-release $ yum -y install https://mirrors.cloud.tencent.com/percona/release/7/RPMS/noarch/percona-release-0.1-4.noarch.rpm $ sed -i \"s/gpgcheck = 1/gpgcheck = 0/g\" /etc/yum.repos.d/percona-release.repo $ yum -y install percona-xtrabackup-24 qpress numactl libaio* $ wget -P /usr/local/src/ https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz $ mkdir -p /usr/local/mysql \u0026\u0026 tar -xvf /usr/local/src/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -C /usr/local/mysql --strip-components 1 设置权限 $ groupadd mysql $ useradd -r -g mysql mysql $ cd /usr/local/ $ chown -R mysql:mysql ./mysql 初始化数据库 $ /usr/local/mysql/bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data $ /usr/local/mysql/bin/mysql_ssl_rsa_setup --datadir=/usr/local/mysql/data $ /usr/local/mysql/bin/mysqld_safe --datadir=/usr/local/mysql/data $ chown -R mysql:mysql /usr/local/mysql 修改配置文件 $ echo '[mysqld] character_set_server=utf8mb4 init_connect='SET NAMES utf8' basedir=/usr/local/mysql datadir=/usr/local/mysql/data socket=/tmp/mysql.sock ## 开启binlog log-bin = mysql-bin binlog_format = ROW expire_logs_days = 7 server-id=3306110 # 端口加本机IP最后几位 ## 不区分大小写 lower_case_table_names = 1 ## 不开启sql严格模式 ## sql_mode = \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\" sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION' default_authentication_plugin= mysql_native_password log-error=/var/log/mysqld.log pid-file=/usr/local/mysql/data/mysqld.pid' \u003e/etc/my.cnf 修改启动文件配置参数并启动数据库 $ mysqlconf=/etc/init.d/mysqld $ cp /usr/local/mysql/support-files/mysql.server $mysqlconf $ sed -i '46s,basedir=,basedir=/usr/local/mysql,' $mysqlconf $ sed -i '47s,datadir=,datadir=/usr/local/mysql/data,' $mysqlconf # 启动数据库 $ service mysqld start # 添加软连接 $ ln -s /usr/local/mysql/bin/mysql /usr/bin # 查看端口号 $ netstat -nuplt | grep :3306 # 防火墙开放端口 $ firewall-cmd --permanent --new-ipset=db_whitelist --type=hash:ip $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='db_whitelist' port port='16303' protocol='tcp' accept\" $ firewall-cmd --reload 普通用户部署Mysql 8 安装扩展 # Linux8/Red Hat8(EL8)：这些平台默认不安装文件/lib64/libtinfo.so.5，MySQL客户端bin/mysql需要该文件来安装 $ yum -y install ncurses-compat-libs wget git epel-release $ yum -y install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm $ sed -i \"s/gpgcheck = 1/gpgcheck = 0/g\" /etc/yum.repos.d/percona-release.repo $ yum -y install percona-xtrabackup-24 qpress numactl libaio* $ wget -P /usr/local/src/ https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz 创建用户以及程序使用目录 $ groupadd myadmin \u0026\u0026 useradd -g myadmin myadmin # 创建程序运行用户 $ echo \"password\"|passwd --stdin myadmin \u0026\u003e/dev/null $ mkdir -p /opt/{apps,conf,src,backup,scripts,data，logs} /opt/data/{data_16303,data_16304} /opt/logs/mysql $echo \"##### Start/Stop Service ##### Cmnd_Alias MYADMIN_START_SERVICES = /etc/init.d/mysql, /etc/init.d/mysql.server, /opt/* swadmin ALL=(ALL)NOPASSWD:MYADMIN_START_SERVICES \"\u003e/etc/sudoers.d/myadmin $ chmod 660 /etc/sudoers.d/myadmin 编写配置文件，方便使用配置文件初始化数据库 $ echo '[mysqld] character_set_server=utf8mb4 init_connect='SET NAMES utf8' basedir=/opt/apps/mysql datadir=/opt/data/data_16303 socket=/tmp/mysql.sock # 不区分大小写 lower_case_table_names = 1 # 不开启sql严格模式 # sql_mode = \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\" log-error=/opt/logs/mysql/mysqld.log pid-file=/opt/data/data_16303/mysqld.pid' \u003e /opt/conf/mysql/mysql_master_16303.cnf $ chown -R myadmin:myadmin /opt/* 使用普通用户下载安装Mysql 8 $ su myadmin -c \" wget -P /opt/src/ https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz mkdir -p /opt/apps/mysql \u0026\u0026 tar xvf /opt/src/mysql-8.0.21-linux-glibc2.12-x86_64.tar.xz -C /opt/apps/mysql --strip-components 1 chmod 750 /opt/apps/mysql /opt/apps/mysql/bin/mysqld --defaults-file=/opt/conf/mysql/my.cnf --initialize-insecure --user=myadmin sleep 8 /opt/apps/mysql/bin/mysql_ssl_rsa_setup --defaults-file=/opt/conf/mysql/my.cnf sleep 5 /opt/apps/mysql/bin/mysqld_safe --defaults-file=/opt/conf/mysql/my.cnf --user=myadmin \u0026 sleep 8 \" 修改启动文件配置参数并启动数据库 $ mysqlconf=/etc/init.d/mysqld $ cp /opt/apps/mysql/support-files/mysql.serverr $mysqlconf $ sed -i '46s,basedir=,basedir=/opt/apps/mysql,' $mysqlconf $ sed -i '47s,datadir=,datadir=/opt/data/data_16303,' $mysqlconf $ echo \"alias nginx='sudo /etc/init.d/nginx' alias tomcat='sudo /etc/init.d/tomcat' alias mysqld='sudo /etc/init.d/mysqld' alias redis='sudo /etc/init.d/redis' \"\u003e\u003e/home/myadmin/.bashrc # 启动数据库 $ service mysqld start # 添加软连接 $ ln -s /usr/local/mysql/bin/mysql /usr/bin # 查看端口号 $ netstat -nuplt | grep :3306 # 防火墙开放端口 $ firewall-cmd --permanent --new-ipset=db_whitelist --type=hash:ip $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='db_whitelist' port port='16303' protocol='tcp' accept\" $ firewall-cmd --reload ",
    "description": "部署Mysql 5.7 从0开始搭建SQL Server AlwaysOn第四篇-配置异地机房节点 Mysql产品档案 安装扩展下载Mysql并解压安装包 # Debian系统 $ sudo apt-get install build-essential cmake bison libncurses5-dev libssl-dev pkg-config g++ libaio1 libnuma1 libncurses5 # CentOS $ yum -y remove mariadb* mariadb $ yum -y install numactl libaio* wget git epel-release $ yum -y install https://mirrors.",
    "tags": [],
    "title": "Install_Mysql",
    "uri": "/systems/linux/databases/install_mysql/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Daemon",
    "content": "安装Supervisord进程守护服务 安装supervisord Supervisord官网 Supervisord安装与使用 supervisord初体验 使用Supervisord守护php-fpm进程 Supervisord管理redis进程 使用Supervisord管理Redis进程 安装扩展，下载安装包 $ yum install python-setuptools -y # 安装python程序开发过程库 $ cd /usr/local/src/ $ wget https://pypi.python.org/packages/7b/17/88adf8cb25f80e2bc0d18e094fcd7ab300632ea00b601cbbbb84c2419eae/supervisor-3.3.2.tar.gz # 下载安装包 # https://files.pythonhosted.org/packages/0a/ba/52611dc8278828eb9ec339e6914a0f865f9e2af967214905927835dfac0a/setuptools-63.2.0.tar.gz # 新的下载地址 $ tar -zxvf supervisor-3.3.2.tar.gz # 解压安装包 $ cd supervisor-3.3.2 # 进入程序目录 $ python setup.py install # 执行安装脚本 修改配置文件 $ echo_supervisord_conf \u003e/etc/supervisord.conf # 执行命令生成配置文件 $ mkdir /etc/supervisor # 创建需要守护的进程目录 $ vim /etc/supervisord.conf ;[include] ;files = relative/directory/*.ini 修改为: [include] files=/etc/supervisor/*.conf (注意去掉分号,第一次安装的时候就因为没去掉分号出现了问题!); $ supervisord -c /etc/supervisord.conf # 启动服务 $ supervisorctl reload # 重新载入 编写服务进程守护配置文件 Redis进程守护配置文件 [program:redisd] command=bash -c \"sleep 1 \u0026\u0026 /usr/local/redis/bin/redis-server /usr/local/redis/redis.conf\" #启动supervisor会自动运行这个command directory = /Users/xinxingegeya/IDE/redis/redis_7000 #程序的启动目录 process_name=%(program_name)s #调用流程名称 autostart=true #当程序跑出exit的时候，这个program会自动重启 autorestart=true #程序重启时候停留在runing状态的秒数 startretries=5 #启动 5 秒后没有异常退出，就当作已经正常启动了 startretries = 3 #启动失败自动重试次数，默认是 3 user = xinxingegeya #用哪个用户启动 exitcodes=0,2,70 #退出码 stopsignal=QUIT #停止信号:QUIT(放弃) stopwaitsecs=2 #停止等待秒数 stdout_logfile=/var/log/supervisor/redis.log stdout_logfile_maxbytes=1MB stdout_logfile_backups=10 php-fpm进程守护配置文件 [program:php-fpm] command=bash -c \"sleep 1 \u0026\u0026 /usr/local/php/sbin/php-fpm --fpm-config /usr/local/php/etc/php-fpm.conf --pid /usr/local/php/var/run/php-fpm.pid\" process_name=%(program_name)s autostart=true autorestart=true startretries=5 exitcodes=0,2,70 stopsignal=QUIT stopwaitsecs=2 stdout_logfile=/var/log/supervisord/php-fpm.log 其他配置项 redirect_stderr=true ; (max main logfile bytes b4 rotation;default 50MB) logfile=/web/crontab_agent/Logs/swcAgent.log ; logfile_maxbytes=500MB ; (num of main logfile rotation backups;default 10) logfile_backups=10 ; loglevel=info ; stdout_logfile=/web/crontab_agent/Logs/swcAgent.log ; stdout log path, NONE for none; default AUTO stdout_logfile_maxbytes=500MB ; max # logfile bytes b4 rotation (default 50MB) stdout_logfile_backups=2 ; # of stdout logfile backups (default 10) stderr_logfile=/web/crontab_agent/Logs/swcAgent.log ; stderr log path, NONE for none; default AUTO stderr_logfile_maxbytes=500MB ; max # logfile bytes b4 rotation (default 50MB) stderr_logfile_backups=2 ; # of stderr logfile backups (default 10) ",
    "description": "安装Supervisord进程守护服务 安装supervisord Supervisord官网 Supervisord安装与使用 supervisord初体验 使用Supervisord守护php-fpm进程 Supervisord管理redis进程 使用Supervisord管理Redis进程 安装扩展，下载安装包 $ yum install python-setuptools -y # 安装python程序开发过程库 $ cd /usr/local/src/ $ wget https://pypi.",
    "tags": [],
    "title": "Install_Supervisord",
    "uri": "/systems/linux/daemon/install_supervisord/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Crontab",
    "content": "安装xxl-job 官方下载部署文档 Maven3+ Jdk1.8+ Mysql5.7+ 安装Maven 下载Maven $ wget https://dlcdn.apache.org/maven/maven-3/3.8.5/binaries/apache-maven-3.8.5-bin.tar.gz 配置环境变量 $ echo 'export PATH=/opt/apache-maven-3.8.5/bin:$PATH' \u003e\u003e/etc/profile 国内配置阿里云Maven源 将Maven源改为国内阿里云仓库 $ cat \u003e/usr/local/maven/conf/settings.xml\u003c\u003c-EOF \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云公共仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云谷歌仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/google\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云阿帕奇仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/apache-snapshots\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云spring仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/spring\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云spring插件仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/spring-plugin\u003c/url\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003c/settings\u003e EOF 安装xxl-job /xxl-job/doc/db/tables_xxl_job.sql：初始化数据库 修改配置文件 $ vim /xxl-job/xxl-job-admin/src/main/resources/application.properties ### 调度中心JDBC链接：链接地址请保持和 2.1章节 所创建的调度数据库的地址一致 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true\u0026characterEncoding=UTF-8\u0026autoReconnect=true\u0026serverTimezone=Asia/Shanghai spring.datasource.username=root spring.datasource.password=root_pwd spring.datasource.driver-class-name=com.mysql.jdbc.Driver ### 报警邮箱 spring.mail.host=smtp.qq.com spring.mail.port=25 spring.mail.username=xxx@qq.com spring.mail.password=xxx spring.mail.properties.mail.smtp.auth=true spring.mail.properties.mail.smtp.starttls.enable=true spring.mail.properties.mail.smtp.starttls.required=true spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory ### 调度中心通讯TOKEN [选填]：非空时启用； xxl.job.accessToken= ### 调度中心国际化配置 [必填]： 默认为 \"zh_CN\"/中文简体, 可选范围为 \"zh_CN\"/中文简体, \"zh_TC\"/中文繁体 and \"en\"/英文； xxl.job.i18n=zh_CN ## 调度线程池最大线程配置【必填】 xxl.job.triggerpool.fast.max=200 xxl.job.triggerpool.slow.max=100 ### 调度中心日志表数据保存天数 [必填]：过期日志自动清理；限制大于等于7时生效，否则, 如-1，关闭自动清理功能； xxl.job.logretentiondays=30 # 执行打包，install包含了 package的所有阶段 $ mvn package $ mvn clean install xxl-job-admin/target：目录下生成：xxl-job-admin-2.3.0.jar java -jar xxl-job-admin-2.3.0.jar：启动xxl-job ",
    "description": "安装xxl-job 官方下载部署文档 Maven3+ Jdk1.8+ Mysql5.7+ 安装Maven 下载Maven $ wget https://dlcdn.apache.org/maven/maven-3/3.8.5/binaries/apache-maven-3.8.5-bin.tar.gz 配置环境变量 $ echo 'export PATH=/opt/apache-maven-3.",
    "tags": [],
    "title": "Install Xxl Job",
    "uri": "/systems/linux/crontab/install_xxl_job/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Codes",
    "content": "配置SonarQube OpenAI Codex Github copilot 配置SonarQube中文 搜索Chinese Pack中文插件 1.2 如果匹配Gitlab不成功可能是版本不对， 需要更新版本\n1.3 配置sonar-scanner的sonar-project.properties文件\n$ cat \u003e/opt/php/project/sonar-project.properties\u003c\u003c-EOF # 必须指定projectKey sonar.projectKey=php:admin # 定义检测后展示名称 sonar.projectName=Project NAME # 指定版本 sonar.projectVersion=4.7 # 项目代码存放目录 sonar.sources=/opt/admin # 项目代码使用的开发语言 sonar.language=php sonar.dynamicAnalysis=false # Encoding of the source files sonar.sourceEncoding=UTF-8 EOF # 切换项目目录下执行 $ /opt/sonar-scanner/bin/sonar-scanner -Dsonar.login=admin -Dsonar.password=password -Dsonar.host.url=http://sonarqube.erge.com ",
    "description": "配置SonarQube OpenAI Codex Github copilot 配置SonarQube中文 搜索Chinese Pack中文插件 1.2 如果匹配Gitlab不成功可能是版本不对， 需要更新版本",
    "tags": [],
    "title": "Configure_SonarQube",
    "uri": "/systems/linux/codes/configure_sonarqube/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Codes",
    "content": "安装SonarQube代码质量管理系统 grype Docker 镜像扫描 Archery代码检查服务 SonarQube是一个用于管理代码质量的开放平台，可以快速的定位代码中潜在的或者明显的错误。目前支持java、C#、C/C++、Python、PL/SQL、Cobol、JavaScrip、Groovy等二十几种编程语言的代码质量管理与检测 从七个维度检测代码质量 复杂度分布(complexity):代码复杂度过高将难以理解 重复代码(duplications):程序中包含大量复制、粘贴的代码而导致代码臃肿，sonar可以展示源码中重复严重的地方 单元测试统计(unit tests):统计并展示单元测试覆盖率，开发或测试可以清楚测试代码的覆盖情况 代码规则检查(coding rules):通过Findbugs、PMD、CheckStyle等检查代码是否符合规范 注释率(comments):若代码注释过少，特别是人员变动后，其他人接手比较难接手；若过多，又不利于阅读 潜在的Bug(potential bugs):通过Findbugs、PMD、CheckStyle等检测潜在的bug 结构与设计(architecture \u0026 design):找出循环，展示包与包、类与类之间的依赖、检查程序之间耦合度 安装要求 环境要求 版本 备注 postgresql 9.7 JDK 11 SonarQube 9.7.1 Elasticsearch 使用PostgreSQL创建SonarQube数据库 # 创建sonar用户 $ ./bin/createuser sonar # 创建新用户 sonar，create user sonar; $ ./bin/psql -d template1 # 进入命令行模式 $ ALTER USER sonar WITH ENCRYPTED password 'sonar@123!'; # 设置sonar用户密码(否则会导致连不上数据库) # 创建sonar数据库 $ CREATE DATABASE sonar WITH ENCODING 'UTF8' OWNER sonar TEMPLATE=template0; # create database sonar; 下载SonarQube SonarQube→Distribution→SonarQube $ curl -O https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-9.6.1.59531.zip $ yum -y install unzip $ unzip sonarqube-9.6.1.59531.zip -d /opt/ $ mv sonarqube-9.6.1.59531 /opt/sonarqube 配置sonar.properties文件 $ vim /opt/sonarqube/conf/sonar.properties sonar.jdbc.username=sonar sonar.jdbc.password=sonar sonar.jdbc.url=jdbc:postgresql://localhost/sonar # WEB SERVER sonar.web.host=0.0.0.0 sonar.web.port=9000 SonarQube不能通过root用户执行，新建用户 $ useradd sonar $ chown -R sonar. /opt/sonarqube $ su - sonar $ ulimit -n 65535 $ echo \"* soft nofile 65536 * hard nofile 65536 * soft nproc 32000 * hard nproc 32000 * hard memlock unlimited * soft memlock unlimited \"\u003e\u003e/etc/security/limits.conf echo \"vm.max_map_count=655360\" \u003e\u003e/etc/sysctl.conf 启动SonarQube $ cd /opt/sonarqube/ $ ./bin/linux-x86-64/sonar.sh start 登录SonarQube $ http://IP:9000 # 默认用户名密码：admin/admin 安装扫描客户端 下载**SonarScanner** $ wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.7.0.2747-linux.zip $ unzip sonar-scanner-cli-4.7.0.2747-linux.zip $ mv sonar-scanner-4.7.0.2747-linux /opt/sonar-scanner ",
    "description": "安装SonarQube代码质量管理系统 grype Docker 镜像扫描 Archery代码检查服务 SonarQube是一个用于管理代码质量的开放平台，可以快速的定位代码中潜在的或者明显的错误。目前支持java、C#、C/C++、Python、PL/SQL、Cobol、JavaScrip、Groovy等二十几种编程语言的代码质量管理与检测 从七个维度检测代码质量 复杂度分布(complexity):代码复杂度过高将难以理解 重复代码(duplications):程序中包含大量复制、粘贴的代码而导致代码臃肿，sonar可以展示源码中重复严重的地方 单元测试统计(unit tests):统计并展示单元测试覆盖率，开发或测试可以清楚测试代码的覆盖情况 代码规则检查(coding rules):通过Findbugs、PMD、CheckStyle等检查代码是否符合规范 注释率(comments):若代码注释过少，特别是人员变动后，其他人接手比较难接手；若过多，又不利于阅读 潜在的Bug(potential bugs):通过Findbugs、PMD、CheckStyle等检测潜在的bug 结构与设计(architecture \u0026 design):找出循环，展示包与包、类与类之间的依赖、检查程序之间耦合度 安装要求 环境要求 版本 备注 postgresql 9.",
    "tags": [],
    "title": "Install_SonarQube",
    "uri": "/systems/linux/codes/install_sonarqube/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend \u003e Tomcat",
    "content": "配置Tomcat 清理Tomcat日志 清理超过七天以上的日 $ echo \"#!/bin/bash/ tomdate=\"$(date +\"%Y%m%d%s\")\" tomlog='/opt/logs/tomcat*' echo $tomdate # echo $tomlog find $tomlog/*.log -type f -ctime +7 -exec rm -f {} \\; find $tomlog/*.txt -type f -ctime +7 -exec rm -f {} \\; \"\u003e/opt/scripts/DEL_TOMLOG.sh 清理日志脚本添加到计划任务 $ echo \"### tomcat超過七天log刪除 1 0 * * * /bin/bash /opt/scripts/DEL_TOMLOG.sh \u003e\u003e ~/del_tom.log 2\u003e\u00261\" \u003e\u003e /var/spool/cron/myadmin 日志做每日切割 $ echo \"/opt/data/logs/tomcat/catalina.out{ copytruncate daily rotate 7 missingok compress size 100k su root root } \"\u003e\u003e /etc/logrotate.d/tomcat 安全设置规范 telnet管理端口保护（强制） 类别 配置内容及说明 标准配置 备注 telnet管理端口保护 1.修改默认的8005管理端口为不易猜测的端口（大于1024）； 2.修改SHUTDOWN指令为其他字符串； 1.以上配置项的配置内容只是建议配置，可以按照服务实际情况进行合理配置，但要求端口配置在8000~8999之间； ajp连接端口保护（推荐） 类别 配置内容及说明 标准配置 备注 Ajp 连接端口保护 1.修改默认的ajp 8009端口为不易冲突的大于1024端口； 2.通过iptables规则限制ajp端口访问的权限仅为线上机器； 以上配置项的配置内容仅为建议配置，请按照服务实际情况进行合理配置，但要求端口配置在8000~8999之间；； 保护此端口的目的在于防止线下的测试流量被mod_jk转发至线上tomcat服务器； 禁用管理端（强制） 类别 配置内容及说明 标准配置 备注 禁用管理端 1. 删除默认的{Tomcat安装目录}/conf/tomcat-users.xml文件，重启tomcat后将会自动生成新的文件； 2. 删除{Tomcat安装目录}/webapps下默认的所有目录和文件； 3.将tomcat应用根目录配置为tomcat安装目录以外的目录； 对于前段web模块，Tomcat管理端属于tomcat的高危安全隐患，一旦被攻破，黑客通过上传web shell的方式将会直接取得服务器的控制权，后果极其严重； 降权启动（强制） 类别 配置内容及说明 标准配置 备注 降权启动 1.tomcat启动用户权限必须为非root权限，尽量降低tomcat启动用户的目录访问权限； 2.如需直接对外使用80端口，可通过普通账号启动后，配置iptables规则进行转发； - 避免一旦tomcat服务被入侵，黑客直接获取高级用户权限危害整个server的安全； 文件列表访问控制（强制） 类别 配置内容及说明 标准配置 备注 文件列表访问控制 1.conf/web.xml文件中default部分listings的配置必须为false； listings false false为不列出目录文件，true为允许列出，默认为false； 版本信息隐藏（强制） 类别 配置内容及说明 标准配置 备注 版本信息隐藏 1.修改conf/web.xml，重定向403、404以及500等错误到指定的错误页面； 2.也可以通过修改应用程序目录下的WEB-INF/web.xml下的配置进行错误页面的重定向； 403 /forbidden.jsp 404 /notfound.jsp 500 /systembusy.jsp 在配置中对一些常见错误进行重定向，避免当出现错误时tomcat默认显示的错误页面暴露服务器和版本信息； 必须确保程序根目录下的错误页面已经存在； 2.7 Server header重写（推荐） 类别 配置内容及说明 标准配置 备注 Server header重写 在HTTP Connector配置中加入server的配置； server=\"webserver\" 当tomcat HTTP端口直接提供web服务时此配置生效，加入此配置，将会替换http 响应Server header部分的默认配置，默认是Apache-Coyote/1.1 访问限制（可选） 类别 配置内容及说明 标准配置或操作 备注 访问限制 通过配置，限定访问的ip来源 \u003cValve className=“org.apache.catalina.valves.RemoteAddrValve” allow=“61.148.18.138,61.135.165.*” deny=\"*.*.*.*\"/\u003e 通过配置信任ip的白名单，拒绝非白名单ip的访问，此配置主要是针对高保密级别的系统，一般产品线不需要； 起停脚本权限回收（推荐） 类别 配置内容及说明 标准配置或操作 备注 起停脚本权限回收 去除其他用户对Tomcat的bin目录下shutdown.sh、startup.sh、catalina.sh的可执行权限； chmod -R 744 tomcat/bin/* 防止其他用户有起停线上Tomcat的权限； 访问日志格式规范（推荐） 类别 配置内容及说明 标准配置或操作 备注 访问日志格式规范 开启Tomcat默认访问日志中的Referer和User-Agent记录 开启Referer和User-Agent是为了一旦出现安全问题能够更好的根据日志进行问题排查； 建议配置及标准执行方案 配置部分${CATALINA_HOME}conf/server.xml $ cat \u003e${CATALINA_HOME}conf/server.xml\u003c\u003c-EOF \u003cServer port=\"8527\" shutdown=\" dangerous\"\u003e \u003c!-- Define a non-SSL HTTP/1.1 Connector on port 8080 --\u003e \u003cConnector port=\"8080\" server=\"webserver\"/\u003e \u003c!-- Define an AJP 1.3 Connector on port 8528 --\u003e \u003c!--Define an accesslog --\u003e \u003cValve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i %D\" resolveHosts=\"false\"/\u003e \u003cConnector port=\"8528\" protocol=\"AJP/1.3\" /\u003e \u003cContext path=\"\" docBase=\"/home/work/local/tomcat_webapps\" debug=\"0\" reloadable=\"false\" crossContext=\"true\"/\u003e EOF 配置部分${CATALINA_HOME}conf/web.xml或者WEB-INF/web.xml $ cat \u003e${CATALINA_HOME}conf/web.xml或者WEB-INF/web.xml\u003c\u003c-EOF \u003cinit-param\u003e \u003cparam-name\u003elistings\u003c/param-name\u003e \u003cparam-value\u003efalse\u003c/param-value\u003e \u003c/init-param\u003e \u003cerror-page\u003e \u003cerror-code\u003e403\u003c/error-code\u003e \u003clocation\u003e/forbidden.jsp\u003c/location\u003e \u003c/error-page\u003e \u003cerror-page\u003e \u003cerror-code\u003e404\u003c/error-code\u003e \u003clocation\u003e/notfound.jsp\u003c/location\u003e \u003c/error-page\u003e \u003cerror-page\u003e \u003cerror-code\u003e500\u003c/error-code\u003e \u003clocation\u003e/systembusy.jsp\u003c/location\u003e \u003c/error-page\u003e EOF 删除如下tomcat的默认目录和默认文件 $ rm -rf tomcat/webapps/* $ rm -rf tomcat/conf/tomcat-user.xml 去除其他用户对tomcat起停脚本的执行权限 $ chmod 744 –R tomcat/bin/* ",
    "description": "配置Tomcat 清理Tomcat日志 清理超过七天以上的日 $ echo \"#!/bin/bash/ tomdate=\"$(date +\"%Y%m%d%s\")\" tomlog='/opt/logs/tomcat*' echo $tomdate # echo $tomlog find $tomlog/*.",
    "tags": [],
    "title": "Configure_Tomcat",
    "uri": "/systems/linux/backend/tomcat/configure_tomcat/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend \u003e Tomcat",
    "content": "部署Tomcat服务 Tomcat官网 8.3.x版本Tomcat安装包 安装Tomcat前准备 创建Tomcat启动用户 $ groupadd myadmin \u0026\u0026 useradd -g myadmin myadmin $ echo \"20210627@123\"|passwd --stdin myadmin \u0026\u003e/dev/null $ echo \"#########Start/Stop Service############### Cmnd_Alias MYADMIN_START_SERVICES = /etc/init.d/nginx, /etc/init.d/tomcat, /opt/* /usr/bin/kill myadmin ALL=(ALL)NOPASSWD:MYADMIN_START_SERVICES\" \u003e /etc/sudoers.d/myadmin $ chmod 660 /etc/sudoers.d/myadmin 创建Tomcat部署目录 $ mkdir -p /opt/{data,apps,src,deploy,scripts,logs/tomcat} 检测JDK环境 $ yum list |grep openjdk # 包有 @ 代表安装 $ echo \"#######JDK環境變數######################## export JAVA_HOME=/opt/data/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin CATALINA_HOME=/opt/data/tomcat # 部署多实例启动脚本应用 export CATALINA_HOME \"\u003e\u003e/home/myadmin/.bash_profile $ source /home/myadmin/.bash_profile $ ln -s /opt/data/jdk/bin/java /sbin/java # 使jar包可以直接运行,后面做软连接,授权 下载安装Tomcat 下载Tomcat安装包 $ wget -P /opt/src/ https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.35/bin/apache-tomcat-8.5.35.tar.gz $ wget -P /opt/src/ https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.35/bin/apache-tomcat-8.5.35.tar.gz.sha512 检测安装包完整性 # md5sum -c apache-tomcat-6.0.35.tgz.md5 $ sha512sum -c apache-tomcat-8.5.35.tar.gz.sha512 解压以及更改权限 # ln -s /opt/lucky/apache-tomcat-8.5.35 /opt/data/tomcat # 可做软连接 $ tar -zxvf /opt/src/apache-tomcat-8.5.35.tar.gz -C /opt/data/ 修改Tomcat主配置文件 $ sed -i \"s/8080/8000/g\" /opt/data/tomcat/conf/server.xml $ sed -i 's/logs/\\/opt\\/data\\/logs\\/tomcat/g' /opt/data/tomcat/conf/server.xml 修改Tomcat的Cataline.sh文件 $ sed -i '/# OS specific support/iJAVA_OPTS=\"-Dfile.encoding=UTF-8 -server -Xms2048m -Xmx2048m -Xmn1024m -XX:SurvivorRatio=10 -XX:MaxTenuringThreshold=15 -XX:NewRatio=2 -XX:+DisableExplicitGC\"' /opt/data/tomcat/bin/catalina.sh $ sed -i 's/\"$CATALINA_BASE\"\\/logs\\/catalina.out/\\/opt\\/data\\/logs\\/tomcat\\/catalina.out/g' /opt/data/tomcat/bin/catalina.sh # sed -i '/ \u003c\\/Host\u003e/i\\ \u003cContext path=\"/\" docBase=\"/opt/lucky/publish-luckybackend\" reloadable=\"true\"\u003e\u003c\\/Context\u003e' /opt/data/tomcat/conf/server.xml $ sed -i 's/${catalina.base}\\/logs/\\/opt\\/data\\/logs\\/tomcat/g' /opt/data/tomcat/conf/logging.properties 防火墙开放端口 8005：端口是tomcat本身管理端口，修改一个不易猜到\n8080：端口是tomcat负责建立HTTP连接。在通过浏览器访问tomcat服务器的web应用时，使用的就是这个端口\n8009：tomcat负责和其他的HTTP服务器建立连接，如nginx和apache互通使用\n$ firewall-cmd --permanent --new-ipset=tomcat_whitelist --type=hash:ip $ firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source ipset='tomcat_whitelist' port prot='7000-7007' protocol='tcp' accept\" $ firewall-cmd --reload 网站根目录以及连接数据库 # 默认网站的主目录 $ ls /usr/local/tomcat/webapps/ $ cat \u003e/usr/local/tomcat/webapps/ROOT/WEB-INF/config/jdbc.properties\u003c\u003c-EOF # jdbc.url=jdbc:mysql://192.168.213.50:16303/jspgou?characterEncoding=UTF-8 # jspgou代表数据库 # jdbc.username=root # jdbc.password=123 EOF 启动Tomcat $ /opt/data/tomcat/bin/startup.sh 编写Tomcat启动文件 $ cat \u003etomcat.sh\u003c\u003c-EOF #!/bin/bash TOMCAT_PATH=/usr/local/tomcat usage(){ echo \"Usage: $0 [start|stop|status|restart]\" } status_tomcat(){ ps aux | grep java | grep tomcat | grep -v 'grep' } start_tomcat(){ /usr/local/tomcat/bin/startup.sh } stop_tomcat(){ TPID=$(ps aux | grep java | grep tomcat | grep -v 'grep' | awk '{print $2}') kill -9 $TPID sleep 5; TSTAT=$(ps aux | grep java | grep tomcat | grep -v 'grep' | awk '{print $2}') if [ -z $TSTAT ];then echo \"tomcat stop\" else kill -9 $TSTAT fi cd $TOMCAT_PATH rm temp/* -rf rm work/* -rf } main(){ case $1 in start) start_tomcat;; stop) stop_tomcat;; status) status_tomcat;; restart) stop_tomcat \u0026\u0026 start_tomcat;; *) usage; esac } main $1 EOF 多端口启动Tomcat $ cat \u003etomcat\u003c\u003c-EOF #!/bin/bash ## 此脚本用来启动停止以及查看tomcat多实例 ## 2021/04/18\tauthor：Neek export JAVA_HOME=/opt/lucky/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin ## 目录 CATALINA_BASE='/opt/lucky/tomcat/' WEBAPPS_PATH='/opt/lucky/tomcat/webapps' CATALINA_HOME='/opt/lucky/tomcat/' . /etc/init.d/functions read -p \"请输入要启动的的端口号，8080,6000，7000~7007，8818：\" port case $port in 8080) export CATALINA_BASE=\"/opt/lucky/tomcat\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 8080 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 6000) export CATALINA_BASE=\"/opt/lucky/tomcat/6000/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 6000 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7000) export CATALINA_BASE=\"/opt/lucky/tomcat/7000/\" read -p \"启动停止tomcat确定吗？确定请输入操作指令(start/stop/restart)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7000 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7001) export CATALINA_BASE=\"/opt/lucky/tomcat/7001/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7001 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7002) export CATALINA_BASE=\"/opt/lucky/tomcat/7002/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7002 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7003) export CATALINA_BASE=\"/opt/lucky/tomcat/7003/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7003 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7004) export CATALINA_BASE=\"/opt/lucky/tomcat/7004/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7004 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7005) export CATALINA_BASE=\"/opt/lucky/tomcat/7005/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7005 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7006) export CATALINA_BASE=\"/opt/lucky/tomcat/7006/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7006 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 7007) export CATALINA_BASE=\"/opt/lucky/tomcat/7007/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 7007 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; 8818) export CATALINA_BASE=\"/opt/lucky/tomcat/8818/\" read -p \"启动停止tomcat以及查看状态，确定请输入操作指令(start/stop/restart/status)：\" port_st case \"$port_st\" in start) $CATALINA_HOME/bin/startup.sh ;; stop) $CATALINA_HOME/bin/shutdown.sh ;; restart) $CATALINA_HOME/bin/shutdown.sh sleep 5 $CATALINA_HOME/bin/startup.sh ;; status) tomcat_status=$(ss -unplt |egrep 8818 |egrep -i listen) [ -z \"$tomcat_status\" ] \u0026\u0026 echo -e \"\\ntomcat\\033[31m start failed ...\\033[0m\\n\" || echo -e \"\\ntomcat\\033[32m is running ...\\033[0m\\n\" ;; esac;; esac export JAVA_OPTS='-Xms64m -Xmx128m' EOF ",
    "description": "部署Tomcat服务 Tomcat官网 8.3.x版本Tomcat安装包 安装Tomcat前准备 创建Tomcat启动用户 $ groupadd myadmin \u0026\u0026 useradd -g myadmin myadmin $ echo \"20210627@123\"|passwd --stdin myadmin \u0026\u003e/dev/null $ echo \"#########Start/Stop Service############### Cmnd_Alias MYADMIN_START_SERVICES = /etc/init.",
    "tags": [],
    "title": "Install_Tomcat",
    "uri": "/systems/linux/backend/tomcat/install_tomcat/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend \u003e PHP",
    "content": "安装配置PHP扩展 安装PHP-redis扩展 下载、安装PHP-redis扩展 $ cd /usr/local/src $ curl -O https://pecl.php.net/get/redis-4.0.0.tgz $ tar zxvf /usr/local/src/redis-4.0.0.tgz -C /usr/local/src $ cd /usr/local/src/redis-4.0.0 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make \u0026\u0026 make install 配置PHP启用PHP-Redis扩展 $ sed -i 'N;736iextension =/usr/local/php/lib/php/extensions/no-debug-non-zts20170718/redis.so' /usr/local/php/etc/php.ini # 修改配置文件启用redis模块 # 重启php使之生效 $ systemctl restart php-fpm # /etc/init.d/php-fpm restart $ php -m|grep redis $ php --ri redis # 查看redis扩展版本 安装php-swoole扩展 docker install swoft 下载、安装php-swoole扩展 $ cd /usr/local/src $ git clone https://github.com/swoole/swoole-src.git $ cd /usr/local/src/swoole-src/ $ git checkout v4.4.7 # 切换指定版本 $ git branch # 查看当前版本 $ phpize $ ./configure $ make -j4 \u0026\u0026 make install 配置PHP启用PHP-Swoole扩展 $ sed -i 'N;736iextension =/usr/local/php/lib/php/extensions/no-debug-non-zts20170718/swoole.so' /usr/local/php/etc/php.ini # 修改配置文件启用swoole模块 # sed -i 'N;736iswoole.enable_coroutine = Off' /usr/local/php/etc/php.ini $ systemctl restart php-fpm # /etc/init.d/php-fpm restart $ php -m|grep swoole $ php --ri swoole 安装PHP-Freetype扩展 下载、安装PHP-Freetype扩展 $ wget -P /usr/local/src https://download.savannah.gnu.org/releases/freetype/freetype-2.9.tar.gz # https://mirror.hostiran.ir/gnu/releases/freetype/freetype-2.12.1.tar.gz $ tar zxvf /usr/local/src/freetype-2.9.tar.gz -C /usr/local/src/ $ cd /usr/local/src/freetype-2.9/ $ ./configure --prefix=/usr/local/freetype $ make -j4 \u0026\u0026 make install Debian系统安装FreeType # 进入php中的gd 目录 $ cd /opt/src/php-7.2.22/ext/gd/ # 利用phpize $ /opt/php/bin/phpize # 清理之前的安装配置 $ make clean # 检查参数 $ ./configure --with-php-config=/opt/php/bin/php-config --with-jpeg-dir --with-png-dir --with-freetype-dir=/opt/php/freetype --with-zlib-dir --with-gd # 编译安装 $ make -j4 \u0026 make install # 修改 php.ini文件 $ cat \u003e/opt/php/etc/php.ini\u003c\u003c-EOF extension=/opt/php/lib/php/extensions/no-debug-non-zts-20170718/gd.so EOF 配置PHP加入扩展路径 $ php -i # 查看configure中使用参数 $ ./configure --prefix=/usr/local/php --with-freetype-dir=/usr/local/freetype # --with-freetype-dir=/usr/local/freetype 启用此扩展 安装PHP-Amqp扩展 第一种方式安装PHP-amqp $ /usr/local/php/bin/pecl install amqp 第二种方式安装PHP-amqp 下载、安装PHP-amqp扩展 $ wget -P /usr/local/src/ https://pecl.php.net/get/amqp-1.9.4.tgz $ tar -xvf /usr/local/src/amqp-1.9.4.tgz -C /usr/local/src $ cd /usr/local/src/amqp-1.9.4 $ /usr/local/php/bin/phpize $ ./configure --with-php-config=/usr/local/php/bin/php-config 如果安装中报错处理方式 $ wget -P /usr/local/src https://github.com/alanxz/rabbitmq-c/releases/download/v0.7.1/rabbitmq-c0.7.1.tar.gz $ tar zxvf /usr/local/src/rabbitmq-c-0.7.1.tar.gz -C /usr/local/src/ $ cd /usr/local/src/rabbitmq-c-0.7.1 $ ./configure --prefix=/usr/local/rabbitmq-c-0.7.1 $ make \u0026\u0026 make install 重新配置编译安装 $ cd /usr/local/src/amqp-1.9.4 $ ./configure --with-php-config=/usr/local/php/bin/php-config --with-amqp --withlibrabbitmq-dir=/usr/local/rabbitmq-c-0.7.1 $ make \u0026\u0026 make install 配置PHP启用PHP-amqp扩展 $ sed -i 'N;736iextension =/usr/local/php/lib/php/extensions/no-debug-non-zts20170718/amqp.so' /usr/local/php/etc/php.ini # 修改配置文件启用php-amqp模块 # 重启php使之生效 $ systemctl restart php-fpm # /etc/init.d/php-fpm restart $ php -m|grep amqp $ php --ri amqp PHP-FastCGI 什么是CGI CGI的全称为通用网关接口(Common Gateway Interface)，为HTTP服务器与其他机器上的程序 服务通信交流的一种工具，CGI程序须运行在网络服务器上。 传统CGI接口方式的主要缺点是性能较差，因为每次HTTP服务器遇到动态程序时都需要重新启动解析器 来执行解析，之后结果才会被返回给HTTP服务器。这在处理高并发访问时几乎是不可用的，因此就诞生 了FastCGI。另外，传统的CGI接口方式安全性也很差，故而现在已经很少被使用了。\n什么是FastCGI FastCGI是一个可伸缩地、高速地在HTTP服务器和动态脚本语言间通信的接口（在Linux下，FastCG接 口即为socket，这个socket可以是文件socket，也可以是IP socket），主要优点是把动态语言和HTTP服务器分离开来。多数流行的HTTP服务器都支持FastCGI，包括Apache、Nginx和Lighttpd等。 同时，FastCGI也被许多脚本语言所支持，例如当前比较流行的脚本语言PHP。FastCGI接口采用的是C/S 架构，它可以将HTTP服务器和脚本解析服务器分开，同时还能在脚本解析服务器上启动一个或多个脚本 来解析守护进程。当HTTP服务器遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得 到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求，或者将动态脚本服务器的结 果返回给客户端，这在很大程度上提高了整个应用系统的性能。\nFastCGI的重要特点如下： HTTP服务器和动态脚本语言间通信的接口或工具\n可把动态语言解析和HTTP服务器分离开\nNginx、Apache、Lighttpd以及多数动态语言都支持FastCGI\nFastCGI接口方式采用C/S结构，分为客户端：HTTP服务器，和服务器端：动态语言解析服务器\n动态语言服务器端可以启动多个FastCGI的守护进程，例如：php-fpm(fcgi process mangement)\nHTTP服务器通过，例如：Nginx fastcgi_pass。FastCGI客户端和动态语言FastCGI服务器端通信，例如：php-fpm\n阿里云epel 阿里云epel简介 设定阿里云epel源阿里云epel下载 # 备份其他epel源 $ mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backup $ mv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo.backup $ wget -O /etc/yum.repos.d/epel.repo https://mirrors.aliyun.com/repo/epel-7.repo $ yum -y install mhash $ yum -y install mcrypt $ yum -y install libmcrypt-devel $ yum install zlib-devel libxml2-devel libjpeg-devel libjpeg-turbo-devel libiconv-devel -y $ yum install freetype-devel libpng-devel gd-devel libcurl-devel libxslt-devel libxslt-devel -y 下载安装libiconv $ wget -P /usr/local/src http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gz $ tar -zxf /usr/local/src/libiconv-1.14.tar.gz -C /usr/local/src cd /usr/local/src/libiconv-1.14 $ ./configure --prefix=/usr/local/libiconv $ make $ make install 3.1 配置PHP启用libiconv --prefix=/application/php5.5.32： 表示指定PHP的安装路径 --with-mysql=/application/mysql：表示需要指定MySQL的安装路径，安装PHP需要MySQL的相关内容，当然如果没有MySQL安装包也可以不单独安装，这样情况下使用--with-mysql=mysqlnd替代--with-mysql=/application/mysql，因为PHP软件自带连接MySQL客户工具 --with-fpm-user=nginx：表示指定PHP-FPM进程管理用户为Nginx，此处最好和Nginx服务用户统一 --with-fpm-group=nginx：表示指定PHP-FPM进程管理组为Nginx，此处最好和Nginx服务用户组统一 --enable-fpm:表示激活PHP-FPM方式服务，即FastCGIF方式运行PHP服务 可以通过执行./configure --help命令来详细查看以上各参数用途 $ cd /usr/local/src/php5.5.32 $ ./configure \\ --prefix=/application/php5.5.32 \\ --with-iconv-dir=/usr/local/libiconv \\ --with-mysql=mysqlnd --with-libxml-dir=/usr \\ --with-freetype-dir --with-jpeg-dir --with-png-dir \\ --with-zlib --enable-xml --disable-rpath --enable-safe-mode \\ --enable-bcmath --enable-shmop --enable-sysvsem --with-curl \\ --enable-inline-optimization --with-curlwrappers --enable-fpm \\ --enable-mbregex --enable-mbstring --with-mcrypt --with-gd \\ --enable-gd-native-ttf --with-openssl --with-mhash --enable-pcntl \\ --enable-sockets --with-xmlrpc --enable-zip --enable-soap \\ --enable-short-tags --enable-zend-multibyte --enable-ftp \\ --enable-static --with-xsl --enable-opcache=no --with-fpm-user=www \\ --with-fpm-group=www $ ln -s /application/mysql/lib/libmysqlclient.so.18 /usr/lib64/ $ touch ext/phar/phar.phar $ make \u0026\u0026 make install 在Nginx的conf配置中字段server编写php的location location ~ .*\\.(php|php5)?$ { root html/blog; fastcgi_pass 127.0.0.1:9000; # 或者使用：unix:/tmp/php-cgi-56.sock; fastcgi_index index.php; fastcgi_split_path_info ^((?U).+\\.php)(/?.+)$; fastcgi_param PATH_INFO $fastcgi_path_info; include fastcgi_params; # include fastcgi.conf } 配置fastcgi.conf文件 $ cat \u003efastcgi.conf\u003c\u003c-EOF fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;# 脚本文件请求的路径 fastcgi_param QUERY_STRING $query_string; # 请求的参数;如?app=123 fastcgi_param REQUEST_METHOD $request_method; # 请求的动作(GET,POST) fastcgi_param CONTENT_TYPE $content_type; # 请求头中的Content-Type字段 fastcgi_param CONTENT_LENGTH $content_length; # 请求头中的Content-length字段 fastcgi_param SCRIPT_NAME $fastcgi_script_name; # 脚本名称 fastcgi_param REQUEST_URI $request_uri; # 请求的地址不带参数 fastcgi_param DOCUMENT_URI $document_uri; # 与document_uri; #与uri相同 fastcgi_param DOCUMENT_ROOT $document_root; # 网站的根目录。在server配置中root指令中指定的值 fastcgi_param SERVER_PROTOCOL $server_protocol; # 请求使用的协议，通常是HTTP/1.0或HTTP/1.1 fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; # https 如果value非空才进行设置 fastcgi_param GATEWAY_INTERFACE CGI/1.1; # cgi 版本 fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; # nginx 版本号，可修改、隐藏 fastcgi_param REMOTE_ADDR $remote_addr; # 客户端IP fastcgi_param REMOTE_PORT $remote_port; # 客户端端口 fastcgi_param SERVER_ADDR $server_addr; # 服务器IP地址 fastcgi_param SERVER_PORT $server_port; # 服务器端口 fastcgi_param SERVER_NAME $server_name; # 服务器名，域名在server配置中指定的server_name ## GeoIP #fastcgi_param GEOIP_ADDR $remote_addr; #fastcgi_param GEOIP_COUNTRY_CODE $geoip_country_code; #fastcgi_param GEOIP_COUNTRY_NAME $geoip_country_name; #fastcgi_param GEOIP_REGION $geoip_region; #fastcgi_param GEOIP_REGION_NAME $geoip_region_name; #fastcgi_param GEOIP_CITY $geoip_city; #fastcgi_param GEOIP_AREA_CODE $geoip_area_code; #fastcgi_param GEOIP_LATITUDE $geoip_latitude; #fastcgi_param GEOIP_LONGITUDE $geoip_longitude; #fastcgi_param GEOIP_POSTAL_CODE $geoip_postal_code; #fastcgi_param GEOIP_ORGANIZATION $geoip_org; # PHP only, required if PHP was built with --enable-force-cgi-redirect fastcgi_param REDIRECT_STATUS 200; EOF nginx -t检查语法成功，重启nginx，写一个PHP页面 \u003c?php phpinfo()； ?\u003e 测试PHP连接mysql \u003c?php $link_id=mysql_connect('localhost','root','oldboy123') or mysql_error(); if($link_id){ echo \"mysql successful by oldboy !\"; }else{ echo mysql_error(); } ?\u003e ",
    "description": "安装配置PHP扩展 安装PHP-redis扩展 下载、安装PHP-redis扩展 $ cd /usr/local/src $ curl -O https://pecl.php.net/get/redis-4.0.0.tgz $ tar zxvf /usr/local/src/redis-4.",
    "tags": [],
    "title": "Configure_PHP_Expand",
    "uri": "/systems/linux/backend/php/configure_php_expand/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend \u003e PHP",
    "content": "安装PHP 安装依赖 # 修整优化 $ yum -y install epel-release $ yum -y install gcc gcc-c++ wget libxml2-devel sqlite-devel bzip2-devel \\ libpng-devel libwebp-devel libjpeg-devel libXpm-devel freetype-devel \\ oniguruma oniguruma-devel ncurses-devel readline-devel openssl-devel \\ libcurl-devel # yum安装版本不够高， 手动安装libzip $ wget https://mirrors.oneinstack.com/oneinstack-repo/7/x86_64/libzip-0.11.2-6.el7.psychotic.x86_64.rpm $ wget https://mirrors.oneinstack.com/oneinstack-repo/7/x86_64/libzip-devel-0.11.2-6.el7.psychotic.x86_64.rpm $ yum localinstall libzip-0.11.2-6.el7.psychotic.x86_64.rpm $ yum localinstall libzip-devel-0.11.2-6.el7.psychotic.x86_64.rpm # Debian系统 $ sudo apt-get install libxml2 libxml2-dev libbz2-dev libjpeg-dev libtool pkgconf \\ libpng-dev libfreetype6-dev libreadline-dev build-essential autoconf automake \\ bison flex re2c gdb php-gd libcurl4-openssl-dev gcc make libssl-dev libsqlite3-dev \\ libwebp-dev oniguruma-dev libzip-dev libXpm-dev 下载安装包配置 下载解压安装包 $ useradd -s /sbin/nologin php-fpm # 添加程序用户 $ cd /usr/local/src/ $ curl -O https://www.php.net/distributions/php-7.4.30.tar.gz $ tar -zxvf /usr/local/src/php-7.4.30.tar.gz -C /usr/local/src/ 配置，Debian系统不要使用默认--wiht-gd，CentOS不使用 --with-curl 函数参考 $ cd /usr/local/src/php-7.4.30 # 切换到解压目录 $ ./configure --prefix=/usr/local/php --sysconfdir=/usr/local/php/etc \\ --with-config-file-path=/usr/local/php/etc/ --with-fpm-user=php-fpm \\ --with-fpm-group=php-fpm --enable-fpm --with-libxml-dir --with-xmlrpc \\ --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-mhash \\ --with-zlib --with-bz2 --with-gd --with-jpeg-dir --with-png-dir \\ --with-iconv-dir --with-pcre-dir --with-pear --enable-mbstring \\ --enable-sockets --enable-zip --enable-session --enable-xml \\ --enable-gd-jis-conv --enable-shared --enable-soap --enable-bcmath \\ --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-mbregex \\ --enable-pcntl --with-gettext --enable-exif --with-readline --enable-ftp \\ --with-freetype-dir=/usr/local/freetype # php 7.4.X以上版本 $ ./configure --prefix=/usr/local/php --sysconfdir=/usr/local/php/etc \\ --with-config-file-path=/usr/local/php/etc/ --enable-fpm \\ --with-fpm-user=php-fpm --with-fpm-group=php-fpm --with-xmlrpc \\ --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-mhash \\ --with-zip --with-zlib --with-bz2 --enable-gd --with-jpeg \\ --with-xpm --with-webp --with-freetype --with-pear --with-openssl \\ --enable-mbstring --enable-sockets --enable-gd-jis-conv \\ --enable-shared --enable-soap --enable-bcmath --enable-sysvmsg \\ --enable-sysvsem --enable-sysvshm --enable-mbregex --enable-pcntl \\ --with-gettext --enable-exif --with-readline --enable-ftp --with-openssl 编译安装 $ make -j4 \u0026\u0026 make install 拷贝配置文件 $ cp /usr/local/src/php-7.4.30/php.ini-production /usr/local/php/etc/php.ini # 拷贝PHP解析器配置文件 # 拷贝启动文件 $ cp /usr/local/src/php-7.4.30/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm $ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf $ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf 拷贝改名PHP-FPM进程管理器配置文件，以及根据CPU、内存性能优化 $ mv /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf pm = static # 静态_子进程固定数量 pm = dynamic # 动态_子进程数量 pm.max_children = 500 # 最小等待处理的子进程 pm.start_servers = 200 # 启动时创建子进程数 pm.min_spare_servers = 5 # 最小处于等待处理子进程数 pm.max_spare_servers = 15 # 最大处于等待处理子进程数 pm.max_requests = 10000 request_terminate_timeout = 0 修改PHP通信方式 # Unix socket，Nginx和php-fpm在同一台服务器上，使用这种方式效率要比tcp socket高，需要再nginx配置文件中填写php-fpm的pid文件位置， $ cat \u003e/usr/local/php/etc/php-fpm.d/www.conf\u003c\u003c-EOF listen = /usr/local/php/logs/php7.sock # 自定义添加 EOF # tcp socket的优点是可以跨服务器，当Nginx和php-fpm不在同一台机器上时，只能使用这种方式 $ listen = 127.0.0.1:9000 修改权限启动服务 # 修改权限 $ chmod 755 /etc/init.d/php-fpm # 添加到启动项 $ chkconfig --add php-fpm # 开机自启 $ chkconfig php-fpm on # 启动服务 $ service php-fpm start # 重启配置 $ sed -i \"N;56iexport PATH=/usr/local/php/bin:$PATH\" /etc/profile $ source /etc/profile # 写入测试文件 $ echo '\u003c?php phpinfo(); ?\u003e' \u003e/usr/local/nginx/html/index.php # 修改配置nginx文件 $ nginxconf=/usr/local/nginx/conf/nginx.conf $ sed -i '45s/index.html/index.php index.html/' $nginxconf $ sed -i '65,71s/#//' $nginxconf $ sed -i '70s/fastcgi_params/fastcgi.conf/' $nginxconf $ sed -i '69d' $nginxconf # 重启nginx $ /usr/local/nginx/sbin/nginx -s reload $ php -v # 查看端口号 $ netstat -nuplt | grep :9000 使用systemctl启动 $ echo '[Unit] Description=php-fpm After=syslog.target network.target [Service] Type=forking ExecStart=/usr/local/php/sbin/php-fpm ExecReload=/bin/kill -USR2 $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target' \u003e /usr/lib/systemd/system/php-fpm.service # 修改权限 $ chmod 755 /usr/lib/systemd/system/php-fpm.service $ chmod 755 /etc/init.d/php-fpm $ systemctl daemon-reload \u0026\u0026 systemctl enable php-fpm $ systemctl start php-fpm $ systemctl status php-fpm ",
    "description": "安装PHP 安装依赖 # 修整优化 $ yum -y install epel-release $ yum -y install gcc gcc-c++ wget libxml2-devel sqlite-devel bzip2-devel \\ libpng-devel libwebp-devel libjpeg-devel libXpm-devel freetype-devel \\ oniguruma oniguruma-devel ncurses-devel readline-devel openssl-devel \\ libcurl-devel # yum安装版本不够高， 手动安装libzip $ wget https://mirrors.",
    "tags": [],
    "title": "Install_PHP",
    "uri": "/systems/linux/backend/php/install_php/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Ansible",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Use_Slatstack",
    "uri": "/systems/linux/ansible/use_slatstack/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Ansible",
    "content": "使用Ansible 地址 名称 简介 ansible总结 — —- Ansible指南 —- —- 关于become属性 —- —- Ansible剧本的语法 —- —- Ansible的内置模块列表 —- —- Ansible批量自动化管理工具roles标准化 —- — ansible-playbook调用zabbix-api自动添加主机 —- —- Ansible批量安装zabbix-agent并使用zabbix自动添加主机 —- —- 选项 描述 详解 -a MODULE_ARGS, --args=MODULE_ARGS 模块参数 -C, --check、 运行检查，不执行任何操作 -e EXTRA_VARS, --extra-vars=EXTRA_VARS 设置附加变量key=value -f FORKS, --forks=FORKS 指定并行进程数量，默认5 -i INVENTORY, --inventory=INVENTORY 指定主机清单文件路径 --list-hosts 输出匹配的主机列表，不执行任何操作 -m MODULE_NAME, --module-name=MODULE_NAME 执行的模块名，默认command -o 简洁输出法 --syntax-check 语法检查playbook文件，不执行任何操作 -t TREE, --tree=TREE 将日志输出到此目录 -v, --verbose 详细信息：-vvv，更多：-vvvv debug --version 查看程序版本 连接选项 控制谁连接主机和如何连接 详解 -k, --ask-pass 请求连接密码 --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE 私钥文件 -u REMOTE_USER，--user=REMOTE_USER 连接用户，默认None -T TIMEOUT，--timeout=TIMEOUT 覆盖连接超时时间，默认10秒 提权选项 控制在目标主机以什么用户身份运行 详解 -b, --become 以另一个用户身份操作 --become-method=BECOME_METHOD 提权方法，默认sudo --become-user=BECOME_USER 提权后的用户身份，默认root -K, --ask-become-pass 提权密码 配置文件指令 描述 详解 ansible_ssh_host 指定主机别名对应的真实IP ansible_ssh_port 指定连接到这个主机的ssh端口，默认22 ansible_ssh_user 连接到该主机的ssh用户 ansible_ssh_pass 连接到该主机的ssh密码(连-k选项都省了)，安全考虑还是建议使用私钥或在命令行指定-k选项输入 ansible_sudo_pass sudo密码 ansible_sudo_exe(v1.8+的新特性) sudo命令路径 ansible_ssh_private_key_file 私钥文件路径 ansible_nodename ansible_connection 连接类型，可以是local、ssh或paramiko，ansible1.2之前默认为paramiko ansible_os_family ansible_pkg_mgr ansible_shell_type 目标系统的shell类型，默认为sh,如果设置csh/fish，那么命令需要遵循它们语法 ansible_processor ansible_processor_cores ansible_python_interpreter python解释器路径，默认是/usr/bin/python，但是如要要连*BSD系统的话，就需要该指令修改python路径 ansible_*_interpreter 这里的*可以是ruby或perl或其他语言的解释器，作用和ansible_python_interpreter类似 主配置文件 主机名不能使用下划线_ $ cat \u003e/etc/ansible/ansible.cfg\u003c\u003c-EOF [defaults] inventory = /etc/ansible/hosts # library = /usr/share/my_modules/ # module_utils = /usr/share/my_module_utils/ # remote_tmp = ~/.ansible/tmp # local_tmp = ~/.ansible/tmp # plugin_filters_cfg = /etc/ansible/plugin_filters.yml forks = 5 # poll_interval = 15 # sudo_user = root # ask_sudo_pass = True # ask_pass = True # transport = smart remote_port = 22 # module_lang = C # module_set_locale = False become = root host_key_checking = False timeout = 10 log_path = /var/log/ansible.log private_key_file = /root/.ssh/id_rsa # gathering = implicit # gather_subset = all # gather_timeout = 10 # inject_facts_as_vars = True # remote_user = root # roles_path = /etc/ansible/roles # module_name = command # uncomment this to disable SSH key host checking host_key_checking = False # executable = /bin/sh # stdout_callback = skippy # 修改为 json # callback_whitelist = timer, mail # timer：计算整个playbook运行时间 # task_includes_static = False # handler_includes_static = False # error_on_missing_handler = True # sudo_exe = sudo # sudo_flags = -H -S -n # hash_behaviour = replace # private_role_vars = yes # jinja2_extensions = jinja2.ext.do,jinja2.ext.i18n # private_key_file = /path/to/file # vault_password_file = /path/to/vault_password_file # ansible_managed = Ansible managed # display_skipped_hosts = True # display_args_to_stdout = False # error_on_undefined_vars = False # system_warnings = True # deprecation_warnings = True # command_warnings = False # set plugin path directories here, separate with colons # action_plugins = /usr/share/ansible/plugins/action # become_plugins = /usr/share/ansible/plugins/become # cache_plugins = /usr/share/ansible/plugins/cache # callback_plugins = /usr/share/ansible/plugins/callback # connection_plugins = /usr/share/ansible/plugins/connection # lookup_plugins = /usr/share/ansible/plugins/lookup # inventory_plugins = /usr/share/ansible/plugins/inventory # vars_plugins = /usr/share/ansible/plugins/vars # filter_plugins = /usr/share/ansible/plugins/filter # test_plugins = /usr/share/ansible/plugins/test # terminal_plugins = /usr/share/ansible/plugins/terminal # strategy_plugins = /usr/share/ansible/plugins/strategy # strategy = free # bin_ansible_callbacks = False # nocows = 1 # cow_selection = default # cow_selection = random # cow_whitelist=bud-frogs,bunny,cheese,daemon,default,dragon,elephant-in-snake,elephant,eyes,\\ # hellokitty,kitty,luke-koala,meow,milk,moofasa,moose,ren,sheep,small,stegosaurus,\\ # stimpy,supermilker,three-eyes,turkey,turtle,tux,udder,vader-koala,vader,www # nocolor = 1 # fact_caching = memory # For the redis plugin, the value is a host:port:database triplet: fact_caching_connection = localhost:6379:0 # fact_caching_connection=/tmp # retry_files_enabled = False # retry_files_save_path = ~/.ansible-retry # squash_actions = apk,apt,dnf,homebrew,pacman,pkgng,yum,zypper # no_log = False # no_target_syslog = False # allow_world_readable_tmpfiles = False # var_compression_level = 9 # module_compression = 'ZIP_DEFLATED' # max_diff_size = 1048576 # merge_multiple_cli_flags = True # show_custom_stats = True # inventory_ignore_extensions = ~, .orig, .bak, .ini, .cfg, .retry, .pyc, .pyo # network_group_modules=eos, nxos, ios, iosxr, junos, vyos # allow_unsafe_lookups = False # any_errors_fatal = False [inventory] # enable inventory plugins, default: 'host_list', 'script', 'auto', 'yaml', 'ini', 'toml' # enable_plugins = host_list, virtualbox, yaml, constructed # ignore_extensions = .pyc, .pyo, .swp, .bak, ~, .rpm, .md, .txt, ~, .orig, .ini, .cfg, .retry # ignore_patterns= # unparsed_is_failed=False [privilege_escalation] # become=True # become_method=sudo # become_user=root # become_ask_pass=False [paramiko_connection] # record_host_keys=False # pty=False # look_for_keys = False # host_key_auto_add = True [ssh_connection] # ssh_args = -C -o ControlMaster=auto -o ControlPersist=60s # control_path_dir = /tmp/.ansible/cp # control_path_dir = ~/.ansible/cp # control_path = %(directory)s/%%h-%%r # control_path = # pipelining = False # scp_if_ssh = smart # transfer_method = smart # sftp_batch_mode = False # usetty = True # retries = 3 [persistent_connection] # connect_timeout = 30 # command_timeout = 30 [accelerate] # accelerate_port = 5099 # accelerate_timeout = 30 # accelerate_connect_timeout = 5.0 # accelerate_daemon_timeout = 30 # accelerate_multi_key = yes [selinux] # special_context_filesystems=nfs,vboxsf,fuse,ramfs,9p,vfat # libvirt_lxc_noseclabel = yes [colors] # highlight = white # verbose = blue # warn = bright purple # error = red # debug = dark gray # deprecate = purple # skip = cyan # unreachable = red # ok = green # changed = yellow # diff_add = green # diff_remove = red # diff_lines = cyan [diff] # context = 3 # 示例1：未分组的主机 green.example.com blue.example.com 192.168.100.1 192.168.100.10 # 示例2：属于webservers组主机集合 [webservers] alpha.example.org beta.example.org 192.168.1.100 192.168.1.110 www[001:006].example.com # 示例3：属于dbservers组主机集合 [dbservers] db01.intranet.mydomain.net db02.intranet.mydomain.net 10.25.1.56 10.25.1.57 db-[99:101]-node.example.com # 主机和主机组变量： [webservers:vars] http_port=8080 server_name=www.ctnrs.com ansible_ssh_user=\"username\" ansible_ssh_pass=\"password\" ansible_ssh_port=\"port\" # 子组，children：为固定写法 [father:children] webservers dbservers # SSH密码认证 [webservers] 192.168.1.10 ansible_ssh_user=root ansible_ssh_pass='123456’ http_port=80 192.168.1.11 ansible_ssh_user=root ansible_ssh_pass='123456’ http_port=80 # SSH密钥对认证 [webservers] 192.168.1.10:22 ansible_ssh_user=root ansible_ssh_key=/root/.ssh/id_rsa [master] k8s-master ansible_ssh_user=\"username\" ansible_ssh_pass=\"password\" ansible_ssh_port=\"port\" ansible_ssh_host=\"IP\" [node] k8s-node-1 ansible_ssh_user=\"username\" ansible_ssh_pass=\"password\" ansible_ssh_port=\"port\" # 应用示例 aws_host ansible_ssh_private_key_file=/home/example/.ssh/aws.pem freebsd_host ansible_python_interpreter=/usr/local/bin/python ruby_module_host ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 EOF 配置sshd $ rpm -iUvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm $ sed -i 's/^#host_key_checking/host_key_checking/g' /etc/ansible/ansible.cfg $ sed -i 's/PasswordAuthentication[ \\t]*no/PasswordAuthentication yes/' /etc/ssh/sshd_config $ systemctl restart sshd 子配置文件 对主机有效配置 /etc/ansible/host_vars/all # host_vars 目录用于存放 host 变量，all文件对所有主机有效 /etc/ansible/host_vars/foosball # 文件foosball要和hosts里面定义的主机名一样，表示只对 foosball主机有效 对组有效配置 /etc/ansible/group_vars/all # group_vars目录用于存放 group 变量，all文件对所有组有效 /etc/ansible/group_vars/raleigh # 文件 raleigh 要和 hosts 里面定义的组名一样，表示对raleigh组下的所有主机有效 $ cat \u003e/etc/ansible/group_vars/webservers.yaml\u003c\u003c-EOF http_port: 8080 server_name: www.ctnrs.com EOF 命令使用 ansible-doc --help：获取使用帮助 ansible-playbook --help：获取剧本使用帮助 使用Ansible模块和插件 # 列出所有模块 $ ansible-doc -l # 查看其中某一个模块使用方式，找到其中的：EXAMPLES(例子) $ ansible-doc copy # 查看某个模块简单实用方式 $ ansible-doc -s copy # 查看回调插件列表 $ ansible-doc -t callback -l 常用模块 **描述 ** 详解 command、shell 执行shell命令，shell支持管道符等字符 script 脚本模块 copy、file、synchronize 文件传输，copy{src,dest,mode}，file模块可以直接操作远程服务器，synchronize yum 管理软件包 user 用户和组 git 从源代码管理系统部署 service 管理服务 setup 收集目标主机信息 参数解释 -i指定Ansible主机清单，可以指定外部 -m指定要执行的模块，比如：ping、shell、copy -a指定模块的参数， 例如：cppy里的src、dest -o简洁输出法 ping测试 $ ansible all -m ping # 以bruce身份 ping 所有主机 $ ansible all -m ping -u bruce # 用bruce用户 以root身份 ping $ ansible all -m ping -u bruce --sudo # 用bruce用户 sudo到 batman用户 ping $ ansible all -m ping -u bruce --sudo --sudo-user batman # 在所有节点上执行命令 $ ansible all -a \"/bin/echo hello\" 并行性和shell命令 # 重启 altanta 主机组的所有机器，每次重启 10 台 $ ansible atlanta -a \"/sbin/reboot\" -f 10 # 以 geekwolf 用户身份在 atlanta 组的所有主机运行 foo 命令 $ ansible atlanta -a \"/usr/bin/foo\" -u geekwolf # 以 geekwolf 用户身份 sudo 执行命令 foo（--ask-sudo-pass (-K) 如果有 sudo 密码请使用此参数） $ ansible atlanta -a \"/usr/bin/foo\" -u geekwolf --sudo [--ask-sudo-pass] # 也可以 sudo 到其他用户执行命令非 root $ ansible atlanta -a \"/usr/bin/foo\" -u username -U otheruser [--ask-sudo-pass] # 默认情况下，ansible 使用的 module 是 command，这个模块并不支持 shell 变量和管道等，若想使用shell 来执行模块，请使用-m 参数指定 shell 模块 # 使用 shell 模块在远程主机执行命令 $ ansible raleigh -m shell -a 'echo $TERM 传输文件 copy模块 src源 dest目的地 mode权限 owner属主 group属组 backup备份 # 把本地/etc/hosts文件拷贝到 atlanta主机组所有主机的/tmp/hosts(空目录除外),如果使用playbooks 则可以充分利用 template 模块 $ ansible atlanta -m copy -a \"src=/etc/hosts dest=/tmp/hosts\" file模块 # file 模块允许更改文件的用户及权限 $ ansible webservers -m file -a \"dest=/srv/foo/a.txt mode=600\" $ ansible webservers -m file -a \"dest=/srv/foo/b.txt mode=600 owner=mdehaan group=mdehaan\" # 使用 file 模块创建目录，类似 mkdir -p $ ansible webservers -m file -a \"dest=/path/to/c mode=755 owner=mdehaan group=mdehaan state=directory\" # 使用 file 模块删除文件或者目录 $ ansible webservers -m file -a \"dest=/path/to/c state=absent\" synchronize 管理软件包 注释：Ansible支持很多操作系统的软件包管理，使用时-m指定相应的软件包管理工具模块，如果没有这样的模块，可以自己定义类似的模块或者使用command模块来安装软件包 # present 确认安装， 但不更新 $ ansible webservers -m apt -a \"name=nginx state=present\" # 确认安装一个特定版本 $ ansible webservers -m apt -a \"name=nginx-1.5 state=present\" # installed 确认安装 $ ansible webservers -m apt -a \"name=nginx state=installed\" # latest 确认安装包为最新 $ ansible webservers -m apt -a \"name=nginx state=latest\" # absent 和 removed 确认删除 $ ansible webservers -m apt -a \"name=nginx state=absent\" 用户和用户组 # 使用 user 或者 group 模块对于创建新用户和更改、删除已存在用户非常方便 $ ansible all -m user -a \"name=foo password=\u003ccrypted password here\u003e\" $ ansible all -m group -a \"name=foo state=absent\" systemd、service服务管理 daemon_reload重新载入systemd enabled是否开机启动yes|no name服务名称httpd|sshd|nginx state对当前服务操作， 例如： 启动、停止started、stopped、restarted、reloaded # 确保 webservers 组所有主机的 httpd 是启动的 $ ansible webservers -m service -a \"name=httpd state=started\" # 重启 webservers 组所有主机的 httpd 服务 $ ansible webservers -m service -a \"name=httpd state=restarted\" # 确保 webservers 组所有主机的 httpd 是关闭的 $ ansible webservers -m service -a \"name=httpd state=stopped\" 后台运行 长时间运行的操作可以放到后台执行，ansible会检查任务的状态；在主机上执行的同一个任务会分配同一个job ID # 后台执行命令 3600s，-B 表示后台执行的时间 $ ansible all -B 3600 -a \"/usr/bin/long_running_operation --do-stuff\" # 检查任务的状态 $ ansible all -m async_status -a \"jid=123456789\" # 后台执行命令最大时间是 1800s 即 30 分钟，-P 每 60s 检查下状态默认 15s $ ansible all -B 1800 -P 60 -a \"/usr/bin/long_running_operation --do-stuff\" 搜集系统信息 gather_facts: no关闭Facts变量 # Facts 在 playbooks 一章中会有详细的描述，这里只通过命令获取所有的系统信息搜集主机的所有系统信息 $ ansible all -m setup # 搜集系统信息并以主机名为文件名分别保存在/tmp/facts 目录 $ ansible all -i localhost, -m setup --tree /tmp/facts.txt # 搜集和内存相关的信息 $ ansible all -i localhost, -m setup -a 'filter=ansible_*_mb' # 搜集网卡信息 ansible_default_ipv4 $ ansible all -i localhost, -m setup -a 'filter=ansible_all_ipv4_addresses' 使用Galaxy 从Galaxy和Github获得第三方的角色 # 初始化项目，生成默认目录 $ ansible-galaxy init nginx # 使用galaxy 安装服务 $ ansible-galaxy install -p roles darkraiden.ansible-pip $ ansible-galaxy install -p roles git+https://github.com/avinetworks/ansible-role-docker,master 配置Playbook Ansible-Playbook目录、字段定义 地址 描述 Ansible官网文档 Ansible Playbook官方文档 Ansible示例参考 示例参考网址 $ ansible-playbook -i /etc/ansible/hosts example.yml -C # -C 模拟运行查看流程是否会出错 $ ansible-playbook -i /etc/ansible/hosts example.yml --syntax-check # 校验PlayBook脚本语法 $ ansible-playbook -i /etc/ansible/hosts example.yml --tags \"configuration,install\" # 指定安装 $ ansible-playbook -i /etc/ansible/hosts example.yml --skip-tags \"install\" # 跳过 Install 步骤 # 校验yaml文件 $ pip3 install pyyaml # 使用sys标准输入验证 $ python3 -c 'import yaml,sys; print(yaml.safe_load(sys.stdin))' \u003c my_yaml.yaml # 其中，-i inventory_file 指定了你的 Ansible inventory 文件或者直接指定主机名 $ ansible-playbook -i inventory_file execute_local_script.yaml 执行时动态传入主机参数 your_playbook.yaml 是你的Ansible playbook文件名。 target_hosts 是一个变量，可以根据需要设定为具体的主机组名称，比如 web_servers。 -l your_target_hosts 是用来指定要执行的主机组的选项，指定执行目标为单个主机 hostname，指定执行目标为多个主机 host1,host2，使用模式匹配选择所有主机名以 web* 开头的主机 $ ansible-playbook your_playbook.yaml -e \"target_hosts=your_target_hosts\" -l your_target_hosts Roles角色 playbook-roles/ └── roles # 剧本 ├── mysql │ ├── defaults │ │ └── main.yaml │ ├── files │ ├── handlers │ │ └── main.yaml │ ├── meta │ │ └── main.yaml │ ├── README.md │ ├── tasks │ │ └── main.yaml │ ├── templates │ ├── tests │ │ ├── inventory │ │ └── test.yaml │ └── vars │ └── main.yml ├── nginx # Nginx的角色剧本 │ ├── defaults/ # 存放默认变量文件 │ │ └── main.yaml │ ├── files/ # 存放需要传输的静态文件 │ │ └── index.html │ ├── handlers/ # 触发器目录，在变更时执行操作 │ │ └── main.yaml │ ├── meta/ # 存放 role 的元数据文件 │ │ └── main.yaml │ ├── README.md # 用于描述 role 的 README 文件 │ ├── tasks/ # 存放主要任务文件，用来安装程序服务 │ │ └── main.yaml │ ├── templates/ # 存放模板文件 │ │ └── nginx.conf.j2 │ ├── tests/ # 存放测试相关文件 │ │ ├── inventory │ │ └── test.yaml │ └── vars/ # 存放其他变量文件 │ └── main.yaml └── site.yaml # 定义那个节点或者那组服务器执行，可以定义多个角色剧本 playbook-roles→site.yaml name：每个play名字 hosts：每个play涉及被管理的服务器，同ad-hoc中的资产选择器 tasks：每个play中具体要完成的任务，以列表的形式表达，register: 注册变量 become：如果需要提权，则加上become相关属性 become_user：若要提权的话，提权到那个用户上 remote_user：指定连接到远程节点的用户，就是在远程服务器上执行具体操作的用户吗，若不指定，则默认使用当前执行ansible-playbook的用户 进阶剧本语法 when逻辑判断：==、!=、\u003e \u003e=、\u003c \u003c=、is defined、is not defined、true/false、and or、 include剧本引用 Handlers触发器 Roles→Nginx Roles→Nginx目录下文件夹配置 Files存放需要传输的静态文件 $ cat \u003e/opt/ansible-playbook/roles/nginx/files/index.html\u003c\u003c-EOF TEST EOF Handlers触发器目录 $ cat \u003e/opt/ansible-playbook/roles/nginx/handlers/main.yaml\u003c\u003c-EOF --- - name: restart nginx service: name=nginx state=restarted EOF Tasks存放主要任务文件，用来安装程序服务 $ cat \u003e/opt/ansible-playbook/roles/nginx/tasks/main.yaml\u003c\u003c-EOF --- # 声明 - hosts: webservers vars: hello: Ansible tasks: - name: Add repo yum_repository: name: nginx description: nginx repo baseurl: http://nginx.org/packages/centos/7/$basearch/ gpgcheck: no enabled: 1 register: reposyntsx # 检测值 # 定义执行项目名称，安装服务 - name: Install Nginx packge yum: name={{ item }} state=lates # item 为内置变量 with_items: - epel-release - nginx debug: var=reposyntsx # 判断是否成功 when: reposyntsx.rc == 0 # 等于0 代表成功 # 拷贝文件 - name: Copy index.html copy: src: index.html dest: /usr/local/nginx/html/index.html # 拷贝文件 - name: Copy nginx.conf Teplate temlate: src: nginx.conf.j2 dest: /usr/local/nginx/conf/ notify: restart nginx # nginx.conf.j2 文件拷贝成功，通知handlers(触发器) 重启使之生效 # 启动服务 - name: make sure nginx service running service: name: nginx state: started enabled: yes # 创建项目目录 - name: Create wwwroot directory file: dest: /var/www/html state: directory # 创建一个索引文件 - name: Create test page index.html shell: echo \"hello {{hello}}\" \u003e /var/www/html/index.html EOF Templates模板目录 $ cat \u003e/opt/ansible-playbook/roles/nginx/templates/nginx.conf.j2\u003c\u003c-EOF user nobody; worker_processes {{ ansible_processor_cores }}; # 服务内置变量 {# 我是注释 #} events { worker_connections {{ worker_connections }}; # 自定义变量 } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } EOF vars自定义变量目录 $ cat \u003e/opt/ansible-playbook/roles/nginx/vars/main.yaml\u003c\u003c-EOF worker_connections: 10240; EOF site.conf目录 $ cat \u003esite.yaml\u003c\u003c-EOF server { listen 80; server_name www.ctnrs.com; location / { root /var/www/html; index index.html; } } EOF 配置Ansible-Playbook下Roles目录下site.yaml文件 site.yaml文件，定义那个节点或者那组服务器执行什么程序 $ cat \u003e/opt/ansible-playbook/roles/site.yaml\u003c\u003c-EOF - hosts: web roles: - nginx - hosts: mysql roles: - mysql EOF Playbook完整剧本示例 $ cat \u003e/opt/ansible-playbook/nginx.yaml\u003c\u003c-EOF - hosts: web_server vars: app_path: \"{{ base_path }}/app\" http_port: 80 max_clients: 256 become: true # 需要目标主机的用户具有sudo权限 tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: ensure apahech is running service: name=httpd state=started - name: # 创建或修改文件\u0026目录 file: path: /tmp/demo state: directory mode: 0755 - name: # 拷贝文件到目标主机 copy: src: /etc/hostname dest: /tmp/demo/hostname - name: disable selinux command: /sbin/setenforce 0 - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true ignore_errors: True # 忽略报错信息 - name: # 用模板生成配置文件 template: src: demo.j2 dest: \"{{ ansible_user_dir }}/demo.cfg\" handlers - name: restart apache service: name=httpd state=restart EOF $ cat \u003c\u003cEOF \u003eroles/demo-role/tasks/main.yml - include: yum.yml when: (ansible_distribution|lower == 'redhat') or (ansible_distribution|lower == 'centos') - include: apt.yml when: (ansible_distribution|lower == 'debian') or (ansible_distribution|lower == 'ubuntu') EOF $ cat \u003c\u003cEOF \u003eroles/demo-role/tasks/yum.yml - name: # 使用Yum安装Apache服务 yum: name: \"{{ redhat_app }}\" state: \"{{ app_state }}\" notify: - done EOF $ cat \u003c\u003cEOF \u003eroles/demo-role/tasks/apt.yml - name: # 使用Apt安装Apache服务 apt: name: \"{{ debian_app }}\" state: \"{{ app_state }}\" notify: - done EOF $ cat \u003c\u003cEOF \u003eroles/demo-role/vars/main.yml redhat_app: httpd debian_app: apache2 EOF $ cat \u003c\u003cEOF \u003eroles/demo-role/handlers/main.yml - name: done debug: msg: \"Apache服务已部署\" EOF 自动部署Tomcat --- - hosts: webservers gather_facts: no vars: tomcat_version: 8.5.34 tomcat_install_dir: /usr/local tasks: - name: Install jdk1.8 yum: name=java-1.8.0-openjdk state=present - name: Download tomcat get_url: url=http://mirrors.hust.edu.cn/apache/tomcat/tomcat- 8/v{{ tomcat_version }}/bin/apache-tomcat-{{ tomcat_version }}.tar.gz dest=/tmp - name: Unarchive tomcat-{{ tomcat_version }}.tar.gz unarchive: src: /tmp/apache-tomcat-{{ tomcat_version }}.tar.gz dest: \"{{ tomcat_install_dir }}\" copy: no - name: Start tomcat shell: cd {{ tomcat_install_dir }} \u0026\u0026 mv apache-tomcat-{{ tomcat_version }} tomcat8 \u0026\u0026 cd tomcat8/bin \u0026\u0026 nohup ./startup.sh \u0026 ",
    "description": "使用Ansible 地址 名称 简介 ansible总结 — —- Ansible指南 —- —- 关于become属性 —- —- Ansible剧本的语法 —- —- Ansible的内置模块列表 —- —- Ansible批量自动化管理工具roles标准化 —- — ansible-playbook调用zabbix-api自动添加主机 —- —- Ansible批量安装zabbix-agent并使用zabbix自动添加主机 —- —- 选项 描述 详解 -a MODULE_ARGS, --args=MODULE_ARGS 模块参数 -C, --check、 运行检查，不执行任何操作 -e EXTRA_VARS, --extra-vars=EXTRA_VARS 设置附加变量key=value -f FORKS, --forks=FORKS 指定并行进程数量，默认5 -i INVENTORY, --inventory=INVENTORY 指定主机清单文件路径 --list-hosts 输出匹配的主机列表，不执行任何操作 -m MODULE_NAME, --module-name=MODULE_NAME 执行的模块名，默认command -o 简洁输出法 --syntax-check 语法检查playbook文件，不执行任何操作 -t TREE, --tree=TREE 将日志输出到此目录 -v, --verbose 详细信息：-vvv，更多：-vvvv debug --version 查看程序版本 连接选项 控制谁连接主机和如何连接 详解 -k, --ask-pass 请求连接密码 --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE 私钥文件 -u REMOTE_USER，--user=REMOTE_USER 连接用户，默认None -T TIMEOUT，--timeout=TIMEOUT 覆盖连接超时时间，默认10秒 提权选项 控制在目标主机以什么用户身份运行 详解 -b, --become 以另一个用户身份操作 --become-method=BECOME_METHOD 提权方法，默认sudo --become-user=BECOME_USER 提权后的用户身份，默认root -K, --ask-become-pass 提权密码 配置文件指令 描述 详解 ansible_ssh_host 指定主机别名对应的真实IP ansible_ssh_port 指定连接到这个主机的ssh端口，默认22 ansible_ssh_user 连接到该主机的ssh用户 ansible_ssh_pass 连接到该主机的ssh密码(连-k选项都省了)，安全考虑还是建议使用私钥或在命令行指定-k选项输入 ansible_sudo_pass sudo密码 ansible_sudo_exe(v1.",
    "tags": [],
    "title": "Use_Ansible",
    "uri": "/systems/linux/ansible/use_ansible/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Ansible",
    "content": "Slatstack Saltstack基本命令,模块,组件详解 $ salt \"*\" sys.doc \u003e /tmp/saltstack-status.txt ",
    "description": "Slatstack Saltstack基本命令,模块,组件详解 $ salt \"*\" sys.doc \u003e /tmp/saltstack-status.txt ",
    "tags": [],
    "title": "Install_Slatstack",
    "uri": "/systems/linux/ansible/install_slatstack/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Ansible",
    "content": "控制机和目标机 控制机：安装Python、Docker、Pip和Sshpass 目标机：安装Python 地址 名称 描述 阿良老师博客 Ansible安装包 Ansible官网 Github-Ansible原代码 Github Ansible原代码 Install Ansible 安装控制端程序 安装Ansible yum安装Ansible $ rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm $ rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 $ yum -y install epel-release $ sudo yum -y install ansible apt安装Ansible $ sudo apt-get install python-dev $ cat \u003e/etc/apt/source.list\u003c\u003c-EOF deb http://ppa.launchpad.net/ansible/ansible/ubuntu trusty main deb-src http://ppa.launchpad.net/ansible/ansible/ubuntu trusty main EOF $ sudo apt-get install software-properties-common $ sudo apt-add-repository ppa:ansible/ansible $ sudo apt-get update $ sudo apt-get install ansible 使用Python的pip安装Ansible $ pip install ansible $ curl https://raw.githubusercontent.com/mitsuhiko/pipsi/master/get-pipsi.py | \\ python $ pipsi install ansible 源码安装Ansible $ git clone git://github.com/ansible/ansible.git $ cd ./ansible $ make rpm $ sudo rpm -Uvh ~/rpmbuild/ansible-*.noarch.rpm $ git clone git://github.com/ansible/ansible.git --recursive $ cd ./ansible $ source ./hacking/env-setup $ sudo easy_install pip $ sudo pip install paramiko PyYAML Jinja2 httplib2 升级Ansible $ git pull --rebase $ git submodule update --init --recursive 安装Python $ yum install python-pip python3 # 安装python 3 $ python3.6 -m pip install --upgrade --force pip # 通过 python 3 安装pip3 安装Docker $ yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine $ yum makecache fast $ yum list docker-ce --showduplicates|sort -r $ yum install -y docker-ce-20.10.4 docker-ce-cli-20.10.4 containerd.io docker-compose-plugin $ systemctl enable docker \u0026\u0026 systemctl start docker 安装Sshpass $ yum -y install sshpass ",
    "description": "控制机和目标机 控制机：安装Python、Docker、Pip和Sshpass 目标机：安装Python 地址 名称 描述 阿良老师博客 Ansible安装包 Ansible官网 Github-Ansible原代码 Github Ansible原代码 Install Ansible 安装控制端程序 安装Ansible yum安装Ansible $ rpm -Uvh http://dl.",
    "tags": [],
    "title": "Install_Ansible",
    "uri": "/systems/linux/ansible/install_ansible/"
  },
  {
    "breadcrumb": "Services \u003e Shopping",
    "content": "PrestaShop商城系统 PrestaShop ",
    "description": "PrestaShop商城系统 PrestaShop ",
    "tags": [],
    "title": "Install_PrestaShop",
    "uri": "/services/shopping/install_prestashop/"
  },
  {
    "breadcrumb": "Services \u003e Shopping",
    "content": "OpenCart商城系统 OpenCart ",
    "description": "OpenCart商城系统 OpenCart ",
    "tags": [],
    "title": "Install_OpenCart",
    "uri": "/services/shopping/install_opencart/"
  },
  {
    "breadcrumb": "Services \u003e Shopping",
    "content": "JeePay支付系统 JeePay Github JeePay Gitee 部署运行 ",
    "description": "JeePay支付系统 JeePay Github JeePay Gitee 部署运行 ",
    "tags": [],
    "title": "Install_JeePay",
    "uri": "/services/shopping/install_jeepay/"
  },
  {
    "breadcrumb": "Basics \u003e Video",
    "content": "视频下载 VLC media player视频播放器 Streamja视频保存 Youtube视频下载 yt-dlp工具使用、使用查看\"完整播放列表\"、获取完整列表链接 you-get Youtube-dl的详细使用方法 -f：选择格式为最优的mp4格式 -k：保存文件 -c：断点续传 -i：忽略错误 -r, --limit-rate=600K：最大下载速率/秒（以字节为单位） --yes-playlist、--playlist-items 8,15,20,23：指定仅下载播放列表中的8,15,20,23这几集视频 -output 'TJ_%(id)s.%(ext)s'：泰迦拼音首字母缩写 + 视频的ID号 + 格式(.mp4) -x --audio-format mp3：下载歌曲，到mp3格式 $ ./yt-dlp --yes-playlist -f best[ext=mp4] --limit-rate=1024K -k -c -i https://www.youtube.com/playlist?list=PL6YsTaFq7KcMH0cljmGf7F0jK0fdUov10 $ youtube-dl -f best[ext=mp4] -k -c -i --playlist-items 8,15,20,23 https://www.youtube.com/playlist?list=PL6YzOVgBYcEZSB30tzuXeSAhNX3nwu4Wd $ youtube-dl -f best[ext=mp4] -k -c -i --output 'TJ_%(id)s.%(ext)s' https://www.youtube.com/playlist?list=PL6YzOVgBYcEZSB30tzuXeSAhNX3nwu4Wd $ youtube-dl -x --audio-format mp3 https://www.youtube.com/watch?v=Sm_EGqzs2aA bilibili视频下载 哔哩哔哩UWP：下载器 哔哩下载姬 B站视频下载神器 唧唧Down 硕鼠 bilibili哔哩哔哩下载助手 Python爬取视频 Ffmpeg安装合并软件 $ yum -y install epel-release $ yum -y install yasm gcc $ make \u0026\u0026 make install $ echo \"export PATH=$PATH:/usr/local/ffmpeg/bin\" \u003e\u003e/etc/profile $ source /etc/profile Python爬虫脚本 $ cat \u003e/opt/python/Python_Reptile_Youtube.py\u003c\u003c-EOF #!/usr/bin/python3 ''' pip3 install requests --upgrade ''' import requests # 数据请求模块 import re # 正则表达式模块，把数据解析为结构化数据，分别有：parsel、lxml、re import json # 数据类型处理模块 from tqdm import tqdm #进度条配置 import os # 处理文件和目录 import pprint # 格式化输出模块 import subprocess # # 发送请求获取数据 headers = { # 身份信息 'cookie': 'VISITOR_INFO1_LIVE=9qZVrzB27uI; PREF=f4=4000000\u0026tz=Asia.Shanghai; _ga=GA1.2.621834420.1648121145; _gcl_au=1.1.1853038046.1648121145; NID=511=Zc1APdmEbCD-iqVNVgI_vD_0S3LVI3XSfl-wUZEvvMU2MLePFKsQCaKUlUtchHSg-kWEVMGOhWUbxpQMwHeIuLjhxaslwniMh1OsjVfmOeTfhpwcRYpMgqpZtNQ7qQApY21xEObCvIez6DCMbjRhRQ5P7siOD3X87QX0CFyUxmY; OTZ=6430350_24_24__24_; GPS=1; YSC=0E115KqM_-I; GOOGLE_ABUSE_EXEMPTION=ID=d02004902c3d0f4d:TM=1648620854:C=r:IP=47.57.243.77-:S=YmZXPW7dxbu83bDuauEpXpE; CONSISTENCY=AGDxDeNysJ2boEmzRP4v6cwgg4NsdN4-FYQKHCGhA0AeW1QjFIU1Ejq1j8l6lwAc6c-pYTJiSaQItZ1M6QeI1pQ3wictnWXTOZ6_y8EKlt0Y_JdakwW6srR39-NLuPgSgXrXwtS0XTUGXpdnt4k3JjQ', # 防盗链 'referer': 'https://www.youtube.com/', # 浏览器基本信息 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36' } url = 'https://www.youtube.com/watch?v=HuCsEvYPURs\u0026list=PL2Kp-qxDDM0GKCurzpJ448Hr_dxVdPjLp\u0026index=2' # 发送请求，网站自己补全一下 response = requests.get(url=url, headers=headers) print(response.text) # 匹配json数据，.*：匹配任意字符0~N次，?：非贪婪匹配、数据过长有可能截断， json_str = re.findall('var ytInitialPlayerResponse = (.*?);var', response.text)[0] # json字符串转变为字典 json_data = json.loads(json_str) # 提取视频链接 video_url = json_data['streamingData']['adaptiveFormats'][0]['url'] # 提取音频链接 audio_url = json_data['streamingData']['adaptiveFormats'][-2]['url'] # 提取标题 title = json_data['videoDetails']['title'] # 替换掉标题当中的空格 title = title.replace(' ', '') # 替换掉标题当中的不合法字符 title = re.sub(r'[\\/:|?*\"\u003c\u003e]', '', title) # print(video_url) # print(audio_url) # print(title) # 向视频链接发送请求 video = requests.get(video_url, stream=True) # 获取视频大小 file_size = int(video.headers.get('Content-Length')) # 初始化进度条大小 video_pbar = tqdm(total=file_size) # 开始保存视频 with open(f'{title}.mp4', mode='wb') as f: # 把视频分成 1024 * 1024 * 2 为等分的大小 进行遍历 for video_chunk in video.iter_content(1024*1024*2): # 写入数据 f.write(video_chunk) # 更新进度条 video_pbar.set_description(f'正在下载：{title}视频中......') # 更新进度条长度 video_pbar.update(1024*1024*2) # 下载完毕 video_pbar.set_description('下载完成！') # 关闭进度条 video_pbar.close() # 音频同理 audio = requests.get(audio_url, stream=True) file_size = int(audio.headers.get('Content-Length')) audio_pbar = tqdm(total=file_size) with open(f'{title}.mp3', mode='wb') as f: for audio_chunk in audio.iter_content(1024*1024*2): f.write(audio_chunk) audio_pbar.set_description(f'正在下载：{title}音频中......') audio_pbar.update(1024*1024*2) audio_pbar.set_description('下载完成！') audio_pbar.close() def merge(title): print('视频合成开始：', title) # ffmpeg = r'D:\\Download\\ffmpeg\\bin\\ffmpeg.exe -i ' + title + '.mp4 -i ' + title + '.mp3 -acodec copy -vcodec copy ' + title + '-out.mp4' # windows系统 ffmpeg = r'ffmpeg -i ' + title + '.mp4 -i ' + title + '.mp3 -acodec copy -vcodec copy ' + title + '-out.mp4' os.popen(ffmpeg) print('视频合成结束：', title) merge(title) EOF$ cat \u003ePython_Reptile_Youtube-01.py\u003c\u003c-EOF #!/usr/bin/python3 ''' pip3 install requests --upgrade pip3 install tqdm --upgrade ''' import requests # 数据请求模块 import re # 正则表达式模块 import json # 数据类型处理模块 from tqdm import tqdm #进度条配置 import os # 处理文件和目录 import pprint # 格式化输出模块 for page in range(1, 151): print(f'\\n===================== 正在爬取第{page}章视频数据 ======================') # 下载其他视频列表，请更换视频链接 url = 'https://www.youtube.com/watch?v=3ytZtZXQNHE\u0026list=PL2Kp-qxDDM0HrLhEmmbdbuC5PfItF38nN' # 定义获取服务器返回数据函数 def get_response(html_url): # 定义请求客户端 headers = { 'referer': 'https://www.youtube.com/', # 防盗链配置，防盗链作用：告诉服务器，我们发送请求的URL地址，是从哪里过来的 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36' } response = requests.get(url=html_url, headers=headers) # 发送数据请求 # return 返回出去数据 return response # 定义获取视频信息函数 def get_video_info(html_url): response = get_response(html_url) # 正则表达式匹配出来的数据是列表 [0] 索引取0 取出列表内的内容：字符串 html_data = re.findall('var ytInitialPlayerResponse = (.*?);var', response.text)[0] # 像json字典数据，把字符串转成json字典数据 json_data = json.loads(html_data) # pprint.pprint(json_data) # 格式化打印输出，用于查找网址关键字 # 提取标题 title = json_data['videoDetails']['title'] title = title.replace(' ', '') # 替换掉标题当中的空格 title = re.sub(r'[\\/:|?*\"\u003c\u003e]', '', title) # 替换掉标题当中的不合法字符 # 数据解析、键值对取值、提取视频链接 video_url = json_data['streamingData']['adaptiveFormats'][0]['url'] # 数据解析、键值对取值、提取音频链接 audio_url = json_data['streamingData']['adaptiveFormats'][-2]['url'] # 取出的数据保存到列表 video_info = [title, audio_url, video_url] # return 返回出去数据 return video_info # 定义保存视频音频数据函数 def save(title, audio_url, video_url): # 音频/视频/图片/特定格式文件、都以二进制数据进行保存 # 向音频链接发送请求、获取音频大小、初始化进度条大小、开始保存音频 audio = requests.get(audio_url, stream=True) file_size = int(audio.headers.get('Content-Length')) audio_pbar = tqdm(total=file_size) with open(f'{title}.mp3', mode='wb') as f: for audio_chunk in audio.iter_content(1024*1024*2): f.write(audio_chunk) audio_pbar.set_description(f'正在下载：{title}音频中......') audio_pbar.update(1024*1024*2) audio_pbar.set_description('下载完成！') audio_pbar.close() # 向音视频接发送请求、获取视频大小、初始化进度条大小、开始保存视频 video = requests.get(video_url, stream=True) file_size = int(video.headers.get('Content-Length')) video_pbar = tqdm(total=file_size) with open(f'{title}.mp4', mode='wb') as f: # 把视频分成 1024 * 1024 * 2 为等分的大小 进行遍历 for video_chunk in video.iter_content(1024*1024*2): # 写入数据 f.write(video_chunk) # 更新进度条 video_pbar.set_description(f'正在下载：{title}视频中......') # 更新进度条长度 video_pbar.update(1024*1024*2) # 下载完毕 video_pbar.set_description('下载完成！') # 关闭进度条 video_pbar.close() video_info = get_video_info(url) save(video_info[0], video_info[1], video_info[2]) def merge(title): print('视频合成开始：', title) FFMPEG = f'ffmpeg -i ' + title + '.mp4 -i ' + title + '.mp3 -acodec copy -vcodec copy ' + title + '-out.mp4' subprocess.Popen(FFMPEG, shell=True) print('视频合成结束：', title) merge(title) EOF ",
    "description": "视频下载 VLC media player视频播放器 Streamja视频保存 Youtube视频下载 yt-dlp工具使用、使用查看\"完整播放列表\"、获取完整列表链接 you-get Youtube-dl的详细使用方法 -f：选择格式为最优的mp4格式 -k：保存文件 -c：断点续传 -i：忽略错误 -r, --limit-rate=600K：最大下载速率/秒（以字节为单位） --yes-playlist、--playlist-items 8,15,20,23：指定仅下载播放列表中的8,15,20,23这几集视频 -output 'TJ_%(id)s.",
    "tags": [],
    "title": "Video_Download",
    "uri": "/basics/video/video_download/"
  },
  {
    "breadcrumb": "Basics \u003e template",
    "content": " Hugo通过Chroma提供非常快速的语法高亮显示，现Hugo中使用Chroma作为代码块高亮支持，它内置在Go语言当中，速度是真的非常、非常快，而且最为重要的是它也兼容之前我们使用的Pygments方式。 以下通过Hugo内置短代码highlight和Markdown代码块方式分别验证不同语言的代码块渲染效果并能正确高亮显示，有关优化语法突出显示的更多信息，请参阅 Hugo文档。 编程语言 GO func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case \"go\": return strings.Title case \"chicago\": return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle) } } Java import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame frame.setTitle(\"Hi!\"); //Setting title frame frame.add(new JLabel(\"Hello, world!\"));//Adding text to frame frame.pack(); //Setting size to smallest frame.setLocationRelativeTo(null); //Centering frame frame.setVisible(true); //Showing frame } } Python print \"Hello, world!\" Git对比 ",
    "description": "Hugo通过Chroma提供非常快速的语法高亮显示，现Hugo中使用Chroma作为代码块高亮支持，它内置在Go语言当中，速度是真的非常、非常快，而且最为重要的是它也兼容之前我们使用的Pygments方式。 以下通过Hugo内置短代码highlight和Markdown代码块方式分别验证不同语言的代码块渲染效果并能正确高亮显示，有关优化语法突出显示的更多信息，请参阅 Hugo文档。 编程语言 GO func GetTitleFunc(style string) func(s string) string { switch strings.",
    "tags": [],
    "title": "Syntax_Highlighting",
    "uri": "/basics/template/syntax_highlighting/"
  },
  {
    "breadcrumb": "Basics \u003e template",
    "content": "二维码生成管理系统 开源二维码生成管理 Dynamic QRcode、部署文档 Laravel QRCode Scan XOOPS和ImpressCMS的Qr模块 Campus QR Qr-code-generator Event QR ticket management system Nova QR Code Manager 安装Impresscms 安装Install安装工具 $ wget https://getcomposer.org/installer $ /opt/apps/php/bin/php installer 安装Composer.phar $ mv composer.phar /opt/apps/php/bin/ $ /opt/apps/php/bin/php /opt/apps/php/bin/composer.phar # 配置软连接 $ sudo ln -s /opt/apps/php/bin/composer.phar /usr/bin/composer $ sudo ln -s /opt/apps/php/bin/php /usr/bin/php 安装Impresscms $ /opt/apps/php/bin/composer.phar create-project -s dev impresscms/impresscms 安装PHP-Dynamic-Qr-code 需要Mysql、PHP环境 $ git clone https://github.com/giandonatoinverso/PHP-Dynamic-Qr-code.git 修改数据库链接文件 $ cat /opt/qrcode/PHP-Dynamic-Qr-code/qrcode/config/environment.php 配置Nginx server{ listen 80; server_name dynamicqr.erge.com; location / { root /opt/qrcode/PHP-Dynamic-Qr-code/qrcode; index index.php index.html index.htm; # 添加\"index.php\" } # tcp socket 通信模式 location ~ \\.php$ { root\t/opt/qrcode/PHP-Dynamic-Qr-code/qrcode; fastcgi_pass 127.0.0.1:9000; # 可以设置为：unix:/tmp/php7.sock fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # fastcgi_param行改成这个。 include fastcgi_params; } # Unix socke 通信模式 # location ~ \\.php$ { # root\t/opt/PHP-Dynamic-Qr-code/qrcode; # fastcgi_pass unix:/opt/logs/php/php7.sock; # fastcgi_index index.php; # fastcgi_split_path_info ^((?U).+\\.php)(/?.+)$; # fastcgi_param PATH_INFO $fastcgi_path_info; # include vhosts/fastcgi.conf; # } error_page 404 http://dynamicqr.erge.com; access_log /opt/logs/nginx/dynamicqr-access.log main; error_log /opt/logs/nginx/dynamicqr-error.log info; } docker安装 $ docker-compose build --build-arg PUID=1000 --build-arg PGID=1000 ",
    "description": "二维码生成管理系统 开源二维码生成管理 Dynamic QRcode、部署文档 Laravel QRCode Scan XOOPS和ImpressCMS的Qr模块 Campus QR Qr-code-generator Event QR ticket management system Nova QR Code Manager 安装Impresscms 安装Install安装工具 $ wget https://getcomposer.",
    "tags": [],
    "title": "QRcode_Manager",
    "uri": "/basics/template/qrcode_manager/"
  },
  {
    "breadcrumb": "Basics \u003e template",
    "content": "使用说明 Mermaid 实现以纯文本的方式绘制流程图、序列图、甘特图、状态图、关系图行等等，随着 Mermaid 也在逐步发展，后续还会有各种各样的图被引入进来，更多的类型及使用方式可关注其官方网站：mermaid-js.github.io 在文章头部配置mermaid: true 使用短代码书写各种类型的图，自带2个参数：align(对齐)和bc(背景色)，可参考如下使用示例 流程图 graph TD; A--\u003eB; A--\u003eC; B--\u003eD; C--\u003eD; 时序图 sequenceDiagram participant Alice participant Bob Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003e\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts \u003cbr/\u003eprevail! John--\u003e\u003eAlice: Great! John-\u003e\u003eBob: How about you? Bob--\u003e\u003eJohn: Jolly good! 类图 classDiagram Class01 \u003c|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u003e C2 : Where am i? Class09 --* C3 Class09 --|\u003e Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u003c--\u003e C2: Cool label 甘特图 gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d 实体关系图 erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 用户旅程 journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me ",
    "description": "使用说明 Mermaid 实现以纯文本的方式绘制流程图、序列图、甘特图、状态图、关系图行等等，随着 Mermaid 也在逐步发展，后续还会有各种各样的图被引入进来，更多的类型及使用方式可关注其官方网站：mermaid-js.github.io 在文章头部配置mermaid: true 使用短代码书写各种类型的图，自带2个参数：align(对齐)和bc(背景色)，可参考如下使用示例 流程图 graph TD; A--\u003eB; A--\u003eC; B--\u003eD; C--\u003eD; 时序图 sequenceDiagram participant Alice participant Bob Alice-\u003e\u003eJohn: Hello John, how are you?",
    "tags": [],
    "title": "Mermaid_Charts",
    "uri": "/basics/template/mermaid_charts/"
  },
  {
    "breadcrumb": "Basics \u003e template",
    "content": "例子 mathjax 和 katex 两种不的方案支持数学公式的渲染，可根据自已的需求进行选择 接下的示例中，将使用MathJax方案来展示渲染效果 使用hugo new命令创建一篇新的文章 可以全局启用数据公式渲染，请在项目配置参数 math: katex 或 math: mathjax 或是将该参数配置到需要显示数学公式的页面头部（减少不必要的加载消耗） 注意： 使用支持的TeX功能的联机参考资料 重复的分数 $$ \u003e \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} \\equiv \u003e 1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}} {1+\\frac{e^{-8\\pi}} {1+\\cdots} } } } \u003e $$ 总和记号 $$ \u003e \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right) \u003e $$ 几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \\displaystyle。 $$ \u003e \\displaystyle\\sum_{i=1}^{k+1}i \u003e $$ $$ \u003e \\displaystyle= \\left(\\sum_{i=1}^{k}i\\right) +(k+1) \u003e $$ $$ \u003e \\displaystyle= \\frac{k(k+1)}{2}+k+1 \u003e $$ $$ \u003e \\displaystyle= \\frac{k(k+1)+2(k+1)}{2} \u003e $$ $$ \u003e \\displaystyle= \\frac{(k+1)(k+2)}{2} \u003e $$ $$ \u003e \\displaystyle= \\frac{(k+1)((k+1)+1)}{2} \u003e $$ 乘记号 $$ \u003e \\displaystyle 1 + \\frac{q^2}{(1-q)}+\\frac{q^6}{(1-q)(1-q^2)}+\\cdots = \\displaystyle \\prod_{j=0}^{\\infty}\\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \\displaystyle\\text{ for }\\lvert q\\rvert \u003c 1. \u003e $$ 随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。 $$ \u003e k_{n+1} = n^2 + k_n^2 - k_{n-1} \u003e $$ 希腊字母 $$ \u003e \\Gamma\\ \\Delta\\ \\Theta\\ \\Lambda\\ \\Xi\\ \\Pi\\ \\Sigma\\ \\Upsilon\\ \\Phi\\ \\Psi\\ \\Omega \u003e \\alpha\\ \\beta\\ \\gamma\\ \\delta\\ \\epsilon\\ \\zeta\\ \\eta\\ \\theta\\ \\iota\\ \\kappa\\ \\lambda\\ \\mu\\ \\nu\\ \\xi \\ \\omicron\\ \\pi\\ \\rho\\ \\sigma\\ \\tau\\ \\upsilon\\ \\phi\\ \\chi\\ \\psi\\ \\omega\\ \\varepsilon\\ \\vartheta\\ \\varpi\\ \\varrho\\ \\varsigma\\ \\varphi \u003e $$ 箭头 $$ \u003e \\gets\\ \\to\\ \\leftarrow\\ \\rightarrow\\ \\uparrow\\ \\Uparrow\\ \\downarrow\\ \\Downarrow\\ \\updownarrow\\ \\Updownarrow \u003e $$ $$ \u003e \\Leftarrow\\ \\Rightarrow\\ \\leftrightarrow\\ \\Leftrightarrow\\ \\mapsto\\ \\hookleftarrow \u003e \\leftharpoonup\\ \\leftharpoondown\\ \\rightleftharpoons\\ \\longleftarrow\\ \\Longleftarrow\\ \\longrightarrow \u003e $$ $$ \u003e \\Longrightarrow\\ \\longleftrightarrow\\ \\Longleftrightarrow\\ \\longmapsto\\ \\hookrightarrow\\ \\rightharpoonup \u003e $$ $$ \u003e \\rightharpoondown\\ \\leadsto\\ \\nearrow\\ \\searrow\\ \\swarrow\\ \\nwarrow \u003e $$ 符号 $$ \u003e \\surd\\ \\barwedge\\ \\veebar\\ \\odot\\ \\oplus\\ \\otimes\\ \\oslash\\ \\circledcirc\\ \\boxdot\\ \\bigtriangleup \u003e $$ $$ \u003e \\bigtriangledown\\ \\dagger\\ \\diamond\\ \\star\\ \\triangleleft\\ \\triangleright\\ \\angle\\ \\infty\\ \\prime\\ \\triangle \u003e $$ 微积分学 $$ \u003e \\int u \\frac{dv}{dx}\\,dx=uv-\\int \\frac{du}{dx}v\\,dx \u003e $$ $$ \u003e f(x) = \\int_{-\\infty}^\\infty \\hat f(\\xi)\\,e^{2 \\pi i \\xi x} \u003e $$ $$ \u003e \\oint \\vec{F} \\cdot d\\vec{s}=0 \u003e $$ 洛伦茨方程 $$ \u003e \\begin{aligned} \\dot{x} \u0026 = \\sigma(y-x) \\\\\\\\ \\dot{y} \u0026 = \\rho x - y - xz \\\\\\\\ \\dot{z} \u0026 = -\\beta z + xy \\end{aligned} \u003e $$ 交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。 $$ \u003e \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} \u0026 \\mathbf{j} \u0026 \\mathbf{k} \\\\\\\\ \\frac{\\partial X}{\\partial u} \u0026 \\frac{\\partial Y}{\\partial u} \u0026 0 \\\\\\\\ \\frac{\\partial X}{\\partial v} \u0026 \\frac{\\partial Y}{\\partial v} \u0026 0 \\end{vmatrix} \u003e $$ 这里有一个解决方案:使用mfrac类(在MathJax情况下没有区别)的额外类使分数更小: $$ \u003e \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} \u0026 \\mathbf{j} \u0026 \\mathbf{k} \\\\\\\\ \\frac{\\partial X}{\\partial u} \u0026 \\frac{\\partial Y}{\\partial u} \u0026 0 \\\\\\\\ \\frac{\\partial X}{\\partial v} \u0026 \\frac{\\partial Y}{\\partial v} \u0026 0 \\end{vmatrix} \u003e $$ 强调 $$ \u003e \\hat{x}\\ \\vec{x}\\ \\ddot{x} \u003e $$ 有弹性的括号 $$ \u003e \\left(\\frac{x^2}{y^3}\\right) \u003e $$ 评估范围 $$ \u003e \\left.\\frac{x^3}{3}\\right|_0^1 \u003e $$ 诊断标准 $$ \u003e f(n) = \\begin{cases} \\frac{n}{2}, \u0026 \\text{if } n\\text{ is even} \\\\\\\\ 3n+1, \u0026 \\text{if } n\\text{ is odd} \\end{cases} \u003e $$ 麦克斯韦方程组 $$ \u003e \\begin{aligned} \\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} \u0026 = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\\\\ \\nabla \\cdot \\vec{\\mathbf{E}} \u0026 = 4 \\pi \\rho \\\\\\\\ \\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} \u0026 = \\vec{\\mathbf{0}} \\\\\\\\ \\nabla \\cdot \\vec{\\mathbf{B}} \u0026 = 0 \\end{aligned} \u003e $$ 统计学 固定词组： $$ \u003e \\frac{n!}{k!(n-k)!} = {^n}C_k \u003e {n \\choose k} \u003e $$ 分数在分数 $$ \u003e \\frac{\\frac{1}{x}+\\frac{1}{y}}{y-z} \u003e $$ ｎ次方根 $$ \u003e \\sqrt[n]{1+x+x^2+x^3+\\ldots} \u003e $$ 矩阵 $$ \u003e \\begin{pmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{pmatrix} \u003e \\begin{bmatrix} 0 \u0026 \\cdots \u0026 0 \\\\\\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\ 0 \u0026 \\cdots \u0026 0 \\end{bmatrix} \u003e $$ 标点符号 $$ \u003e f(x) = \\sqrt{1+x} \\quad (x \\ge -1) \u003e f(x) \\sim x^2 \\quad (x\\to\\infty) \u003e $$ 现在用标点符号: $$ \u003e f(x) = \\sqrt{1+x}, \\quad x \\ge -1 \u003e f(x) \\sim x^2, \\quad x\\to\\infty \u003e $$ ",
    "description": "例子 mathjax 和 katex 两种不的方案支持数学公式的渲染，可根据自已的需求进行选择 接下的示例中，将使用MathJax方案来展示渲染效果 使用hugo new命令创建一篇新的文章 可以全局启用数据公式渲染，请在项目配置参数 math: katex 或 math: mathjax 或是将该参数配置到需要显示数学公式的页面头部（减少不必要的加载消耗） 注意： 使用支持的TeX功能的联机参考资料 重复的分数 $$ \u003e \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5}}-\\phi\\Bigr) e^{\\frac25 \\pi}} \\equiv \u003e 1+\\frac{e^{-2\\pi}} {1+\\frac{e^{-4\\pi}} {1+\\frac{e^{-6\\pi}} {1+\\frac{e^{-8\\pi}} {1+\\cdots} } } } \u003e $$ 总和记号 $$ \u003e \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right) \u003e $$ 几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \\displaystyle。 $$ \u003e \\displaystyle\\sum_{i=1}^{k+1}i \u003e $$ $$ \u003e \\displaystyle= \\left(\\sum_{i=1}^{k}i\\right) +(k+1) \u003e $$ $$ \u003e \\displaystyle= \\frac{k(k+1)}{2}+k+1 \u003e $$ $$ \u003e \\displaystyle= \\frac{k(k+1)+2(k+1)}{2} \u003e $$ $$ \u003e \\displaystyle= \\frac{(k+1)(k+2)}{2} \u003e $$ $$ \u003e \\displaystyle= \\frac{(k+1)((k+1)+1)}{2} \u003e $$ 乘记号 $$ \u003e \\displaystyle 1 + \\frac{q^2}{(1-q)}+\\frac{q^6}{(1-q)(1-q^2)}+\\cdots = \\displaystyle \\prod_{j=0}^{\\infty}\\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \\displaystyle\\text{ for }\\lvert q\\rvert \u003c 1.",
    "tags": [],
    "title": "Math Formula",
    "uri": "/basics/template/math_formula/"
  },
  {
    "breadcrumb": "Basics \u003e MarkDown",
    "content": "Markdown语法使用 Markdown官方教程 **Markdown是编写HTML**的一种更好的方式，它没有通常伴随的所有复杂性和丑陋性，一些主要优点包括 Markdown简单易学，额外字符很少，因此编写内容也更快 使用Markdown写作时出错的可能性较小 产生有效的HTML输出 将内容和视觉显示分开，这样您就不会弄乱网站的外观 在您喜欢的任何文本编辑器或Markdown应用程序中书写 Typora主题选择 Typora Drake主题 Notion主题 Markdown目录跳转方式 [标题样式](#标题样式) [段落格式](#段落格式) [列表类型](#列表类型) [块引用](#块引用) [表格](#表格) [`Code`](#Code) [其它元素：`abbr`、`sub`、`sup`、`kbd`等等](#其它元素：abbr、sub、sup、kbd等等) [文字颜色](#文字颜色) [toc] 我是目录跳转 more截断文档显示阅读全文按钮 \u003c!-- more --\u003e toc标签会生成本篇文章的目录 \u003c!-- toc --\u003e 标准和扩展 除非另有说明，所展示的示例均遵循Commonmark标准。此外，该主题还支持以下扩展，可在您的hugo.toml或者内置于主题中: 在GitHub标准Markdown之上进行扩展，遵循GitHub Flavored Markdown 在PHP标准Markdown之上进行扩展，遵循PHP Markdown Pants由John Gruber遵循SmartyPants进行的扩展 Hugo支持的Hugo Extra扩展 Relearn 特定于该主题的扩展 HTML如果允许使用HTML，主题将支持进一步的HTML元素的样式 段落 在Markdown中，您的内容通常横跨整个可用文档宽度。这称为块。在生成的文档中，块与相邻块之间始终以空格分隔\n任何不以特殊符号开头的文本都将以普通的纯文本段落块的形式写出，并且必须用空行与相邻的块分隔开\n根据W3C定义的HTML5规范，HTML 文档由元素和文本组成。每个元素的组成都由一个开始标记表示，例如： \u003cbody\u003e ，和结束标记表示，例如： \u003c/body\u003e 。（某些开始标记和结束标记在某些情况下可以省略，并由其他标记暗示。）\n元素可以具有属性，这些属性控制元素的工作方式。例如：超链接是使用 a 元素及其 href 属性形成的\n标题 一个好主意是使用标题和副标题来组织您的内容。从h1到的HTML标题由每个级别的h6构成。# 在Hugo中您通常不会使用它，h1因为它是由您的主题生成的，并且您在一个文档中应该只有一个这样的元素 # h1 标题 ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 水平线 为了进一步组织内容，您可以添加水平线。它们在段落块之间创建主题分隔符。在Markdown中，您可以使用三个连续的破折号来创建它---。 文本标记 粗体 您可以通过将一段文本括在两个星号中来显示其重要性，并且使用较大的字体粗细来显示这段文本**。 斜体 您可以通过在文本片段左右加上下划线来用斜体强调该文本片段_。 标记文本 您可以使用样式表的预定义强调色来标记文本 Hugo从Hugo 0.126.0开始，你可以通过Hugo Extra Extension激活此功能hugo.toml ==部分== 文本 ==标记== HTML您还可以通过配置Hugo来使用它以使用HTML。 \u003cmark\u003e部分\u003c/mark\u003e文本\u003cmark\u003e标记\u003c/mark\u003e部分文本标记\n插入文本 您可以将文本添加标记到现有文本中 Hugo从Hugo 0.126.0开始，你可以通过Hugo Extra Extension激活此功能hugo.toml 这是 ++插入++ 文本 HTML您还可以通过配置Hugo来使用它以使用HTML 这是\u003cins\u003e插入\u003c/ins\u003e文本这是插入文本\n删除文本 您可以通过用两个波浪号括住文本来添加删除线~~。 ~~Strike through~~ 这是删除线Strike through 这是删除线\n特殊排版 文本替换 Pants您可以将多个标点符号组合成单个印刷实体。这仅适用于代码块或内联代码之外的文本 括起文本的双引号\"和单引号'分别被**“双花引号”和“单花引号”**取代。\n双破折号--和三破折号被短破折号和长破折号实体---取代。\n\u003c\u003c指向左或右的双箭头被箭头**“和”**实体\u003e\u003e取代。\n三个连续的点...被省略号**…**实体取代。\n上标和下标 您还可以使用下标和上标文本。对于更复杂的内容，您可以使用math简码。\nHugo从Hugo 0.126.0开始，你可以通过Hugo Extra Extension激活此功能hugo.toml\nHow many liters H~2~O fit into 1dm^3^? 1dm^3^ 中能容纳多少升 H~2~O?\nHTML您还可以通过配置Hugo来使用它以使用HTML How many liters H\u003csub\u003e2\u003c/sub\u003eO fit into 1dm\u003csup\u003e3\u003c/sup\u003e?1dm3中能容纳多少升H2O\n键盘快捷键 HTML您可以使用该\u003ckbd\u003e元素来设置键盘快捷键的样式 按下 \u003ckbd\u003eSTRG\u003c/kbd\u003e \u003ckbd\u003eALT\u003c/kbd\u003e \u003ckbd\u003eDEL\u003c/kbd\u003e 即可提前结束轮班按下 STRG ALT DEL 即可提前结束轮班\n列表 无序列表 您可以编写一个项目列表，其中项目的顺序并不重要 可以通过缩进下一子级的项目来嵌套列表 -您可以使用或中的任一个*来+表示每个列表项的项目符号，但不应在整个列表内切换这些符号 有序列表 您可以创建一个项目列表，其中项目的顺序确实很重要 可以通过缩进下一子级的项目来嵌套列表 Markdown会自动为您的每件商品进行连续编号。这意味着您提供的订单号无关紧要 嵌套列表 借助HTML的ul元素来实现 \u003cul\u003e \u003cli\u003e第一项\u003c/li\u003e \u003cli\u003e第二项 \u003cul\u003e \u003cli\u003e第二项第一个子项目\u003c/li\u003e \u003cli\u003e第二项第二个子项目 \u003cul\u003e \u003cli\u003e第二项第二分项第一分项\u003c/li\u003e \u003cli\u003e第二项第二分项第二分项\u003c/li\u003e \u003cli\u003e第二项第二分项第三分项\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003e第二项第三个子项目 \u003col\u003e \u003cli\u003e第二项第三分项第一分项\u003c/li\u003e \u003cli\u003e第二项第三分项第二分项\u003c/li\u003e \u003cli\u003e第二项第三分项第三分项\u003c/li\u003e \u003c/ol\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003e第三项\u003c/li\u003e \u003c/ul\u003e 自定义列表 通过HTML的dl元素还支持自定义列表（表格列表） \u003cdl\u003e \u003cdt\u003eHugo 目录结构\u003c/dt\u003e \u003cdd\u003eassets\u003c/dd\u003e \u003cdd\u003econfig.toml\u003c/dd\u003e \u003cdd\u003econtent\u003c/dd\u003e \u003cdd\u003edata\u003c/dd\u003e \u003cdd\u003etheme\u003c/dd\u003e \u003cdd\u003estatic\u003c/dd\u003e \u003cdt\u003eHugo 模板\u003c/dt\u003e \u003cdd\u003e基础模板\u003c/dd\u003e \u003cdd\u003e列表模板\u003c/dd\u003e \u003cdd\u003e单页模板\u003c/dd\u003e \u003c/dl\u003e 任务 GitHub您可以添加任务列表，从而得到选中或未选中的不可点击项目 - [x] Basic Test - [ ] More Tests - [x] View - [x] Hear - [ ] Smell 表格 在任何标题下方的破折号左侧和/或右侧添加冒号将相应地对齐该列的文本 | 选项 | 数字 | 描述 | |----:|:---:|:-----| | 数据 | 1 | 提供将传递到模板的数据的数据文件路径 | | 引擎 | 2 | 用于处理模板的引擎。默认为 Handlebars | | 扩展 | 3 | 用于目标文件的扩展名 | 可以使用 : （英文格式冒号）来对表格内容进行对齐。 表格 可以是 很酷 左对齐 居中 右对齐 左对齐 居中 右对齐 左对齐 居中 右对齐 同样也可以在表格中使用 Markdown 语法 表格 中 使用 Markdown 语法 斜体 粗体 中划线 代码块 链接 自动链接 对URL将自动转换为链接 这是指向https://example.com的链接\n基本链接 如果您想使用非绝对URL或想要提供不同的文本，您可以明确定义链接 Assemble\n带有工具提示的链接 如需更多信息，您可以添加额外的文本，当鼠标悬停在链接上时，该文本会显示在工具提示中 [Upstage](https://github.com/upstage/ \"Visit Upstage!\")Upstage\n链接参考 通过使用参考ID稍后定义URL位置，可以简化链接的重复使用。如果您想在文档中多次使用链接，这可以简化书写 [Example][somelinkID] [somelinkID]: https://example.com \"Go to example domain\"Example\n脚注 PHP脚注的作用与参考样式的链接非常相似。脚注由两部分组成：文本中的标记（将成为上标数字）和脚注定义（将放置在脚注列表中） 通常，脚注列表会显示在文档末尾。如果我们在通知框中使用脚注，则会将其列在通知框末尾 脚注可以包含块元素，这意味着您可以在脚注中放置多个段落、列表、块引用等。它与列表项的工作方式相同，只需在脚注定义中将以下段落缩进四个空格即可 That's some text with a footnote[^1] [^1]: And that's the footnote. That's some more text with a footnote.[^someid] [^someid]: Anything of interest goes here. Blue light glows blue. 图片 基本图片 Markdown语法图像的语法与链接类似，但包含前面的感叹号 ![图像说明](图像地址) HTML IMG标签. \u003cimg src=\"图像地址\" width=\"宽度\" height=\"高度\" /\u003e SVG格式 \u003csvg\u003exxxxxx\u003c/svg\u003e\u003csvg class=\"canon\" xmlns=\"http://www.w3.org/2000/svg\" overflow=\"visible\" viewBox=\"0 0 496 373\" height=\"373\" width=\"496\"\u003e\u003cg fill=\"none\"\u003e\u003cpath stroke=\"#000\" stroke-width=\".75\" d=\"M.599 372.348L495.263 1.206M.312.633l494.95 370.853M.312 372.633L247.643.92M248.502.92l246.76 370.566M330.828 123.869V1.134M330.396 1.134L165.104 124.515\"\u003e\u003c/path\u003e\u003cpath stroke=\"#ED1C24\" stroke-width=\".75\" d=\"M275.73 41.616h166.224v249.05H275.73zM54.478 41.616h166.225v249.052H54.478z\"\u003e\u003c/path\u003e\u003cpath stroke=\"#000\" stroke-width=\".75\" d=\"M.479.375h495v372h-495zM247.979.875v372\"\u003e\u003c/path\u003e\u003cellipse cx=\"498.729\" cy=\"177.625\" rx=\".75\" ry=\"1.25\"\u003e\u003c/ellipse\u003e\u003cellipse cx=\"247.229\" cy=\"377.375\" rx=\".75\" ry=\"1.25\"\u003e\u003c/ellipse\u003e\u003c/g\u003e\u003c/svg\u003e 带有工具提示的图像 与链接类似，图像也可以添加工具提示 ![Picard](https://octodex.github.com/images/jean-luc-picat.jpg \"Jean Luc Picard\") 图片参考 图像还可以通过参考 ID 进行链接，以便稍后定义 URL 位置。如果您想在文档中多次使用图像，这将简化书写过程 ![La Forge][laforge] [laforge]: https://octodex.github.com/images/trekkie.jpg \"Geordi La Forge\" 图像效果 Relearn主题允许通过在图像URL末尾设置查询参数来设置其他非标准格式。默认行为可通过您的hugo.toml或frontmatter参数 调整大小 添加查询参数width和/或height到链接图像以调整图像大小。值为CSS值（默认为auto） ![Minion](https://octodex.github.com/images/minion.png?width=20vw)![Minion](https://octodex.github.com/images/minion.png?height=50px)![Minion](https://octodex.github.com/images/minion.png?height=50px\u0026width=40vw) 阴影 ![Spidertocat](https://octodex.github.com/images/spidertocat.png?classes=shadow) 边界 ![DrOctocat](https://octodex.github.com/images/droctocat.png?classes=border) 左边 ![Supertocat](https://octodex.github.com/images/okal-eltocat.jpg?classes=left) 右边 ![Riddlocat](https://octodex.github.com/images/riddlocat.jpg?classes=right) 并排 ![Spidertocat](https://octodex.github.com/images/spidertocat.png?classes=inline) ![DrOctocat](https://octodex.github.com/images/droctocat.png?classes=inline) ![Supertocat](https://octodex.github.com/images/okal-eltocat.jpg?classes=inline) ![Riddlocat](https://octodex.github.com/images/riddlocat.jpg?classes=inline) 组合 ![X-tocat](https://octodex.github.com/images/xtocat.jpg?classes=shadow,border,left) 灯箱 添加查询参数lightbox=false到图像链接来禁用灯箱 ![Homercat](https://octodex.github.com/images/homercat.png?lightbox=false) 如果你想将图片包装在链接中，lightbox=true是您的默认设置，您必须明确禁用灯箱以避免它劫持您的链接，例如： [![Homercat](https://octodex.github.com/images/homercat.png?lightbox=false)](https://octodex.github.com/#homercat) Code \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 字体颜色 写法 \u003cfont color=#0099ff\u003e蓝色\u003c/font\u003e \u003cfont color=red\u003e红色\u003c/font\u003e 蓝色 # 蓝色效果 红色 # 红色效果 常用颜色 color=maroon\ncolor=grey\ncolor=silver\ncolor=lightgrey\ncolor=HotPink\ncolor=DeepPink\ncolor=VioletRed\ncolor=Purple color=navy\ncolor=Blue\ncolor=DeepSkyBlue\ncolor=LightSkyBlue\ncolor=aqua\ncolor=DarkTurquoise\ncolor=LightSeaGreen\ncolor=YellowGreen\ncolor=LawnGreen\ncolor=GreenYellow\ncolor=Yellow\ncolor=Tomato\ncolor=red\ncolor=fuchsia\ncolor=MediumOrchid\ncolor=DarkViolet\n文字与代码高亮编写方法 ==highlight 1== \u003cmark\u003ehighlight 2\u003c/mark\u003e ```code 1``` `code 2` == highlight1 == # 效果展示 highlight 2 # 效果展示 code 1 # 效果展示 code 2 # 效果展示 字体字号 默认字体 \u003cfont face=\"黑体\"\u003e黑体\u003c/font\u003e \u003cfont face=\"微软雅黑\"\u003e微软雅黑\u003c/font\u003e \u003cfont size=2 face=\"黑体\"\u003e黑体2号\u003c/font\u003e \u003cfont color=red size=6 face=\"黑体\"\u003e红色6号黑体\u003c/font\u003e 黑体 # 效果展示 微软雅黑 # 效果展示 黑体2号 # 效果展示 红色6号黑体 # 效果展示 剧中写法 \u003ccenter\u003e我是居中写法\u003c/center\u003e 注释、隐藏 \u003cp hidden\u003e我也是隐藏\u003c/p\u003e 空格与缩进Tab 我是空格缩进代码块：\u0026nbsp;或\u0026#160; 我是两个空格缩进代码块：\u0026ensp;或\u0026#8194; 我是Tab缩进代码块：\u0026emsp;或\u0026#8195; HTML语法 HTML中 `\u003ch1\u003e`-`\u003ch6\u003e样式标题 \u003cb\u003e粗體文字\u003c/b\u003e 或 \u003cstrong\u003e粗體文字\u003c/strong\u003e \u003ci\u003e斜體文字\u003c/i\u003e 或 \u003cem\u003e斜體文字\u003c/em\u003e \u003cu\u003e底線文字\u003c/u\u003e, \u003cins\u003e底線文字\u003c/ins\u003e \u003cs\u003e刪除線文字\u003c/s\u003e 或 \u003cstrike\u003e刪除線文字\u003c/strike\u003e 或 \u003cdel\u003e刪除線文字\u003c/del\u003e \u003cb\u003e粗體文字 \u003ci\u003e粗斜體文字 \u003cs\u003e粗斜體刪除線文字\u003c/s\u003e \u003cu\u003e粗斜底線文字\u003c/u\u003e\u003c/i\u003e 粗體文字\u003c/b\u003e \u003ca href=\"超連結網址\"\u003e超連結文字\u003c/a\u003e \u003ccode\u003e等寬字體\u003c/code\u003e \u003cpre\u003e多行等寬字體 的文字區塊\u003c/pre\u003e HTML标签实现目录跳转 ",
    "description": "Markdown语法使用 Markdown官方教程 **Markdown是编写HTML**的一种更好的方式，它没有通常伴随的所有复杂性和丑陋性，一些主要优点包括 Markdown简单易学，额外字符很少，因此编写内容也更快 使用Markdown写作时出错的可能性较小 产生有效的HTML输出 将内容和视觉显示分开，这样您就不会弄乱网站的外观 在您喜欢的任何文本编辑器或Markdown应用程序中书写 Typora主题选择 Typora Drake主题 Notion主题 Markdown目录跳转方式 [标题样式](#标题样式) [段落格式](#段落格式) [列表类型](#列表类型) [块引用](#块引用) [表格](#表格) [`Code`](#Code) [其它元素：`abbr`、`sub`、`sup`、`kbd`等等](#其它元素：abbr、sub、sup、kbd等等) [文字颜色](#文字颜色) [toc] 我是目录跳转 more截断文档显示阅读全文按钮 \u003c!",
    "tags": [],
    "title": "Markdown_Syntax",
    "uri": "/basics/markdown/markdown_syntax/"
  },
  {
    "breadcrumb": "Basics \u003e Hugo_Theme_Next",
    "content": " Emoji可以通过多种方式在Hugo项目中启用 emojify方法可以直接在模板中调用, 或者使用行内Shortcodes 要全局使用emoji, 需要在你的网站配置中设置 enableEmoji 为 true，然后你就可以直接在文章中输入emoji的代码。 它们以冒号开头和结尾，并且包含emoji的代码： 去露营啦! {:}tent: 很快就回来. 真开心! {:}joy: 呈现的输出效果如下: 去露营啦! :tent: 很快就回来。\n真开心! :joy:\n表情与情感 以下符号清单是emoji代码的非常有用的参考 笑脸表情 图标 代码 图标 代码 :grinning: grinning :smiley: smiley :smile: smile :grin: grin :laughing: laughing satisfied :sweat_smile: sweat_smile :rofl: rofl :joy: joy :slightly_smiling_face: slightly_smiling_face :upside_down_face: upside_down_face :wink: wink :blush: blush :innocent: innocent 爱意表情 图标 代码 图标 代码 :heart_eyes: heart_eyes :kissing_heart: kissing_heart :kissing: kissing :relaxed: relaxed :kissing_closed_eyes: kissing_closed_eyes :kissing_smiling_eyes: kissing_smiling_eyes 吐舌头表情 图标 代码 图标 代码 :yum: yum :stuck_out_tongue: stuck_out_tongue :stuck_out_tongue_winking_eye: stuck_out_tongue_winking_eye :stuck_out_tongue_closed_eyes: stuck_out_tongue_closed_eyes :money_mouth_face: money_mouth_face 国家和地区旗帜 图标 代码 图标 代码 :andorra: andorra :united_arab_emirates: united_arab_emirates :afghanistan: afghanistan :antigua_barbuda: antigua_barbuda :anguilla: anguilla :albania: albania :armenia: armenia :angola: angola :antarctica: antarctica :argentina: argentina :american_samoa: american_samoa :austria: austria :australia: australia :aruba: aruba :aland_islands: aland_islands :azerbaijan: azerbaijan :bosnia_herzegovina: bosnia_herzegovina :barbados: barbados :bangladesh: bangladesh :belgium: belgium :burkina_faso: burkina_faso :bulgaria: bulgaria :bahrain: bahrain :burundi: burundi :benin: benin :st_barthelemy: st_barthelemy :bermuda: bermuda :brunei: brunei :bolivia: bolivia :caribbean_netherlands: caribbean_netherlands :brazil: brazil :bahamas: bahamas :bhutan: bhutan :botswana: botswana :belarus: belarus :belize: belize :canada: canada :cocos_islands: cocos_islands :congo_kinshasa: congo_kinshasa :central_african_republic: central_african_republic :congo_brazzaville: congo_brazzaville :switzerland: switzerland :cote_divoire: cote_divoire :cook_islands: cook_islands :chile: chile :cameroon: cameroon :cn: cn :colombia: colombia :costa_rica: costa_rica :cuba: cuba :cape_verde: cape_verde :curacao: curacao :christmas_island: christmas_island :cyprus: cyprus :czech_republic: czech_republic :de: de :djibouti: djibouti :denmark: denmark :dominica: dominica :dominican_republic: dominican_republic :algeria: algeria :ecuador: ecuador :estonia: estonia :egypt: egypt :western_sahara: western_sahara :eritrea: eritrea :es: es :ethiopia: ethiopia :eu: eu european_union :finland: finland :fiji: fiji :falkland_islands: falkland_islands :micronesia: micronesia :faroe_islands: faroe_islands :fr: fr :gabon: gabon :gb: gb uk :grenada: grenada :georgia: georgia :french_guiana: french_guiana :guernsey: guernsey :ghana: ghana :gibraltar: gibraltar :greenland: greenland :gambia: gambia :guinea: guinea :guadeloupe: guadeloupe :equatorial_guinea: equatorial_guinea :greece: greece :south_georgia_south_sandwich_islands: south_georgia_south_sandwich_islands :guatemala: guatemala :guam: guam :guinea_bissau: guinea_bissau :guyana: guyana :hong_kong: hong_kong :honduras: honduras :croatia: croatia :haiti: haiti :hungary: hungary :canary_islands: canary_islands :indonesia: indonesia :ireland: ireland :israel: israel :isle_of_man: isle_of_man :india: india :british_indian_ocean_territory: british_indian_ocean_territory :iraq: iraq :iran: iran :iceland: iceland :it: it :jersey: jersey :jamaica: jamaica :jordan: jordan :jp: jp :kenya: kenya :kyrgyzstan: kyrgyzstan :cambodia: cambodia :kiribati: kiribati :comoros: comoros :st_kitts_nevis: st_kitts_nevis :north_korea: north_korea :kr: kr :kuwait: kuwait :cayman_islands: cayman_islands :kazakhstan: kazakhstan :laos: laos :lebanon: lebanon :st_lucia: st_lucia :liechtenstein: liechtenstein :sri_lanka: sri_lanka :liberia: liberia :lesotho: lesotho :lithuania: lithuania :luxembourg: luxembourg :latvia: latvia :libya: libya :morocco: morocco :monaco: monaco :moldova: moldova :montenegro: montenegro :madagascar: madagascar :marshall_islands: marshall_islands :macedonia: macedonia :mali: mali :myanmar: myanmar :mongolia: mongolia :macau: macau :northern_mariana_islands: northern_mariana_islands :martinique: martinique :mauritania: mauritania :montserrat: montserrat :malta: malta :mauritius: mauritius :maldives: maldives :malawi: malawi :mexico: mexico :malaysia: malaysia :mozambique: mozambique :namibia: namibia :new_caledonia: new_caledonia :niger: niger :norfolk_island: norfolk_island :nigeria: nigeria :nicaragua: nicaragua :netherlands: netherlands :norway: norway :nepal: nepal :nauru: nauru :niue: niue :new_zealand: new_zealand :oman: oman :panama: panama :peru: peru :french_polynesia: french_polynesia :papua_new_guinea: papua_new_guinea :philippines: philippines :pakistan: pakistan :poland: poland :st_pierre_miquelon: st_pierre_miquelon :pitcairn_islands: pitcairn_islands :puerto_rico: puerto_rico :palestinian_territories: palestinian_territories :portugal: portugal :palau: palau :paraguay: paraguay :qatar: qatar :reunion: reunion :romania: romania :serbia: serbia :ru: ru :rwanda: rwanda :saudi_arabia: saudi_arabia :solomon_islands: solomon_islands :seychelles: seychelles :sudan: sudan :sweden: sweden :singapore: singapore :st_helena: st_helena :slovenia: slovenia :slovakia: slovakia :sierra_leone: sierra_leone :san_marino: san_marino :senegal: senegal :somalia: somalia :suriname: suriname :south_sudan: south_sudan :sao_tome_principe: sao_tome_principe :el_salvador: el_salvador :sint_maarten: sint_maarten :syria: syria :swaziland: swaziland :turks_caicos_islands: turks_caicos_islands :chad: chad :french_southern_territories: french_southern_territories :togo: togo :thailand: thailand :tajikistan: tajikistan :tokelau: tokelau :timor_leste: timor_leste :turkmenistan: turkmenistan :tunisia: tunisia :tonga: tonga :tr: tr :trinidad_tobago: trinidad_tobago :tuvalu: tuvalu :taiwan: taiwan :tanzania: tanzania :ukraine: ukraine :uganda: uganda :us: us :uruguay: uruguay :uzbekistan: uzbekistan :vatican_city: vatican_city :st_vincent_grenadines: st_vincent_grenadines :venezuela: venezuela :british_virgin_islands: british_virgin_islands :us_virgin_islands: us_virgin_islands :vietnam: vietnam :vanuatu: vanuatu :wallis_futuna: wallis_futuna :samoa: samoa :kosovo: kosovo :yemen: yemen :mayotte: mayotte :south_africa: south_africa :zambia: zambia :zimbabwe: zimbabwe ",
    "description": "Emoji可以通过多种方式在Hugo项目中启用 emojify方法可以直接在模板中调用, 或者使用行内Shortcodes 要全局使用emoji, 需要在你的网站配置中设置 enableEmoji 为 true，然后你就可以直接在文章中输入emoji的代码。 它们以冒号开头和结尾，并且包含emoji的代码： 去露营啦!",
    "tags": [],
    "title": "Emoji_Support",
    "uri": "/basics/hugo_theme_next/emoji_support/"
  },
  {
    "breadcrumb": "Basics \u003e Hugo_Theme_Next",
    "content": " 对于熟悉前端开发的用户来说，可以通过自定义文件配置，实现对站点的样式和布局进行个性化的调整。其中布局方面主要是支持左侧边栏的站点概览部分，以及站点底部2个位置，但样式的重置可以是整个站点的任意位置\n打开配置参数 首先要明确在配置文件的params区域中有配置如下参数 customFilePath: sidebar: custom_sidebar.html footer: custom_footer.html style: /css/custom_style.css 注意：sidebar 和 footer 的文件命名不可以与它们的参数名称相同，不然会影响系统默认的布局设计，切记！！！ :smile:\n然后在站点的根目录下创建 layouts/partials 2个目录，用于存放自定布局设计文件，另外在站点根目录下创建 statics/css 2个目录，用于存放自定义CSS样式文件。一切就绪后，就可以参考如下的步骤，完成自己的设计想法\n侧边栏设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下： \u003cdiv class=\"mydefined animated\" itemprop=\"custom\"\u003e \u003cspan\u003e支持自定义CSS和Sidebar布局啦💄💄💄\u003c/span\u003e \u003c/div\u003e 再把该文件的路径配置到相应的参数中，效果请查看左侧边栏底部的效果 底部设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下： \u003cdiv class=\"custom-footer\"\u003e Website source code \u003ca href=\"https://github.com/hugo-next/hugo-theme-next/tree/develop/exampleSite/layouts/partials/custom-footer.html\" target=\"_blank\"\u003ehere\u003c/a\u003e \u003c/div\u003e 再把该文件的路径配置到相应的参数中，效果请查看站点底部的效果 自定义样式 在前面创建 css 目录中新一个后缀名为 css 的文件，然后可以在里面把站点的样式进行重定义，或是增加一些自己定义的样式设计，在写文章时进行引用，示例如下： .custom-head5 { font-size: 1.2em; color: #ed6c24; font-weight: bold; } 再把该文件的路径配置到相应的参数中，效果参考如下： ",
    "description": "对于熟悉前端开发的用户来说，可以通过自定义文件配置，实现对站点的样式和布局进行个性化的调整。其中布局方面主要是支持左侧边栏的站点概览部分，以及站点底部2个位置，但样式的重置可以是整个站点的任意位置\n打开配置参数 首先要明确在配置文件的params区域中有配置如下参数 customFilePath: sidebar: custom_sidebar.html footer: custom_footer.html style: /css/custom_style.",
    "tags": [],
    "title": "Custom_Files",
    "uri": "/basics/hugo_theme_next/custom_files/"
  },
  {
    "breadcrumb": "Basics",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Hugo_Theme_Next",
    "uri": "/basics/hugo_theme_next/"
  },
  {
    "breadcrumb": "Basics",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Video",
    "uri": "/basics/video/"
  },
  {
    "breadcrumb": "Basics",
    "content": "",
    "description": "",
    "tags": [],
    "title": "MarkDown",
    "uri": "/basics/markdown/"
  },
  {
    "breadcrumb": "Basics \u003e AI",
    "content": "智能AI ChatGPT ChatGPT地址，以及插件地址 名称 描述 ChatGPT ChatGPT Web浏览器地址 Chat GPT登陆获取Token 获取登录Token ChatGPT Github ChatGPT PC终端安装包 OpenAI Plugins插件商城 ChatGPT Voice、Chat gpt voice ChatGPT语音插件地址 ChatGPT Prompt Genius ChatGPT导入导出对话结果、对话模板，在插件管理中操作导入导出 Merlin ChatGPT解答 Merlin - ChatGPT Assistant for All Websites ChatGPT总结 ChatGPT for Google ChatGPT翻译 WebChatGPT：可访问互联网的 ChatGPT ChatGPT网络访问 YouTube Summary with ChatGPT、ChatGPT网站和YouTube视频摘要 YouTube Summary with ChatGPT视频段落定位 Summarize您的AI助手可以立即汇总文章和文本 文章总结 LINER: ChatGPT谷歌助手和高亮显示工具 文章搜索高亮 GPT-2 Output Detector Demo 文章检测 Paraphrasing Tool 文章改写工具 Auto-GPT Auto-GPT Midjourney绘画AI 名称 描述 Discord Discord机器人 Quick Start Midjourney Midjourney使用帮助 Midjourney Discord Midjourney在Discord中的主页 ChatGPT和Telegram_Bot加入群组并且给予管理员权限 名称 描述 Replit托管运行代码 ChatGPT-Telegram-Bot Telegram Bot: GPT-4 ChatGPT-bot Youtube ChatGPT Telegram Bot on Python Youtube Telegram Bot ChatGPT ChatGPT之眼 ",
    "description": "智能AI ChatGPT ChatGPT地址，以及插件地址 名称 描述 ChatGPT ChatGPT Web浏览器地址 Chat GPT登陆获取Token 获取登录Token ChatGPT Github ChatGPT PC终端安装包 OpenAI Plugins插件商城 ChatGPT Voice、Chat gpt voice ChatGPT语音插件地址 ChatGPT Prompt Genius ChatGPT导入导出对话结果、对话模板，在插件管理中操作导入导出 Merlin ChatGPT解答 Merlin - ChatGPT Assistant for All Websites ChatGPT总结 ChatGPT for Google ChatGPT翻译 WebChatGPT：可访问互联网的 ChatGPT ChatGPT网络访问 YouTube Summary with ChatGPT、ChatGPT网站和YouTube视频摘要 YouTube Summary with ChatGPT视频段落定位 Summarize您的AI助手可以立即汇总文章和文本 文章总结 LINER: ChatGPT谷歌助手和高亮显示工具 文章搜索高亮 GPT-2 Output Detector Demo 文章检测 Paraphrasing Tool 文章改写工具 Auto-GPT Auto-GPT Midjourney绘画AI 名称 描述 Discord Discord机器人 Quick Start Midjourney Midjourney使用帮助 Midjourney Discord Midjourney在Discord中的主页 ChatGPT和Telegram_Bot加入群组并且给予管理员权限 名称 描述 Replit托管运行代码 ChatGPT-Telegram-Bot Telegram Bot: GPT-4 ChatGPT-bot Youtube ChatGPT Telegram Bot on Python Youtube Telegram Bot ChatGPT ChatGPT之眼 ",
    "tags": [],
    "title": "ChatGPT",
    "uri": "/basics/ai/chatgpt/"
  },
  {
    "breadcrumb": "Basics",
    "content": "",
    "description": "",
    "tags": [],
    "title": "AI",
    "uri": "/basics/ai/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tomcat",
    "uri": "/systems/linux/backend/tomcat/"
  },
  {
    "breadcrumb": "Systems \u003e Linux \u003e Backend",
    "content": "",
    "description": "",
    "tags": [],
    "title": "PHP",
    "uri": "/systems/linux/backend/php/"
  },
  {
    "breadcrumb": "Systems",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Linux",
    "uri": "/systems/linux/"
  },
  {
    "breadcrumb": "Systems \u003e Activation Key",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Windows",
    "uri": "/systems/activation_key/windows/"
  },
  {
    "breadcrumb": "Systems \u003e Activation Key \u003e Vmware",
    "content": "VMware ESXI 8.0激活Key 版本 Key 类型 ESXi 7.0 JJ2WR-25L9P-H71A8-6J20P-C0K3F VMware vSphere ESXi 7.0 Enterprise Plus ESXi 7.0 HN2X0-0DH5M-M78Q1-780HH-CN214 VMware vSphere ESXi 7.0 Enterprise Plus ESXi 7.0 JH09A-2YL84-M7EC8-FL0K2-3N2J2 VMware vSphere ESXi 7.0 Enterprise Plus ESXi 7.0 J1608-4GJEQ-071L8-9VA0H-2MUK6 VMware vSphere 7 Enterprise Plus with Add-on for Kubernetes ESXi 7.0 M10DH-8YL47-474L1-DV3U0-8H054 VMware vSphere 7 Enterprise Plus with Add-on for Kubernetes ESXi 7.0 MM4MR-2G005-H7039-JVCAP-2RAL8 VMware vSphere 7 Enterprise Plus with Add-on for Kubernetes ESXi 7.0 104HH-D4343-07879-MV08K-2D2H2 VMware vCenter 7.0 Standard ESXi 7.0 410NA-DW28H-H74K1-ZK882-948L4 VMware vCenter 7.0 Standard ESXi 7.0 406DK-FWHEH-075K8-XAC06-0JH08 VMware vCenter 7.0 Standard ESXi 7.0 JJ2WR-25L9P-H71A8-6J20P-C0K3F VMware vSphere ESXi 7.0 Enterprise Plus ESXi 7.0 HN2X0-0DH5M-M78Q1-780HH-CN214 VMware vSphere ESXi 7.0 Enterprise Plus ESXi 7.0 JH09A-2YL84-M7EC8-FL0K2-3N2J2 VMware vSphere ESXi 7.0 Enterprise Plus ESXi 8.0 4V492-44210-48830-931GK-2PRJ4 VMware vSphere ESXi 8.0 ESXi 8.0 HG00K-03H8K-48929-8K1NP-3LUJ4 VMware vSphere ESXi 8.0 ESXi 8.0 4F40H-4ML1K-M89U0-0C2N4-1AKL4 VMware vSphere ESXi 8.0 ESXi 8.0 0Z20K-07JEH-08030-908EP-1CUK4 VMware vSphere VCSA 8.0 ESXi 8.0 0F41K-0MJ4H-M88U1-0C3N0-0A214 VMware vSphere VCSA 8.0 ESXi 8.0 4F282-0MLD2-M8869-T89G0-CF240 VMware vSphere VCSA 8.0 ESXi 8.0 NF212-08H0K-488X8-WV9X6-1F024 VMware vSphere vSAN 8.0 ESXi 8.0 JF61H-48K8K-488X9-W98Z0-1FH24 VMware vSphere vSAN witness 8.0 ESXi 8.0 0G4DA-49J81-M80R1-012N4-86KH4 Horizon Enterprise v8.x ",
    "description": "VMware ESXI 8.0激活Key 版本 Key 类型 ESXi 7.0 JJ2WR-25L9P-H71A8-6J20P-C0K3F VMware vSphere ESXi 7.",
    "tags": [],
    "title": "VMware ESXI8.0 Key",
    "uri": "/systems/activation_key/vmware/vmware-esxi8.0-key/"
  },
  {
    "breadcrumb": "Systems \u003e Activation Key",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Vmware",
    "uri": "/systems/activation_key/vmware/"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Services",
    "uri": "/services/"
  },
  {
    "breadcrumb": "Systems \u003e Activation Key",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Sublime Text",
    "uri": "/systems/activation_key/sublime_text/"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Systems",
    "uri": "/systems/"
  },
  {
    "breadcrumb": "Services",
    "content": "Shop Awesome Open Source E-commerce Platforms ",
    "description": "Shop Awesome Open Source E-commerce Platforms ",
    "tags": [],
    "title": "Shopping",
    "uri": "/services/shopping/"
  },
  {
    "breadcrumb": "Services",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Certificate",
    "uri": "/services/certificate/"
  },
  {
    "breadcrumb": "Services \u003e Blog",
    "content": "Hexo博客系统 windows安装hexo Ngx Ngxhk Terence Chuen Hexo安装使用 hexo-cli依赖nodejs先安装nodejs：国内安装cnpm $ npm install -g cnpm --registry=https://registry.npm.taobao.org 安装git 安装hexo $ winget install --id Git.Git -e --source winget # 安装git $ npm.cmd install -g hexo-cli # 安装hexo $ hexo.cmd --version 创建目录并初始化 $ mkdir blog \u0026\u0026 cd blog $ hexo.cmd init # 初始化 $ hexo.cmd s # 启动hexo 生成文章 $ hexo.cmd new \"install_hexo\" $ cd .\\source\\_posts\\ 安装主题、部署到远程 hexo-next主题优化以及更换主题 $ git clone https://github.com/theme-next/hexo-theme-next themes/next $ vim _config.yml theme: landscape # 替换：next 部署到远端，部署到远端需要git $ npm.cmd install --sove hexo-deployer-git $ vim _config.yml # 在文件最下面添加修改 type: git repo: https://github.com/username/username.github.io.git # 指定仓库 branch: master # 填写分支名称 生成博客、推送远程 $ hexo.cmd cleon # 清理缓存 $ hexo.cmd g # 重新生成 $ hexo.cmd d # 推送到远端 迁移hexo博客系统 备份一下几个目录和文件 _config.yml package.json scaffolds/ source/ themes/ 安装hexo所需要模块 $ npm install # 静态资源压缩 $ npm install gulp -g $ npm install gulp-minify-css --save $ npm install gulp-uglify --save $ npm install gulp-htmlmin --save $ npm install gulp-htmlclean --save $ npm install gulp-imagemin --save # 统计字符 $ npm install hexo-wordcount --save # 推送远端模块 $ npm install hexo-deployer-git --save # 安装RSS插件 $ npm install hexo-generator-feed --save # 加速网页收录速度 $ npm install hexo-generator-sitemap --save # 本地搜索 $ npm install hexo-generator-searchdb --save ",
    "description": "Hexo博客系统 windows安装hexo Ngx Ngxhk Terence Chuen Hexo安装使用 hexo-cli依赖nodejs先安装nodejs：国内安装cnpm $ npm install -g cnpm --registry=https://registry.",
    "tags": [],
    "title": "Install Blog Hexo",
    "uri": "/services/blog/install-blog-hexo/"
  },
  {
    "breadcrumb": "Services",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Blog",
    "uri": "/services/blog/"
  },
  {
    "breadcrumb": "Languges",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Lua",
    "uri": "/language/lua/"
  },
  {
    "breadcrumb": "Languges \u003e Lua",
    "content": "Lua语言使用 IDE插件 EmmyLua for IntelliJ IDEA EmmyLua插件中文文档 LDT基于Eclipse Eclipse-LDT 保留关键字 保留关键字 描述 if 如果 then 执行 elseif 其它 else 否则 for do 执行 while 循环 in end 结束 true 数字：0等代表：true false and or not break until return repeat nil 空值，可以代表 false local 代表局部变量 function Lua注释 行注释 -- 两个减号是行注释 块注释 --[[ 我是块注释 一块一块的 --]] 循环 while循环 local i = 0 local max = 10 while i \u003c= max do i = i +1 print(i) end if-else语句 local age = 140 -- 局部变量 local sex = \"Male\" if age == 40 and sex == \"Male\" then print(\" 男人四十一枝花\") elseif age \u003e 60 and sex ~= \"Female\" then -- 大于60，并且 不定于Female print(\"old man!!!\") elseif age \u003c 20 then io.write(\"too yung, too simple!!!\\n\") else print(\"Your age is\"..age) -- 使用：.. 引用变量 end for语句使用 sum = 0 for i = 100, 1, -2 do -- i 等于100， i小于1，i减2。其它写法：i=0, 100, +2 sum = sum + i print(sum) end print(sum) function函数 function myPower(x,y) return y+x end power2 = myPower(2,3) print(power2)function newCounter() local i = 0 return function() i = i + 1 return i end end c1 = newCounter() print(c1()) -- 等于 1 print(c1()) -- 等于 2 print(c1()) -- 等于 3function isMyGirl(name) return name == 'shangsan', name end local bol,name = isMyGirl('zhangsan') print(name,bol) key value键值对方式 local function main() man = {name='lisi',age=18,height=1.75} man.age=35 print(man.name,man.age,man.height) print(man) end main() 数组，使用下标取值 local function main() array = {'string', 100, 'man',function() print('lisi') return 1 end} print(array[4]()) end 遍历数组 local function main() array = {'string', 100, 'man',function() print('lisi') return 1 end} for key, value in pairs(array) do print(key, value) end end main() 函数添加值 local function main() person = {name='zhangsan', age = 23} function person.eat(food) print(person.name ..\" 正在 \"..food) end person.eat('吃火锅') end main() Lua连接Redis Lua Redis-Cluster集群支持 $ cat \u003econf/lua/redis.lua\u003c\u003c-EOF local redis = require \"resty.redis\" local red = redis:new() -- 创建新连接 res:set_tineouts(1000, 1000, 1000) -- 1 sec -- 超过一秒为连接超时 local ok, error = red:connect(\"127.0.0.1\", 6379) -- 连接地址 if not ok then ngx.say(\"failed to connect: \", error) return end ok, error = red:set(\"dog\", \"an animal\") -- 写入数据 if not ok then ngx.say(\"failed to set dog: \", error) -- 写入不成功报错 return end ngx.say(\"set result: \", ok) -- 写入成功 local res, error = red:get(\"dog\") -- 获取数据 fi not res then ngx.say(\"failed to get dog: \", error) -- 获取不到报错 return end if res == ngx.null then -- 空值 ngx.say(\"dog not found.\") -- 空值提醒 return end ngx.say(\"dog: \", res) EOF Lua连接Mysql Lua-Resty-Mysql $ cat \u003econf/lua/mysql.lua\u003c\u003c-EOF local mysql = require \"resty.mysql\" local db, error = mysql:new() if not db then ngx.say(\"failed to instantiate mysql: \", error) return end db:set_timeout(1000) -- 1 sec local ok, error, errcode, sqlstate = db:connect{ host = \"192.168.1.1\", port = 3306, database = \"db_name\", user = \"root\", password = \"password\", charset = \"utf8\", max_packet_size = 1024 * 1024, } ngx.say(\"connected to mysql.\u003cbr\u003e\") -- 删除cats表 local res, error, errcode, sqlstate = db:query(\"drop table if exists cats\") if not res then ngx.say(\"bad result: \", error, \": \", errcode, \": \", sqlstate, \".\") return end -- 创建cats表 res, error, errcode, sqlstate = db:query(\"create table cats \"..\"(id serial primary key. \"..\"name varchar(5))\") if not res then ngx.say(\"bad result: \", error, \": \", errcode, \": \", sqlstate, \".\") return end ngx.say(\"table cats created.\") -- 查询表 res, error, errcode, sqlstate = db:query(\"select * from t_emp\") if not res then ngx.say(\"bad result: \", error, \": \", errcode, \": \", sqlstate, \".\") return end -- 返回结果转义为Json格式 local cjson = require \"cjson\" ngx.say(\"result: \", cjson.encode(res)) -- 复用连接池 local ok, error = db:set_keepalive(10000, 100) if not ok then ngx.say(\"failed to set keepalive: \", error) return end EOF 模板引擎 Lua-Resty-Template Lua开源项目 WAF防火墙 Ngx_Lua_Waf防火墙 Kong流量网关 ABTestingGateway动态分流策略网关 ApiSix网关、入口控制 ",
    "description": "Lua语言使用 IDE插件 EmmyLua for IntelliJ IDEA EmmyLua插件中文文档 LDT基于Eclipse Eclipse-LDT 保留关键字 保留关键字 描述 if 如果 then 执行 elseif 其它 else 否则 for do 执行 while 循环 in end 结束 true 数字：0等代表：true false and or not break until return repeat nil 空值，可以代表 false local 代表局部变量 function Lua注释 行注释 -- 两个减号是行注释 块注释 --[[ 我是块注释 一块一块的 --]] 循环 while循环 local i = 0 local max = 10 while i \u003c= max do i = i +1 print(i) end if-else语句 local age = 140 -- 局部变量 local sex = \"Male\" if age == 40 and sex == \"Male\" then print(\" 男人四十一枝花\") elseif age \u003e 60 and sex ~= \"Female\" then -- 大于60，并且 不定于Female print(\"old man!",
    "tags": [],
    "title": "Language_Lua",
    "uri": "/language/lua/language_lua/"
  },
  {
    "breadcrumb": "Languges \u003e Yaml",
    "content": "Yaml简介 YAML是YAML Ain't a Markup Language（YAML非标记语言）的递归缩写。在开发的这种语言时，YAML的意思其实是：Yet Another Markup Language（仍是一种标记语言),YAML的配置文件后缀为.yml和yaml 基本语法 #号表示注释 ---分割代码块 大小写敏感 使用空格键缩进表示层级关系，不支持Tab键 缩进空格数不重要，只要相同层级的元素左对齐即可 数据结构 字符串 列表 字典 布尔 语法校验 d $ pip3 install pyyaml # 源码包安装 $ python setup.py install # 使用sys标准输入验证 $ python3 -c 'import yaml,sys; print(yaml.safe_load(sys.stdin))' \u003c my_yaml.yaml 数据类型 Yaml字典(ditionary) Yaml对象：键值对的集合，又称为映射(mapping)、哈希(hashes)、对象 使用冒号表示键值对结构key: value，冒号后面要加一个空格 也可以使用key:{key1: value1, key2: value2, ...} name: zhangsan age: 18 # 另一种写法，将所有键值对写成一个行内对象 hash: { name: zhangsan, age: 18 } 较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value ? - complexkey1 - complexkey2 : - complexvalue1 - complexvalue2 意思即对象的属性是一个数组[complexkey1,complexkey2]，对应的值也是一个数组complexvalue1,complexvalue2 Yaml列表(list) Yaml数组：一组按次序排列的值，又称为序列(sequence)、数组 以-开头的行表示构成一个数组 animal - Cat - Dog YAML支持多维数组，可以使用行内表示： animal: [Cat, Dog] 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格，意思是companies属性是一个数组，每一个数组元素又是由id、name、price三个属性构成 companies: - id: 1 name: company1 price: 200W - id: 2 name: company2 price: 500W # 另一种写法，将所有数组写成一个行内对象 companies: [{id: 1,name: company1,price: 200W},{id: 2,name: company2,price: 500W}] 数组和对象可以构成复合结构 languages: - Ruby - Perl - Python websites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 转换为json格式 { languages: [ 'Ruby', 'Perl', 'Python'], websites: { YAML: 'yaml.org', Ruby: 'ruby-lang.org', Python: 'python.org', Perl: 'use.perl.org' } } Yaml纯量(scalars) Yaml纯量`(scalars)``：单个的、不可再分的值 字符串：字符串直接以字面量形式表示，默认不使用引号，如果字符串之中包含空格或者特殊字符，需要放在引号之中，单引号和双引号\"\"都可以使用双引号不会对特殊字符转义，单引号之中如果还有单引号，必须连续使用两个单引号转义 number: 12.30 str1: '内容\\n字符串' str2: \"内容\\n字符串\" # 使用单引号转义 str: `labor''s day` string: - 哈哈 - 'Hello world' # 可以使用双引号或者单引号包裹特殊字符 - newline newline2 # 字符串可以拆成多行，每一行会被转化成一个空格 多行字符串可以使用|保留换行符，也可以使用\u003e折叠换行 this: | Foo Bar that: \u003e Foo Bar +表示保留文字块末尾的换行，-表示删除字符串末尾的换行 str1: | Foo str2: |+ Foo str3: |- Foo 布尔值：布尔值用true和false表示 boolean: - TRUE # true,True都可以 - FALSE # false，False都可以 整数： int: - 123 - 0b1010_0111_0100_1010_1110 # 二进制表示 浮点数： float: - 3.14 - 6.8523015e+5 # 可以使用科学计数法 Null：用~表示 null: nodeName: 'node' parent: ~ # 使用~表示null 日期：必须使用ISO 8601格式，即yyyy(年)-MM(月)-dd(日) date: - 2018-02-17 时间：使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 datetime: - 2018-02-17T15:02:31+08:00 # 8. yaml允许使用两个感叹号，强制转换数据类型 e: !!str 123 f: !!str true Yaml变量 引用相当于定义变量名和变量值 \u0026：定义锚点 *：引用锚点 \u003c\u003c：表示合并到当前数据 defaults: \u0026defaults adapter: postgres host: localhost development: database: myapp_development \u003c\u003c: *defaults test: database: myapp_test \u003c\u003c: *defaults 相当于 defaults: adapter: postgres host: localhost development: database: myapp_development adapter: postgres host: localhost test: database: myapp_test adapter: postgres host: localhost ",
    "description": "Yaml简介 YAML是YAML Ain't a Markup Language（YAML非标记语言）的递归缩写。在开发的这种语言时，YAML的意思其实是：Yet Another Markup Language（仍是一种标记语言),YAML的配置文件后缀为.yml和yaml 基本语法 #号表示注释 ---分割代码块 大小写敏感 使用空格键缩进表示层级关系，不支持Tab键 缩进空格数不重要，只要相同层级的元素左对齐即可 数据结构 字符串 列表 字典 布尔 语法校验 d $ pip3 install pyyaml # 源码包安装 $ python setup.",
    "tags": [],
    "title": "Language Yaml",
    "uri": "/language/yaml/language-yaml/"
  },
  {
    "breadcrumb": "Languges",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Yaml",
    "uri": "/language/yaml/"
  },
  {
    "breadcrumb": "Languges \u003e Python",
    "content": "Django框架 $ python3 -m pip install Django $ django-admin startproject manager_qrcode 目录文件定义 主目录project name manage.pyDjango命令行管理工具 project name项目主目录 asgi.py用于网路请求接受 __init__.py包管理器 settings.py项目管理配置文件，以及数据库连接，app创建 urls.py项目URL(接口路由管理)管理器，以及视图对应关系 wsgi.py：Web服务器管理入口，兼容WSGI，用于网路请求接受 templates文件夹，用来存放HTML页面 app项目工程目录 admin.py后台管理文件 apps.py应用配置文件 __init__.py包管理器 migrations数据迁移目录 models.py模块文件 tests.py测试文件 views.py视图展示文件 ",
    "description": "Django框架 $ python3 -m pip install Django $ django-admin startproject manager_qrcode 目录文件定义 主目录project name manage.",
    "tags": [],
    "title": "Language Python Django",
    "uri": "/language/python/language-python-django/"
  },
  {
    "breadcrumb": "Languges \u003e Python",
    "content": "Python IDE IDE与快捷键使用 IDE Pycharm IDE Anaconda IDE Jupyter 查找、设置快捷键：File→Settings→Keymap 全局搜索 双击Shift打开全局搜索功能，或者：Ctrl+Shift+a 关闭全局搜索功能：双击Shift→Actions→输入搜索：Registry打开设置面板后搜索：ide.suppress.double.click.handler 快速格式化代码：Ctrl+Alt+l 快速复制粘贴：Ctrl+d 上下移动代码：Ctrl+Shift+ ↑↓箭头 光标前后移动：home键/end键、fn键+\u003c\u003e键 快速注释取消注释：Ctrl+/ 按Ctrl移动光标到关键字，按鼠标左键跳转到帮助页面 鼠标左键选中不松开，按Tab键，进行快速缩进 Python语言 Python简介 Python是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。Python的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。 名称地址 描述 Python基础概念 Python模块索引 Python函数索引 youtube尚硅谷 Python学习者 Youtube楚阳 莫烦Python Python-100天从新手到大师 Python语言基础50课 UST 爬虫合集 Python托管计划 菜鸟在线编辑工具 Griffith格里菲斯 Education \u0026 Outreach Flask轻量级Web应用框架 Replit线上集成开发环境 Cainiaojc程序在线编辑工具 Python代码分析visualizing code execution Python图解 ASCII码百度百科 Python注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释 注释最好使用英文，完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符 块注释： 在一段代码前增加的注释 行注释：在一句代码后加注释，但是这种方式尽量少使用 Python标识符 命名规则 Python对各种变量名、方法(模块名)、函数名、类名等命名时使用的字符序列称为标识符。Python标识符由26个英文字母大小写0-9，_组成、不能以数字开头、严格区分大小写 Python标识符不能包含空格@、%以及$等特殊字符，不能以系统保留关键字作为标识符（一共有25个） 命名注意事项 Python标识符尽量采取有意义的包名，简短，有意义，不要和系统保留关键字冲突 Python标识符以单下划线开头的标识符，表示不能直接访问的类属性，其无法通过import的方式导入 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线，以双下划线开头的标识符，表示类的私有成员 以双下划线作为开头和结尾的标识符，是专用标识符 Python标识符允许使用汉字作为标识符 标识符规范 标识符用作模块名时，应尽量短小，并且全部使用小写字母，可以使用下划线分割多个字母 标识符用作包的名称时，应尽量短小，也全部使用小写字母，不推荐使用下划线 标识符用作类名时，应采用单词首字母大写的形式也就是大驼峰命名CapWords、模块内部使用的类采用下划线+首字母大写_CapWords 的方式 函数名、类中的属性名和方法名，应全部使用小写字母，多个单词之间可以用下划线分割 常量命名应全部使用大写字母，单词之间可以用下划线分割 异常命名使用 CapWords+Error后缀的方式 全局变量尽量只在模块内有效，类似C语言 中的static 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls Python编码规范 代码缩进 在Python中，代码缩进推荐使用四个空格，而不是一个tab键 空格 各种右括号前不要加空格 逗号、冒号、分号前不要加空格 函数的左括号前不要加空格，如Func(1) 序列的左括号前不要加空格，如list[2] 操作符左右各加一个空格，不要为了对齐增加空格 函数默认参数使用的赋值符左右省略空格 空行 使用空行分割顶层函数和类的定义。类中的方法的定义使用单个空行进行分割 额外的空行可以必要的时候用于分割不同的函数组，但是要尽量节约使用 额外的空行可以必要的时候在函数中用于分割不同的逻辑块，但是要尽量节约使用 最大行宽 限制所有行的最大行宽为79字符。文本长块，比如文档字符串或注释，行长度应限制为72个字符 基本语法 进制转换 数据进制表示 bin代表二进制：0b开头，数字为0~1 a = 32 print(bin(a)) # bin 参数查看转换后的二进制位数 oct代表八进制：0o开头，数字为0~7。三个二进制数为一组代表一个八进制 a =32 print(oct(a)) # oct 参数查看转换后的八进制位数 dec代表十进制：数字为0~9 hex代表十六进制：0x开头，数字为0~9、字母为a~f。a代表10，b代表11以此类推。四个二进制数为一组代表一个十六进制 a = 32 print(hex(a)) # hex 参数查看转换后的十六进制位数 解encode编码 x = b'\\xe4\\xbd\\xa0' # b开始代表是一个二进制字符 print(x.decode('utf8')) 内置函数chr(对应字符)、ord(对应编码号)函数查看对应编码 print(ord('a')) 97 # 输出为97 print(chr(77)) M # 输出为大写 M 运算符 运算符优先级 描述 ** 幂运算符(次方)，指数（最高优先级） ~、+、- 按位反转(取反)，一元加号(正号)和一元减号(负号)，方法为：+@、-@ *、/、%、// 乘、除、取模(取余数)、整除(取整数结果) +、- 加、减 \u003c\u003c、\u003e\u003e 左移、右移 \u0026 按位运算符：与and ^、` ` \u003e、\u003e=、\u003c、\u003c= 比较运算符：大于、大于等于、小于、小于等于 ==、!=、\u003c\u003e 等于、不等于运算符 = 赋值运算符 +=、-=、*=、/=、//=、%=、**= 加等于、减等于、乘等于、除等于、整除等于、模等于、幂等于 is、is not 身份运算符 in、not in 成员运算符 not\u003eand\u003eor 逻辑运算符：非、并且(与)、或 逻辑运算符 逻辑运算符、短路，运算符优先级：not \u003e and \u003e or，开发中最好方式用：() 表示优先级 并且and 只有所有的运算数都是True，结果才为True。只要有一个运算数是False，结果就是False 4 \u003e 3 and print(\"Hello\") 4 \u003c 3 and print(\"你好\") # 有一个False 形成短路问题， 其结果不打印 and运算符取值时，取第一个为False的值，如果所有运算数都是True，取最后一个值 print( 1 and 2 and 0 and \"Hello\") # 遇到False(0) 停止并且打印输出False结果 print(\"Hello\" and \"yes\" and \"ok\" and 100) # 都是True取最后一个值100 或or 只有所有的运算数都是False，结果才是False。只要有一个运算数是True，结果就是True 4 \u003e 3 or print(\"Hello\") # 有一个True 形成短路问题， 其结果不打印 4 \u003c 3 or print(\"你好\") or运算符取值时，取第一个为True的值，如果所有运算数都是False，取组后一个值 print(0 or [] or 'Hello' or 'yes') # 遇到True(Hello) 停止并且打印输出True结果 print(0 or [] or {} or ()) # 都是False 取值最后一个() 非not print(not (6 \u003e 3)) 按位运算符 按位：与\u0026 与\u0026运算符：换算成二进制后， 同为1则为1，否则为0 a = 23 # 0001 0111 b = 15 # 0000 1111 # 0000 0111 同为1则为1，否则为0 print(a \u0026 b) # 输出为：7， 按位：或| 或|运算符：换算成二进制后， 只要有一个为1，就为1 a = 23 # 0001 0111 b = 15 # 0000 1111 # 0001 1111 只要有一个为1，就为1 print(a | b) # 输出为：31， print(bin(0xFF)) # 不使用FF默认为0 按位：异或^ 异或^运算符：换算成二进制后， 相同为0，不同为1 a = 23 # 0001 0111 b = 15 # 0000 1111 # 0001 1000 相同为0，不同为1 print(a ^ b) # 输出为：24， 按位：左移\u003c\u003c 左移\u003c\u003c运算符：换算成二进制后，在右边补0位 a = 23 # 0001 0111 print(a \u003c\u003c 2) # 0101 1100 2代表左移两位，在右边补两位00 # 输出为：92，a \u003c\u003c n, a*2的n次方 按位：右移\u003e\u003e 右移\u003e\u003e运算符：换算成二进制，在左边补0位 a = 23 # 0001 0111 print(a \u003e\u003e 2) # 0000 0101 2代表右移两位，在左边补两位00 # 输出为：5，a \u003e\u003e n, a除2的n次方 按位：取反~ 取反~运算符：换算成二进制后， 即把1变成0，把0变成1 a = 23 # 0001 0111 # 1110 1000 取反后结果，负数二进制 print(~a) # 输出为：-24，~a后再减1，即：~a-1 身份运算符 身份运算符：is 比较对象的内存地址，判断两个对象是否为同一个对象 Identity_1 = {'张三', 23} Identity_2 = {'张三', 23} print(hex(id(Identity_1)), bin(id(Identity_2)), Identity_1 is Identity_2) # 打印内存地址，并且打印比较结果 # 输出结果为：False， 分别存储在两个内存空间中 isinstance()：用来判断一个对象是否是由指定类(或父类)实例化出来 占位符 添加占位符 ljust右侧添加占位符，默认为空格，举例 print('Hello'.ljust(10, '+')) # 换成+号字符 Hello+++++ rjust左侧添加占位符，默认空格，举例 print(\"Hello\".rjust(10,'-')) # 换成-减号字符 -----Hello center左右添加占位符，默认空格，举例 print('Hello'.center(11, '*')) # 换成*号 ***Hello*** 去掉占位符 lstrip去左侧空格占位符 print(' Hello '.lstrip()) Hello rstrip去右侧空格占位符 print(' Hello '.rstrip()) Hello strip去左右两侧占位符 print(' Hello '.strip()) Hello 格式化字符串 使用%号格式化字符串 name = 'aaa' age = 23 print('Hello,word', name, '今年', age, sep='') # sep方式去掉空格 %s表示字符串占位符，%d、%nd前面加空格、%-nd后面加空格、%0nd前面加零、n表示数字、表示整数(数字)占位符，%f、%.2f保留几位小数点，浮点数占位符，%x或%X将数字使用十六进制输出 name = 'aaa' age = 23 print('Hello,word%s, 今年%d' % (name, age)) # %方式格式化 {}、.format()占位符 # {根据数字顺序填写} a = '我叫{0}, 我{1}岁'.format('李四', 23) print(a) # {根据变量名填写} b = '我叫{name}, 我{age}岁, 我来自{addre}'.format(age=18, name='王五', addre='西安') print(b) # {根据列表使用} c = ['赵四', 23, '威海', 178] d = '我叫{}, 我{}岁， 我来自{}， 身高{}cm'.format(c[0], c[1], c[2], c[3]) # 或者使用*进行拆包.format(*c) # {根据字典使用} e = {'name': '嬴政', 'age': 23, 'addre': '咸阳', 'height': 187} f = '我是{name}, 我{age}岁, 我来自{addre}, 身高{height}cm'.format(**e) print(f) 内置类 Windows安装Python W3cSchool 数据类型 整型(int) 字符串(str)转整型(int) INT_AGE = int(input('请输入数字：')) print( INT_AGE + 1 ) STR_AGES = '23' # 使用 '23' 单、双引号括起来代表为字符串(str)类型 INT_STR_AGES = int(STR_AGES) # 使用 int 把age变量转换为整数(int)类型 print(type(STR_AGES), type(INT_STR_AGES)) STR_INT = '1a2c' print(int(STR_INT, 16), type(STR_INT)) # 16代表把 x 变量转换为十六进制 浮点型(float) STR_FLOAT = '12.34' print(float(STR_FLOAT), type(STR_FLOAT)) # 使用 float() 把a转换为浮点型 复数型(complex) 字符串型(str) 整型(int)转字符串(str) Python字符串 INT = 23 print(str(INT), type(INT)) # 使用str把 a变量转换为字符串(str)类型 # 响应头 response_header = 'HTTP/1.1 200 OK\\n' + 'content-type:text/html;charset=utf8\\n' response_header += '\\n' 布尔型(bool) 真(True) 在Python中只有空字符串''，\"\"，数字0，空列表[]，空元组()，空字典{}，空集合set()和空数据None会被转换为False，其他都被转换为True print(bool(100)) # 为 True print(bool(0), bool(''), bool(\"\"), bool(None), bool([]), bool(())) # 都为 False 假(False) 变量值交换 方式一：三方变量实现 a = 10 b = 20 c = b b = a a = c print(a) print(b) 方式二：运算符实现 a = 10 b = 20 a = a + b b = a - b a = a - b print(a) print(b) 方式三：异或运算符实现 a = 10 b = 20 a = a ^ b b = a ^ b a = a ^ b print(a) print(b) 方式四：使用Python自有方式 a = 10 b = 20 a, b = b, a print(a) print(b) 不可变类型 Python不可变类型：字符串、数字、元组，可使用：id查看内存地址 不可变数据类型，如果修改值，内存地址发生变化 a = 10 b = a print('修改前内存ID地址, a={}, b={}'.format(id(a), id(b))) a = 20 print('修改后内存ID地址, a={}, b={}'.format(id(a), id(b))) # 或者使用% print('修改前内存ID地址, a=0x%X, b=0x%X' % (id(a), id(b))) a = 20 print('修改后内存ID地址, a=0x%X, b=0x%X' % (id(a), id(b))) 可变类型 Python可变类型：列表、字典、集合 可变数据类型，如果修改值，内存地址不发生变化 Numbers = [10, 20 ,30] Nums = Numbers print('修改前内存ID地址, Numbers=0x%X, Nums=0x%X' % (id(Numbers), id(Nums))) Numbers[0] = 40 print('修改后内存ID地址, Numbers=0x%X, Nums=0x%X' % (id(Numbers), id(Nums))) 列表list 使用[方]括号表示：列表[list] list = [a,b,c,1,2,3] 字符串列表转换 split通过指定分隔符对字符串进行切片 rsplit从字符串的右端开始分割字符串 splitlines按照行分隔 partition根据指定分隔符将字符串进行分割，把字符串分割为三部分，并以元组形式返回分割结果 rpartition该方法是从目标字符串末尾，也就是右边开始搜索分割符 a = 'aaa+bbb+ccc+ddd+eee' name = a.split('+') print(name) 使用join(可迭代对象)将列表转换成字符串 a = ['aaa', 'bbb', 'ccc', 'ddd'] print('+'.join(a)) # 使用+号相链接 元组转换为列表 names = ('刘一', '陈二', '张三', '李四', '王五', '赵六', '孙七', '周八', '吴九', '郑十') print(list(names)) print('+'.join(names)) # 使用+号相链接 names = list(('刘一', '陈二', '张三', '李四', '王五', '赵六', '孙七', '周八', '吴九', '郑十')) print(names) print(names[5]) # 输出5个名称，或者print(names[3:8]) 切片 names.reverse() # 倒序排列 print(names) names[2] = '嬴政' # 通过下标(下标即索引)修改字符串 print(names) append：在列表后面追加数据，insert：可以选择位置插入数据，extend：合并列表、也可以使用加法+ clear：清空列表，pop：默认删除最后一个字符串，remove：删除指定数据，del： 列表一次input只能接收一次用户输入 Numbers = [] while True: Number = input('请输入数字，输入exit则退出，输入：') if Number == 'exit': break Numbers.append(int(Number)) print(Numbers) # 第二种方式 Numbers = input('请输入多个数据，数据中间使用英文逗号分割：') Number = Numbers.split(',') print(Number) 元组tuple 使用(小)括号表示：元组(tuple)：元组数据不可更改 Tuple = (23,) # 只有一个元素需要加上逗号, 代表元组 Tuple = ('a', 'b', 'c', 1, 2, 3) # 不拆包整体进行赋值 a,b,c = 1,2,3 # 元组进行拆包 *a,b,c = 1,2,3,4,5,6,7 # *：星代表可变参数，会把：1~5给到*a 列表转换为元组 names = ['刘一', '陈二', '张三', '李四', '王五', '赵六', '孙七', '周八', '吴九', '郑十'] print(tuple(names)) print('+'.join(names)) # 使用+号相链接 可以使用加法+让两个元组合并 字典dict 使用{大}括号表示：字典{dict}，key:value为一组键值对，每个键值对之间用逗号 , 分割 字典里Key不允许重复，如果Key有重复现象，后一个Key覆盖前一个Key Key的值只能是不可变类型 Dictionary = {'a': 1, 'b': 2, 'b': '3'} Personal = {'name': '张三', 'age': 23, 'height': 178, 'isPass': True, # value可以是布尔值 'hobbies': ['音乐', '旅游', '电子产品'] # value 也可以是列表 } print(Personal) 曾、删、改 # 增 Personal['width'] = '75kg' # 删 pop Personal.pop('name') # 使用pop内置函数删除指定字典的key和value # 改 Personal['name'] = '李四' # 如果Key存在，更改Key的value值，如果Key不存在则添加 查 print(Personal['name']) # 获取Key对应的value print(Personal.get('width')) # 使用get方式获取一个Key，如果这个Key不存在，返回：None 合并字典update Personal = {'name': '张三', 'age': 23, 'height': 178 } Personals = {'width': '75kg', 'isPass': True, # 可以是布尔值 'hobbies': ['音乐', '旅游', '电子产品'] # 也可以是列表 } Personal.update(Personals) print(Personal) 字典遍历 for循环遍历字典 Personal = {'name': '张三', 'age': 23, 'height': 178, 'width': '75kg', 'isPass': True, # 可以是布尔值 'hobbies': ['音乐', '旅游', '电子产品'] # 也可以是列表 } for i in Personal: print(i, '=', Personal[i]) # 使用内置函数:keys/values 获取key for i in Personal.keys(): print(i, '=', Personal[i]) # 使用内置函数:items 获取key:values for i in Personal.items(): print(i[0], '=', i[1]) # 简洁写法 for k, v in Personal.items(): print(k, '=', v) 集合set 集合：set：无序不重复的元素系列，使用{}或者set() set集合自动去重，添加使用：add、清空使用：clear Basketball = ('嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Ping_Pong = ('赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Football = ('刘邦', '项羽', '赵匡胤', '李世民', '朱元璋') Hobby = Basketball + Ping_Pong + Football Hobby_Set = set(Hobby) print(Hobby_Set) print(len(Hobby_Set)) # 更简洁写法 Hobby = set(Basketball + Ping_Pong + Football) print(Hobby) print(len(Hobby)) set集合指定删除remove Basketball = {'嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣'} Basketball.remove('项羽') print(Basketball) set集合合并union，新增update使用元组、列表 Basketball = {'嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣'} print(Basketball.union({'朱厚照', '李渊'})) # 新增 Basketball.update({'朱厚照', '李渊'}) print(Basketball) set集合高级使用 set支持多种运算符 Basketball = {'嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣'} Ping_Pong = {'赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣'} print(Basketball - Ping_Pong) # - 减法运算符，减去相同 print(Basketball \u0026 Ping_Pong) # \u0026 与运算符， 留下相同 print(Basketball | Ping_Pong) # | 或运算符，去除相同多余 print(Basketball ^ Ping_Pong) # ^ 异或运算符，留下不相同 内置函数 Pycharm查看内置函数、内置类，Show Options Menu设置→Tree Appearance→Show Members 点击：Select Opened File圆形瞄准镜似的按钮，或者：Alt+F1 Project→External Libraries→Scripts Python.exx→Binary Skeletons→Builitins.py→Show Options Menu设置→Tree Appearance→Show Members 红色圆点中间是f为函数 蓝色圆点中间是c内置类 使用dir(__builtins__)获取python内置函数、内置类，属性、行为等，以及获取其他命令变量使用方法 按照默认的字母顺序，先是大写字母A-Z，然后是下划线_开头的，然后是小写字母a-z，为什么是这个顺序？因为按照ASCII码表，表示小写字母的数字比表示大写字母的数字要大，而表示下划线_的数字居中 # 只在命令行使用 print(dir(__builtins__)) for item in dir(__builtins__): print(item) # 使用help查看内置函数dir、def等帮助文档 \u003e\u003e\u003e help(\"dir\") \u003e\u003e\u003e print(dir('自定义属性')) # 查看自定义属性 获取保留字符 $ pydoc keyword $ pydoc keyword.kwlist\u003e\u003e\u003e help(\"keyword\") \u003e\u003e\u003e import keyword \u003e\u003e\u003e keyword.kwlist 获取函数使用，函数三要素：函数名、参数、返回值 $ pydoc def\u003e\u003e\u003e help(\"def\") def：函数 # 定义函数代码块 def Function_Name(参数:parameters): # Function_Name:为自定义函数名，参数:parameters相当于定义变量名 # 函数要执行的操作 # 调用函数块 Function_Name() # 执行函数模块，参数相当于：变量值 举例 def Variable_Name(Variable_1, Variable_2, Variable_3, Variable_4='默认值'): # Variable_4如果不传参使用默认值 print('我是{}, 我是{}'.format(Variable_1, Variable_2)) print('我是' + Variable_3) Variable_Name('变量 1', '变量 2', '变量 3') # 位置参数一定要放到关键字参数前面 Variable_Name('传参 1', '传参 2', '传参 3') Variable_Name(Variable_1='变量名 1', Variable_2='变量名 2', Variable_3='变量名 3') # 关键字参数没有顺序要求def Number_add(a, b,): c = a + b return c # return 把执行结果反出，如果不使用 return反出将输出：None print(Number_add(2, 4)) # 或者定义一个变量 result = Number_add(2, 4) print(result) 内置函数 eval使用 Python中使用内置函数 eval调用定义的命令，使用 eval可以转换为Json Input = 'input(\"请输入：\")' eval(Input) # 调用运算符 Nunber = '3+4' print(eval(Nunber)) 数学函数 abs：取绝对值 divmod：求两个数相除的商和余数 max：求最大数 min：求最小数 可迭代对象函数 all：如果所有的元素转换成为布尔值，都是True结果是True，否则是False any：只要有一个元素转换为布尔值是True，结果就是True len：获取元素长度 iter：获取到可迭代对象的迭代器 next：for ... in循环本质就是调用迭代器的next方法 变量函数 globals：查看全局变量，locals：查看局部变量，global：修改全局变量，nonlocal：修改局部变量 print('locals = {}, globals = {}'.format(locals(), globals())) 判断对象函数 isinstance：判断一个对象是否由一个类创建 issubclass：判断一个对象是否是一个类的子类 文件打开关闭open open参数以及使用 encoding='utf8'：使用utf8打开文件 File_Name.read()：读取文件内容，File_Name.write('写入文件内容') r：只读模式，文件必须存在，否则报错，r+：可写可读 w：写入模式，文件不存在创建，文件存在覆盖并且内容清空，w+可读可写 b二进制模式，rb：二进制模式读取、rw：二进制模式写入 a：追加模式，文件不存在创建，文件存在追加 File = open(r'file_name.txt', 'r', encoding='utf8') # r 函数以及保留字符 可变参数 *args表示可变元组位置参数，依一个*表示可变参数，依元组形式代表 **kwargs表示可变字典关键字参数，依两个**代表可变关键字，依字典形式代表 def Numbers(a, b, *args, **kwargs): # 传递进来数据会依元组形式存储在args可变参数中,传进来多余的关键字参数会依照字典形式保存在kwargs可变关键字参数中 c = a + b for arg in args: c += arg return c print(Numbers(2, 3)) print(Numbers(4, 7, 2, 8, 3, 9, 2, 6)) print(Numbers(3, 5, 8, 2, 9, 5, 3, 7, 2, 6, 4)) 函数递归参数 count = 0 def Speak_Story(): global count count += 1 print(\"\"\" 如果你已经为人父母，当你的孩子正在学习走路时，你会给他几次机会？ 你会在他跌倒十次之后，让他改坐轮椅吗？还是只给他二十次学走的机会， 若学不会走路就要他放弃？或者当你身边有五十个人叫嚣着劝你放弃，你就决定让他坐轮椅呢？ 我想你的答案是：不会。的确，当我间每一位父母，会给你的孩子几次机会呢？ 他们都说：我会给他无数次机会，直到他站起来，学会走路为止：是的，一直坚持到底者，最终都会站起来。 为什么许多父母只给孩子一次联考的机会？为什么常用失望的口气告诉孩子不适合某种行业， 要求他转行呢？而许多人竟也因为没有坚定的信念，一遇挫折就认为自己能力不足， 因此放弃了他们的理想。其实，凡事 没有失败，只有暂时停止成功\"\"\") if count \u003c 5: Speak_Story() # 函数内部自己调用自己实现递归，注意：一定要限制次数， 如果不限制会陷入死循环 Speak_Story() # 递归求1~n的和 def Get_Sum(n): if n == 0: return 0 return n + Get_Sum(n - 1) print(Get_Sum(7)) filter过滤内置类，map作用重新执行元素，reduce求和 from functools import reduce # 导入函数 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 44, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] # 使用lambda匿名函数 print(reduce(lambda x, y: x + y['age'], Students, 0)) # 使用def函数 def Age_Sum(x, y): return x + y['age'] # x的初始值是0， print(reduce(Age_Sum, Students, 0)) # 0 为设置的初始值 Python代码练习案例 九九乘法表 j = 0 while j \u003c 9: j += 1 i = 0 while i \u003c j: i += 1 print(i, '*', j, '=', (j * i), end=\"\\t\") print() 冒泡排序 Numbers = [6, 5, 3, 1, 8, 7, 2, 4] count = 0 i = 0 while i \u003c len(Numbers) - 1: flag = True # flag 标签假设语句，假设每一趟都没有换行 n = 0 while n \u003c len(Numbers) - 1 - i: count += 1 if Numbers[n] \u003e Numbers[n + 1]: # flag 进行交换，假设就不成立 flag = False # 开始进行交换 Numbers[n], Numbers[n + 1] = Numbers[n + 1], Numbers[n] n += 1 if flag: # 如果这趟走完，flag依然是True，说明没有进行数据交换， break i += 1 print(Numbers) print('比较%d次' % count) # 输出结果为 [5, 3, 1, 6, 7, 2, 4, 8] [3, 1, 5, 6, 2, 4, 7, 8] [1, 3, 5, 2, 4, 6, 7, 8] [1, 3, 2, 4, 5, 6, 7, 8] [1, 2, 3, 4, 5, 6, 7, 8] 比较27次 Python专用方式sort Numbers = [6, 5, 3, 1, 8, 7, 2, 4] Numbers.sort() Numbers.sort(reverse=True) # 倒序排列 print(Numbers) # Python使用sorted方式重新生成新的有序数据 Numbers = [6, 5, 3, 1, 8, 7, 2, 4] a = sorted(Numbers) print(a) # sort字典排序 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 44, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] # 使用lambda匿名函数 Students.sort(key=lambda Parameters: Parameters['age']) print(Students) # 或者使用def函数 def Variable(Parameters): # print(\"Parameters = {}\".format(Parameters)) return Parameters['age'] # 通过返回值告诉sort方法，按照元素的那个属性进行排序 # 在sort内部实现的时候，调用Parameters方法，并且传入一个参数，参数就是列表里的元素 Students.sort(key=Variable) print(Students, end='\\n') 求列表里最大的数 升序方式：取最后一位 Numbers = [3, 5, 7, 2, 9, 6, 4, 8, 1] Numbers.sort() print(Numbers) print(Numbers[-1]) # 输出结果为 [1, 2, 3, 4, 5, 6, 7, 8, 9] 9 降序方式：取第一位 Numbers = [3, 5, 7, 2, 9, 6, 4, 8, 1] Numbers.sort(reverse=True) print(Numbers[0]) # 输出结果为 9 for循环假设方式 Numbers = [3, 5, 7, 2, 9, 2, 4, 8, 1] Nums = Numbers[0] # 假设第0个是最大数 for i in Numbers: if i \u003e Nums: # 如果发现列表里存在比假设数还要大的数字 Nums = i # 说明假设不成立， 把假设的值换成为发现的数字 print('列表里最大的数是：%d, 它的下标是：%d' % (Nums, Numbers.index(Nums))) # 输出结果为 列表里最大的数是：9, 它的下标是：4 while循环假设方式 Numbers = [3, 5, 7, 2, 9, 2, 4, 8, 1] Nums = Numbers[0] Index = 0 i = 0 while i \u003c len(Numbers): if Numbers[i] \u003e Nums: Nums = Numbers[i] Index = i i += 1 print('列表里最大的数是：%d, 它的下标是：%d' % (Nums, Numbers.index(Nums))) # 输出结果为 列表里最大的数是：9, 它的下标是：4 删除列表里面的空字符串 for循环删除列表内空字符串，使用for循环操作时不要对元素进行增删操作 # 使用remove 移除方式 Strings = ['Hello', 'Good', '', 'Yes', '', 'Ok'] for Strin in Strings: if Strin == '': Strings.remove(Strin) print(Strings) # 输出结果为 ['Hello', 'Good', 'Yes', 'Ok'] # 使用append添加方式 Strings = ['Hello', 'Good', '', 'Yes', '', 'Ok'] New_String = [] for i in Strings: if i != '': New_String.append(i) Strings = New_String print(Strings) # 输出结果为 ['Hello', 'Good', 'Yes', 'Ok'] while循环删除列表内空字符串 Strings = ['Hello', 'Good', '', 'Yes', '', 'Ok'] i = 0 while i \u003c len(Strings): if Strings[i] == \"\": Strings.remove(Strings[i]) i -= 1 i += 1 print(Strings) # 输出结果为 ['Hello', 'Good', 'Yes', 'Ok'] 列表的嵌套 for循环为老师嵌套随机分配房间 import random Teachers = ['苍老师', '北条麻妃老师', '林美玲老师', '蓝旖琳', '杨丽玲', '惠美梨', '稻森丽奈'] Rooms = [[], [], []] for Teacher in Teachers: Room = random.choice(Rooms) # choice 从列表里随机选择一个数据 Room.append(Teacher) print(Rooms) # 统计某个房间分别有几个老师 for i, Room in enumerate(Rooms): print('房间：%d里面一共有：%d个老师, 分别是：' % (i, len(Room)), end='') for Teacher in Room: print(Teacher, end=' ') print() # 输出结果为 [['苍老师', '惠美梨'], ['北条麻妃老师', '蓝旖琳'], ['林美玲老师', '杨丽玲', '稻森丽奈']] 房间：0里面一共有：2个老师, 分别是：苍老师 惠美梨\t房间：1里面一共有：2个老师, 分别是：北条麻妃老师 蓝旖琳\t房间：2里面一共有：3个老师, 分别是：林美玲老师 杨丽玲 稻森丽奈 for循环推导式列表 range：0~9 Numbers = [i for i in range(10)] print(Numbers) # 另一种写法 Numbers = [] for i in range(10): Numbers.append(i) print(i, end=' ') range：只获取偶数 Numbers = [i for i in range(10) if i % 2 == 0] print(Numbers) # 另一种写法获取偶数 Numbers = [] for i in range(10): if i % 2 == 0: Numbers.append(i) print(Numbers) range：只获取奇数 Numbers = [i for i in range(10) if i % 2] print(Numbers) # 另一种写法获取奇数 Numbers = [] for i in range(10): if i % 2: Numbers.append(i) print(Numbers) range：排列元组内容 Numbers = [(x, y) for x in range(3, 9) for y in range(10, 15)] print(Numbers) # 另一种写法获取 Numbers = [] for x in range(3, 9): for y in range(10, 15): Numbers.append((x, y)) print(Numbers) 1~100列表切片分组 Numbers = [i for i in range(1, 101)] Nums = [Numbers[j:j + 3] for j in range(0, 100, 3)] # range里面的 3：代表步长 print(Nums) 统计列表里出现的元素 拿到所有元素出现次数 Lists = ['a', 'b', 'c', 'd', 'a', 'e', 'c', 'a', 'b', 'f', 'g', 'a'] Dicts = {} for List in Lists: if List in Dicts: # print('这个字符：%s已存在于字典中' % List) Dicts[List] += 1 else: # print('这个字符：%s不存在于字典中' % List) Dicts[List] = 1 # {'a':1} print(Dicts) # 更简洁方式 Lists = ['a', 'b', 'c', 'd', 'a', 'e', 'c', 'a', 'b', 'f', 'g', 'a'] Dicts = {} for List in Lists: if List not in Dicts: Dicts[List] = Lists.count(List) print(Dicts) 拿到列表中出现最多的元素 Lists = ['a', 'b', 'c', 'd', 'a', 'e', 'c', 'a', 'b', 'f', 'g', 'a'] Dicts = {} for List in Lists: if List not in Dicts: Dicts[List] = Lists.count(List) Values = Dicts.values() Max_count = max(Values) for k, v in Dicts.items(): if v == Max_count: print(k, v) 判断名字是否存在 for、else语句判断名字是否存在 Persons_Dicts = [{'name': '张三', 'age': 23}, {'name': '李四', 'age': 25}, {'name': '王五', 'age': 28}] User_Names = input('请输入您的名字：') for Persons in Persons_Dicts: if Persons['name'] == User_Names: print('您输入的名字存在！！！') break else: print('您输入的名字不存在') # 不存在就新增 New_Persons_Dicts = {'name': User_Names} New_Ages = int(input('请输入您的年龄：')) New_Persons_Dicts['age'] = New_Ages # 把新增数据存储到 Persons_Dicts Persons_Dicts.append(New_Persons_Dicts) print('新增用户添加成功') print(Persons_Dicts) 颠倒字典中数据 for循环颠倒字典中数据 Dicts_1 = {'a': 10, 'b': 20, 'c': 30, 'd': 40} Dicts_2 = {} for k, v in Dicts_1.items(): Dicts_2[v] = k print(Dicts_2) # 字典推导式颠倒数据 Dicts_1 = {'a': 10, 'b': 20, 'c': 30, 'd': 40} Dicts_1 = {v: k for k, v in Dicts_1.items()} print(Dicts_1) 遍历字典中的数据 for循环遍历字典，并安条件输出结果 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 16, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] # 1. 统计不几个的学生 # 2. 输出不及格学生的名字和成绩 # 3. 统计未成年学生 # 4. 输出手机尾号是8的学生名字 Score_Count = 0 Ages_Count = 0 Score_Max = Students[0]['score'] # 假设第0个学生是最高分 Score_Index = 0 for i, Student in enumerate(Students): # enumerate 带下标的遍历 if Student['score'] \u003c 60: Score_Count += 1 print('%s不及格,分数是：%d' % (Student['name'], Student['score'])) if Student['age'] \u003c 18: Ages_Count += 1 # if Student['tel'].endswith('8'): if Student['tel'][-1] == '8': # 另一种写法 print('%s的手机号结尾是8' % Student['name']) if Student['score'] \u003e Score_Max: # 遍历时，发现有比假设成绩大的最大数 Score_Max = Student['score'] # Score_Index = i # 修改最高分的同时也把最高分的下标修改 print('不及格的学生有：%d个' % Score_Count) print('未成年的学生有：%d个' % Ages_Count) 输出学生最高分的学生和名字 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 16, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] Score_Count = 0 Ages_Count = 0 Score_Max = Students[0]['score'] # 假设第0个学生是最高分 Score_Index = 0 for i, Student in enumerate(Students): if Student['score'] \u003e Score_Max: # 遍历时，发现有比假设成绩大的最大数 Score_Max = Student['score'] # Score_Index = i # 修改最高分的同时也把最高分的下标修改 print('最高分成绩是：%d' % Score_Max) for Student in Students: if Student['score'] == Score_Max: print('最高分成绩的学生是：%s' % Student['name']) 删除性别不明的学生 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 16, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] 方式一：将不需要删除的数据添加到新列表中 Student = [un for un in Students if un['gender'] != 'unknown'] print(Student) 方式二：使用for循环倒着删除将要删除的数据，避免坑 i = 0 for i in range(len(Students) - 1, -1, -1): if Students[i]['gender'] == 'unknown': Students.remove(Students[i]) print(Students) 方式三：使用while循环删除将要删除的数据，并及时补齐因删除的数据而导致的列表数据变化，避免漏删数据 i = 0 while i \u003c len(Students): if Students[i]['gender'] == 'unknown': Students.remove(Students[i]) i -= 1 i += 1 print(Students) 方式四：遍历新的列表，删除原来列表(Students[:]是Students的切片，所以修改Students对切片没影响) i = 0 for Student in Students[::]: if Student['gender'] == 'unknown': Students.remove(Student) print(Students) 方式五：使用内置函数filter()和匿名函数 Student = filter(lambda x: x['gender'] != 'unknown', Students) print(list(Student)) 将列表中学生成绩按照从大到小排序 Students = [{'name': '张三', 'age': 21, 'score': 99, 'tel': '13888888888', 'gender': 'female'}, {'name': '李四', 'age': 14, 'score': 96, 'tel': '13888889999', 'gender': 'male'}, {'name': '王五', 'age': 22, 'score': 94, 'tel': '13888887777', 'gender': 'unknown'}, {'name': '赵六', 'age': 25, 'score': 56, 'tel': '13888886668', 'gender': 'male'}, {'name': '秦桧', 'age': 16, 'score': 49, 'tel': '13888885555', 'gender': 'female'}, {'name': '岳飞', 'age': 24, 'score': 92, 'tel': '13888883233', 'gender': 'unkown'}, ] for j in range(0, len(Students) - 1): for i in range(0, len(Students) - 1): if Students[i]['score'] \u003c Students[i + 1]['score']: Students[i], Students[i + 1] = Students[i + 1], Students[i] print(Students) 去重、以及按条件挑选 Basketball = ('嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Ping_Pong = ('赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Football = ('刘邦', '项羽', '赵匡胤', '李世民', '朱元璋') Hobby = Basketball + Ping_Pong + Football Hobby_Set = set(Hobby) print(Hobby_Set) print(len(Hobby_Set)) # 更简洁写法 Hobby = set(Basketball + Ping_Pong + Football) print(Hobby) print(len(Hobby)) 求只选第一个学科人的数量和名字 Basketball = ('嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Ping_Pong = ('赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Football = ('刘邦', '项羽', '赵匡胤', '李世民', '朱元璋') Traverse_Basketball = [] for Traverse in Basketball: if Traverse not in Ping_Pong and Traverse not in Football: Traverse_Basketball.append(Traverse) print('只选择第一个兴趣爱好的人有：{}，分别是{}'.format(len(Traverse_Basketball), Traverse_Basketball)) 统计多少人分别报了几个兴趣班 Basketball = ('嬴政', '姬发', '刘邦', '项羽', '赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Ping_Pong = ('赵匡胤', '李世民', '朱元璋', '刘彻', '朱棣') Football = ('刘邦', '项羽', '赵匡胤', '李世民', '朱元璋') Hobby = Basketball + Ping_Pong + Football Traverse_Dict = {} for Traverse in Hobby: if Traverse not in Traverse_Dict: Traverse_Dict[Traverse] = Hobby.count(Traverse) print(Traverse_Dict) for k, v in Traverse_Dict.items(): if v == 1: print('报了一门兴趣爱好的有', k) elif v == 2: print('报了二门兴趣爱好的有', k) elif v == 3: print('报了三门兴趣爱好的有', k) 去重排序 Nunbers = [5, 3, 6, 7, 2, 8, 3, 6, 3, 5, 8, 9] x = set(Nunbers) y = list(x) y.sort(reverse=True) # 加reverse 为倒序， 不加为正序 print(y) 求和，return返回多个数据使用：[list]列表、(Tuple)元组、{dict}字典 # 定义函数求[n~m]之间所有整数之和 def Number_add(n, m): x = 0 for i in range(n, m): x += i return x print(Number_add(0, 101)) # 还可以使用列表、集合、range等 # 求n的阶乘 def Factorial(n): x = 1 for i in range(1, n + 1): x *= i return x print(Factorial(5)) # 计算m阶乘的和 def Factorial(n): x = 1 for i in range(1, n + 1): x *= i return x def Fac_Sum(m): x = 0 for i in range(1, m + 1): x += Factorial(i) return x print(Fac_Sum(5)) # 使用递归求n的阶乘 def Factorial(n): if n == 0: return 1 return n * Factorial(n - 1) print(Factorial(5)) # 使用递归求斐波那契数列的第n个数字 def Fibonacci(n): if n == 1 or n == 2: return 1 return Fibonacci(n - 2) + Fibonacci(n - 1) print(Fibonacci(8)) 匿名函数(回调函数) def Calculate(a, b, fn): c = fn(a, b) return c def Addition(x, y): # 传参给加法处理相关 return x + y def Subtraction(x, y): # 传参给减法处理相关 return x - y print(Calculate(2, 4, Addition)) # 计算加法 print(Calculate(13, 4, Subtraction)) # 计算减法 # 或者使用lambda匿名函数表达式 def Calculate(a, b, fn): c = fn(a, b) return c Numbers_1 = Calculate(4, 6, lambda x, y: x + y) Numbers_2 = Calculate(13, 6, lambda x, y: x - y) Numbers_3 = Calculate(4, 6, lambda x, y: x * y) Numbers_4 = Calculate(42, 6, lambda x, y: x / y) print(Numbers_1, Numbers_2, Numbers_3, Numbers_4) Numbers_1 = Calculate(4, 6, lambda x, y: x + y) Numbers_2 = Calculate(13, 6, lambda x, y: x - y) Numbers_3 = Calculate(4, 6, lambda x, y: x * y) Numbers_4 = Calculate(42, 6, lambda x, y: x / y) print(Numbers_1, Numbers_2, Numbers_3, Numbers_4) 装饰器的开放封闭原则使用 # 使用 *args参数 def Can_Play(fn): def Inner(name, game, *args, **kwargs): # print(args) if args[0] \u003c= 22: fn(name, game) else: print('太晚了，洗洗睡吧') return Inner @Can_Play def Play_Game(name, game): print('{}正在玩儿{}'.format(name, game)) Play_Game('张三', '英雄联盟',19) Play_Game('李四', '魔兽世界', 24) ############################################ 使用 **kwargs参数 def Can_Play(fn): def Inner(name, game, *args, **kwargs): Current_Time = kwargs.get('Current_Time', 23) if Current_Time \u003c= 22: fn(name, game) else: print('太晚了，洗洗睡吧') return Inner @Can_Play def Play_Game(name, game): print('{}正在玩儿{}'.format(name, game)) Play_Game('张三', '英雄联盟', Current_Time=19) Play_Game('李四', '魔兽世界', Current_Time=24) 面向对象练习 # 房子(Houses) 有户型、总面积、剩余面积(等于总面积的60%) 和家具名称、列表、属性 # 新房子没有任何家具 # 将家具的名称追加到家具名称列表中 # 判断家具的面积是否超过剩余面积， 如果超过，提示不能添加这件家具 # 定义一个类， Houses为类名，大驼峰命名 class Houses(object): # __slots__ 属性直接定义在类里， 是一个元组，用来规定对象可以存在的属性 # __slots__ = ('House_Type','Total_Area') # Fru_List 不存在元组中报错 # Fru_List：缺省参数，在__init__方法里， 以参数形式定义属性 def __init__(self, House_Type, Total_Area, Fru_List=None): if Fru_List is None: # 如果这个值是None Fru_List = [] # 将Fru_List 设置为空列表 self.House_Type = House_Type self.Total_Area = Total_Area self.Free_area = Total_Area * 0.6 self.Fru_list = Fru_List def Add_Fru(self,x): if self.Free_area \u003c x.Area: print('剩余面积不足，放不下，建议换个大房子') else: self.Fru_list.append(x.Name) self.Free_area -= x.Area # 减少面积 def __str__(self): return \"户型={}，总面积={}，剩余面积={}，家具列表={}\".format(self.House_Type,self.Total_Area,self.Free_area,self.Fru_list) ''' 家具(Furniture)有名字和占地面积属性，其中 席梦思(Bed)占地 4平米 衣柜(Chest)占地 2平米 餐桌(Table)占地 1.5平米 将以上三件家具添加到房子中 打印房子时，要求输出：户型、总面积、剩余面积、家具名称列表 ''' class Furniture(object): def __init__(self, Name, Area): self.Name = Name self.Area = Area # 创建房间对象，定义户型和总面积，先通过调用__new__ 方法，申请一段内存空间，然后使用 Houses 类，自动调用 __init__ 方法， House = Houses('两室一厅', 56) # 创建家具对象，定义名称和占地面积 Bed = Furniture('席梦思', 4) Chest = Furniture('衣柜', 2) Table = Furniture('餐桌', 1.5) # 根据业务逻辑，让不同的对象执行不同的行为，例如：将家具添加到房间里面(面向对象关注点：让谁做) House.Add_Fru(Bed) House.Add_Fru(Chest) House.Add_Fru(Table) House.Sofa = '沙发' # 动态属性：属性如果存在修改，不存在则添加 # 打印出内存地址，打印一个对象的时候，会调用这个对象的 __repr__ 或者 __str__，获取它们返回值， 相当于：print(House.__str__()) # print(House, Bed, Chest, Table) print(House.__str__()) 求素数(质数) for...else方式求素数(质数) # 素数也叫质数，除了1和它本身以外，不能再被其它任何数整除 for i in range(101, 201): for j in range(2, int(i ** 0.5): # 也可以使用开方的方式 if i % j == 0: # i 除以某一个数字，除尽了，i就是合数 break # break放在内循环里，用来结束内循环 else: print(i, \"是质数\") 假设成立法求素数 for i in range(2, 101): flag = True # 每次都假设 i 是一个质数 for j in range(2, int(i ** 0.5) + 1): if i % j ==0: # 除尽说明 i 是合数 flag = False break if flag: # if flag == True print(i, \"是质数\") 计数法求素数 for i in range(2, 101): count = 0 # 假设这个数能被0个数字整除 for j in range(2, i): if i % j ==0: # 除尽了是合数 count += 1 if count == 0: print(i, \"是一个合数\") else: print(i, \"是一个合数，它能被\", count, \"个数字整除\") 高级语法 模块 获取模块使用列表以及方式 获取模块列表 在Python中一个.py文件就是一个模块 安装python3 $ yum install python3 获取模块列表 $ pydoc modules # 命令行执行获取支持模块 $ pydoc modules json # 获取某一个模块使用方式，例如：os、json、yum、sys 第二种获取方式，和第一种效果结果一样 \u003e\u003e\u003e help(\"modules\") # 获取所有支持模块 \u003e\u003e\u003e help(\"sys\") # 获取某个模块使用方式 import模块导入使用方式 import导入始终在文件的顶部，在模块注释和文档字符串之后，在模块全局变量和常量之前 导入顺序如下：标准库进口，相关的第三方库，本地库。各组的导入之间要有空行 不要在一行import多个库，每行只能import一个库 import time # 导入模块 from random import * # from 模块名 import *，此方法导入所有函数使用，不用引用模块前缀名称 from random import as alias # 导入模块并重新起一个别名 from random import randint # from 模块名 import 函数名字，此方法只导入某个函数使用 pip：python第三方包管理工具 查找Python模块 安装pip以及使用pip安装第三方插件 # 通过python3 安装 pip3 $ python3.6 -m pip install --upgrade --force pip # 使用pip3 安装第三方 Telegram模块 $ pip3 install python-telegram-bot --upgrade # 临时国内下载， $ pip3 install package_name -i https://pypi.douban.com/simple/ # 报错执行 $ pip install --upgrade setuptools $ pip install ez_setup # 列出已安装第三方模块，包含模块名称和版本号 $ pip3 list $ pip3 freeze \u003erequirements.txt # 把本地安装所有模块重定向到文件， 以便在服务器安装 # 使用pip3卸载第三方模块 $ pip3 uninstall python-telegram-bot # 使用 -r requirements.txt 读取文件内模块和版本号，并安装 $ pip3 install -r requirements.txt re正则表达式 非打印字符 字符 描述 \\cx 匹配有x指明的控制字符，例如：\\cM匹配一个Control-M。x的值必须是：A~Z或a~z之一，否则将c视为一个原义(普通)c字符 \\f 匹配一个换页符，等价于：\\x0C和\\cL \\n 匹配一个换行符，等价于：\\x0a和\\cJ \\r 匹配一个回车符，等价于：\\x0d和\\cM \\s 匹配任何空白字符，包括：空格、制表符(Tab)键、换页符等等，等价于[\\f\\n\\r\\t\\v]，注意：Unicode正则表达式会匹配全角空格符 \\S 匹配任何非空白字符，等价于取反：[^ \\f\\n\\r\\t\\v] \\t 匹配一个制表符(Tab)键，等价于：\\x09和\\cl \\v 匹配一个垂直制表符，等价于：\\x0b和\\cK 特殊字符 2.1 特殊字符有一些特殊含义，若要匹配特殊字符必须使用转义符\\转义后才能匹配 特殊字符 描述 () 表示为分组默认为第零分组，可以使用多个：()()()表示分多个组，要匹配这些字符使用\\(和\\)， [] 中括号内为取值区间范围，要匹配单独的[，使用：\\[ {} 限定大括号前面字符、组、出现的次数，要匹配单独的{，使用：\\{ . 匹配除换行符(\\n)之外的任意字符，要匹配单独的.，使用：\\. \\ 将下一个字符标记为：特殊字符、原义字符、向后引用、八进制转义符等等，例如：匹配n字符，使用：\\n。匹配\\，使用：\\\\。匹配\\(，使用：\\( ` ` \\d 只匹配一个数字字符，等价于：[0-9]，匹配多个数字使用：\\d+ [0-9] 匹配任何数字，等价于：\\d，匹配多个数字使用：[0-9]+ \\D 匹配一个非数字字符，等价于取反：[^0-9] [a-z] 匹配任何小写字母 [A-Z] 匹配任何大写字母 [a-zA-Z0-9] 匹配任何：大小写字母、数字，等价于：\\w \\w 匹配_下划线、大小写字母、数字字符，等价于：[A-Za-z0-9_]，不包含：+-*.@#$%\u0026等标点符号， \\W 匹配任何非单独字符，等价于取反：[^A-Za-z0-9_]，获取标点符号 \\u4e00-\\u9fa5 匹配纯中文 定位符 3.1 使用定位符能够将正则表达式固定到行首或者行尾，这些正则表达式出现在单词开头和结尾位置 3.2 定位符用来描述字符串或单词的边界，^代表开始、$代表结束，\\b描述单词前或者后的边界，\\B表示非单词边界 定位符 描述 ^ 匹配输入字符串的开始位置，例如：^h匹配以h开头。在方括号[]中时表示取反，例如：[^0-9]匹配除了数字意外的数据。要匹配单^字符，使用：\\^ $ 匹配输入字符串的结尾位置，要匹配单独$字符，使用：\\$ \\b 匹配一个单词边界，即字符与空格之间的位置 \\B 非单词边界匹配 限定符 4.1 限定符用来匹配正则表达式的一个给定组件必须要出现多少次才能满足匹配，有：*、+、?、{n}、{n,}、{n,m}六种 限定符 描述 * 匹配前面子表达式的零次或多次，例如：z*能匹配zoom或zookeeper，等价于：{0,} + 匹配前面子表达式最少一次或多次，例如：zo+能匹配zo以及zoo，不能匹配z。等价于：{1,}，可以匹配：()+、[]+、{}+允许括号内出现多次 ? 匹配前面元素零次或一次，例如：do(es)?可以匹配do、does中的does、doxy中的do，等价于：{0,1}，可以将贪婪模式转换为非贪婪模式 {n} 是一个非负整数，匹配确定字符的n次，例如：o{2}限定o出现两次 {n,} 是一个非负整数，至少匹配n次，例如：o{2,}匹配o出现n次，o{0,}等价于：o*，o{1,}等价于：o+。 {,n} 是一个非负整数，匹配不能超过限定次数，例如：o{,2}限定不能超过两次以上 {n,m} n和m均为非负整数，其中n \u003c= m，最少匹配 n次且最多匹配m次，例如：o{1,3}将匹配fooooooood中的前三个o，o{0,1}等价于：o?。注意：在逗号和两个数之间不能有空格 正则表达式修饰符 修饰符 描述 re.I 使匹配结果对大小写不敏感 re.M 多行匹配，影响^和$ re.S 使.匹配，包括换行在内的所有字符 关键字使用 属性和方法 说明 pos 搜索开始的位置 endpos 搜索结束的位置 string 搜索的字符串 re 当前使用的正则表达式对象 lastindex 最后匹配的组索引 lastgroup 最后匹配的组名 group(index=0) 某个分组匹配结果，如果index等于0，便是匹配整个正则表达式 groups 所有分组匹配的结果，每个分组返回结果组成一个列表 groupdict() 返回组名作为key，每个分组匹配结果作为value的字典 start([group]) 获取组开始的位置 end([group]) 获取组结束的位置 span([group]) 获取组开始和结束的位置 expand(template) 使用组匹配结果替换模板template中的内容，并把替换后的内容返回 re选项 第一个为规则匹配，第二个xxx为要匹配字符串、列表、字典等，只匹配一次 查询相关操作 re.search(r'', xxx)：匹配整个字符串 re.match(r'', '字符串')：只匹配开头，没有则为：None re.fullmatch re.finditer：把匹配到的数据放到可迭代对象中 re.findall：把匹配到的数据放到列表中 分组查询span和group span使用元组类型匹配字符串下标 group：正则表达式分组，依英文小括号表示：()，可以有多个分组，获取匹配结果 groupdict()：使用字典模式进行key:value 替换操作 第一个参数是被替换的 第二个参数是新字符或者一个函数 第三个参数是原来字符串 import re print(re.sub(r'b', 'X', 'bbdgdsgrdshgbb')) # 把b替换为大写X 示例练习 示例 re.search(r'\\s', '大家好 我是 代码') # 匹配所有的空字符 re.search(r'\\S', '大家好 我是 代码') # 匹配所有非空字符 re.search(r'\\n', '大家好\\n我是代码') # 匹配换行 re.search(r'n$', 'hello python') # 匹配以n结尾字符 re.search(r'^h.+n$', 'hello python') # 匹配以h开头，中间出现一次或多次任意字符，并且以n结尾 re.search(r'^ha*', 'h') # 匹配以h开头，a出现0次或一次 print(re.findall(r'\\w+', 'h+E-11.0_X*L%')) ['h', 'E', '11', '0_X', 'L'] # 打印结果为 匹配IPV4的IP地址 第一组：^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)以括号内开头、出现零次或者一次，25[0-5] - 表示从250到255的数字，2[0-4][0-9] – 表示从200到249的数字，[01]?[0-9][0-9]?- 表示从0到199的数字 第二组：\\.匹配一个点 第三组：{3}表示括号中的内容出现三次 第四组：(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$以括号中内容结尾 regexp = '^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$' # IPV6 regexp = '^([\\da-fA-F]{1,4}:){7}[\\da-fA-F]{1,4}$' 匹配邮箱 第一组：^([A-Za-z0-9_\\-\\.])+以小括号内中开头， 匹配最少一次或多次，再加：@ 第二组：([A-Za-z0-9_\\-\\.])+匹配括号内中内容， 最少一次或者多次，再加：\\. 第三组：([A-Za-z]{2,4})$匹配方括号中内容，出现2次或者4次，以方括号内中字母结尾 regexp = '^([A-Za-z0-9_\\-\\.])+@([A-Za-z0-9_\\-\\.])+\\.([A-Za-z]{2,4})$' 匹配手机号 第一组：(13[0-9])|匹配小括号中内容，使用：|或者匹配第二组 第二组：(14[5|7])|匹配小括号中内容，使用：|或者匹配第三组 第三组：(15([0-3]|[5-9]))|匹配小括号中内容，使用：|或者匹配第四组 第四组：(18[05-9]))匹配括号中内容 第五组：\\d{8}$：后面为任意八个数字结尾 regexp = '^((13[0-9])|(14[5|7])|(15([0-3]|[5-9]))|(18[05-9]))\\d{8}$' 匹配身份证号 第一组：^[1-9]匹配方括号中内容以数组开头，后面为\\d{5}任意五个数字 第二组：(18|19|20|)匹配括号内的年份，后面为\\d{2}任意两个数字 第三组：((0[1-9])|(10|11|12))为生日月份1~12 第四组：(([0-2][1-9])|10|20|30|31)为生日日期1~31 第五组：\\d{3}任意三个数字 第六组：[0-9Xx]$身份证最后一位，以方括号内中字符结尾 regexp = '^[1-9]\\d{5}(18|19|20|)\\d{2}((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\\d{3}[0-9Xx]$' 匹配URL (https?|ftp|file)://[-A-Za-z0-9+\u0026@#/%?=~_|!:,.;]+[-A-Za-z0-9+\u0026@#/%=~_|] regexp = '((ht|f)tps?):\\/\\/([\\w\\-]+(\\.[\\w\\-]+)*\\/)*[\\w\\-]+(\\.[\\w\\-]+)*\\/?(\\?([\\w\\-\\.,@?^=%\u0026:\\/~\\]))' OS系统操作 OS：模块全称为：OperationSystem操作系统 os.name：获取操作系统名称：Windows系统 ==\u003ent，非Windows系统 ==\u003eposit os.path：使用 os.path.isdir：判断是否是目录，是目录为：True，否则为：False\nos.path.isfile：判断是否是文件，是文件为：True，否则为：False\nos.path.exists：判断文件是否存在，存在为：True，否则为：False\nos.path.abspath：获取文件绝对路径\nos.path.splitext：分割文件名，和rpartition作用类似\nos.getcwd：获取当前工作目录\nos.rename：文件重命名\nos.remove：删除文件\nos.rmdir：删除空文件夹\nos.mkdir：创建一个目录\nos.listdir：列出指定目录下所有文件以及文件夹\nos.getpid()获取进程ID\nimport os print(os.path.isfile('main.py')) # 判断是否是文件是文件为：True，否则为：False SYS系统操作 sys：系统相关功能 sys.path：获取Python所有模块路径，并以列表形式展示 sys.stdin sys.stdout sys.stderr Uuid生成 uuid：用来生成一个全局ID 方法 作用 uuid.uuid1() 基于MAC地址，时间戳，随机数来生成唯一的uuid，可以保证全球范围内的唯一性 uuid.uuid2() 算法与uuid1不同，不同的是把时间戳的前四位置换位POSI的UID，不过需要注意的是python中没有基于DCE的算法，所以python的uuid模块中没有uuid2这个方法 uuid.uuid3(namespace，name) 通过计算一个命名空间和名字的MD5散列值来给出一个uuid，所以可以保证命名空间中的不同名字具有不同的uuid，但是相同的名字就是相同的uuid，namesp并不是一个自己手动指定的字符串或其他量，而是在uuid模块中本身给出的一些值。比如：uuid.NAMESPACE_DNS，uuid.NAMESPACE_URL，uuid.NAMESPACE_OID等，这些值也是uuid对象，根据一定的规则计算得出 uuid.uuid4() 通过伪随机数得到uuid，有一定重复的概率性， uuid.uuid5(namespace，name) 和uuid3基本相同，只不过采用的散列算法是sha1 import uuid print(uuid.uuid1()) print(uuid.uuid3(uuid.NAMESPACE_DNS, '嬴政')) # NAMESPACE_URL、NAMESPACE_OID、NAMESPACE_X500 Time时间 time：显示时间、控制程序、暂停程序 time.time：获取从1970-01-01 00:00:00 UTC到现在的时间戳秒数 time.strftime：按照指定格式输出日期、时间 time.asctime： time.ctime：把时间戳转换为时间 time.sleep：睡眠时间 import time print(time.time()) print(time.strftime(\"%F %T\")) # (\"%Y-%m-%d %H:%M:%S\") print(time.asctime()) print(time.ctime()) import arrow print(arrow.utcnow().timestamp())import time Start = time.time() print('Start = ', Start) Numbers = 0 for i in range(1, 100000000): Numbers += i print(Numbers) End = time.time() print('代码执行耗时{}秒：'.format(End - Start)) print('Stop = ', End) 定义函数调用time import time def Time_Calculate(fn): Start = time.time() print('Start = ', Start) fn() End = time.time() print('代码执行耗时{}秒：'.format(End - Start)) print('Stop = ', End) def Numbers_Calculate(): Numbers = 0 for i in range(1, 100000000): Numbers += i print(Numbers) def Str_Calculate(): print('Hello') time.sleep(5) print('World') Time_Calculate(Numbers_Calculate) Time_Calculate(Str_Calculate) time模块使用装饰器 import time def Time_Calculate(fn): def Inner(): Start = time.time() print('Start = ', Start) fn() End = time.time() print('代码执行耗时{}秒：'.format(End - Start)) print('Stop = ', End) return Inner @Time_Calculate # 装饰器语法，Numbers_Calculate函数调用@Time_Calculate装饰器 def Numbers_Calculate(): Numbers = 0 for i in range(1, 100000000): Numbers += i print(Numbers) Numbers_Calculate() Copy复制 copy：模块深复制、浅复制 copy.copy浅拷贝相当于软连接 copy.deepcopy深拷贝重新复制一份 Math数学 math：数学相关模块 math.factorial：阶乘相关函数 math.pow：幂运算(次方) math.floor：向下取整 math.ceil：向上取整 Json字符串 Python 、Json数据类型对应 Python Json dict object list、tuple array str string int、float number True true False false None null Python中Json模块的转换 dict字典转换为Json字符串 json.dumps：将数据转换成Json字符串，不会将数据保存到文件里 json.dump：将数据转换成Json字符串的同时写入到指定文件 import json from pprint import pprint # 应用换行模块 Dicts = {'name': '张三', 'age': 23, 'height': 178, 'width': '75kg', 'isPass': True, # 可以是布尔值 'hobbies': ['音乐', '旅游', '电子产品'], # 也可以是列表 } Jsons = json.dumps(Dicts) # 其他列表、元组也可以转换为Json print(type(Jsons) # 查看类型 pprint(Jsons) # pprint模块换行输出，或者使用：rich import json names_list = ['嬴政', '刘彻', '李世民', '赵匡胤'] file_name = open('name.txt', 'w', encoding='utf8') json.dump(names_list, file_name) file_name() Json字符串转换为字典dict json.loads：将Json字符串转换成字典dict类型 json.load：读取文件，将读取到的文件内容加载成一个对象，对象可以是list列表、tuple元组、dict字典，看存储内容类型 import json from pprint import pprint # 应用换行模块 Jsons = '{\"name\": \"张三\", \"age\": 23, \"height\": 178, \"width\": \"75kg\"}' Jsons_Eval = eval(Jsons) print(Jsons_Eval) pprint(Jsons_Eval) # pprint模块换行输出，或者使用：rich # 第二种方式，使用Json模块中的loads import json from pprint import pprint # 应用换行模块 Jsons = '{\"name\": \"张三\", \"age\": 23, \"height\": 178, \"width\": \"75kg\"}' Jsons_Loads = json.loads(Jsons) print(Jsons_Loads) pprint(Jsons_Loads) # pprint模块换行输出，或者使用：rich Random随机 random：随机生成一个随机数 random.randint：随机生成一个a~b整数，包含开始和结尾数 random.random：随机生成一个0~1浮点数 pexpect控制交互式进程 pexpect交互式进程控制模块 pexpect.spawn： import pexpect # SSH 登录信息 ssh_command = 'ssh user@example.com' # 启动 SSH 进程 ssh_session = pexpect.spawn(ssh_command) # 匹配输出，等待 \"password\" 提示 ssh_session.expect('password:') # 发送密码 ssh_session.sendline('your_password') # 匹配输出，等待登录成功 ssh_session.expect('Welcome') # 登录成功后，发送其他命令 ssh_session.sendline('ls -l') # 等待输出并打印 ssh_session.expect(pexpect.EOF) print(ssh_session.before) # 关闭 SSH 连接 ssh_session.close() Datetime时间 datetime：用来显示日期、时间 datetime.date：用来显示日期 datetime.time：用来显示时间 datetime.datetime：用来显示日期时间 datetime.timedelta：用来计算时间 import datetime print(datetime.date(2023, 11, 11)) # 创建一个日期 print(datetime.time(22, 30, 00)) # 创建一个时间 print(datetime.datetime.now()) # 获取当前时间 print(datetime.datetime.now() + datetime.timedelta(3)) # 计算三天后日期时间 Pickle二进制 Pickle：模块将Python中任意对象转换成二进制数据 序列化：dump、dumps 反序列化：load、loads import pickle names_list = ['嬴政', '刘彻', '李世民', '赵匡胤'] file_name = open('name.txt', 'wb', encoding='utf8') pickle.dump(names_list, file_name) NumPy数值计算 Numpy多维数组与矩阵运算 pandas数据处理 pandas数据操纵和分析 Web Scraper 数据可视化 Matplotlib图表分析库文档链接 不支持中文，最多、最老的图标库，只支持静态 Plotly图表分析库文档链接 图标库丰富，图表相对专业性更强 Seaborn图表分析库文档链接 不支持中文文档，图表相对好看，配置代码量少，图表量少 Ggplot图表分析库 Bokeh图表分析库文档链接 偏向学术风格 Pyecharts图表分析库文档链接 支持中文文档，样式好看 Pygal图表分析库 视频数据对比要点视频类型，科技、生活 B站、小红书 播放量 涨粉 观众喜爱度 互动率 视频内容类型 pycurl沟通协议等 #!/usr/bin/python3 # -*- coding: utf-8 -*- #Typ_www.typ520.cn import os,sys,time,sys,pycurl #URL=\"www.so.com\" URL=sys.argv[1] c = pycurl.Curl() c.setopt(pycurl.URL, URL) c.setopt(pycurl.CONNECTTIMEOUT, 5) #下载超时时间,5秒 c.setopt(pycurl.TIMEOUT, 5) c.setopt(pycurl.FORBID_REUSE, 1) c.setopt(pycurl.MAXREDIRS, 1) c.setopt(pycurl.NOPROGRESS, 1) c.setopt(pycurl.DNS_CACHE_TIMEOUT,30) indexfile = open(os.path.dirname(os.path.realpath(__file__))+\"/content.txt\", \"wb\") c.setopt(pycurl.WRITEHEADER, indexfile) c.setopt(pycurl.WRITEDATA, indexfile) #异常处理,连接错误 try: c.perform() except Exception as e: print (\"connecion error:\"+str(e)) indexfile.close() c.close() sys.exit() NAMELOOKUP_TIME = c.getinfo(c.NAMELOOKUP_TIME) CONNECT_TIME = c.getinfo(c.CONNECT_TIME) PRETRANSFER_TIME = c.getinfo(c.PRETRANSFER_TIME) STARTTRANSFER_TIME = c.getinfo(c.STARTTRANSFER_TIME) TOTAL_TIME = c.getinfo(c.TOTAL_TIME) HTTP_CODE = c.getinfo(c.HTTP_CODE) SIZE_DOWNLOAD = c.getinfo(c.SIZE_DOWNLOAD) HEADER_SIZE = c.getinfo(c.HEADER_SIZE) SPEED_DOWNLOAD=c.getinfo(c.SPEED_DOWNLOAD) print (\"解析域名: %s\" %(URL)) print (\"HTTP状态码：%s\" %(HTTP_CODE)) print (\"DNS解析时间：%.2f ms\"%(NAMELOOKUP_TIME*1000)) print (\"建立连接时间：%.2f ms\" %(CONNECT_TIME*1000)) print (\"准备传输时间：%.2f ms\" %(PRETRANSFER_TIME*1000)) print (\"传输开始时间：%.2f ms\" %(STARTTRANSFER_TIME*1000)) print (\"传输结束总时间：%.2f ms\" %(TOTAL_TIME*1000)) print (\"下载数据包大小：%d bytes/s\" %(SIZE_DOWNLOAD)) print (\"显示HTTP数据包头部大小：%d byte\" %(HEADER_SIZE)) print (\"平均下载速度：%d bytes/s\" %(SPEED_DOWNLOAD)) indexfile.close() c.close()import pycurl url='https://www.baidu.com/' c=pycurl.Curl # 需要一个curl对象，所以第一步先创建curl对象 c.setopt(pycurl.URL,\"https://www.baidu.com/\") # 发起请求 设置请求头 c.setopt(pycurl.USERAGENT,\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36\") c.setopt(pycurl.URL,url) c.setopt(pycurl.CONNECTTIMEOUT,5) # 设置连接等待时间 c.setopt(pycurl.NOPROGRESS,0) # 下载进度条，非0时候不显示 c.setopt(pycurl.MAXREDIRS,3) # 最大重定向次数 c.getinfo(pycurl.HTTP_CODE) # 返回请求状态码码 c.getinfo(pycurl.TOTAL_TIME) # 显示传输结束需要的时间 c.getinfo(pycurl.SIZE_UPLOAD) # 显示上传数据包大小 c.getinfo(pycurl.SIZE_DOWNLOAD) # 显示下载数据包大小 c.getinfo(pycurl.SPPEED_DOWNLOAD) # 显示下载速度 c.getinfo(pycurl.SPEED_UPLOAD) # 显示上传速度 c.getinfo(pycurl.HEADER_SIZE) # 显示数据包头部大小 wsgiref服务 handle_request()：一次请求 serve_forever()：多次请求 import wsgiref from wsgiref.simple_server import make_server Socket通信 创建、链接参数 socket.AF_INET：表示使用网络连接 socket.SOCK_DGRAM：表示是UDP协议 socket.SOCK_STREAM：表示TCP协议 发送数据 sendto('要发送的数据'.encode('utf8'), ('接受消息地址 IP', 端口号)) # 发送UDP消息 send('要发送的数据内容'.encode('utf8')) # 发送TCP消息 接收数据 recvfrom(1024)接收到消息是元组模式，需要进行拆包 recv(1024)接收消息 关闭Socket close() 案例 发送数据 import socket # 模式、协议 Network_Protocol_Socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # 绑定 IP 端口 Network_Protocol_Socket.bind(('本机IP地址', 本机端口)) # 发送基于TCP协议，为客户端 Network_Protocol_Socket.connect(('接收方IP地址', 接收方端口号)) # 先建立链接 Network_Protocol_Socket.send('要发送的数据内容'.encode('utf8')) # 发送消息 # 发送基于UDP数据 Network_Protocol_Socket.sendto('要发送的数据内容'.encode('utf8'), ('接收方IP地址'， 接收方端口)) # 关闭连接 Send_Socket.close() 接收数据 import socket # 模式、协议 Network_Protocol_Socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # 绑定 IP 端口 Network_Protocol_Socket.bind(('本机IP地址', 本机端口)) # 接收基于TCP数据，TCP协议等待客户端发送数据，为服务端 Network_Protocol_Socket.listen(128) # 被动监听socket # 获取到元组数据，第0个是socket客户端连携， 第1个是客户端地址和端口 Client_Socket, Client_Address = Network_Protocol_Socket.accept() Client_Socket.recv(1024) # 读取数据内容 # 接受基于UDP数据，1024：代表每次读取1024字节 Data, Address = Network_Protocol_Socket.recvfrom(1024) print('从地址{}端口号{}接收到了消息，消息内容是：{}'.format(Address[0], Address[1], data.decode('utf8'))) # 关闭连接 Send_Socket.close( Queue消息队列 遵循：先进先出规则，与之相反的是stack栈结构，遵循：后进先出，先进后出 put()：生产消息 get()：消费消息 full()：判断队列是否存满 block：在队列满的情况下，等待阻塞队列 timeout：超时等待，超过等待时间报错 import queue queue.Queue() # 创建队列 webbrowser浏览器 Requests发送网络连接 import requests response = requests.get('https://URL:port') # 获取文本 print(response.text) # 解析Json字符串 print(response.json) # 解析为python对应数据类型 print(response.json()) # 获取状态 print(response.status_code) # 进行解码 print(response.content.decode('utf8')) Threading线程控制 lock.acquite()：加同步锁，加锁要考虑出现死锁问题 lock.release()：释放同步锁 threading.Thread()创建主进程，共享全局变量进行子进程的运行 threading.current_thread().name Multiprocessing跨平台多进程 multiprocessing.Process() from multiprocessing import Queue # 进程间使用的Queue from multiprocessing import Pool # 使用Pool创建进程池 # 创建使用进程池 Rrocess_Pool = Pool(5) # 5 代表创建5个进程 Rrocess_Pool.apply_asyncd() # 使用进程池 # 创建队列，默认为：0 不限制 multiprocessing.Queue() Hashlib、Hmac加密 hashlib：加密模块，支持：md5、sha两种加密方式，十六进制转换为二进制 md5：加密 import hashlib Md5 = hashlib.md5('aaa'.encode('utf8')) # 使用MD5加密 print(Md5.hexdigest()) # 打印加密结果 sha：加密，分别有：hashlib.sha1、hashlib.sha256、hashlib.sha512等 hmac：加密模块，可以使用定义密钥指定加密 hmac.new import hmac Hmacs = hmac.new('keys'.encode(), 'encrypted_object'.encode(), digestmod='sha256') # digestmod= 为必须指定函数 result = Hmacs.hexdigest() print(result) 高级语法 面向对象 包的概念 包中名以及参数定义 __init__.py：文件控制着包的导入行为，如果改文件内容为空仅仅是把这个包导入，不会导入保重模块 from . import Function_Name # 使用点 . 为当前文件，后面为函数名称 __all__：在__init__.py文件中定义一个__all__变量，它控制着from包名import *时导入的模块 _Underscore：一个下划线建议只在定义名称所在模块使用 _Underscore = aaa del(_Underscore,_Underscore_2) # 调用后删除 __name__：当直接运行这个py文件时候值是：__main__，如果这个py文件作为一个模块导入的时候，值是：__name__所在文件名 魔法方法/魔术方法 是内里的特殊的一些方法，特点： 一般情况不需要手动调用，会在合适时机自动调用 这些方法都使用__下划线开始、使用__下划线结束 __init__：在创建对象时，自动调用__init__ __del__：对象被销毁时，自动调用__del__，手动销毁是使用del __str__、__repr__：当打印一个对象的时候，会调用这个对象的__str__或__repr__方法，需要return返回，如果两个方法都定义默认选择__str__ __str__：方法，在意可读性结果 __repr__：方法，在意正确性结果，例如：datetime模块里的datetime类 __call__：方法定义，变量、函数、定义__call__方法后不报错 class Person(object): def __init__(self, name, age): # self：指的是实例对象，引用类对象传过来的参数 print('调用__init__魔法') self.Name = name self.Age = age def __call__(self, *args, **kwargs): print('Args={}, Kwargs={}'.format(args,kwargs)) # 在这里 Call_Person 定义为实例对象名，调用 Person类对象进行传参 Call_Person = Person('嬴政', 33) # 调用__call__魔法 Call_Person(1, 4, 6, 8, 3, n='Yes', m='Ok') __eq__：==调用__eq__方法，获取比较结果，__eq__方法有列表、对象等，各不相同 __ne__：!=不等于运算符调用__ne__方法， 获取比较结果，__ne__方法有列表、对象等，各不相同 __gt__：\u003e大于运算符调用__gt__方法，获取比较结果，__gt__方法有列表、对象等，各不相同 __ge__：\u003e=大于等于运算符调用__ge__，获取比较结果，__ge__方法有列表、对象等，各不相同 __class__：class '__main__.Person' __dict__：把对象转换为一个字典 __doc__：看文档、注释等 __dir__： 等价于dir __settitem__：[]中括号调用对象的__settitem__方法 @staticmethod：静态方法 class Calculator(object): @staticmethod # 静态方法不需要self 参数 def Add(a, b): return a + b @staticmethod def Minus(a, b): return a - b print(Calculator.Add(3, 7)) print(Calculator.Minus(13, 4)) @classmethod：类方法 class Calculator(object): Type = 'Class_Name' @classmethod # 类方法 def Class_(cls): print(cls.Type) print(Calculator.Class_()) __new__：通过调用__new__方法，申请内存空间，__new__方法后面覆盖前面 class Singleton(object): Instance = None @classmethod def __new__(cls, *args, **kwargs): if cls.Instance is None: # 申请内存，创建对象，并把对象类型设置为：cls cls.Instance = object.__new__(cls) return cls.Instance def __init__(self, a, b): self.A = a self.B = b X1 = Singleton('aaa', 'bbb') X2 = Singleton('ccc', 'ddd') print(X1, X2, X2 is X2) __mro__：查看调用顺序，__mro__可以查看父类调用，深度优先 异常处理语句 try、except异常处理语句 try: file_name = open('error.txt') print(file_name.read()) except Exception as error_name: # 程序出错执行，别名为：error_name print(error_name) # 打印错误信息 else: # 程序正常运行打印 print(Ok) try、finally的使用方式 try: file.read() finally: file.close() # 出错关闭文件 with(上下文管理器)使用完成自动关闭文件参数 with open('test.txt', 'r') as file: # file：为别名 file.read() ",
    "description": "Python IDE IDE与快捷键使用 IDE Pycharm IDE Anaconda IDE Jupyter 查找、设置快捷键：File→Settings→Keymap 全局搜索 双击Shift打开全局搜索功能，或者：Ctrl+Shift+a 关闭全局搜索功能：双击Shift→Actions→输入搜索：Registry打开设置面板后搜索：ide.",
    "tags": [],
    "title": "Language Python",
    "uri": "/language/python/language-python/"
  },
  {
    "breadcrumb": "Languges \u003e Python",
    "content": "爬虫脚本限制 通用性爬虫脚本需要考虑很多方面，包括不同类型的网站、数据格式、反爬机制等等。以下是一个简单的示例爬虫脚本，用于爬取豆瓣电影Top250的数据，并使用pandas库进行数据分析和可视化 这个脚本使用requests库和BeautifulSoup库来爬取豆瓣电影Top250的数据，然后将数据保存到CSV文件中。接着，使用pandas库将CSV文件读取为DataFrame，并进行数据分析和可视化。这个脚本只是一个简单的示例，如果要编写更复杂的爬虫脚本，需要仔细研究目标网站的结构和反爬机制 import requests from bs4 import BeautifulSoup import pandas as pd import matplotlib.pyplot as plt # 设置请求头，模拟浏览器访问 headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"} # 爬取数据 url = \"https://movie.douban.com/top250\" movies = [] for i in range(0, 250, 25): params = {\"start\": str(i), \"filter\": \"\"} response = requests.get(url, params=params, headers=headers) soup = BeautifulSoup(response.text, \"html.parser\") items = soup.select(\".grid_view .item\") for item in items: rank = item.select(\".pic em\")[0].text.strip() title = item.select(\".title\")[0].text.strip() rating = item.select(\".rating_num\")[0].text.strip() comments = item.select(\".quote span\")[0].text.strip() movie = {\"rank\": rank, \"title\": title, \"rating\": rating, \"comments\": comments} movies.append(movie) # 将数据保存到CSV文件 df = pd.DataFrame(movies) df.to_csv(\"movies.csv\", index=False) # 数据分析 print(\"豆瓣电影Top250数据分析：\") print(\"平均评分：\", df[\"rating\"].mean()) print(\"评分分布：\") df[\"rating\"].plot(kind=\"hist\", bins=20) plt.show() 抖音短视频平台具有反爬机制，因此编写抖音短视频爬虫脚本需要进行额外的设置和处理。以下是一个基本的示例，演示如何爬取某个特定用户的短视频，然后分析观看、点赞和收藏人数. 这个脚本模拟了一台手机客户端，使用requests库发送API请求获取目标用户的短视频数据，并将数据保存到CSV文件中。然后，使用pandas库将CSV文件读取为DataFrame，并进行数据分析和可视化。在这个脚本中，我们只爬取了目标用户的基本统计信息，例如播放量、点赞数 import requests import json import time import pandas as pd import matplotlib.pyplot as plt # 设置请求头，模拟手机客户端访问 headers = { \"User-Agent\": \"Mozilla/5.0 (Linux; Android 5.1.1; Google Nexus 6 - 5.1.0 - API 22 - 1440x2560 Build/LMY47D; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/80.0.3987.162 Mobile Safari/537.36/aweme/14.3.0\", \"Host\": \"aweme.snssdk.com\", \"Connection\": \"keep-alive\", \"Accept-Encoding\": \"gzip\", } # 设置API请求参数 user_id = \"123456\" # 修改为目标用户ID max_cursor = 0 api_url = f\"https://aweme.snssdk.com/aweme/v1/aweme/post/?user_id={user_id}\u0026max_cursor={max_cursor}\u0026count=21\" # 爬取数据 videos = [] while True: response = requests.get(api_url, headers=headers) data = json.loads(response.text) for item in data[\"aweme_list\"]: statistics = item[\"statistics\"] video = { \"desc\": item[\"desc\"], \"play_count\": statistics[\"play_count\"], \"digg_count\": statistics[\"digg_count\"], \"comment_count\": statistics[\"comment_count\"], \"download_count\": statistics[\"download_count\"], \"share_count\": statistics[\"share_count\"], \"collect_count\": statistics[\"collect_count\"], } videos.append(video) if not data[\"has_more\"]: break max_cursor = data[\"max_cursor\"] api_url = f\"https://aweme.snssdk.com/aweme/v1/aweme/post/?user_id={user_id}\u0026max_cursor={max_cursor}\u0026count=21\" time.sleep(1) # 添加间隔时间，避免被反爬检测 # 将数据保存到CSV文件 df = pd.DataFrame(videos) df.to_csv(\"videos.csv\", index=False) # 数据分析 print(\"抖音短视频数据分析：\") print(\"平均播放量：\", df[\"play_count\"].mean()) print(\"平均点赞数：\", df[\"digg_count\"].mean()) print(\"平均收藏数：\", df[\"collect_count\"].mean()) print(\"播放量分布：\") df[\"play_count\"].plot(kind=\"hist\", bins=20) plt.show() ",
    "description": "爬虫脚本限制 通用性爬虫脚本需要考虑很多方面，包括不同类型的网站、数据格式、反爬机制等等。以下是一个简单的示例爬虫脚本，用于爬取豆瓣电影Top250的数据，并使用pandas库进行数据分析和可视化 这个脚本使用requests库和BeautifulSoup库来爬取豆瓣电影Top250的数据，然后将数据保存到CSV文件中。接着，使用pandas库将CSV文件读取为DataFrame，并进行数据分析和可视化。这个脚本只是一个简单的示例，如果要编写更复杂的爬虫脚本，需要仔细研究目标网站的结构和反爬机制 import requests from bs4 import BeautifulSoup import pandas as pd import matplotlib.",
    "tags": [],
    "title": "Python Crawler",
    "uri": "/language/python/python-crawler/"
  },
  {
    "breadcrumb": "Languges \u003e Golang",
    "content": "Golang语言 Golang IDE ",
    "description": "Golang语言 Golang IDE ",
    "tags": [],
    "title": "Language Golang",
    "uri": "/language/golang/language-golang/"
  },
  {
    "breadcrumb": "Languges",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Golang",
    "uri": "/language/golang/"
  },
  {
    "breadcrumb": "Languges",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Python",
    "uri": "/language/python/"
  },
  {
    "breadcrumb": "Basics",
    "content": " 请注意：使用时，Hugo会覆盖此主题自带的默认原型模板hugo new site my-new-site要稍后真正看到您的页面，您必须删除draft=true或者替换为：draft=false来自页面的前言 # 最后编辑者的显示名称 LastModifierDisplayName: \"\" # 最后编辑者的电子邮件地址 LastModifierEmail: \"\" # 子菜单的初始展开状态 alwaysopen: \"\" # 是否显示可折叠菜单 collapsibleMenu: true # 自定义MathJax库的URL customMathJaxURL: \"\" # 自定义Mermaid库的URL customMermaidURL: \"\" # 自定义OpenAPI库的URL customOpenapiURL: \"\" # 页面的描述 description: \"\" # 是否隐藏面包屑导航 disableBreadcrumb: false # 是否禁用MathJax disableMathJax: true # 是否禁用Mermaid disableMermaid: true # 是否隐藏上一篇和下一篇按钮 disableNextPrev: false # 是否禁用OpenAPI disableOpenapi: true # 是否隐藏目录按钮 disableToc: false # 编辑页面的URL前缀 editURL: \"\" # 内容区域标题的后缀 headingPost: \"\" # 内容区域标题的前缀 headingPre: \"\" # 是否隐藏页面 hidden: false # 代码块是否自动换行 highlightWrap: true # 图片效果选项 imageEffects: border: true lazy: true lightbox: true shadow: false # 页面的社交媒体图片 images: - images/hero.png mathJaxInitialize: '{}' # 主菜单标题的后缀 menuPost: \"\" # 主菜单标题的前缀 menuPre: \"\" # MathJax的初始化选项 mermaidInitialize: '{ \"securityLevel\": \"loose\" }' # 是否允许缩放Mermaid图表 mermaidZoom: true # 主菜单子菜单的排序方式 ordersectionsby: weight # 页面的顺序，使用数据代表 weight: \"\" # 自定义标题作为菜单项 linkTitle: Lua ",
    "description": "请注意：使用时，Hugo会覆盖此主题自带的默认原型模板hugo new site my-new-site要稍后真正看到您的页面，您必须删除draft=true或者替换为：draft=false来自页面的前言 # 最后编辑者的显示名称 LastModifierDisplayName: \"\" # 最后编辑者的电子邮件地址 LastModifierEmail: \"\" # 子菜单的初始展开状态 alwaysopen: \"\" # 是否显示可折叠菜单 collapsibleMenu: true # 自定义MathJax库的URL customMathJaxURL: \"\" # 自定义Mermaid库的URL customMermaidURL: \"\" # 自定义OpenAPI库的URL customOpenapiURL: \"\" # 页面的描述 description: \"\" # 是否隐藏面包屑导航 disableBreadcrumb: false # 是否禁用MathJax disableMathJax: true # 是否禁用Mermaid disableMermaid: true # 是否隐藏上一篇和下一篇按钮 disableNextPrev: false # 是否禁用OpenAPI disableOpenapi: true # 是否隐藏目录按钮 disableToc: false # 编辑页面的URL前缀 editURL: \"\" # 内容区域标题的后缀 headingPost: \"\" # 内容区域标题的前缀 headingPre: \"\" # 是否隐藏页面 hidden: false # 代码块是否自动换行 highlightWrap: true # 图片效果选项 imageEffects: border: true lazy: true lightbox: true shadow: false # 页面的社交媒体图片 images: - images/hero.",
    "tags": [],
    "title": "template",
    "uri": "/basics/template/"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/"
  }
]
